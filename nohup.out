WARNING:tensorflow:From unet.py:152: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
2017-11-10 17:27:10.501604: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-10 17:27:10.736968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:86:00.0
totalMemory: 11.17GiB freeMemory: 10.80GiB
2017-11-10 17:27:10.737021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:86:00.0, compute capability: 3.7)
Setting up summary op...
Setting up image reader...
FLAGS.data_dir: /home/CAD409/unet/Unet-sensing-image-tensorflow-master/Data/
Found pickle file!
107653
161
Setting up dataset reader
Initializing Batch Dataset Reader...
{'resize': False, 'resize_size': 160}
Initializing Batch Dataset Reader...
{'resize': False, 'resize_size': 160}
Setting up Saver...
Step: 0, Train_acc:0.656832
Step: 0, Val_acc:0.620604
==================>
2017-11-10 17:27:22.859770 ---> Validation_loss: 0.680551
Step: 10, Train_acc:0.77167
Step: 10, Val_acc:0.7562
==================>
Step: 20, Train_acc:0.787014
Step: 20, Val_acc:0.799305
==================>
Step: 30, Train_acc:0.798005
Step: 30, Val_acc:0.800789
==================>
Step: 40, Train_acc:0.763706
Step: 40, Val_acc:0.783076
==================>
Step: 50, Train_acc:0.795614
Step: 50, Val_acc:0.757697
==================>
Step: 60, Train_acc:0.807178
Step: 60, Val_acc:0.770615
==================>
Step: 70, Train_acc:0.851912
Step: 70, Val_acc:0.764796
==================>
Step: 80, Train_acc:0.807903
Step: 80, Val_acc:0.805048
==================>
Step: 90, Train_acc:0.811374
Step: 90, Val_acc:0.765996
==================>
Step: 100, Train_acc:0.85756
Step: 100, Val_acc:0.775607
==================>
2017-11-10 17:30:02.117289 ---> Validation_loss: 0.567218
Step: 110, Train_acc:0.767329
Step: 110, Val_acc:0.826421
==================>
Step: 120, Train_acc:0.812894
Step: 120, Val_acc:0.800181
==================>
Step: 130, Train_acc:0.81584
Step: 130, Val_acc:0.773888
==================>
Step: 140, Train_acc:0.842904
Step: 140, Val_acc:0.832108
==================>
Step: 150, Train_acc:0.840076
Step: 150, Val_acc:0.82094
==================>
Step: 160, Train_acc:0.804441
Step: 160, Val_acc:0.826067
==================>
Step: 170, Train_acc:0.848868
Step: 170, Val_acc:0.830198
==================>
Step: 180, Train_acc:0.782461
Step: 180, Val_acc:0.796295
==================>
Step: 190, Train_acc:0.819169
Step: 190, Val_acc:0.812983
==================>
Step: 200, Train_acc:0.863489
Step: 200, Val_acc:0.813473
==================>
2017-11-10 17:32:40.913782 ---> Validation_loss: 0.501522
Step: 210, Train_acc:0.808586
Step: 210, Val_acc:0.815944
==================>
Step: 220, Train_acc:0.841848
Step: 220, Val_acc:0.819866
==================>
Step: 230, Train_acc:0.840818
Step: 230, Val_acc:0.82136
==================>
Step: 240, Train_acc:0.835873
Step: 240, Val_acc:0.760497
==================>
Step: 250, Train_acc:0.772511
Step: 250, Val_acc:0.74975
==================>
Step: 260, Train_acc:0.823901
Step: 260, Val_acc:0.810165
==================>
Step: 270, Train_acc:0.852482
Step: 270, Val_acc:0.825587
==================>
Step: 280, Train_acc:0.825443
Step: 280, Val_acc:0.822189
==================>
Step: 290, Train_acc:0.825142
Step: 290, Val_acc:0.819159
==================>
Step: 300, Train_acc:0.818357
Step: 300, Val_acc:0.86245
==================>
2017-11-10 17:35:17.445838 ---> Validation_loss: 0.430799
Step: 310, Train_acc:0.812554
Step: 310, Val_acc:0.846703
==================>
Step: 320, Train_acc:0.86816
Step: 320, Val_acc:0.813201
==================>
Step: 330, Train_acc:0.834677
Step: 330, Val_acc:0.835485
==================>
Step: 340, Train_acc:0.842847
Step: 340, Val_acc:0.792404
==================>
Step: 350, Train_acc:0.834142
Step: 350, Val_acc:0.807653
==================>
Step: 360, Train_acc:0.83304
Step: 360, Val_acc:0.782286
==================>
Step: 370, Train_acc:0.877897
Step: 370, Val_acc:0.798302
==================>
Step: 380, Train_acc:0.842817
Step: 380, Val_acc:0.851694
==================>
Step: 390, Train_acc:0.845258
Step: 390, Val_acc:0.772678
==================>
Step: 400, Train_acc:0.821689
Step: 400, Val_acc:0.882681
==================>
2017-11-10 17:37:54.126222 ---> Validation_loss: 0.444099
Step: 410, Train_acc:0.840947
Step: 410, Val_acc:0.823586
==================>
Step: 420, Train_acc:0.862424
Step: 420, Val_acc:0.825647
==================>
Step: 430, Train_acc:0.860753
Step: 430, Val_acc:0.759047
==================>
Step: 440, Train_acc:0.864209
Step: 440, Val_acc:0.828873
==================>
Step: 450, Train_acc:0.851715
Step: 450, Val_acc:0.889644
==================>
Step: 460, Train_acc:0.830726
Step: 460, Val_acc:0.819043
==================>
Step: 470, Train_acc:0.830551
Step: 470, Val_acc:0.849719
==================>
Step: 480, Train_acc:0.815206
Step: 480, Val_acc:0.85723
==================>
Step: 490, Train_acc:0.845365
Step: 490, Val_acc:0.842118
==================>
Step: 500, Train_acc:0.800216
Step: 500, Val_acc:0.793406
==================>
****************** Epochs completed: 1******************
2017-11-10 17:40:30.346303 ---> Validation_loss: 0.365408
Step: 510, Train_acc:0.85213
Step: 510, Val_acc:0.834109
==================>
Step: 520, Train_acc:0.88239
Step: 520, Val_acc:0.816892
==================>
Step: 530, Train_acc:0.845552
Step: 530, Val_acc:0.808512
==================>
Step: 540, Train_acc:0.864203
Step: 540, Val_acc:0.807668
==================>
Step: 550, Train_acc:0.872242
Step: 550, Val_acc:0.823511
==================>
Step: 560, Train_acc:0.84552
Step: 560, Val_acc:0.846515
==================>
Step: 570, Train_acc:0.854639
Step: 570, Val_acc:0.822788
==================>
Step: 580, Train_acc:0.833995
Step: 580, Val_acc:0.854927
==================>
Step: 590, Train_acc:0.838048
Step: 590, Val_acc:0.836219
==================>
Step: 600, Train_acc:0.841664
Step: 600, Val_acc:0.854255
==================>
2017-11-10 17:43:06.996591 ---> Validation_loss: 0.401171
Step: 610, Train_acc:0.858822
Step: 610, Val_acc:0.84657
==================>
Step: 620, Train_acc:0.864462
Step: 620, Val_acc:0.835533
==================>
Step: 630, Train_acc:0.833655
Step: 630, Val_acc:0.808483
==================>
Step: 640, Train_acc:0.838456
Step: 640, Val_acc:0.802203
==================>
Step: 650, Train_acc:0.822978
Step: 650, Val_acc:0.810309
==================>
Step: 660, Train_acc:0.869202
Step: 660, Val_acc:0.865397
==================>
Step: 670, Train_acc:0.774678
Step: 670, Val_acc:0.812625
==================>
Step: 680, Train_acc:0.864889
Step: 680, Val_acc:0.849174
==================>
Step: 690, Train_acc:0.831551
Step: 690, Val_acc:0.808285
==================>
Step: 700, Train_acc:0.83412
Step: 700, Val_acc:0.861217
==================>
2017-11-10 17:45:44.514471 ---> Validation_loss: 0.430761
Step: 710, Train_acc:0.845134
Step: 710, Val_acc:0.835464
==================>
Step: 720, Train_acc:0.840485
Step: 720, Val_acc:0.799663
==================>
Step: 730, Train_acc:0.852523
Step: 730, Val_acc:0.829222
==================>
Step: 740, Train_acc:0.852007
Step: 740, Val_acc:0.760553
==================>
Step: 750, Train_acc:0.862562
Step: 750, Val_acc:0.800435
==================>
Step: 760, Train_acc:0.852773
Step: 760, Val_acc:0.841772
==================>
Step: 770, Train_acc:0.87545
Step: 770, Val_acc:0.835803
==================>
Step: 780, Train_acc:0.83459
Step: 780, Val_acc:0.848229
==================>
Step: 790, Train_acc:0.825837
Step: 790, Val_acc:0.824136
==================>
Step: 800, Train_acc:0.797472
Step: 800, Val_acc:0.776135
==================>
2017-11-10 17:48:21.481900 ---> Validation_loss: 0.327784
Step: 810, Train_acc:0.87204
Step: 810, Val_acc:0.83718
==================>
Step: 820, Train_acc:0.838838
Step: 820, Val_acc:0.889631
==================>
Step: 830, Train_acc:0.869818
Step: 830, Val_acc:0.864344
==================>
Step: 840, Train_acc:0.880148
Step: 840, Val_acc:0.833112
==================>
Step: 850, Train_acc:0.833372
Step: 850, Val_acc:0.802474
==================>
Step: 860, Train_acc:0.84321
Step: 860, Val_acc:0.849803
==================>
Step: 870, Train_acc:0.873621
Step: 870, Val_acc:0.825645
==================>
Step: 880, Train_acc:0.862109
Step: 880, Val_acc:0.846904
==================>
Step: 890, Train_acc:0.83228
Step: 890, Val_acc:0.850275
==================>
Step: 900, Train_acc:0.838864
Step: 900, Val_acc:0.826699
==================>
2017-11-10 17:50:57.946802 ---> Validation_loss: 0.46193
Step: 910, Train_acc:0.828356
Step: 910, Val_acc:0.822583
==================>
Step: 920, Train_acc:0.855173
Step: 920, Val_acc:0.845479
==================>
Step: 930, Train_acc:0.853274
Step: 930, Val_acc:0.849309
==================>
Step: 940, Train_acc:0.827449
Step: 940, Val_acc:0.842273
==================>
Step: 950, Train_acc:0.843212
Step: 950, Val_acc:0.799923
==================>
Step: 960, Train_acc:0.814292
Step: 960, Val_acc:0.817518
==================>
Step: 970, Train_acc:0.850802
Step: 970, Val_acc:0.824113
==================>
Step: 980, Train_acc:0.833121
Step: 980, Val_acc:0.835198
==================>
Step: 990, Train_acc:0.836364
Step: 990, Val_acc:0.888387
==================>
Step: 1000, Train_acc:0.842501
Step: 1000, Val_acc:0.813628
==================>
****************** Epochs completed: 2******************
2017-11-10 17:53:34.098343 ---> Validation_loss: 0.391118
Step: 1010, Train_acc:0.823423
Step: 1010, Val_acc:0.889933
==================>
Step: 1020, Train_acc:0.819835
Step: 1020, Val_acc:0.839364
==================>
Step: 1030, Train_acc:0.880122
Step: 1030, Val_acc:0.850448
==================>
Step: 1040, Train_acc:0.762758
Step: 1040, Val_acc:0.851788
==================>
Step: 1050, Train_acc:0.82892
Step: 1050, Val_acc:0.872708
==================>
Step: 1060, Train_acc:0.862461
Step: 1060, Val_acc:0.852427
==================>
Step: 1070, Train_acc:0.868036
Step: 1070, Val_acc:0.794785
==================>
Step: 1080, Train_acc:0.86557
Step: 1080, Val_acc:0.804705
==================>
Step: 1090, Train_acc:0.88072
Step: 1090, Val_acc:0.798671
==================>
Step: 1100, Train_acc:0.879652
Step: 1100, Val_acc:0.848947
==================>
2017-11-10 17:56:10.733078 ---> Validation_loss: 0.310394
Step: 1110, Train_acc:0.865745
Step: 1110, Val_acc:0.843867
==================>
Step: 1120, Train_acc:0.846439
Step: 1120, Val_acc:0.791581
==================>
Step: 1130, Train_acc:0.85551
Step: 1130, Val_acc:0.887753
==================>
Step: 1140, Train_acc:0.810576
Step: 1140, Val_acc:0.842426
==================>
Step: 1150, Train_acc:0.857339
Step: 1150, Val_acc:0.85623
==================>
Step: 1160, Train_acc:0.890857
Step: 1160, Val_acc:0.847832
==================>
Step: 1170, Train_acc:0.86585
Step: 1170, Val_acc:0.784194
==================>
Step: 1180, Train_acc:0.777604
Step: 1180, Val_acc:0.797826
==================>
Step: 1190, Train_acc:0.892275
Step: 1190, Val_acc:0.855175
==================>
Step: 1200, Train_acc:0.847142
Step: 1200, Val_acc:0.865629
==================>
2017-11-10 17:58:47.403376 ---> Validation_loss: 0.277686
Step: 1210, Train_acc:0.844824
Step: 1210, Val_acc:0.843186
==================>
Step: 1220, Train_acc:0.866876
Step: 1220, Val_acc:0.833192
==================>
Step: 1230, Train_acc:0.853859
Step: 1230, Val_acc:0.885431
==================>
Step: 1240, Train_acc:0.871997
Step: 1240, Val_acc:0.795293
==================>
Step: 1250, Train_acc:0.847528
Step: 1250, Val_acc:0.826681
==================>
Step: 1260, Train_acc:0.874529
Step: 1260, Val_acc:0.889402
==================>
Step: 1270, Train_acc:0.794871
Step: 1270, Val_acc:0.875491
==================>
Step: 1280, Train_acc:0.904022
Step: 1280, Val_acc:0.855313
==================>
Step: 1290, Train_acc:0.838171
Step: 1290, Val_acc:0.827581
==================>
Step: 1300, Train_acc:0.873809
Step: 1300, Val_acc:0.839713
==================>
2017-11-10 18:01:24.656241 ---> Validation_loss: 0.386475
Step: 1310, Train_acc:0.835709
Step: 1310, Val_acc:0.853375
==================>
Step: 1320, Train_acc:0.834941
Step: 1320, Val_acc:0.841251
==================>
Step: 1330, Train_acc:0.819655
Step: 1330, Val_acc:0.85954
==================>
Step: 1340, Train_acc:0.85437
Step: 1340, Val_acc:0.837799
==================>
Step: 1350, Train_acc:0.864244
Step: 1350, Val_acc:0.858076
==================>
Step: 1360, Train_acc:0.818087
Step: 1360, Val_acc:0.845154
==================>
Step: 1370, Train_acc:0.81359
Step: 1370, Val_acc:0.846213
==================>
Step: 1380, Train_acc:0.819625
Step: 1380, Val_acc:0.829043
==================>
Step: 1390, Train_acc:0.873978
Step: 1390, Val_acc:0.824225
==================>
Step: 1400, Train_acc:0.850059
Step: 1400, Val_acc:0.857244
==================>
2017-11-10 18:04:00.607131 ---> Validation_loss: 0.354819
Step: 1410, Train_acc:0.900308
Step: 1410, Val_acc:0.855625
==================>
Step: 1420, Train_acc:0.851664
Step: 1420, Val_acc:0.793954
==================>
Step: 1430, Train_acc:0.830809
Step: 1430, Val_acc:0.841776
==================>
Step: 1440, Train_acc:0.866243
Step: 1440, Val_acc:0.879592
==================>
Step: 1450, Train_acc:0.82713
Step: 1450, Val_acc:0.83786
==================>
Step: 1460, Train_acc:0.846303
Step: 1460, Val_acc:0.774946
==================>
Step: 1470, Train_acc:0.829865
Step: 1470, Val_acc:0.863638
==================>
Step: 1480, Train_acc:0.869121
Step: 1480, Val_acc:0.862872
==================>
Step: 1490, Train_acc:0.886475
Step: 1490, Val_acc:0.80156
==================>
Step: 1500, Train_acc:0.804838
Step: 1500, Val_acc:0.844841
==================>
****************** Epochs completed: 3******************
2017-11-10 18:06:37.041944 ---> Validation_loss: 0.306696
Step: 1510, Train_acc:0.846063
Step: 1510, Val_acc:0.846785
==================>
Step: 1520, Train_acc:0.813358
Step: 1520, Val_acc:0.858783
==================>
Step: 1530, Train_acc:0.82718
Step: 1530, Val_acc:0.837954
==================>
Step: 1540, Train_acc:0.774864
Step: 1540, Val_acc:0.858655
==================>
Step: 1550, Train_acc:0.863577
Step: 1550, Val_acc:0.810297
==================>
Step: 1560, Train_acc:0.82283
Step: 1560, Val_acc:0.802607
==================>
Step: 1570, Train_acc:0.857488
Step: 1570, Val_acc:0.897776
==================>
Step: 1580, Train_acc:0.850337
Step: 1580, Val_acc:0.848104
==================>
Step: 1590, Train_acc:0.807859
Step: 1590, Val_acc:0.85369
==================>
Step: 1600, Train_acc:0.850475
Step: 1600, Val_acc:0.869287
==================>
2017-11-10 18:09:13.178187 ---> Validation_loss: 0.356914
Step: 1610, Train_acc:0.842646
Step: 1610, Val_acc:0.858964
==================>
Step: 1620, Train_acc:0.905038
Step: 1620, Val_acc:0.890332
==================>
Step: 1630, Train_acc:0.87416
Step: 1630, Val_acc:0.862689
==================>
Step: 1640, Train_acc:0.85083
Step: 1640, Val_acc:0.850569
==================>
Step: 1650, Train_acc:0.856014
Step: 1650, Val_acc:0.761893
==================>
Step: 1660, Train_acc:0.852434
Step: 1660, Val_acc:0.834058
==================>
Step: 1670, Train_acc:0.857173
Step: 1670, Val_acc:0.832272
==================>
Step: 1680, Train_acc:0.859551
Step: 1680, Val_acc:0.865264
==================>
Step: 1690, Train_acc:0.901516
Step: 1690, Val_acc:0.858435
==================>
Step: 1700, Train_acc:0.857159
Step: 1700, Val_acc:0.852731
==================>
2017-11-10 18:11:49.347754 ---> Validation_loss: 0.346558
Step: 1710, Train_acc:0.88032
Step: 1710, Val_acc:0.843667
==================>
Step: 1720, Train_acc:0.88249
Step: 1720, Val_acc:0.850457
==================>
Step: 1730, Train_acc:0.856726
Step: 1730, Val_acc:0.826356
==================>
Step: 1740, Train_acc:0.860989
Step: 1740, Val_acc:0.866504
==================>
Step: 1750, Train_acc:0.849668
Step: 1750, Val_acc:0.825341
==================>
Step: 1760, Train_acc:0.839076
Step: 1760, Val_acc:0.848657
==================>
Step: 1770, Train_acc:0.820312
Step: 1770, Val_acc:0.810486
==================>
Step: 1780, Train_acc:0.834711
Step: 1780, Val_acc:0.820584
==================>
Step: 1790, Train_acc:0.881339
Step: 1790, Val_acc:0.837347
==================>
Step: 1800, Train_acc:0.888219
Step: 1800, Val_acc:0.864177
==================>
2017-11-10 18:14:25.313362 ---> Validation_loss: 0.296891
Step: 1810, Train_acc:0.895
Step: 1810, Val_acc:0.792458
==================>
Step: 1820, Train_acc:0.894142
Step: 1820, Val_acc:0.855023
==================>
Step: 1830, Train_acc:0.891371
Step: 1830, Val_acc:0.875712
==================>
Step: 1840, Train_acc:0.880988
Step: 1840, Val_acc:0.85749
==================>
Step: 1850, Train_acc:0.873212
Step: 1850, Val_acc:0.862637
==================>
Step: 1860, Train_acc:0.879066
Step: 1860, Val_acc:0.873761
==================>
Step: 1870, Train_acc:0.853662
Step: 1870, Val_acc:0.835707
==================>
Step: 1880, Train_acc:0.84391
Step: 1880, Val_acc:0.833887
==================>
Step: 1890, Train_acc:0.873303
Step: 1890, Val_acc:0.84371
==================>
Step: 1900, Train_acc:0.833628
Step: 1900, Val_acc:0.852861
==================>
2017-11-10 18:17:02.134302 ---> Validation_loss: 0.347101
Step: 1910, Train_acc:0.801398
Step: 1910, Val_acc:0.844143
==================>
Step: 1920, Train_acc:0.849008
Step: 1920, Val_acc:0.804596
==================>
Step: 1930, Train_acc:0.865576
Step: 1930, Val_acc:0.838108
==================>
Step: 1940, Train_acc:0.869662
Step: 1940, Val_acc:0.803022
==================>
Step: 1950, Train_acc:0.868325
Step: 1950, Val_acc:0.870291
==================>
Step: 1960, Train_acc:0.866549
Step: 1960, Val_acc:0.834117
==================>
Step: 1970, Train_acc:0.820344
Step: 1970, Val_acc:0.84304
==================>
Step: 1980, Train_acc:0.892603
Step: 1980, Val_acc:0.86756
==================>
Step: 1990, Train_acc:0.846089
Step: 1990, Val_acc:0.868202
==================>
Step: 2000, Train_acc:0.768059
Step: 2000, Val_acc:0.890066
==================>
****************** Epochs completed: 4******************
2017-11-10 18:19:38.638540 ---> Validation_loss: 0.327807
Step: 2010, Train_acc:0.868491
Step: 2010, Val_acc:0.836998
==================>
Step: 2020, Train_acc:0.870554
Step: 2020, Val_acc:0.868191
==================>
Step: 2030, Train_acc:0.870419
Step: 2030, Val_acc:0.848945
==================>
Step: 2040, Train_acc:0.871433
Step: 2040, Val_acc:0.856691
==================>
Step: 2050, Train_acc:0.870831
Step: 2050, Val_acc:0.832339
==================>
Step: 2060, Train_acc:0.844646
Step: 2060, Val_acc:0.836669
==================>
Step: 2070, Train_acc:0.833571
Step: 2070, Val_acc:0.871119
==================>
Step: 2080, Train_acc:0.841177
Step: 2080, Val_acc:0.843589
==================>
Step: 2090, Train_acc:0.824175
Step: 2090, Val_acc:0.812312
==================>
Step: 2100, Train_acc:0.887363
Step: 2100, Val_acc:0.831912
==================>
2017-11-10 18:22:14.317170 ---> Validation_loss: 0.394912
Step: 2110, Train_acc:0.863016
Step: 2110, Val_acc:0.856381
==================>
Step: 2120, Train_acc:0.838406
Step: 2120, Val_acc:0.759395
==================>
Step: 2130, Train_acc:0.850287
Step: 2130, Val_acc:0.790356
==================>
Step: 2140, Train_acc:0.805198
Step: 2140, Val_acc:0.840664
==================>
Step: 2150, Train_acc:0.856488
Step: 2150, Val_acc:0.87094
==================>
Step: 2160, Train_acc:0.824061
Step: 2160, Val_acc:0.865001
==================>
Step: 2170, Train_acc:0.88329
Step: 2170, Val_acc:0.835032
==================>
Step: 2180, Train_acc:0.821866
Step: 2180, Val_acc:0.852849
==================>
Step: 2190, Train_acc:0.843615
Step: 2190, Val_acc:0.810555
==================>
Step: 2200, Train_acc:0.861108
Step: 2200, Val_acc:0.839399
==================>
2017-11-10 18:24:50.759386 ---> Validation_loss: 0.290142
Step: 2210, Train_acc:0.863629
Step: 2210, Val_acc:0.781022
==================>
Step: 2220, Train_acc:0.851685
Step: 2220, Val_acc:0.843345
==================>
Step: 2230, Train_acc:0.869724
Step: 2230, Val_acc:0.816366
==================>
Step: 2240, Train_acc:0.81106
Step: 2240, Val_acc:0.823281
==================>
Step: 2250, Train_acc:0.87036
Step: 2250, Val_acc:0.856445
==================>
Step: 2260, Train_acc:0.857374
Step: 2260, Val_acc:0.855945
==================>
Step: 2270, Train_acc:0.830054
Step: 2270, Val_acc:0.895638
==================>
Step: 2280, Train_acc:0.868818
Step: 2280, Val_acc:0.859005
==================>
Step: 2290, Train_acc:0.847529
Step: 2290, Val_acc:0.838247
==================>
Step: 2300, Train_acc:0.826661
Step: 2300, Val_acc:0.865118
==================>
2017-11-10 18:27:26.660010 ---> Validation_loss: 0.343637
Step: 2310, Train_acc:0.816105
Step: 2310, Val_acc:0.88702
==================>
Step: 2320, Train_acc:0.854032
Step: 2320, Val_acc:0.862174
==================>
Step: 2330, Train_acc:0.868793
Step: 2330, Val_acc:0.849182
==================>
Step: 2340, Train_acc:0.817496
Step: 2340, Val_acc:0.832294
==================>
Step: 2350, Train_acc:0.864703
Step: 2350, Val_acc:0.883488
==================>
Step: 2360, Train_acc:0.903618
Step: 2360, Val_acc:0.844469
==================>
Step: 2370, Train_acc:0.84953
Step: 2370, Val_acc:0.856243
==================>
Step: 2380, Train_acc:0.837423
Step: 2380, Val_acc:0.84454
==================>
Step: 2390, Train_acc:0.862526
Step: 2390, Val_acc:0.816185
==================>
Step: 2400, Train_acc:0.889019
Step: 2400, Val_acc:0.861442
==================>
2017-11-10 18:30:03.069110 ---> Validation_loss: 0.359531
Step: 2410, Train_acc:0.878102
Step: 2410, Val_acc:0.861136
==================>
Step: 2420, Train_acc:0.850674
Step: 2420, Val_acc:0.836556
==================>
Step: 2430, Train_acc:0.85694
Step: 2430, Val_acc:0.783175
==================>
Step: 2440, Train_acc:0.867473
Step: 2440, Val_acc:0.862656
==================>
Step: 2450, Train_acc:0.844448
Step: 2450, Val_acc:0.819293
==================>
Step: 2460, Train_acc:0.799276
Step: 2460, Val_acc:0.860836
==================>
Step: 2470, Train_acc:0.83024
Step: 2470, Val_acc:0.836871
==================>
Step: 2480, Train_acc:0.851622
Step: 2480, Val_acc:0.834266
==================>
Step: 2490, Train_acc:0.852544
Step: 2490, Val_acc:0.822848
==================>
Step: 2500, Train_acc:0.871873
Step: 2500, Val_acc:0.825214
==================>
****************** Epochs completed: 5******************
2017-11-10 18:32:39.198981 ---> Validation_loss: 0.31849
Step: 2510, Train_acc:0.788491
Step: 2510, Val_acc:0.866498
==================>
Step: 2520, Train_acc:0.829425
Step: 2520, Val_acc:0.843364
==================>
Step: 2530, Train_acc:0.873314
Step: 2530, Val_acc:0.829529
==================>
Step: 2540, Train_acc:0.8308
Step: 2540, Val_acc:0.807784
==================>
Step: 2550, Train_acc:0.869626
Step: 2550, Val_acc:0.841134
==================>
Step: 2560, Train_acc:0.867721
Step: 2560, Val_acc:0.80662
==================>
Step: 2570, Train_acc:0.870137
Step: 2570, Val_acc:0.875198
==================>
Step: 2580, Train_acc:0.857612
Step: 2580, Val_acc:0.869072
==================>
Step: 2590, Train_acc:0.884344
Step: 2590, Val_acc:0.803403
==================>
Step: 2600, Train_acc:0.877183
Step: 2600, Val_acc:0.812875
==================>
2017-11-10 18:35:15.288404 ---> Validation_loss: 0.281264
Step: 2610, Train_acc:0.845908
Step: 2610, Val_acc:0.847211
==================>
Step: 2620, Train_acc:0.876567
Step: 2620, Val_acc:0.866454
==================>
Step: 2630, Train_acc:0.882036
Step: 2630, Val_acc:0.836207
==================>
Step: 2640, Train_acc:0.855491
Step: 2640, Val_acc:0.826013
==================>
Step: 2650, Train_acc:0.858677
Step: 2650, Val_acc:0.857876
==================>
Step: 2660, Train_acc:0.889006
Step: 2660, Val_acc:0.852607
==================>
Step: 2670, Train_acc:0.865536
Step: 2670, Val_acc:0.838925
==================>
Step: 2680, Train_acc:0.829932
Step: 2680, Val_acc:0.84433
==================>
Step: 2690, Train_acc:0.89568
Step: 2690, Val_acc:0.784794
==================>
Step: 2700, Train_acc:0.87425
Step: 2700, Val_acc:0.846035
==================>
2017-11-10 18:37:51.697423 ---> Validation_loss: 0.329265
Step: 2710, Train_acc:0.796222
Step: 2710, Val_acc:0.870615
==================>
Step: 2720, Train_acc:0.83095
Step: 2720, Val_acc:0.819091
==================>
Step: 2730, Train_acc:0.850729
Step: 2730, Val_acc:0.866819
==================>
Step: 2740, Train_acc:0.856
Step: 2740, Val_acc:0.858583
==================>
Step: 2750, Train_acc:0.908734
Step: 2750, Val_acc:0.835006
==================>
Step: 2760, Train_acc:0.847545
Step: 2760, Val_acc:0.832804
==================>
Step: 2770, Train_acc:0.87069
Step: 2770, Val_acc:0.827928
==================>
Step: 2780, Train_acc:0.872739
Step: 2780, Val_acc:0.821674
==================>
Step: 2790, Train_acc:0.869883
Step: 2790, Val_acc:0.862996
==================>
Step: 2800, Train_acc:0.858827
Step: 2800, Val_acc:0.831498
==================>
2017-11-10 18:40:27.566682 ---> Validation_loss: 0.311255
Step: 2810, Train_acc:0.861805
Step: 2810, Val_acc:0.793759
==================>
Step: 2820, Train_acc:0.873408
Step: 2820, Val_acc:0.790217
==================>
Step: 2830, Train_acc:0.872913
Step: 2830, Val_acc:0.851743
==================>
Step: 2840, Train_acc:0.855479
Step: 2840, Val_acc:0.869701
==================>
Step: 2850, Train_acc:0.860634
Step: 2850, Val_acc:0.830688
==================>
Step: 2860, Train_acc:0.844199
Step: 2860, Val_acc:0.788748
==================>
Step: 2870, Train_acc:0.903608
Step: 2870, Val_acc:0.851615
==================>
Step: 2880, Train_acc:0.851021
Step: 2880, Val_acc:0.795944
==================>
Step: 2890, Train_acc:0.885125
Step: 2890, Val_acc:0.845193
==================>
Step: 2900, Train_acc:0.893168
Step: 2900, Val_acc:0.790272
==================>
2017-11-10 18:43:03.943058 ---> Validation_loss: 0.361453
Step: 2910, Train_acc:0.854698
Step: 2910, Val_acc:0.859849
==================>
Step: 2920, Train_acc:0.892942
Step: 2920, Val_acc:0.850522
==================>
Step: 2930, Train_acc:0.858812
Step: 2930, Val_acc:0.838287
==================>
Step: 2940, Train_acc:0.840505
Step: 2940, Val_acc:0.85665
==================>
Step: 2950, Train_acc:0.838844
Step: 2950, Val_acc:0.777809
==================>
Step: 2960, Train_acc:0.841973
Step: 2960, Val_acc:0.854238
==================>
Step: 2970, Train_acc:0.858562
Step: 2970, Val_acc:0.827766
==================>
Step: 2980, Train_acc:0.84822
Step: 2980, Val_acc:0.838124
==================>
Step: 2990, Train_acc:0.86827
Step: 2990, Val_acc:0.84681
==================>
Step: 3000, Train_acc:0.877969
Step: 3000, Val_acc:0.840798
==================>
****************** Epochs completed: 6******************
2017-11-10 18:45:39.825331 ---> Validation_loss: 0.292645
Step: 3010, Train_acc:0.873085
Step: 3010, Val_acc:0.886124
==================>
Step: 3020, Train_acc:0.864036
Step: 3020, Val_acc:0.863661
==================>
Step: 3030, Train_acc:0.887512
Step: 3030, Val_acc:0.848456
==================>
Step: 3040, Train_acc:0.862366
Step: 3040, Val_acc:0.785636
==================>
Step: 3050, Train_acc:0.854484
Step: 3050, Val_acc:0.852999
==================>
Step: 3060, Train_acc:0.860098
Step: 3060, Val_acc:0.847103
==================>
Step: 3070, Train_acc:0.837476
Step: 3070, Val_acc:0.855365
==================>
Step: 3080, Train_acc:0.835874
Step: 3080, Val_acc:0.874955
==================>
Step: 3090, Train_acc:0.889324
Step: 3090, Val_acc:0.798355
==================>
Step: 3100, Train_acc:0.874147
Step: 3100, Val_acc:0.823351
==================>
2017-11-10 18:48:16.560904 ---> Validation_loss: 0.317375
Step: 3110, Train_acc:0.88743
Step: 3110, Val_acc:0.853645
==================>
Step: 3120, Train_acc:0.858864
Step: 3120, Val_acc:0.820251
==================>
Step: 3130, Train_acc:0.854491
Step: 3130, Val_acc:0.800446
==================>
Step: 3140, Train_acc:0.885505
Step: 3140, Val_acc:0.836469
==================>
Step: 3150, Train_acc:0.837721
Step: 3150, Val_acc:0.872852
==================>
Step: 3160, Train_acc:0.861543
Step: 3160, Val_acc:0.831769
==================>
Step: 3170, Train_acc:0.874593
Step: 3170, Val_acc:0.862151
==================>
Step: 3180, Train_acc:0.824083
Step: 3180, Val_acc:0.819309
==================>
Step: 3190, Train_acc:0.841372
Step: 3190, Val_acc:0.799056
==================>
Step: 3200, Train_acc:0.881957
Step: 3200, Val_acc:0.885586
==================>
2017-11-10 18:50:52.445155 ---> Validation_loss: 0.335867
Step: 3210, Train_acc:0.877305
Step: 3210, Val_acc:0.855038
==================>
Step: 3220, Train_acc:0.82896
Step: 3220, Val_acc:0.837322
==================>
Step: 3230, Train_acc:0.840856
Step: 3230, Val_acc:0.866324
==================>
Step: 3240, Train_acc:0.851001
Step: 3240, Val_acc:0.873641
==================>
Step: 3250, Train_acc:0.821979
Step: 3250, Val_acc:0.901982
==================>
Step: 3260, Train_acc:0.879218
Step: 3260, Val_acc:0.847208
==================>
Step: 3270, Train_acc:0.872101
Step: 3270, Val_acc:0.830736
==================>
Step: 3280, Train_acc:0.894254
Step: 3280, Val_acc:0.878683
==================>
Step: 3290, Train_acc:0.846285
Step: 3290, Val_acc:0.855251
==================>
Step: 3300, Train_acc:0.869142
Step: 3300, Val_acc:0.865415
==================>
2017-11-10 18:53:28.136094 ---> Validation_loss: 0.275447
Step: 3310, Train_acc:0.866869
Step: 3310, Val_acc:0.84554
==================>
Step: 3320, Train_acc:0.805609
Step: 3320, Val_acc:0.847272
==================>
Step: 3330, Train_acc:0.857775
Step: 3330, Val_acc:0.876609
==================>
Step: 3340, Train_acc:0.816471
Step: 3340, Val_acc:0.846703
==================>
Step: 3350, Train_acc:0.875714
Step: 3350, Val_acc:0.869304
==================>
Step: 3360, Train_acc:0.865112
Step: 3360, Val_acc:0.867324
==================>
****************** Epochs completed: 1******************
Step: 3370, Train_acc:0.852611
Step: 3370, Val_acc:0.776881
==================>
Step: 3380, Train_acc:0.807593
Step: 3380, Val_acc:0.805892
==================>
Step: 3390, Train_acc:0.87735
Step: 3390, Val_acc:0.880847
==================>
Step: 3400, Train_acc:0.862537
Step: 3400, Val_acc:0.86755
==================>
2017-11-10 18:56:04.599448 ---> Validation_loss: 0.363878
Step: 3410, Train_acc:0.886796
Step: 3410, Val_acc:0.838898
==================>
Step: 3420, Train_acc:0.821165
Step: 3420, Val_acc:0.864091
==================>
Step: 3430, Train_acc:0.895647
Step: 3430, Val_acc:0.853711
==================>
Step: 3440, Train_acc:0.883213
Step: 3440, Val_acc:0.878224
==================>
Step: 3450, Train_acc:0.870458
Step: 3450, Val_acc:0.848441
==================>
Step: 3460, Train_acc:0.897443
Step: 3460, Val_acc:0.848041
==================>
Step: 3470, Train_acc:0.810873
Step: 3470, Val_acc:0.863052
==================>
Step: 3480, Train_acc:0.868274
Step: 3480, Val_acc:0.807059
==================>
Step: 3490, Train_acc:0.876069
Step: 3490, Val_acc:0.807787
==================>
Step: 3500, Train_acc:0.889723
Step: 3500, Val_acc:0.868918
==================>
****************** Epochs completed: 7******************
2017-11-10 18:58:40.633374 ---> Validation_loss: 0.218054
Step: 3510, Train_acc:0.845692
Step: 3510, Val_acc:0.866169
==================>
Step: 3520, Train_acc:0.886033
Step: 3520, Val_acc:0.864489
==================>
Step: 3530, Train_acc:0.890038
Step: 3530, Val_acc:0.875673
==================>
Step: 3540, Train_acc:0.913343
Step: 3540, Val_acc:0.88233
==================>
Step: 3550, Train_acc:0.84764
Step: 3550, Val_acc:0.849713
==================>
Step: 3560, Train_acc:0.881022
Step: 3560, Val_acc:0.888705
==================>
Step: 3570, Train_acc:0.832483
Step: 3570, Val_acc:0.834308
==================>
Step: 3580, Train_acc:0.899258
Step: 3580, Val_acc:0.839037
==================>
Step: 3590, Train_acc:0.881766
Step: 3590, Val_acc:0.880695
==================>
Step: 3600, Train_acc:0.862009
Step: 3600, Val_acc:0.851812
==================>
2017-11-10 19:01:16.303285 ---> Validation_loss: 0.361781
Step: 3610, Train_acc:0.891891
Step: 3610, Val_acc:0.829205
==================>
Step: 3620, Train_acc:0.883004
Step: 3620, Val_acc:0.859044
==================>
Step: 3630, Train_acc:0.8848
Step: 3630, Val_acc:0.870531
==================>
Step: 3640, Train_acc:0.81102
Step: 3640, Val_acc:0.848242
==================>
Step: 3650, Train_acc:0.862816
Step: 3650, Val_acc:0.823424
==================>
Step: 3660, Train_acc:0.852437
Step: 3660, Val_acc:0.852744
==================>
Step: 3670, Train_acc:0.862561
Step: 3670, Val_acc:0.816052
==================>
Step: 3680, Train_acc:0.875702
Step: 3680, Val_acc:0.845867
==================>
Step: 3690, Train_acc:0.825132
Step: 3690, Val_acc:0.85323
==================>
Step: 3700, Train_acc:0.875709
Step: 3700, Val_acc:0.860582
==================>
2017-11-10 19:03:52.854797 ---> Validation_loss: 0.348055
Step: 3710, Train_acc:0.877815
Step: 3710, Val_acc:0.814811
==================>
Step: 3720, Train_acc:0.860891
Step: 3720, Val_acc:0.86978
==================>
Step: 3730, Train_acc:0.872151
Step: 3730, Val_acc:0.838541
==================>
Step: 3740, Train_acc:0.881439
Step: 3740, Val_acc:0.81243
==================>
Step: 3750, Train_acc:0.869504
Step: 3750, Val_acc:0.881787
==================>
Step: 3760, Train_acc:0.880133
Step: 3760, Val_acc:0.84891
==================>
Step: 3770, Train_acc:0.863193
Step: 3770, Val_acc:0.89028
==================>
Step: 3780, Train_acc:0.845703
Step: 3780, Val_acc:0.861599
==================>
Step: 3790, Train_acc:0.817192
Step: 3790, Val_acc:0.870754
==================>
Step: 3800, Train_acc:0.876791
Step: 3800, Val_acc:0.836271
==================>
2017-11-10 19:06:29.099105 ---> Validation_loss: 0.279783
Step: 3810, Train_acc:0.849512
Step: 3810, Val_acc:0.872859
==================>
Step: 3820, Train_acc:0.915136
Step: 3820, Val_acc:0.805771
==================>
Step: 3830, Train_acc:0.808562
Step: 3830, Val_acc:0.806735
==================>
Step: 3840, Train_acc:0.84806
Step: 3840, Val_acc:0.882319
==================>
Step: 3850, Train_acc:0.846383
Step: 3850, Val_acc:0.836732
==================>
Step: 3860, Train_acc:0.86584
Step: 3860, Val_acc:0.827172
==================>
Step: 3870, Train_acc:0.855808
Step: 3870, Val_acc:0.803323
==================>
Step: 3880, Train_acc:0.886627
Step: 3880, Val_acc:0.85525
==================>
Step: 3890, Train_acc:0.878173
Step: 3890, Val_acc:0.844416
==================>
Step: 3900, Train_acc:0.838444
Step: 3900, Val_acc:0.826541
==================>
2017-11-10 19:09:05.297712 ---> Validation_loss: 0.3968
Step: 3910, Train_acc:0.833048
Step: 3910, Val_acc:0.842852
==================>
Step: 3920, Train_acc:0.878295
Step: 3920, Val_acc:0.834828
==================>
Step: 3930, Train_acc:0.891222
Step: 3930, Val_acc:0.859319
==================>
Step: 3940, Train_acc:0.875653
Step: 3940, Val_acc:0.847948
==================>
Step: 3950, Train_acc:0.890518
Step: 3950, Val_acc:0.881641
==================>
Step: 3960, Train_acc:0.83134
Step: 3960, Val_acc:0.886122
==================>
Step: 3970, Train_acc:0.885878
Step: 3970, Val_acc:0.841625
==================>
Step: 3980, Train_acc:0.845123
Step: 3980, Val_acc:0.861694
==================>
Step: 3990, Train_acc:0.879498
Step: 3990, Val_acc:0.882494
==================>
Step: 4000, Train_acc:0.902355
Step: 4000, Val_acc:0.830348
==================>
****************** Epochs completed: 8******************
2017-11-10 19:11:41.633610 ---> Validation_loss: 0.335478
Step: 4010, Train_acc:0.877682
Step: 4010, Val_acc:0.840945
==================>
Step: 4020, Train_acc:0.912775
Step: 4020, Val_acc:0.865482
==================>
Step: 4030, Train_acc:0.881208
Step: 4030, Val_acc:0.821333
==================>
Step: 4040, Train_acc:0.863627
Step: 4040, Val_acc:0.847416
==================>
Step: 4050, Train_acc:0.872385
Step: 4050, Val_acc:0.868413
==================>
Step: 4060, Train_acc:0.895892
Step: 4060, Val_acc:0.85293
==================>
Step: 4070, Train_acc:0.884683
Step: 4070, Val_acc:0.865449
==================>
Step: 4080, Train_acc:0.868525
Step: 4080, Val_acc:0.819078
==================>
Step: 4090, Train_acc:0.881339
Step: 4090, Val_acc:0.840262
==================>
Step: 4100, Train_acc:0.870501
Step: 4100, Val_acc:0.828931
==================>
2017-11-10 19:14:17.732082 ---> Validation_loss: 0.283244
Step: 4110, Train_acc:0.864609
Step: 4110, Val_acc:0.83172
==================>
Step: 4120, Train_acc:0.882332
Step: 4120, Val_acc:0.831735
==================>
Step: 4130, Train_acc:0.838837
Step: 4130, Val_acc:0.852771
==================>
Step: 4140, Train_acc:0.825304
Step: 4140, Val_acc:0.884722
==================>
Step: 4150, Train_acc:0.856414
Step: 4150, Val_acc:0.789983
==================>
Step: 4160, Train_acc:0.866356
Step: 4160, Val_acc:0.815525
==================>
Step: 4170, Train_acc:0.837244
Step: 4170, Val_acc:0.843931
==================>
Step: 4180, Train_acc:0.867539
Step: 4180, Val_acc:0.858387
==================>
Step: 4190, Train_acc:0.844896
Step: 4190, Val_acc:0.870372
==================>
Step: 4200, Train_acc:0.890042
Step: 4200, Val_acc:0.861803
==================>
2017-11-10 19:16:53.977344 ---> Validation_loss: 0.319706
Step: 4210, Train_acc:0.887759
Step: 4210, Val_acc:0.859329
==================>
Step: 4220, Train_acc:0.872172
Step: 4220, Val_acc:0.830833
==================>
Step: 4230, Train_acc:0.860472
Step: 4230, Val_acc:0.853186
==================>
Step: 4240, Train_acc:0.869518
Step: 4240, Val_acc:0.872858
==================>
Step: 4250, Train_acc:0.866093
Step: 4250, Val_acc:0.823301
==================>
Step: 4260, Train_acc:0.875889
Step: 4260, Val_acc:0.810999
==================>
Step: 4270, Train_acc:0.899823
Step: 4270, Val_acc:0.857289
==================>
Step: 4280, Train_acc:0.84017
Step: 4280, Val_acc:0.861816
==================>
Step: 4290, Train_acc:0.881373
Step: 4290, Val_acc:0.799084
==================>
Step: 4300, Train_acc:0.882749
Step: 4300, Val_acc:0.869932
==================>
2017-11-10 19:19:30.228906 ---> Validation_loss: 0.2825
Step: 4310, Train_acc:0.872994
Step: 4310, Val_acc:0.851434
==================>
Step: 4320, Train_acc:0.883092
Step: 4320, Val_acc:0.835962
==================>
Step: 4330, Train_acc:0.857393
Step: 4330, Val_acc:0.868729
==================>
Step: 4340, Train_acc:0.885641
Step: 4340, Val_acc:0.810852
==================>
Step: 4350, Train_acc:0.858343
Step: 4350, Val_acc:0.808738
==================>
Step: 4360, Train_acc:0.884447
Step: 4360, Val_acc:0.879758
==================>
Step: 4370, Train_acc:0.861378
Step: 4370, Val_acc:0.829725
==================>
Step: 4380, Train_acc:0.891838
Step: 4380, Val_acc:0.872003
==================>
Step: 4390, Train_acc:0.842125
Step: 4390, Val_acc:0.863527
==================>
Step: 4400, Train_acc:0.898706
Step: 4400, Val_acc:0.834966
==================>
2017-11-10 19:22:06.405029 ---> Validation_loss: 0.296716
Step: 4410, Train_acc:0.82656
Step: 4410, Val_acc:0.842834
==================>
Step: 4420, Train_acc:0.866986
Step: 4420, Val_acc:0.859264
==================>
Step: 4430, Train_acc:0.898009
Step: 4430, Val_acc:0.82582
==================>
Step: 4440, Train_acc:0.880493
Step: 4440, Val_acc:0.859717
==================>
Step: 4450, Train_acc:0.858777
Step: 4450, Val_acc:0.867041
==================>
Step: 4460, Train_acc:0.850046
Step: 4460, Val_acc:0.862853
==================>
Step: 4470, Train_acc:0.885991
Step: 4470, Val_acc:0.846879
==================>
Step: 4480, Train_acc:0.868356
Step: 4480, Val_acc:0.925873
==================>
Step: 4490, Train_acc:0.864031
Step: 4490, Val_acc:0.825823
==================>
Step: 4500, Train_acc:0.91405
Step: 4500, Val_acc:0.816633
==================>
****************** Epochs completed: 9******************
2017-11-10 19:24:42.574852 ---> Validation_loss: 0.288917
Step: 4510, Train_acc:0.882921
Step: 4510, Val_acc:0.859077
==================>
Step: 4520, Train_acc:0.852673
Step: 4520, Val_acc:0.865592
==================>
Step: 4530, Train_acc:0.871292
Step: 4530, Val_acc:0.838936
==================>
Step: 4540, Train_acc:0.86718
Step: 4540, Val_acc:0.824279
==================>
Step: 4550, Train_acc:0.908806
Step: 4550, Val_acc:0.867821
==================>
Step: 4560, Train_acc:0.905056
Step: 4560, Val_acc:0.893588
==================>
Step: 4570, Train_acc:0.851422
Step: 4570, Val_acc:0.84212
==================>
Step: 4580, Train_acc:0.904689
Step: 4580, Val_acc:0.895518
==================>
Step: 4590, Train_acc:0.878152
Step: 4590, Val_acc:0.876478
==================>
Step: 4600, Train_acc:0.872795
Step: 4600, Val_acc:0.842216
==================>
2017-11-10 19:27:19.300358 ---> Validation_loss: 0.28458
Step: 4610, Train_acc:0.879025
Step: 4610, Val_acc:0.854447
==================>
Step: 4620, Train_acc:0.849558
Step: 4620, Val_acc:0.847734
==================>
Step: 4630, Train_acc:0.865657
Step: 4630, Val_acc:0.843597
==================>
Step: 4640, Train_acc:0.886285
Step: 4640, Val_acc:0.805516
==================>
Step: 4650, Train_acc:0.86796
Step: 4650, Val_acc:0.864856
==================>
Step: 4660, Train_acc:0.803514
Step: 4660, Val_acc:0.859329
==================>
Step: 4670, Train_acc:0.910533
Step: 4670, Val_acc:0.898575
==================>
Step: 4680, Train_acc:0.894775
Step: 4680, Val_acc:0.879681
==================>
Step: 4690, Train_acc:0.819987
Step: 4690, Val_acc:0.83049
==================>
Step: 4700, Train_acc:0.865311
Step: 4700, Val_acc:0.862755
==================>
2017-11-10 19:29:55.872302 ---> Validation_loss: 0.312552
Step: 4710, Train_acc:0.880421
Step: 4710, Val_acc:0.845376
==================>
Step: 4720, Train_acc:0.891987
Step: 4720, Val_acc:0.835201
==================>
Step: 4730, Train_acc:0.890012
Step: 4730, Val_acc:0.797242
==================>
Step: 4740, Train_acc:0.800151
Step: 4740, Val_acc:0.846631
==================>
Step: 4750, Train_acc:0.851033
Step: 4750, Val_acc:0.840629
==================>
Step: 4760, Train_acc:0.929752
Step: 4760, Val_acc:0.871803
==================>
Step: 4770, Train_acc:0.903132
Step: 4770, Val_acc:0.84106
==================>
Step: 4780, Train_acc:0.847245
Step: 4780, Val_acc:0.891591
==================>
Step: 4790, Train_acc:0.903203
Step: 4790, Val_acc:0.817773
==================>
Step: 4800, Train_acc:0.88455
Step: 4800, Val_acc:0.859083
==================>
2017-11-10 19:32:32.582544 ---> Validation_loss: 0.338337
Step: 4810, Train_acc:0.864788
Step: 4810, Val_acc:0.859491
==================>
Step: 4820, Train_acc:0.831145
Step: 4820, Val_acc:0.850879
==================>
Step: 4830, Train_acc:0.889771
Step: 4830, Val_acc:0.830649
==================>
Step: 4840, Train_acc:0.90567
Step: 4840, Val_acc:0.826801
==================>
Step: 4850, Train_acc:0.861084
Step: 4850, Val_acc:0.842955
==================>
Step: 4860, Train_acc:0.858403
Step: 4860, Val_acc:0.799012
==================>
Step: 4870, Train_acc:0.903965
Step: 4870, Val_acc:0.848876
==================>
Step: 4880, Train_acc:0.922999
Step: 4880, Val_acc:0.845925
==================>
Step: 4890, Train_acc:0.910267
Step: 4890, Val_acc:0.863341
==================>
Step: 4900, Train_acc:0.903793
Step: 4900, Val_acc:0.811199
==================>
2017-11-10 19:35:09.474473 ---> Validation_loss: 0.270939
Step: 4910, Train_acc:0.901169
Step: 4910, Val_acc:0.842183
==================>
Step: 4920, Train_acc:0.892736
Step: 4920, Val_acc:0.850493
==================>
Step: 4930, Train_acc:0.907267
Step: 4930, Val_acc:0.868629
==================>
Step: 4940, Train_acc:0.855914
Step: 4940, Val_acc:0.797805
==================>
Step: 4950, Train_acc:0.886797
Step: 4950, Val_acc:0.846851
==================>
Step: 4960, Train_acc:0.852612
Step: 4960, Val_acc:0.870868
==================>
Step: 4970, Train_acc:0.880723
Step: 4970, Val_acc:0.860754
==================>
Step: 4980, Train_acc:0.894999
Step: 4980, Val_acc:0.828486
==================>
Step: 4990, Train_acc:0.862111
Step: 4990, Val_acc:0.858236
==================>
Step: 5000, Train_acc:0.847078
Step: 5000, Val_acc:0.856958
==================>
****************** Epochs completed: 10******************
2017-11-10 19:37:45.844441 ---> Validation_loss: 0.228648
Step: 5010, Train_acc:0.877576
Step: 5010, Val_acc:0.836238
==================>
Step: 5020, Train_acc:0.887695
Step: 5020, Val_acc:0.840084
==================>
Step: 5030, Train_acc:0.906608
Step: 5030, Val_acc:0.820398
==================>
Step: 5040, Train_acc:0.895315
Step: 5040, Val_acc:0.874197
==================>
Step: 5050, Train_acc:0.879412
Step: 5050, Val_acc:0.843942
==================>
Step: 5060, Train_acc:0.880601
Step: 5060, Val_acc:0.853997
==================>
Step: 5070, Train_acc:0.828623
Step: 5070, Val_acc:0.850116
==================>
Step: 5080, Train_acc:0.882781
Step: 5080, Val_acc:0.85598
==================>
Step: 5090, Train_acc:0.872245
Step: 5090, Val_acc:0.867952
==================>
Step: 5100, Train_acc:0.861426
Step: 5100, Val_acc:0.804279
==================>
2017-11-10 19:40:22.342777 ---> Validation_loss: 0.26069
Step: 5110, Train_acc:0.911874
Step: 5110, Val_acc:0.84151
==================>
Step: 5120, Train_acc:0.898223
Step: 5120, Val_acc:0.874623
==================>
Step: 5130, Train_acc:0.861957
Step: 5130, Val_acc:0.872086
==================>
Step: 5140, Train_acc:0.826819
Step: 5140, Val_acc:0.854207
==================>
Step: 5150, Train_acc:0.896881
Step: 5150, Val_acc:0.850333
==================>
Step: 5160, Train_acc:0.860016
Step: 5160, Val_acc:0.870433
==================>
Step: 5170, Train_acc:0.875211
Step: 5170, Val_acc:0.860768
==================>
Step: 5180, Train_acc:0.876917
Step: 5180, Val_acc:0.845876
==================>
Step: 5190, Train_acc:0.838268
Step: 5190, Val_acc:0.86173
==================>
Step: 5200, Train_acc:0.867915
Step: 5200, Val_acc:0.837695
==================>
2017-11-10 19:42:59.066452 ---> Validation_loss: 0.354366
Step: 5210, Train_acc:0.886595
Step: 5210, Val_acc:0.862257
==================>
Step: 5220, Train_acc:0.910381
Step: 5220, Val_acc:0.862341
==================>
Step: 5230, Train_acc:0.866996
Step: 5230, Val_acc:0.841563
==================>
Step: 5240, Train_acc:0.863008
Step: 5240, Val_acc:0.879561
==================>
Step: 5250, Train_acc:0.886041
Step: 5250, Val_acc:0.8338
==================>
Step: 5260, Train_acc:0.879385
Step: 5260, Val_acc:0.860301
==================>
Step: 5270, Train_acc:0.868124
Step: 5270, Val_acc:0.869657
==================>
Step: 5280, Train_acc:0.889224
Step: 5280, Val_acc:0.825634
==================>
Step: 5290, Train_acc:0.909575
Step: 5290, Val_acc:0.829286
==================>
Step: 5300, Train_acc:0.863756
Step: 5300, Val_acc:0.833888
==================>
2017-11-10 19:45:35.701592 ---> Validation_loss: 0.354795
Step: 5310, Train_acc:0.881981
Step: 5310, Val_acc:0.848612
==================>
Step: 5320, Train_acc:0.881276
Step: 5320, Val_acc:0.846681
==================>
Step: 5330, Train_acc:0.842657
Step: 5330, Val_acc:0.858695
==================>
Step: 5340, Train_acc:0.893733
Step: 5340, Val_acc:0.828977
==================>
Step: 5350, Train_acc:0.903054
Step: 5350, Val_acc:0.865983
==================>
Step: 5360, Train_acc:0.850995
Step: 5360, Val_acc:0.793315
==================>
Step: 5370, Train_acc:0.899185
Step: 5370, Val_acc:0.828029
==================>
Step: 5380, Train_acc:0.878007
Step: 5380, Val_acc:0.818643
==================>
Step: 5390, Train_acc:0.845815
Step: 5390, Val_acc:0.843055
==================>
Step: 5400, Train_acc:0.886095
Step: 5400, Val_acc:0.821343
==================>
2017-11-10 19:48:11.911232 ---> Validation_loss: 0.366816
Step: 5410, Train_acc:0.883047
Step: 5410, Val_acc:0.851401
==================>
Step: 5420, Train_acc:0.896095
Step: 5420, Val_acc:0.841345
==================>
Step: 5430, Train_acc:0.838719
Step: 5430, Val_acc:0.841398
==================>
Step: 5440, Train_acc:0.836074
Step: 5440, Val_acc:0.871855
==================>
Step: 5450, Train_acc:0.880363
Step: 5450, Val_acc:0.855654
==================>
Step: 5460, Train_acc:0.92978
Step: 5460, Val_acc:0.828368
==================>
Step: 5470, Train_acc:0.849808
Step: 5470, Val_acc:0.867064
==================>
Step: 5480, Train_acc:0.889982
Step: 5480, Val_acc:0.861455
==================>
Step: 5490, Train_acc:0.893575
Step: 5490, Val_acc:0.855919
==================>
Step: 5500, Train_acc:0.876912
Step: 5500, Val_acc:0.821294
==================>
****************** Epochs completed: 11******************
2017-11-10 19:50:49.201608 ---> Validation_loss: 0.285895
Step: 5510, Train_acc:0.834534
Step: 5510, Val_acc:0.856628
==================>
Step: 5520, Train_acc:0.897694
Step: 5520, Val_acc:0.85968
==================>
Step: 5530, Train_acc:0.852904
Step: 5530, Val_acc:0.831405
==================>
Step: 5540, Train_acc:0.844698
Step: 5540, Val_acc:0.852042
==================>
Step: 5550, Train_acc:0.85896
Step: 5550, Val_acc:0.815662
==================>
Step: 5560, Train_acc:0.91418
Step: 5560, Val_acc:0.812133
==================>
Step: 5570, Train_acc:0.866207
Step: 5570, Val_acc:0.76973
==================>
Step: 5580, Train_acc:0.893957
Step: 5580, Val_acc:0.834132
==================>
Step: 5590, Train_acc:0.900045
Step: 5590, Val_acc:0.869103
==================>
Step: 5600, Train_acc:0.888488
Step: 5600, Val_acc:0.821304
==================>
2017-11-10 19:53:25.931198 ---> Validation_loss: 0.335695
Step: 5610, Train_acc:0.852198
Step: 5610, Val_acc:0.855892
==================>
Step: 5620, Train_acc:0.865087
Step: 5620, Val_acc:0.848226
==================>
Step: 5630, Train_acc:0.838776
Step: 5630, Val_acc:0.819271
==================>
Step: 5640, Train_acc:0.872722
Step: 5640, Val_acc:0.82001
==================>
Step: 5650, Train_acc:0.832844
Step: 5650, Val_acc:0.903503
==================>
Step: 5660, Train_acc:0.89224
Step: 5660, Val_acc:0.861782
==================>
Step: 5670, Train_acc:0.881696
Step: 5670, Val_acc:0.818641
==================>
Step: 5680, Train_acc:0.890721
Step: 5680, Val_acc:0.856078
==================>
Step: 5690, Train_acc:0.873662
Step: 5690, Val_acc:0.838803
==================>
Step: 5700, Train_acc:0.89137
Step: 5700, Val_acc:0.811534
==================>
2017-11-10 19:56:03.046344 ---> Validation_loss: 0.309595
Step: 5710, Train_acc:0.894612
Step: 5710, Val_acc:0.81521
==================>
Step: 5720, Train_acc:0.824456
Step: 5720, Val_acc:0.860536
==================>
Step: 5730, Train_acc:0.843676
Step: 5730, Val_acc:0.841383
==================>
Step: 5740, Train_acc:0.85769
Step: 5740, Val_acc:0.848201
==================>
Step: 5750, Train_acc:0.933453
Step: 5750, Val_acc:0.849618
==================>
Step: 5760, Train_acc:0.85153
Step: 5760, Val_acc:0.872035
==================>
Step: 5770, Train_acc:0.887523
Step: 5770, Val_acc:0.810059
==================>
Step: 5780, Train_acc:0.85609
Step: 5780, Val_acc:0.868307
==================>
Step: 5790, Train_acc:0.89769
Step: 5790, Val_acc:0.819243
==================>
Step: 5800, Train_acc:0.862905
Step: 5800, Val_acc:0.781687
==================>
2017-11-10 19:58:39.865827 ---> Validation_loss: 0.340729
Step: 5810, Train_acc:0.87986
Step: 5810, Val_acc:0.858562
==================>
Step: 5820, Train_acc:0.912764
Step: 5820, Val_acc:0.890726
==================>
Step: 5830, Train_acc:0.886229
Step: 5830, Val_acc:0.800269
==================>
Step: 5840, Train_acc:0.836259
Step: 5840, Val_acc:0.830253
==================>
Step: 5850, Train_acc:0.887627
Step: 5850, Val_acc:0.824923
==================>
Step: 5860, Train_acc:0.880558
Step: 5860, Val_acc:0.829668
==================>
Step: 5870, Train_acc:0.87193
Step: 5870, Val_acc:0.860605
==================>
Step: 5880, Train_acc:0.824429
Step: 5880, Val_acc:0.843456
==================>
Step: 5890, Train_acc:0.902272
Step: 5890, Val_acc:0.835739
==================>
Step: 5900, Train_acc:0.83957
Step: 5900, Val_acc:0.84417
==================>
2017-11-10 20:01:16.700774 ---> Validation_loss: 0.293028
Step: 5910, Train_acc:0.845293
Step: 5910, Val_acc:0.860886
==================>
Step: 5920, Train_acc:0.828755
Step: 5920, Val_acc:0.846427
==================>
Step: 5930, Train_acc:0.845953
Step: 5930, Val_acc:0.851199
==================>
Step: 5940, Train_acc:0.861329
Step: 5940, Val_acc:0.818301
==================>
Step: 5950, Train_acc:0.840486
Step: 5950, Val_acc:0.817447
==================>
Step: 5960, Train_acc:0.865911
Step: 5960, Val_acc:0.835891
==================>
Step: 5970, Train_acc:0.87609
Step: 5970, Val_acc:0.879171
==================>
Step: 5980, Train_acc:0.878063
Step: 5980, Val_acc:0.843787
==================>
Step: 5990, Train_acc:0.887373
Step: 5990, Val_acc:0.8314
==================>
Step: 6000, Train_acc:0.89773
Step: 6000, Val_acc:0.847981
==================>
****************** Epochs completed: 12******************
2017-11-10 20:03:52.983529 ---> Validation_loss: 0.32005
Step: 6010, Train_acc:0.902122
Step: 6010, Val_acc:0.839539
==================>
Step: 6020, Train_acc:0.867639
Step: 6020, Val_acc:0.847633
==================>
Step: 6030, Train_acc:0.870919
Step: 6030, Val_acc:0.894399
==================>
Step: 6040, Train_acc:0.918467
Step: 6040, Val_acc:0.859564
==================>
Step: 6050, Train_acc:0.872032
Step: 6050, Val_acc:0.831335
==================>
Step: 6060, Train_acc:0.876511
Step: 6060, Val_acc:0.83781
==================>
Step: 6070, Train_acc:0.850271
Step: 6070, Val_acc:0.825916
==================>
Step: 6080, Train_acc:0.855925
Step: 6080, Val_acc:0.784668
==================>
Step: 6090, Train_acc:0.893783
Step: 6090, Val_acc:0.864075
==================>
Step: 6100, Train_acc:0.894414
Step: 6100, Val_acc:0.760891
==================>
2017-11-10 20:06:30.398452 ---> Validation_loss: 0.296239
Step: 6110, Train_acc:0.881859
Step: 6110, Val_acc:0.848541
==================>
Step: 6120, Train_acc:0.832831
Step: 6120, Val_acc:0.865714
==================>
Step: 6130, Train_acc:0.878419
Step: 6130, Val_acc:0.878433
==================>
Step: 6140, Train_acc:0.860994
Step: 6140, Val_acc:0.838246
==================>
Step: 6150, Train_acc:0.848368
Step: 6150, Val_acc:0.793834
==================>
Step: 6160, Train_acc:0.874
Step: 6160, Val_acc:0.837593
==================>
Step: 6170, Train_acc:0.86569
Step: 6170, Val_acc:0.813033
==================>
Step: 6180, Train_acc:0.93099
Step: 6180, Val_acc:0.848607
==================>
Step: 6190, Train_acc:0.890475
Step: 6190, Val_acc:0.890372
==================>
Step: 6200, Train_acc:0.85001
Step: 6200, Val_acc:0.859755
==================>
2017-11-10 20:09:07.024262 ---> Validation_loss: 0.320264
Step: 6210, Train_acc:0.907422
Step: 6210, Val_acc:0.804347
==================>
Step: 6220, Train_acc:0.867427
Step: 6220, Val_acc:0.843369
==================>
Step: 6230, Train_acc:0.891555
Step: 6230, Val_acc:0.870504
==================>
Step: 6240, Train_acc:0.880966
Step: 6240, Val_acc:0.877406
==================>
Step: 6250, Train_acc:0.895531
Step: 6250, Val_acc:0.855167
==================>
Step: 6260, Train_acc:0.903618
Step: 6260, Val_acc:0.850496
==================>
Step: 6270, Train_acc:0.803655
Step: 6270, Val_acc:0.826732
==================>
Step: 6280, Train_acc:0.847268
Step: 6280, Val_acc:0.88028
==================>
Step: 6290, Train_acc:0.864543
Step: 6290, Val_acc:0.864425
==================>
Step: 6300, Train_acc:0.866298
Step: 6300, Val_acc:0.895872
==================>
2017-11-10 20:11:43.371764 ---> Validation_loss: 0.282456
Step: 6310, Train_acc:0.908304
Step: 6310, Val_acc:0.841549
==================>
Step: 6320, Train_acc:0.86432
Step: 6320, Val_acc:0.830906
==================>
Step: 6330, Train_acc:0.896572
Step: 6330, Val_acc:0.840093
==================>
Step: 6340, Train_acc:0.888188
Step: 6340, Val_acc:0.846135
==================>
Step: 6350, Train_acc:0.89811
Step: 6350, Val_acc:0.842555
==================>
Step: 6360, Train_acc:0.855283
Step: 6360, Val_acc:0.841681
==================>
Step: 6370, Train_acc:0.869813
Step: 6370, Val_acc:0.850411
==================>
Step: 6380, Train_acc:0.853843
Step: 6380, Val_acc:0.856832
==================>
Step: 6390, Train_acc:0.9225
Step: 6390, Val_acc:0.873737
==================>
Step: 6400, Train_acc:0.89274
Step: 6400, Val_acc:0.830048
==================>
2017-11-10 20:14:19.985542 ---> Validation_loss: 0.337971
Step: 6410, Train_acc:0.869309
Step: 6410, Val_acc:0.814214
==================>
Step: 6420, Train_acc:0.895297
Step: 6420, Val_acc:0.892986
==================>
Step: 6430, Train_acc:0.864896
Step: 6430, Val_acc:0.85386
==================>
Step: 6440, Train_acc:0.895009
Step: 6440, Val_acc:0.858594
==================>
Step: 6450, Train_acc:0.8359
Step: 6450, Val_acc:0.821155
==================>
Step: 6460, Train_acc:0.851893
Step: 6460, Val_acc:0.825072
==================>
Step: 6470, Train_acc:0.876331
Step: 6470, Val_acc:0.831105
==================>
Step: 6480, Train_acc:0.832039
Step: 6480, Val_acc:0.873856
==================>
Step: 6490, Train_acc:0.916838
Step: 6490, Val_acc:0.815021
==================>
Step: 6500, Train_acc:0.889413
Step: 6500, Val_acc:0.832792
==================>
****************** Epochs completed: 13******************
2017-11-10 20:16:56.881550 ---> Validation_loss: 0.307906
Step: 6510, Train_acc:0.910013
Step: 6510, Val_acc:0.819816
==================>
Step: 6520, Train_acc:0.826189
Step: 6520, Val_acc:0.823243
==================>
Step: 6530, Train_acc:0.861947
Step: 6530, Val_acc:0.841873
==================>
Step: 6540, Train_acc:0.907847
Step: 6540, Val_acc:0.843407
==================>
Step: 6550, Train_acc:0.837107
Step: 6550, Val_acc:0.807938
==================>
Step: 6560, Train_acc:0.885813
Step: 6560, Val_acc:0.86252
==================>
Step: 6570, Train_acc:0.912657
Step: 6570, Val_acc:0.902317
==================>
Step: 6580, Train_acc:0.867958
Step: 6580, Val_acc:0.876121
==================>
Step: 6590, Train_acc:0.864822
Step: 6590, Val_acc:0.846826
==================>
Step: 6600, Train_acc:0.859237
Step: 6600, Val_acc:0.854736
==================>
2017-11-10 20:19:34.068503 ---> Validation_loss: 0.307928
Step: 6610, Train_acc:0.882209
Step: 6610, Val_acc:0.865972
==================>
Step: 6620, Train_acc:0.877258
Step: 6620, Val_acc:0.822615
==================>
Step: 6630, Train_acc:0.931686
Step: 6630, Val_acc:0.846719
==================>
Step: 6640, Train_acc:0.890283
Step: 6640, Val_acc:0.847638
==================>
Step: 6650, Train_acc:0.898573
Step: 6650, Val_acc:0.877816
==================>
Step: 6660, Train_acc:0.888964
Step: 6660, Val_acc:0.877867
==================>
Step: 6670, Train_acc:0.879094
Step: 6670, Val_acc:0.870099
==================>
Step: 6680, Train_acc:0.875789
Step: 6680, Val_acc:0.834705
==================>
Step: 6690, Train_acc:0.842819
Step: 6690, Val_acc:0.910311
==================>
Step: 6700, Train_acc:0.885098
Step: 6700, Val_acc:0.86563
==================>
2017-11-10 20:22:10.772112 ---> Validation_loss: 0.357683
Step: 6710, Train_acc:0.908781
Step: 6710, Val_acc:0.81439
==================>
Step: 6720, Train_acc:0.881047
Step: 6720, Val_acc:0.85092
==================>
****************** Epochs completed: 2******************
Step: 6730, Train_acc:0.923595
Step: 6730, Val_acc:0.8133
==================>
Step: 6740, Train_acc:0.892343
Step: 6740, Val_acc:0.831467
==================>
Step: 6750, Train_acc:0.877356
Step: 6750, Val_acc:0.821296
==================>
Step: 6760, Train_acc:0.863434
Step: 6760, Val_acc:0.806934
==================>
Step: 6770, Train_acc:0.860739
Step: 6770, Val_acc:0.848069
==================>
Step: 6780, Train_acc:0.871821
Step: 6780, Val_acc:0.831639
==================>
Step: 6790, Train_acc:0.887778
Step: 6790, Val_acc:0.787268
==================>
Step: 6800, Train_acc:0.882267
Step: 6800, Val_acc:0.810997
==================>
2017-11-10 20:24:48.089374 ---> Validation_loss: 0.315507
Step: 6810, Train_acc:0.886143
Step: 6810, Val_acc:0.813226
==================>
Step: 6820, Train_acc:0.838777
Step: 6820, Val_acc:0.837968
==================>
Step: 6830, Train_acc:0.895099
Step: 6830, Val_acc:0.870107
==================>
Step: 6840, Train_acc:0.896544
Step: 6840, Val_acc:0.794303
==================>
Step: 6850, Train_acc:0.899395
Step: 6850, Val_acc:0.829032
==================>
Step: 6860, Train_acc:0.894247
Step: 6860, Val_acc:0.82459
==================>
Step: 6870, Train_acc:0.862242
Step: 6870, Val_acc:0.821604
==================>
Step: 6880, Train_acc:0.880814
Step: 6880, Val_acc:0.82665
==================>
Step: 6890, Train_acc:0.880529
Step: 6890, Val_acc:0.812072
==================>
Step: 6900, Train_acc:0.912661
Step: 6900, Val_acc:0.895772
==================>
2017-11-10 20:27:24.057369 ---> Validation_loss: 0.253359
Step: 6910, Train_acc:0.903882
Step: 6910, Val_acc:0.850287
==================>
Step: 6920, Train_acc:0.862043
Step: 6920, Val_acc:0.831306
==================>
Step: 6930, Train_acc:0.900999
Step: 6930, Val_acc:0.84812
==================>
Step: 6940, Train_acc:0.904684
Step: 6940, Val_acc:0.849581
==================>
Step: 6950, Train_acc:0.879832
Step: 6950, Val_acc:0.840348
==================>
Step: 6960, Train_acc:0.866858
Step: 6960, Val_acc:0.838584
==================>
Step: 6970, Train_acc:0.878973
Step: 6970, Val_acc:0.839224
==================>
Step: 6980, Train_acc:0.841626
Step: 6980, Val_acc:0.830488
==================>
Step: 6990, Train_acc:0.874665
Step: 6990, Val_acc:0.822432
==================>
Step: 7000, Train_acc:0.898751
Step: 7000, Val_acc:0.832338
==================>
****************** Epochs completed: 14******************
2017-11-10 20:30:00.252744 ---> Validation_loss: 0.280739
Step: 7010, Train_acc:0.84998
Step: 7010, Val_acc:0.830708
==================>
Step: 7020, Train_acc:0.882521
Step: 7020, Val_acc:0.811893
==================>
Step: 7030, Train_acc:0.920569
Step: 7030, Val_acc:0.832925
==================>
Step: 7040, Train_acc:0.898718
Step: 7040, Val_acc:0.88392
==================>
Step: 7050, Train_acc:0.91923
Step: 7050, Val_acc:0.855894
==================>
Step: 7060, Train_acc:0.899098
Step: 7060, Val_acc:0.86458
==================>
Step: 7070, Train_acc:0.894911
Step: 7070, Val_acc:0.822406
==================>
Step: 7080, Train_acc:0.902123
Step: 7080, Val_acc:0.831083
==================>
Step: 7090, Train_acc:0.908586
Step: 7090, Val_acc:0.865076
==================>
Step: 7100, Train_acc:0.895884
Step: 7100, Val_acc:0.861503
==================>
2017-11-10 20:32:36.753216 ---> Validation_loss: 0.346094
Step: 7110, Train_acc:0.883895
Step: 7110, Val_acc:0.832692
==================>
Step: 7120, Train_acc:0.885659
Step: 7120, Val_acc:0.82901
==================>
Step: 7130, Train_acc:0.891749
Step: 7130, Val_acc:0.826407
==================>
Step: 7140, Train_acc:0.873507
Step: 7140, Val_acc:0.815948
==================>
Step: 7150, Train_acc:0.886123
Step: 7150, Val_acc:0.865038
==================>
Step: 7160, Train_acc:0.86052
Step: 7160, Val_acc:0.833389
==================>
Step: 7170, Train_acc:0.855885
Step: 7170, Val_acc:0.844807
==================>
Step: 7180, Train_acc:0.851881
Step: 7180, Val_acc:0.851705
==================>
Step: 7190, Train_acc:0.888824
Step: 7190, Val_acc:0.829315
==================>
Step: 7200, Train_acc:0.840577
Step: 7200, Val_acc:0.830188
==================>
2017-11-10 20:35:12.975155 ---> Validation_loss: 0.232955
Step: 7210, Train_acc:0.891041
Step: 7210, Val_acc:0.821467
==================>
Step: 7220, Train_acc:0.860989
Step: 7220, Val_acc:0.834629
==================>
Step: 7230, Train_acc:0.863213
Step: 7230, Val_acc:0.89251
==================>
Step: 7240, Train_acc:0.882115
Step: 7240, Val_acc:0.843513
==================>
Step: 7250, Train_acc:0.861428
Step: 7250, Val_acc:0.799614
==================>
Step: 7260, Train_acc:0.874181
Step: 7260, Val_acc:0.846158
==================>
Step: 7270, Train_acc:0.881436
Step: 7270, Val_acc:0.867928
==================>
Step: 7280, Train_acc:0.898207
Step: 7280, Val_acc:0.860332
==================>
Step: 7290, Train_acc:0.91959
Step: 7290, Val_acc:0.832406
==================>
Step: 7300, Train_acc:0.87922
Step: 7300, Val_acc:0.889713
==================>
2017-11-10 20:37:49.176130 ---> Validation_loss: 0.352392
Step: 7310, Train_acc:0.87672
Step: 7310, Val_acc:0.871592
==================>
Step: 7320, Train_acc:0.877279
Step: 7320, Val_acc:0.835105
==================>
Step: 7330, Train_acc:0.927754
Step: 7330, Val_acc:0.832482
==================>
Step: 7340, Train_acc:0.884482
Step: 7340, Val_acc:0.876539
==================>
Step: 7350, Train_acc:0.869288
Step: 7350, Val_acc:0.851777
==================>
Step: 7360, Train_acc:0.919663
Step: 7360, Val_acc:0.82002
==================>
Step: 7370, Train_acc:0.872189
Step: 7370, Val_acc:0.843807
==================>
Step: 7380, Train_acc:0.882863
Step: 7380, Val_acc:0.837251
==================>
Step: 7390, Train_acc:0.857189
Step: 7390, Val_acc:0.891338
==================>
Step: 7400, Train_acc:0.85002
Step: 7400, Val_acc:0.866226
==================>
2017-11-10 20:40:25.318529 ---> Validation_loss: 0.391001
Step: 7410, Train_acc:0.880605
Step: 7410, Val_acc:0.842753
==================>
Step: 7420, Train_acc:0.876554
Step: 7420, Val_acc:0.855189
==================>
Step: 7430, Train_acc:0.91353
Step: 7430, Val_acc:0.858231
==================>
Step: 7440, Train_acc:0.897229
Step: 7440, Val_acc:0.828151
==================>
Step: 7450, Train_acc:0.89575
Step: 7450, Val_acc:0.842494
==================>
Step: 7460, Train_acc:0.861858
Step: 7460, Val_acc:0.817521
==================>
Step: 7470, Train_acc:0.908856
Step: 7470, Val_acc:0.83947
==================>
Step: 7480, Train_acc:0.853771
Step: 7480, Val_acc:0.852009
==================>
Step: 7490, Train_acc:0.90933
Step: 7490, Val_acc:0.853937
==================>
Step: 7500, Train_acc:0.899716
Step: 7500, Val_acc:0.83809
==================>
****************** Epochs completed: 15******************
2017-11-10 20:43:01.436888 ---> Validation_loss: 0.208709
Step: 7510, Train_acc:0.889874
Step: 7510, Val_acc:0.882573
==================>
Step: 7520, Train_acc:0.905533
Step: 7520, Val_acc:0.866785
==================>
Step: 7530, Train_acc:0.896099
Step: 7530, Val_acc:0.837108
==================>
Step: 7540, Train_acc:0.891659
Step: 7540, Val_acc:0.867117
==================>
Step: 7550, Train_acc:0.88441
Step: 7550, Val_acc:0.868961
==================>
Step: 7560, Train_acc:0.887394
Step: 7560, Val_acc:0.888528
==================>
Step: 7570, Train_acc:0.858635
Step: 7570, Val_acc:0.870006
==================>
Step: 7580, Train_acc:0.88698
Step: 7580, Val_acc:0.850785
==================>
Step: 7590, Train_acc:0.869241
Step: 7590, Val_acc:0.879365
==================>
Step: 7600, Train_acc:0.926902
Step: 7600, Val_acc:0.848304
==================>
2017-11-10 20:45:37.574634 ---> Validation_loss: 0.392633
Step: 7610, Train_acc:0.838593
Step: 7610, Val_acc:0.857455
==================>
Step: 7620, Train_acc:0.856118
Step: 7620, Val_acc:0.841183
==================>
Step: 7630, Train_acc:0.87307
Step: 7630, Val_acc:0.834589
==================>
Step: 7640, Train_acc:0.891866
Step: 7640, Val_acc:0.821107
==================>
Step: 7650, Train_acc:0.884998
Step: 7650, Val_acc:0.814287
==================>
Step: 7660, Train_acc:0.891986
Step: 7660, Val_acc:0.846199
==================>
Step: 7670, Train_acc:0.897899
Step: 7670, Val_acc:0.825581
==================>
Step: 7680, Train_acc:0.88848
Step: 7680, Val_acc:0.799469
==================>
Step: 7690, Train_acc:0.888779
Step: 7690, Val_acc:0.855481
==================>
Step: 7700, Train_acc:0.906371
Step: 7700, Val_acc:0.83277
==================>
2017-11-10 20:48:13.664392 ---> Validation_loss: 0.307787
Step: 7710, Train_acc:0.873809
Step: 7710, Val_acc:0.826378
==================>
Step: 7720, Train_acc:0.87426
Step: 7720, Val_acc:0.841935
==================>
Step: 7730, Train_acc:0.882595
Step: 7730, Val_acc:0.82845
==================>
Step: 7740, Train_acc:0.913208
Step: 7740, Val_acc:0.859901
==================>
Step: 7750, Train_acc:0.895979
Step: 7750, Val_acc:0.887959
==================>
Step: 7760, Train_acc:0.910878
Step: 7760, Val_acc:0.83085
==================>
Step: 7770, Train_acc:0.888962
Step: 7770, Val_acc:0.839749
==================>
Step: 7780, Train_acc:0.909681
Step: 7780, Val_acc:0.900446
==================>
Step: 7790, Train_acc:0.885129
Step: 7790, Val_acc:0.831477
==================>
Step: 7800, Train_acc:0.897836
Step: 7800, Val_acc:0.854072
==================>
2017-11-10 20:50:50.163810 ---> Validation_loss: 0.315387
Step: 7810, Train_acc:0.903812
Step: 7810, Val_acc:0.80209
==================>
Step: 7820, Train_acc:0.909761
Step: 7820, Val_acc:0.867058
==================>
Step: 7830, Train_acc:0.865184
Step: 7830, Val_acc:0.852015
==================>
Step: 7840, Train_acc:0.847352
Step: 7840, Val_acc:0.847186
==================>
Step: 7850, Train_acc:0.896376
Step: 7850, Val_acc:0.866852
==================>
Step: 7860, Train_acc:0.901257
Step: 7860, Val_acc:0.830922
==================>
Step: 7870, Train_acc:0.901141
Step: 7870, Val_acc:0.876959
==================>
Step: 7880, Train_acc:0.881451
Step: 7880, Val_acc:0.866262
==================>
Step: 7890, Train_acc:0.88922
Step: 7890, Val_acc:0.840641
==================>
Step: 7900, Train_acc:0.897168
Step: 7900, Val_acc:0.874398
==================>
2017-11-10 20:53:26.340986 ---> Validation_loss: 0.377259
Step: 7910, Train_acc:0.905175
Step: 7910, Val_acc:0.877494
==================>
Step: 7920, Train_acc:0.88068
Step: 7920, Val_acc:0.911254
==================>
Step: 7930, Train_acc:0.848351
Step: 7930, Val_acc:0.894633
==================>
Step: 7940, Train_acc:0.921875
Step: 7940, Val_acc:0.868291
==================>
Step: 7950, Train_acc:0.874838
Step: 7950, Val_acc:0.837432
==================>
Step: 7960, Train_acc:0.879853
Step: 7960, Val_acc:0.818103
==================>
Step: 7970, Train_acc:0.89902
Step: 7970, Val_acc:0.833972
==================>
Step: 7980, Train_acc:0.895811
Step: 7980, Val_acc:0.862848
==================>
Step: 7990, Train_acc:0.916874
Step: 7990, Val_acc:0.902933
==================>
Step: 8000, Train_acc:0.881976
Step: 8000, Val_acc:0.882848
==================>
****************** Epochs completed: 16******************
2017-11-10 20:56:02.191680 ---> Validation_loss: 0.325344
Step: 8010, Train_acc:0.879556
Step: 8010, Val_acc:0.843857
==================>
Step: 8020, Train_acc:0.908456
Step: 8020, Val_acc:0.824161
==================>
Step: 8030, Train_acc:0.868915
Step: 8030, Val_acc:0.802695
==================>
Step: 8040, Train_acc:0.861124
Step: 8040, Val_acc:0.844301
==================>
Step: 8050, Train_acc:0.875802
Step: 8050, Val_acc:0.779663
==================>
Step: 8060, Train_acc:0.884631
Step: 8060, Val_acc:0.864316
==================>
Step: 8070, Train_acc:0.864137
Step: 8070, Val_acc:0.864352
==================>
Step: 8080, Train_acc:0.902914
Step: 8080, Val_acc:0.844424
==================>
Step: 8090, Train_acc:0.852782
Step: 8090, Val_acc:0.832748
==================>
Step: 8100, Train_acc:0.873993
Step: 8100, Val_acc:0.855144
==================>
2017-11-10 20:58:38.262775 ---> Validation_loss: 0.305387
Step: 8110, Train_acc:0.907482
Step: 8110, Val_acc:0.814724
==================>
Step: 8120, Train_acc:0.915728
Step: 8120, Val_acc:0.840377
==================>
Step: 8130, Train_acc:0.893158
Step: 8130, Val_acc:0.865958
==================>
Step: 8140, Train_acc:0.887234
Step: 8140, Val_acc:0.847343
==================>
Step: 8150, Train_acc:0.856537
Step: 8150, Val_acc:0.843024
==================>
Step: 8160, Train_acc:0.909581
Step: 8160, Val_acc:0.810844
==================>
Step: 8170, Train_acc:0.896498
Step: 8170, Val_acc:0.861259
==================>
Step: 8180, Train_acc:0.890195
Step: 8180, Val_acc:0.809062
==================>
Step: 8190, Train_acc:0.8987
Step: 8190, Val_acc:0.837223
==================>
Step: 8200, Train_acc:0.888506
Step: 8200, Val_acc:0.812449
==================>
2017-11-10 21:01:14.893242 ---> Validation_loss: 0.287107
Step: 8210, Train_acc:0.894658
Step: 8210, Val_acc:0.841002
==================>
Step: 8220, Train_acc:0.867007
Step: 8220, Val_acc:0.848314
==================>
Step: 8230, Train_acc:0.894613
Step: 8230, Val_acc:0.905723
==================>
Step: 8240, Train_acc:0.846899
Step: 8240, Val_acc:0.832708
==================>
Step: 8250, Train_acc:0.90197
Step: 8250, Val_acc:0.863533
==================>
Step: 8260, Train_acc:0.899822
Step: 8260, Val_acc:0.861439
==================>
Step: 8270, Train_acc:0.893367
Step: 8270, Val_acc:0.844399
==================>
Step: 8280, Train_acc:0.871082
Step: 8280, Val_acc:0.839912
==================>
Step: 8290, Train_acc:0.871526
Step: 8290, Val_acc:0.835625
==================>
Step: 8300, Train_acc:0.8758
Step: 8300, Val_acc:0.867845
==================>
2017-11-10 21:03:51.052293 ---> Validation_loss: 0.272726
Step: 8310, Train_acc:0.882504
Step: 8310, Val_acc:0.828889
==================>
Step: 8320, Train_acc:0.857671
Step: 8320, Val_acc:0.827313
==================>
Step: 8330, Train_acc:0.927534
Step: 8330, Val_acc:0.825704
==================>
Step: 8340, Train_acc:0.945282
Step: 8340, Val_acc:0.846788
==================>
Step: 8350, Train_acc:0.9085
Step: 8350, Val_acc:0.859695
==================>
Step: 8360, Train_acc:0.85817
Step: 8360, Val_acc:0.806437
==================>
Step: 8370, Train_acc:0.865647
Step: 8370, Val_acc:0.815925
==================>
Step: 8380, Train_acc:0.92679
Step: 8380, Val_acc:0.863259
==================>
Step: 8390, Train_acc:0.881056
Step: 8390, Val_acc:0.852886
==================>
Step: 8400, Train_acc:0.867446
Step: 8400, Val_acc:0.81776
==================>
2017-11-10 21:06:26.789425 ---> Validation_loss: 0.362973
Step: 8410, Train_acc:0.882001
Step: 8410, Val_acc:0.799332
==================>
Step: 8420, Train_acc:0.879135
Step: 8420, Val_acc:0.815459
==================>
Step: 8430, Train_acc:0.927664
Step: 8430, Val_acc:0.872607
==================>
Step: 8440, Train_acc:0.868931
Step: 8440, Val_acc:0.869441
==================>
Step: 8450, Train_acc:0.860833
Step: 8450, Val_acc:0.861421
==================>
Step: 8460, Train_acc:0.868281
Step: 8460, Val_acc:0.839692
==================>
Step: 8470, Train_acc:0.90413
Step: 8470, Val_acc:0.816045
==================>
Step: 8480, Train_acc:0.896939
Step: 8480, Val_acc:0.837262
==================>
Step: 8490, Train_acc:0.899552
Step: 8490, Val_acc:0.899133
==================>
Step: 8500, Train_acc:0.875383
Step: 8500, Val_acc:0.869086
==================>
****************** Epochs completed: 17******************
2017-11-10 21:09:03.360359 ---> Validation_loss: 0.355026
Step: 8510, Train_acc:0.886753
Step: 8510, Val_acc:0.844728
==================>
Step: 8520, Train_acc:0.886482
Step: 8520, Val_acc:0.857635
==================>
Step: 8530, Train_acc:0.900745
Step: 8530, Val_acc:0.796143
==================>
Step: 8540, Train_acc:0.894983
Step: 8540, Val_acc:0.823068
==================>
Step: 8550, Train_acc:0.853804
Step: 8550, Val_acc:0.833138
==================>
Step: 8560, Train_acc:0.869999
Step: 8560, Val_acc:0.81356
==================>
Step: 8570, Train_acc:0.902488
Step: 8570, Val_acc:0.873883
==================>
Step: 8580, Train_acc:0.896542
Step: 8580, Val_acc:0.855123
==================>
Step: 8590, Train_acc:0.916862
Step: 8590, Val_acc:0.842664
==================>
Step: 8600, Train_acc:0.898806
Step: 8600, Val_acc:0.878262
==================>
2017-11-10 21:11:39.585199 ---> Validation_loss: 0.248241
Step: 8610, Train_acc:0.888759
Step: 8610, Val_acc:0.856826
==================>
Step: 8620, Train_acc:0.883654
Step: 8620, Val_acc:0.841843
==================>
Step: 8630, Train_acc:0.864551
Step: 8630, Val_acc:0.858804
==================>
Step: 8640, Train_acc:0.884265
Step: 8640, Val_acc:0.828118
==================>
Step: 8650, Train_acc:0.903315
Step: 8650, Val_acc:0.865989
==================>
Step: 8660, Train_acc:0.905598
Step: 8660, Val_acc:0.829283
==================>
Step: 8670, Train_acc:0.843936
Step: 8670, Val_acc:0.826176
==================>
Step: 8680, Train_acc:0.907557
Step: 8680, Val_acc:0.859819
==================>
Step: 8690, Train_acc:0.882401
Step: 8690, Val_acc:0.824218
==================>
Step: 8700, Train_acc:0.887793
Step: 8700, Val_acc:0.855295
==================>
2017-11-10 21:14:16.239346 ---> Validation_loss: 0.296398
Step: 8710, Train_acc:0.898456
Step: 8710, Val_acc:0.893732
==================>
Step: 8720, Train_acc:0.945157
Step: 8720, Val_acc:0.859452
==================>
Step: 8730, Train_acc:0.909674
Step: 8730, Val_acc:0.820946
==================>
Step: 8740, Train_acc:0.895377
Step: 8740, Val_acc:0.826642
==================>
Step: 8750, Train_acc:0.888029
Step: 8750, Val_acc:0.82203
==================>
Step: 8760, Train_acc:0.910924
Step: 8760, Val_acc:0.855063
==================>
Step: 8770, Train_acc:0.881637
Step: 8770, Val_acc:0.876223
==================>
Step: 8780, Train_acc:0.877748
Step: 8780, Val_acc:0.87958
==================>
Step: 8790, Train_acc:0.86377
Step: 8790, Val_acc:0.843876
==================>
Step: 8800, Train_acc:0.910017
Step: 8800, Val_acc:0.843865
==================>
2017-11-10 21:16:52.403817 ---> Validation_loss: 0.357436
Step: 8810, Train_acc:0.910045
Step: 8810, Val_acc:0.868593
==================>
Step: 8820, Train_acc:0.886558
Step: 8820, Val_acc:0.874729
==================>
Step: 8830, Train_acc:0.873445
Step: 8830, Val_acc:0.839635
==================>
Step: 8840, Train_acc:0.862352
Step: 8840, Val_acc:0.903435
==================>
Step: 8850, Train_acc:0.92791
Step: 8850, Val_acc:0.859012
==================>
Step: 8860, Train_acc:0.903245
Step: 8860, Val_acc:0.834816
==================>
Step: 8870, Train_acc:0.894705
Step: 8870, Val_acc:0.860336
==================>
Step: 8880, Train_acc:0.88975
Step: 8880, Val_acc:0.838109
==================>
Step: 8890, Train_acc:0.926124
Step: 8890, Val_acc:0.84389
==================>
Step: 8900, Train_acc:0.857838
Step: 8900, Val_acc:0.817822
==================>
2017-11-10 21:19:28.470760 ---> Validation_loss: 0.296297
Step: 8910, Train_acc:0.865022
Step: 8910, Val_acc:0.869935
==================>
Step: 8920, Train_acc:0.867399
Step: 8920, Val_acc:0.802161
==================>
Step: 8930, Train_acc:0.88132
Step: 8930, Val_acc:0.868488
==================>
Step: 8940, Train_acc:0.88991
Step: 8940, Val_acc:0.871174
==================>
Step: 8950, Train_acc:0.875626
Step: 8950, Val_acc:0.83889
==================>
Step: 8960, Train_acc:0.86755
Step: 8960, Val_acc:0.898309
==================>
Step: 8970, Train_acc:0.872251
Step: 8970, Val_acc:0.832012
==================>
Step: 8980, Train_acc:0.8875
Step: 8980, Val_acc:0.829216
==================>
Step: 8990, Train_acc:0.862781
Step: 8990, Val_acc:0.872488
==================>
Step: 9000, Train_acc:0.880392
Step: 9000, Val_acc:0.887112
==================>
****************** Epochs completed: 18******************
2017-11-10 21:22:05.186883 ---> Validation_loss: 0.266589
Step: 9010, Train_acc:0.866777
Step: 9010, Val_acc:0.827755
==================>
Step: 9020, Train_acc:0.874421
Step: 9020, Val_acc:0.856436
==================>
Step: 9030, Train_acc:0.933884
Step: 9030, Val_acc:0.868174
==================>
Step: 9040, Train_acc:0.874313
Step: 9040, Val_acc:0.861284
==================>
Step: 9050, Train_acc:0.913174
Step: 9050, Val_acc:0.832617
==================>
Step: 9060, Train_acc:0.883381
Step: 9060, Val_acc:0.876443
==================>
Step: 9070, Train_acc:0.858829
Step: 9070, Val_acc:0.862378
==================>
Step: 9080, Train_acc:0.899178
Step: 9080, Val_acc:0.821041
==================>
Step: 9090, Train_acc:0.924619
Step: 9090, Val_acc:0.845118
==================>
Step: 9100, Train_acc:0.86701
Step: 9100, Val_acc:0.862186
==================>
2017-11-10 21:24:41.568883 ---> Validation_loss: 0.283504
Step: 9110, Train_acc:0.900808
Step: 9110, Val_acc:0.831166
==================>
Step: 9120, Train_acc:0.884086
Step: 9120, Val_acc:0.880461
==================>
Step: 9130, Train_acc:0.941001
Step: 9130, Val_acc:0.839351
==================>
Step: 9140, Train_acc:0.905826
Step: 9140, Val_acc:0.868291
==================>
Step: 9150, Train_acc:0.889681
Step: 9150, Val_acc:0.849449
==================>
Step: 9160, Train_acc:0.89723
Step: 9160, Val_acc:0.843207
==================>
Step: 9170, Train_acc:0.884969
Step: 9170, Val_acc:0.865261
==================>
Step: 9180, Train_acc:0.890778
Step: 9180, Val_acc:0.806118
==================>
Step: 9190, Train_acc:0.907466
Step: 9190, Val_acc:0.856829
==================>
Step: 9200, Train_acc:0.862332
Step: 9200, Val_acc:0.817966
==================>
2017-11-10 21:27:17.841473 ---> Validation_loss: 0.363064
Step: 9210, Train_acc:0.899423
Step: 9210, Val_acc:0.853695
==================>
Step: 9220, Train_acc:0.885715
Step: 9220, Val_acc:0.864618
==================>
Step: 9230, Train_acc:0.898218
Step: 9230, Val_acc:0.870264
==================>
Step: 9240, Train_acc:0.906611
Step: 9240, Val_acc:0.830378
==================>
Step: 9250, Train_acc:0.886506
Step: 9250, Val_acc:0.862301
==================>
Step: 9260, Train_acc:0.874723
Step: 9260, Val_acc:0.838036
==================>
Step: 9270, Train_acc:0.871149
Step: 9270, Val_acc:0.852634
==================>
Step: 9280, Train_acc:0.907883
Step: 9280, Val_acc:0.826884
==================>
Step: 9290, Train_acc:0.903322
Step: 9290, Val_acc:0.820762
==================>
Step: 9300, Train_acc:0.92098
Step: 9300, Val_acc:0.865491
==================>
2017-11-10 21:29:54.279975 ---> Validation_loss: 0.265568
Step: 9310, Train_acc:0.892515
Step: 9310, Val_acc:0.868507
==================>
Step: 9320, Train_acc:0.894305
Step: 9320, Val_acc:0.87809
==================>
Step: 9330, Train_acc:0.880778
Step: 9330, Val_acc:0.834878
==================>
Step: 9340, Train_acc:0.906675
Step: 9340, Val_acc:0.857682
==================>
Step: 9350, Train_acc:0.926984
Step: 9350, Val_acc:0.866736
==================>
Step: 9360, Train_acc:0.908969
Step: 9360, Val_acc:0.850541
==================>
Step: 9370, Train_acc:0.866268
Step: 9370, Val_acc:0.867417
==================>
Step: 9380, Train_acc:0.92484
Step: 9380, Val_acc:0.8412
==================>
Step: 9390, Train_acc:0.870579
Step: 9390, Val_acc:0.886664
==================>
Step: 9400, Train_acc:0.891572
Step: 9400, Val_acc:0.870597
==================>
2017-11-10 21:32:30.727988 ---> Validation_loss: 0.360371
Step: 9410, Train_acc:0.907545
Step: 9410, Val_acc:0.82641
==================>
Step: 9420, Train_acc:0.895358
Step: 9420, Val_acc:0.875786
==================>
Step: 9430, Train_acc:0.876656
Step: 9430, Val_acc:0.864014
==================>
Step: 9440, Train_acc:0.901746
Step: 9440, Val_acc:0.88505
==================>
Step: 9450, Train_acc:0.847642
Step: 9450, Val_acc:0.880154
==================>
Step: 9460, Train_acc:0.889479
Step: 9460, Val_acc:0.836213
==================>
Step: 9470, Train_acc:0.909073
Step: 9470, Val_acc:0.843857
==================>
Step: 9480, Train_acc:0.900804
Step: 9480, Val_acc:0.827755
==================>
Step: 9490, Train_acc:0.871173
Step: 9490, Val_acc:0.838882
==================>
Step: 9500, Train_acc:0.908367
Step: 9500, Val_acc:0.844978
==================>
****************** Epochs completed: 19******************
2017-11-10 21:35:07.027635 ---> Validation_loss: 0.255993
Step: 9510, Train_acc:0.882999
Step: 9510, Val_acc:0.856072
==================>
Step: 9520, Train_acc:0.890994
Step: 9520, Val_acc:0.844297
==================>
Step: 9530, Train_acc:0.897981
Step: 9530, Val_acc:0.889883
==================>
Step: 9540, Train_acc:0.892048
Step: 9540, Val_acc:0.865812
==================>
Step: 9550, Train_acc:0.874066
Step: 9550, Val_acc:0.819681
==================>
Step: 9560, Train_acc:0.915353
Step: 9560, Val_acc:0.866924
==================>
Step: 9570, Train_acc:0.906653
Step: 9570, Val_acc:0.813018
==================>
Step: 9580, Train_acc:0.90291
Step: 9580, Val_acc:0.796808
==================>
Step: 9590, Train_acc:0.868928
Step: 9590, Val_acc:0.863621
==================>
Step: 9600, Train_acc:0.863021
Step: 9600, Val_acc:0.850115
==================>
2017-11-10 21:37:43.512183 ---> Validation_loss: 0.354156
Step: 9610, Train_acc:0.85889
Step: 9610, Val_acc:0.854752
==================>
Step: 9620, Train_acc:0.882557
Step: 9620, Val_acc:0.890826
==================>
Step: 9630, Train_acc:0.869805
Step: 9630, Val_acc:0.788588
==================>
Step: 9640, Train_acc:0.895052
Step: 9640, Val_acc:0.877277
==================>
Step: 9650, Train_acc:0.888632
Step: 9650, Val_acc:0.845801
==================>
Step: 9660, Train_acc:0.870242
Step: 9660, Val_acc:0.868298
==================>
Step: 9670, Train_acc:0.922839
Step: 9670, Val_acc:0.850101
==================>
Step: 9680, Train_acc:0.886926
Step: 9680, Val_acc:0.80121
==================>
Step: 9690, Train_acc:0.864227
Step: 9690, Val_acc:0.862365
==================>
Step: 9700, Train_acc:0.95139
Step: 9700, Val_acc:0.852163
==================>
2017-11-10 21:40:19.621854 ---> Validation_loss: 0.276109
Step: 9710, Train_acc:0.914242
Step: 9710, Val_acc:0.836025
==================>
Step: 9720, Train_acc:0.874255
Step: 9720, Val_acc:0.818667
==================>
Step: 9730, Train_acc:0.888452
Step: 9730, Val_acc:0.816161
==================>
Step: 9740, Train_acc:0.910033
Step: 9740, Val_acc:0.868488
==================>
Step: 9750, Train_acc:0.932012
Step: 9750, Val_acc:0.900242
==================>
Step: 9760, Train_acc:0.898472
Step: 9760, Val_acc:0.835103
==================>
Step: 9770, Train_acc:0.891641
Step: 9770, Val_acc:0.819122
==================>
Step: 9780, Train_acc:0.862246
Step: 9780, Val_acc:0.868622
==================>
Step: 9790, Train_acc:0.904344
Step: 9790, Val_acc:0.864866
==================>
Step: 9800, Train_acc:0.88993
Step: 9800, Val_acc:0.84265
==================>
2017-11-10 21:42:56.151542 ---> Validation_loss: 0.315033
Step: 9810, Train_acc:0.837213
Step: 9810, Val_acc:0.830868
==================>
Step: 9820, Train_acc:0.888374
Step: 9820, Val_acc:0.825704
==================>
Step: 9830, Train_acc:0.895468
Step: 9830, Val_acc:0.922491
==================>
Step: 9840, Train_acc:0.880829
Step: 9840, Val_acc:0.856901
==================>
Step: 9850, Train_acc:0.875475
Step: 9850, Val_acc:0.889211
==================>
Step: 9860, Train_acc:0.893606
Step: 9860, Val_acc:0.858497
==================>
Step: 9870, Train_acc:0.894949
Step: 9870, Val_acc:0.853143
==================>
Step: 9880, Train_acc:0.893832
Step: 9880, Val_acc:0.854656
==================>
Step: 9890, Train_acc:0.884999
Step: 9890, Val_acc:0.837162
==================>
Step: 9900, Train_acc:0.887747
Step: 9900, Val_acc:0.884545
==================>
2017-11-10 21:45:32.587343 ---> Validation_loss: 0.293215
Step: 9910, Train_acc:0.890789
Step: 9910, Val_acc:0.822576
==================>
Step: 9920, Train_acc:0.871963
Step: 9920, Val_acc:0.84994
==================>
Step: 9930, Train_acc:0.912191
Step: 9930, Val_acc:0.796489
==================>
Step: 9940, Train_acc:0.920437
Step: 9940, Val_acc:0.850173
==================>
Step: 9950, Train_acc:0.915227
Step: 9950, Val_acc:0.865389
==================>
Step: 9960, Train_acc:0.852415
Step: 9960, Val_acc:0.87397
==================>
Step: 9970, Train_acc:0.883575
Step: 9970, Val_acc:0.815468
==================>
Step: 9980, Train_acc:0.872717
Step: 9980, Val_acc:0.841254
==================>
Step: 9990, Train_acc:0.868759
Step: 9990, Val_acc:0.815237
==================>
Step: 10000, Train_acc:0.893015
Step: 10000, Val_acc:0.844294
==================>
****************** Epochs completed: 20******************
2017-11-10 21:48:09.313713 ---> Validation_loss: 0.315659
Step: 10010, Train_acc:0.879268
Step: 10010, Val_acc:0.856849
==================>
Step: 10020, Train_acc:0.90439
Step: 10020, Val_acc:0.872644
==================>
Step: 10030, Train_acc:0.891779
Step: 10030, Val_acc:0.840278
==================>
Step: 10040, Train_acc:0.890507
Step: 10040, Val_acc:0.840463
==================>
Step: 10050, Train_acc:0.901816
Step: 10050, Val_acc:0.871785
==================>
Step: 10060, Train_acc:0.89717
Step: 10060, Val_acc:0.841006
==================>
Step: 10070, Train_acc:0.8886
Step: 10070, Val_acc:0.838992
==================>
Step: 10080, Train_acc:0.900789
Step: 10080, Val_acc:0.857346
==================>
Step: 10090, Train_acc:0.904747
Step: 10090, Val_acc:0.864026
==================>
****************** Epochs completed: 3******************
Step: 10100, Train_acc:0.897778
Step: 10100, Val_acc:0.845546
==================>
2017-11-10 21:50:45.775906 ---> Validation_loss: 0.30587
Step: 10110, Train_acc:0.914672
Step: 10110, Val_acc:0.876576
==================>
Step: 10120, Train_acc:0.894838
Step: 10120, Val_acc:0.824795
==================>
Step: 10130, Train_acc:0.902953
Step: 10130, Val_acc:0.867493
==================>
Step: 10140, Train_acc:0.899023
Step: 10140, Val_acc:0.854037
==================>
Step: 10150, Train_acc:0.893328
Step: 10150, Val_acc:0.833058
==================>
Step: 10160, Train_acc:0.884197
Step: 10160, Val_acc:0.887417
==================>
Step: 10170, Train_acc:0.923112
Step: 10170, Val_acc:0.822913
==================>
Step: 10180, Train_acc:0.901965
Step: 10180, Val_acc:0.858521
==================>
Step: 10190, Train_acc:0.91433
Step: 10190, Val_acc:0.847443
==================>
Step: 10200, Train_acc:0.923502
Step: 10200, Val_acc:0.892023
==================>
2017-11-10 21:53:21.366887 ---> Validation_loss: 0.387851
Step: 10210, Train_acc:0.884966
Step: 10210, Val_acc:0.838867
==================>
Step: 10220, Train_acc:0.850494
Step: 10220, Val_acc:0.869683
==================>
Step: 10230, Train_acc:0.941453
Step: 10230, Val_acc:0.854479
==================>
Step: 10240, Train_acc:0.910359
Step: 10240, Val_acc:0.909302
==================>
Step: 10250, Train_acc:0.885447
Step: 10250, Val_acc:0.86882
==================>
Step: 10260, Train_acc:0.899668
Step: 10260, Val_acc:0.869143
==================>
Step: 10270, Train_acc:0.889414
Step: 10270, Val_acc:0.861776
==================>
Step: 10280, Train_acc:0.875072
Step: 10280, Val_acc:0.833748
==================>
Step: 10290, Train_acc:0.894919
Step: 10290, Val_acc:0.887633
==================>
Step: 10300, Train_acc:0.900529
Step: 10300, Val_acc:0.900823
==================>
2017-11-10 21:55:57.177574 ---> Validation_loss: 0.290476
Step: 10310, Train_acc:0.859545
Step: 10310, Val_acc:0.826257
==================>
Step: 10320, Train_acc:0.911992
Step: 10320, Val_acc:0.849761
==================>
Step: 10330, Train_acc:0.900801
Step: 10330, Val_acc:0.847067
==================>
Step: 10340, Train_acc:0.928544
Step: 10340, Val_acc:0.872007
==================>
Step: 10350, Train_acc:0.900999
Step: 10350, Val_acc:0.80907
==================>
Step: 10360, Train_acc:0.904197
Step: 10360, Val_acc:0.819463
==================>
Step: 10370, Train_acc:0.894912
Step: 10370, Val_acc:0.884298
==================>
Step: 10380, Train_acc:0.882147
Step: 10380, Val_acc:0.80785
==================>
Step: 10390, Train_acc:0.929618
Step: 10390, Val_acc:0.875896
==================>
Step: 10400, Train_acc:0.916409
Step: 10400, Val_acc:0.853009
==================>
2017-11-10 21:58:34.357629 ---> Validation_loss: 0.265059
Step: 10410, Train_acc:0.924182
Step: 10410, Val_acc:0.847883
==================>
Step: 10420, Train_acc:0.888079
Step: 10420, Val_acc:0.825601
==================>
Step: 10430, Train_acc:0.93364
Step: 10430, Val_acc:0.867013
==================>
Step: 10440, Train_acc:0.879479
Step: 10440, Val_acc:0.810399
==================>
Step: 10450, Train_acc:0.898564
Step: 10450, Val_acc:0.865439
==================>
Step: 10460, Train_acc:0.898517
Step: 10460, Val_acc:0.857671
==================>
Step: 10470, Train_acc:0.887075
Step: 10470, Val_acc:0.85056
==================>
Step: 10480, Train_acc:0.905826
Step: 10480, Val_acc:0.891407
==================>
Step: 10490, Train_acc:0.931779
Step: 10490, Val_acc:0.843978
==================>
Step: 10500, Train_acc:0.93145
Step: 10500, Val_acc:0.847073
==================>
****************** Epochs completed: 21******************
2017-11-10 22:01:10.523158 ---> Validation_loss: 0.323504
Step: 10510, Train_acc:0.868318
Step: 10510, Val_acc:0.877523
==================>
Step: 10520, Train_acc:0.901786
Step: 10520, Val_acc:0.769819
==================>
Step: 10530, Train_acc:0.916227
Step: 10530, Val_acc:0.829886
==================>
Step: 10540, Train_acc:0.901703
Step: 10540, Val_acc:0.835216
==================>
Step: 10550, Train_acc:0.932136
Step: 10550, Val_acc:0.840396
==================>
Step: 10560, Train_acc:0.883116
Step: 10560, Val_acc:0.871511
==================>
Step: 10570, Train_acc:0.911311
Step: 10570, Val_acc:0.832827
==================>
Step: 10580, Train_acc:0.89234
Step: 10580, Val_acc:0.836018
==================>
Step: 10590, Train_acc:0.878883
Step: 10590, Val_acc:0.891649
==================>
Step: 10600, Train_acc:0.895243
Step: 10600, Val_acc:0.824414
==================>
2017-11-10 22:03:46.626894 ---> Validation_loss: 0.310722
Step: 10610, Train_acc:0.884198
Step: 10610, Val_acc:0.80453
==================>
Step: 10620, Train_acc:0.920992
Step: 10620, Val_acc:0.857794
==================>
Step: 10630, Train_acc:0.909305
Step: 10630, Val_acc:0.846995
==================>
Step: 10640, Train_acc:0.919969
Step: 10640, Val_acc:0.839777
==================>
Step: 10650, Train_acc:0.893512
Step: 10650, Val_acc:0.837787
==================>
Step: 10660, Train_acc:0.893228
Step: 10660, Val_acc:0.836696
==================>
Step: 10670, Train_acc:0.883938
Step: 10670, Val_acc:0.863866
==================>
Step: 10680, Train_acc:0.869631
Step: 10680, Val_acc:0.894835
==================>
Step: 10690, Train_acc:0.857448
Step: 10690, Val_acc:0.783219
==================>
Step: 10700, Train_acc:0.876921
Step: 10700, Val_acc:0.868167
==================>
2017-11-10 22:06:23.064222 ---> Validation_loss: 0.304231
Step: 10710, Train_acc:0.902898
Step: 10710, Val_acc:0.845271
==================>
Step: 10720, Train_acc:0.879269
Step: 10720, Val_acc:0.867062
==================>
Step: 10730, Train_acc:0.905712
Step: 10730, Val_acc:0.903674
==================>
Step: 10740, Train_acc:0.906719
Step: 10740, Val_acc:0.785568
==================>
Step: 10750, Train_acc:0.887797
Step: 10750, Val_acc:0.847114
==================>
Step: 10760, Train_acc:0.879727
Step: 10760, Val_acc:0.88902
==================>
Step: 10770, Train_acc:0.918723
Step: 10770, Val_acc:0.8603
==================>
Step: 10780, Train_acc:0.872344
Step: 10780, Val_acc:0.828031
==================>
Step: 10790, Train_acc:0.866077
Step: 10790, Val_acc:0.839563
==================>
Step: 10800, Train_acc:0.91538
Step: 10800, Val_acc:0.875417
==================>
2017-11-10 22:08:59.434708 ---> Validation_loss: 0.28409
Step: 10810, Train_acc:0.932817
Step: 10810, Val_acc:0.874365
==================>
Step: 10820, Train_acc:0.91069
Step: 10820, Val_acc:0.849049
==================>
Step: 10830, Train_acc:0.863499
Step: 10830, Val_acc:0.82781
==================>
Step: 10840, Train_acc:0.907991
Step: 10840, Val_acc:0.88106
==================>
Step: 10850, Train_acc:0.833068
Step: 10850, Val_acc:0.838147
==================>
Step: 10860, Train_acc:0.905654
Step: 10860, Val_acc:0.846274
==================>
Step: 10870, Train_acc:0.913248
Step: 10870, Val_acc:0.846359
==================>
Step: 10880, Train_acc:0.900546
Step: 10880, Val_acc:0.839292
==================>
Step: 10890, Train_acc:0.938997
Step: 10890, Val_acc:0.9091
==================>
Step: 10900, Train_acc:0.894559
Step: 10900, Val_acc:0.894033
==================>
2017-11-10 22:11:35.882012 ---> Validation_loss: 0.283046
Step: 10910, Train_acc:0.874734
Step: 10910, Val_acc:0.832052
==================>
Step: 10920, Train_acc:0.907076
Step: 10920, Val_acc:0.83535
==================>
Step: 10930, Train_acc:0.902
Step: 10930, Val_acc:0.830457
==================>
Step: 10940, Train_acc:0.924011
Step: 10940, Val_acc:0.849396
==================>
Step: 10950, Train_acc:0.912031
Step: 10950, Val_acc:0.886523
==================>
Step: 10960, Train_acc:0.911219
Step: 10960, Val_acc:0.854293
==================>
Step: 10970, Train_acc:0.91688
Step: 10970, Val_acc:0.899338
==================>
Step: 10980, Train_acc:0.913268
Step: 10980, Val_acc:0.856534
==================>
Step: 10990, Train_acc:0.8887
Step: 10990, Val_acc:0.829235
==================>
Step: 11000, Train_acc:0.895138
Step: 11000, Val_acc:0.861433
==================>
****************** Epochs completed: 22******************
2017-11-10 22:14:11.936780 ---> Validation_loss: 0.232762
Step: 11010, Train_acc:0.882766
Step: 11010, Val_acc:0.806005
==================>
Step: 11020, Train_acc:0.897952
Step: 11020, Val_acc:0.875955
==================>
Step: 11030, Train_acc:0.906082
Step: 11030, Val_acc:0.861206
==================>
Step: 11040, Train_acc:0.90286
Step: 11040, Val_acc:0.84782
==================>
Step: 11050, Train_acc:0.891604
Step: 11050, Val_acc:0.832056
==================>
Step: 11060, Train_acc:0.870712
Step: 11060, Val_acc:0.888809
==================>
Step: 11070, Train_acc:0.931554
Step: 11070, Val_acc:0.802349
==================>
Step: 11080, Train_acc:0.886929
Step: 11080, Val_acc:0.820624
==================>
Step: 11090, Train_acc:0.925732
Step: 11090, Val_acc:0.812928
==================>
Step: 11100, Train_acc:0.917061
Step: 11100, Val_acc:0.825759
==================>
2017-11-10 22:16:48.192668 ---> Validation_loss: 0.299733
Step: 11110, Train_acc:0.872782
Step: 11110, Val_acc:0.860392
==================>
Step: 11120, Train_acc:0.905065
Step: 11120, Val_acc:0.866761
==================>
Step: 11130, Train_acc:0.90381
Step: 11130, Val_acc:0.823964
==================>
Step: 11140, Train_acc:0.931758
Step: 11140, Val_acc:0.87364
==================>
Step: 11150, Train_acc:0.887491
Step: 11150, Val_acc:0.856404
==================>
Step: 11160, Train_acc:0.906072
Step: 11160, Val_acc:0.850192
==================>
Step: 11170, Train_acc:0.922697
Step: 11170, Val_acc:0.802158
==================>
Step: 11180, Train_acc:0.931614
Step: 11180, Val_acc:0.836259
==================>
Step: 11190, Train_acc:0.913
Step: 11190, Val_acc:0.847062
==================>
Step: 11200, Train_acc:0.879788
Step: 11200, Val_acc:0.832482
==================>
2017-11-10 22:19:24.591174 ---> Validation_loss: 0.395898
Step: 11210, Train_acc:0.921261
Step: 11210, Val_acc:0.820193
==================>
Step: 11220, Train_acc:0.896948
Step: 11220, Val_acc:0.862043
==================>
Step: 11230, Train_acc:0.885262
Step: 11230, Val_acc:0.854694
==================>
Step: 11240, Train_acc:0.903575
Step: 11240, Val_acc:0.913394
==================>
Step: 11250, Train_acc:0.877538
Step: 11250, Val_acc:0.813586
==================>
Step: 11260, Train_acc:0.911516
Step: 11260, Val_acc:0.827128
==================>
Step: 11270, Train_acc:0.911916
Step: 11270, Val_acc:0.790726
==================>
Step: 11280, Train_acc:0.925172
Step: 11280, Val_acc:0.854517
==================>
Step: 11290, Train_acc:0.88453
Step: 11290, Val_acc:0.836365
==================>
Step: 11300, Train_acc:0.896733
Step: 11300, Val_acc:0.859193
==================>
2017-11-10 22:22:01.031777 ---> Validation_loss: 0.393291
Step: 11310, Train_acc:0.919858
Step: 11310, Val_acc:0.824904
==================>
Step: 11320, Train_acc:0.87676
Step: 11320, Val_acc:0.815049
==================>
Step: 11330, Train_acc:0.901436
Step: 11330, Val_acc:0.859189
==================>
Step: 11340, Train_acc:0.916768
Step: 11340, Val_acc:0.878296
==================>
Step: 11350, Train_acc:0.887554
Step: 11350, Val_acc:0.861824
==================>
Step: 11360, Train_acc:0.889551
Step: 11360, Val_acc:0.867041
==================>
Step: 11370, Train_acc:0.915729
Step: 11370, Val_acc:0.848923
==================>
Step: 11380, Train_acc:0.923295
Step: 11380, Val_acc:0.837253
==================>
Step: 11390, Train_acc:0.935411
Step: 11390, Val_acc:0.871114
==================>
Step: 11400, Train_acc:0.899329
Step: 11400, Val_acc:0.86421
==================>
2017-11-10 22:24:37.322282 ---> Validation_loss: 0.239884
Step: 11410, Train_acc:0.910074
Step: 11410, Val_acc:0.86067
==================>
Step: 11420, Train_acc:0.903303
Step: 11420, Val_acc:0.846952
==================>
Step: 11430, Train_acc:0.911686
Step: 11430, Val_acc:0.882612
==================>
Step: 11440, Train_acc:0.904081
Step: 11440, Val_acc:0.874266
==================>
Step: 11450, Train_acc:0.926548
Step: 11450, Val_acc:0.812433
==================>
Step: 11460, Train_acc:0.899873
Step: 11460, Val_acc:0.827853
==================>
Step: 11470, Train_acc:0.883332
Step: 11470, Val_acc:0.847838
==================>
Step: 11480, Train_acc:0.860114
Step: 11480, Val_acc:0.881506
==================>
Step: 11490, Train_acc:0.923669
Step: 11490, Val_acc:0.826255
==================>
Step: 11500, Train_acc:0.904989
Step: 11500, Val_acc:0.809561
==================>
****************** Epochs completed: 23******************
2017-11-10 22:27:13.808018 ---> Validation_loss: 0.355567
Step: 11510, Train_acc:0.921826
Step: 11510, Val_acc:0.847537
==================>
Step: 11520, Train_acc:0.937777
Step: 11520, Val_acc:0.869827
==================>
Step: 11530, Train_acc:0.917106
Step: 11530, Val_acc:0.904666
==================>
Step: 11540, Train_acc:0.905867
Step: 11540, Val_acc:0.862961
==================>
Step: 11550, Train_acc:0.930538
Step: 11550, Val_acc:0.857548
==================>
Step: 11560, Train_acc:0.901533
Step: 11560, Val_acc:0.8825
==================>
Step: 11570, Train_acc:0.893735
Step: 11570, Val_acc:0.890968
==================>
Step: 11580, Train_acc:0.928105
Step: 11580, Val_acc:0.821002
==================>
Step: 11590, Train_acc:0.888733
Step: 11590, Val_acc:0.811631
==================>
Step: 11600, Train_acc:0.904349
Step: 11600, Val_acc:0.873001
==================>
2017-11-10 22:29:50.352738 ---> Validation_loss: 0.253663
Step: 11610, Train_acc:0.932727
Step: 11610, Val_acc:0.847838
==================>
Step: 11620, Train_acc:0.906962
Step: 11620, Val_acc:0.881803
==================>
Step: 11630, Train_acc:0.897308
Step: 11630, Val_acc:0.852725
==================>
Step: 11640, Train_acc:0.904006
Step: 11640, Val_acc:0.870552
==================>
Step: 11650, Train_acc:0.880548
Step: 11650, Val_acc:0.861464
==================>
Step: 11660, Train_acc:0.893872
Step: 11660, Val_acc:0.807069
==================>
Step: 11670, Train_acc:0.892507
Step: 11670, Val_acc:0.783022
==================>
Step: 11680, Train_acc:0.926876
Step: 11680, Val_acc:0.830404
==================>
Step: 11690, Train_acc:0.91229
Step: 11690, Val_acc:0.809604
==================>
Step: 11700, Train_acc:0.898042
Step: 11700, Val_acc:0.867493
==================>
2017-11-10 22:32:27.041216 ---> Validation_loss: 0.312145
Step: 11710, Train_acc:0.890897
Step: 11710, Val_acc:0.86627
==================>
Step: 11720, Train_acc:0.892047
Step: 11720, Val_acc:0.874429
==================>
Step: 11730, Train_acc:0.917709
Step: 11730, Val_acc:0.842397
==================>
Step: 11740, Train_acc:0.888398
Step: 11740, Val_acc:0.790265
==================>
Step: 11750, Train_acc:0.859435
Step: 11750, Val_acc:0.87272
==================>
Step: 11760, Train_acc:0.876427
Step: 11760, Val_acc:0.833224
==================>
Step: 11770, Train_acc:0.895712
Step: 11770, Val_acc:0.894039
==================>
Step: 11780, Train_acc:0.902629
Step: 11780, Val_acc:0.872061
==================>
Step: 11790, Train_acc:0.904863
Step: 11790, Val_acc:0.809246
==================>
Step: 11800, Train_acc:0.90535
Step: 11800, Val_acc:0.832025
==================>
2017-11-10 22:35:03.493396 ---> Validation_loss: 0.348854
Step: 11810, Train_acc:0.846448
Step: 11810, Val_acc:0.826143
==================>
Step: 11820, Train_acc:0.909401
Step: 11820, Val_acc:0.86614
==================>
Step: 11830, Train_acc:0.916718
Step: 11830, Val_acc:0.853357
==================>
Step: 11840, Train_acc:0.918186
Step: 11840, Val_acc:0.864334
==================>
Step: 11850, Train_acc:0.909258
Step: 11850, Val_acc:0.835292
==================>
Step: 11860, Train_acc:0.895422
Step: 11860, Val_acc:0.875046
==================>
Step: 11870, Train_acc:0.910367
Step: 11870, Val_acc:0.847775
==================>
Step: 11880, Train_acc:0.905841
Step: 11880, Val_acc:0.855818
==================>
Step: 11890, Train_acc:0.912368
Step: 11890, Val_acc:0.834956
==================>
Step: 11900, Train_acc:0.912098
Step: 11900, Val_acc:0.846002
==================>
2017-11-10 22:37:39.625594 ---> Validation_loss: 0.297875
Step: 11910, Train_acc:0.915278
Step: 11910, Val_acc:0.884758
==================>
Step: 11920, Train_acc:0.918901
Step: 11920, Val_acc:0.847474
==================>
Step: 11930, Train_acc:0.934871
Step: 11930, Val_acc:0.906602
==================>
Step: 11940, Train_acc:0.910748
Step: 11940, Val_acc:0.895737
==================>
Step: 11950, Train_acc:0.884208
Step: 11950, Val_acc:0.846965
==================>
Step: 11960, Train_acc:0.935039
Step: 11960, Val_acc:0.860083
==================>
Step: 11970, Train_acc:0.886543
Step: 11970, Val_acc:0.893575
==================>
Step: 11980, Train_acc:0.900165
Step: 11980, Val_acc:0.877206
==================>
Step: 11990, Train_acc:0.892135
Step: 11990, Val_acc:0.816691
==================>
Step: 12000, Train_acc:0.915261
Step: 12000, Val_acc:0.876044
==================>
****************** Epochs completed: 24******************
2017-11-10 22:40:15.777660 ---> Validation_loss: 0.242227
Step: 12010, Train_acc:0.91567
Step: 12010, Val_acc:0.819174
==================>
Step: 12020, Train_acc:0.923883
Step: 12020, Val_acc:0.832307
==================>
Step: 12030, Train_acc:0.952913
Step: 12030, Val_acc:0.840902
==================>
Step: 12040, Train_acc:0.910431
Step: 12040, Val_acc:0.834619
==================>
Step: 12050, Train_acc:0.889205
Step: 12050, Val_acc:0.862869
==================>
Step: 12060, Train_acc:0.904984
Step: 12060, Val_acc:0.874967
==================>
Step: 12070, Train_acc:0.888884
Step: 12070, Val_acc:0.857057
==================>
Step: 12080, Train_acc:0.938019
Step: 12080, Val_acc:0.861719
==================>
Step: 12090, Train_acc:0.876055
Step: 12090, Val_acc:0.878945
==================>
Step: 12100, Train_acc:0.921639
Step: 12100, Val_acc:0.848435
==================>
2017-11-10 22:42:52.141569 ---> Validation_loss: 0.299424
Step: 12110, Train_acc:0.921085
Step: 12110, Val_acc:0.877134
==================>
Step: 12120, Train_acc:0.908187
Step: 12120, Val_acc:0.884404
==================>
Step: 12130, Train_acc:0.893462
Step: 12130, Val_acc:0.810714
==================>
Step: 12140, Train_acc:0.919978
Step: 12140, Val_acc:0.842577
==================>
Step: 12150, Train_acc:0.884968
Step: 12150, Val_acc:0.890027
==================>
Step: 12160, Train_acc:0.943229
Step: 12160, Val_acc:0.845179
==================>
Step: 12170, Train_acc:0.907917
Step: 12170, Val_acc:0.835654
==================>
Step: 12180, Train_acc:0.881715
Step: 12180, Val_acc:0.864662
==================>
Step: 12190, Train_acc:0.863761
Step: 12190, Val_acc:0.859155
==================>
Step: 12200, Train_acc:0.91767
Step: 12200, Val_acc:0.881942
==================>
2017-11-10 22:45:29.295636 ---> Validation_loss: 0.349746
Step: 12210, Train_acc:0.904408
Step: 12210, Val_acc:0.849619
==================>
Step: 12220, Train_acc:0.911185
Step: 12220, Val_acc:0.843806
==================>
Step: 12230, Train_acc:0.889783
Step: 12230, Val_acc:0.841899
==================>
Step: 12240, Train_acc:0.891389
Step: 12240, Val_acc:0.857659
==================>
Step: 12250, Train_acc:0.919495
Step: 12250, Val_acc:0.842653
==================>
Step: 12260, Train_acc:0.902151
Step: 12260, Val_acc:0.818332
==================>
Step: 12270, Train_acc:0.892264
Step: 12270, Val_acc:0.84057
==================>
Step: 12280, Train_acc:0.903683
Step: 12280, Val_acc:0.913425
==================>
Step: 12290, Train_acc:0.906118
Step: 12290, Val_acc:0.869315
==================>
Step: 12300, Train_acc:0.905787
Step: 12300, Val_acc:0.866374
==================>
2017-11-10 22:48:05.854372 ---> Validation_loss: 0.267755
Step: 12310, Train_acc:0.931834
Step: 12310, Val_acc:0.835253
==================>
Step: 12320, Train_acc:0.897546
Step: 12320, Val_acc:0.846029
==================>
Step: 12330, Train_acc:0.889124
Step: 12330, Val_acc:0.824436
==================>
Step: 12340, Train_acc:0.88649
Step: 12340, Val_acc:0.843171
==================>
Step: 12350, Train_acc:0.90189
Step: 12350, Val_acc:0.879186
==================>
Step: 12360, Train_acc:0.927081
Step: 12360, Val_acc:0.836526
==================>
Step: 12370, Train_acc:0.893765
Step: 12370, Val_acc:0.835826
==================>
Step: 12380, Train_acc:0.900544
Step: 12380, Val_acc:0.806073
==================>
Step: 12390, Train_acc:0.919294
Step: 12390, Val_acc:0.839515
==================>
Step: 12400, Train_acc:0.898363
Step: 12400, Val_acc:0.87467
==================>
2017-11-10 22:50:42.391868 ---> Validation_loss: 0.356641
Step: 12410, Train_acc:0.901733
Step: 12410, Val_acc:0.817854
==================>
Step: 12420, Train_acc:0.898545
Step: 12420, Val_acc:0.833613
==================>
Step: 12430, Train_acc:0.94351
Step: 12430, Val_acc:0.849098
==================>
Step: 12440, Train_acc:0.9449
Step: 12440, Val_acc:0.835264
==================>
Step: 12450, Train_acc:0.925496
Step: 12450, Val_acc:0.854307
==================>
Step: 12460, Train_acc:0.89655
Step: 12460, Val_acc:0.876836
==================>
Step: 12470, Train_acc:0.935558
Step: 12470, Val_acc:0.874097
==================>
Step: 12480, Train_acc:0.941332
Step: 12480, Val_acc:0.867643
==================>
Step: 12490, Train_acc:0.898887
Step: 12490, Val_acc:0.885648
==================>
Step: 12500, Train_acc:0.899154
Step: 12500, Val_acc:0.870395
==================>
****************** Epochs completed: 25******************
2017-11-10 22:53:18.885236 ---> Validation_loss: 0.268893
Step: 12510, Train_acc:0.910704
Step: 12510, Val_acc:0.852695
==================>
Step: 12520, Train_acc:0.894595
Step: 12520, Val_acc:0.89972
==================>
Step: 12530, Train_acc:0.898571
Step: 12530, Val_acc:0.845645
==================>
Step: 12540, Train_acc:0.894786
Step: 12540, Val_acc:0.833641
==================>
Step: 12550, Train_acc:0.891265
Step: 12550, Val_acc:0.886713
==================>
Step: 12560, Train_acc:0.903794
Step: 12560, Val_acc:0.857535
==================>
Step: 12570, Train_acc:0.896846
Step: 12570, Val_acc:0.861116
==================>
Step: 12580, Train_acc:0.916043
Step: 12580, Val_acc:0.821698
==================>
Step: 12590, Train_acc:0.912968
Step: 12590, Val_acc:0.862107
==================>
Step: 12600, Train_acc:0.879811
Step: 12600, Val_acc:0.87926
==================>
2017-11-10 22:55:55.715559 ---> Validation_loss: 0.298851
Step: 12610, Train_acc:0.898989
Step: 12610, Val_acc:0.850382
==================>
Step: 12620, Train_acc:0.929719
Step: 12620, Val_acc:0.8687
==================>
Step: 12630, Train_acc:0.927427
Step: 12630, Val_acc:0.865547
==================>
Step: 12640, Train_acc:0.92016
Step: 12640, Val_acc:0.921285
==================>
Step: 12650, Train_acc:0.938832
Step: 12650, Val_acc:0.848495
==================>
Step: 12660, Train_acc:0.921958
Step: 12660, Val_acc:0.862749
==================>
Step: 12670, Train_acc:0.90274
Step: 12670, Val_acc:0.875734
==================>
Step: 12680, Train_acc:0.926243
Step: 12680, Val_acc:0.842583
==================>
Step: 12690, Train_acc:0.926822
Step: 12690, Val_acc:0.87545
==================>
Step: 12700, Train_acc:0.889143
Step: 12700, Val_acc:0.827638
==================>
2017-11-10 22:58:32.325732 ---> Validation_loss: 0.333255
Step: 12710, Train_acc:0.922723
Step: 12710, Val_acc:0.855378
==================>
Step: 12720, Train_acc:0.901305
Step: 12720, Val_acc:0.89734
==================>
Step: 12730, Train_acc:0.895525
Step: 12730, Val_acc:0.8691
==================>
Step: 12740, Train_acc:0.908331
Step: 12740, Val_acc:0.849453
==================>
Step: 12750, Train_acc:0.928542
Step: 12750, Val_acc:0.872286
==================>
Step: 12760, Train_acc:0.905142
Step: 12760, Val_acc:0.88593
==================>
Step: 12770, Train_acc:0.914623
Step: 12770, Val_acc:0.821019
==================>
Step: 12780, Train_acc:0.928468
Step: 12780, Val_acc:0.8363
==================>
Step: 12790, Train_acc:0.90977
Step: 12790, Val_acc:0.882004
==================>
Step: 12800, Train_acc:0.922955
Step: 12800, Val_acc:0.829468
==================>
2017-11-10 23:01:08.843951 ---> Validation_loss: 0.279785
Step: 12810, Train_acc:0.893771
Step: 12810, Val_acc:0.885482
==================>
Step: 12820, Train_acc:0.918746
Step: 12820, Val_acc:0.829852
==================>
Step: 12830, Train_acc:0.872673
Step: 12830, Val_acc:0.843041
==================>
Step: 12840, Train_acc:0.905411
Step: 12840, Val_acc:0.860092
==================>
Step: 12850, Train_acc:0.876492
Step: 12850, Val_acc:0.860442
==================>
Step: 12860, Train_acc:0.90598
Step: 12860, Val_acc:0.860111
==================>
Step: 12870, Train_acc:0.909565
Step: 12870, Val_acc:0.897213
==================>
Step: 12880, Train_acc:0.908812
Step: 12880, Val_acc:0.834393
==================>
Step: 12890, Train_acc:0.900342
Step: 12890, Val_acc:0.873613
==================>
Step: 12900, Train_acc:0.942412
Step: 12900, Val_acc:0.832273
==================>
2017-11-10 23:03:45.368089 ---> Validation_loss: 0.359515
Step: 12910, Train_acc:0.907335
Step: 12910, Val_acc:0.811346
==================>
Step: 12920, Train_acc:0.912054
Step: 12920, Val_acc:0.866704
==================>
Step: 12930, Train_acc:0.878124
Step: 12930, Val_acc:0.831221
==================>
Step: 12940, Train_acc:0.90192
Step: 12940, Val_acc:0.843477
==================>
Step: 12950, Train_acc:0.92198
Step: 12950, Val_acc:0.860443
==================>
Step: 12960, Train_acc:0.880889
Step: 12960, Val_acc:0.857091
==================>
Step: 12970, Train_acc:0.911058
Step: 12970, Val_acc:0.867416
==================>
Step: 12980, Train_acc:0.914418
Step: 12980, Val_acc:0.882963
==================>
Step: 12990, Train_acc:0.91193
Step: 12990, Val_acc:0.895078
==================>
Step: 13000, Train_acc:0.898947
Step: 13000, Val_acc:0.831895
==================>
****************** Epochs completed: 26******************
2017-11-10 23:06:21.821163 ---> Validation_loss: 0.231105
Step: 13010, Train_acc:0.908997
Step: 13010, Val_acc:0.852202
==================>
Step: 13020, Train_acc:0.887201
Step: 13020, Val_acc:0.856219
==================>
Step: 13030, Train_acc:0.887573
Step: 13030, Val_acc:0.84188
==================>
Step: 13040, Train_acc:0.922968
Step: 13040, Val_acc:0.847026
==================>
Step: 13050, Train_acc:0.925286
Step: 13050, Val_acc:0.847188
==================>
Step: 13060, Train_acc:0.913324
Step: 13060, Val_acc:0.824885
==================>
Step: 13070, Train_acc:0.882045
Step: 13070, Val_acc:0.839291
==================>
Step: 13080, Train_acc:0.916973
Step: 13080, Val_acc:0.872126
==================>
Step: 13090, Train_acc:0.891559
Step: 13090, Val_acc:0.857869
==================>
Step: 13100, Train_acc:0.919631
Step: 13100, Val_acc:0.891659
==================>
2017-11-10 23:08:58.203574 ---> Validation_loss: 0.379536
Step: 13110, Train_acc:0.868187
Step: 13110, Val_acc:0.866948
==================>
Step: 13120, Train_acc:0.933778
Step: 13120, Val_acc:0.856243
==================>
Step: 13130, Train_acc:0.913544
Step: 13130, Val_acc:0.890044
==================>
Step: 13140, Train_acc:0.946123
Step: 13140, Val_acc:0.894856
==================>
Step: 13150, Train_acc:0.914147
Step: 13150, Val_acc:0.885692
==================>
Step: 13160, Train_acc:0.933307
Step: 13160, Val_acc:0.853599
==================>
Step: 13170, Train_acc:0.888602
Step: 13170, Val_acc:0.909495
==================>
Step: 13180, Train_acc:0.877567
Step: 13180, Val_acc:0.863734
==================>
Step: 13190, Train_acc:0.885272
Step: 13190, Val_acc:0.889781
==================>
Step: 13200, Train_acc:0.934585
Step: 13200, Val_acc:0.874679
==================>
2017-11-10 23:11:34.493571 ---> Validation_loss: 0.306148
Step: 13210, Train_acc:0.898053
Step: 13210, Val_acc:0.898538
==================>
Step: 13220, Train_acc:0.903458
Step: 13220, Val_acc:0.851143
==================>
Step: 13230, Train_acc:0.889968
Step: 13230, Val_acc:0.90088
==================>
Step: 13240, Train_acc:0.908304
Step: 13240, Val_acc:0.86489
==================>
Step: 13250, Train_acc:0.922719
Step: 13250, Val_acc:0.875322
==================>
Step: 13260, Train_acc:0.921433
Step: 13260, Val_acc:0.85023
==================>
Step: 13270, Train_acc:0.900197
Step: 13270, Val_acc:0.873806
==================>
Step: 13280, Train_acc:0.866807
Step: 13280, Val_acc:0.878616
==================>
Step: 13290, Train_acc:0.91449
Step: 13290, Val_acc:0.854197
==================>
Step: 13300, Train_acc:0.890876
Step: 13300, Val_acc:0.859334
==================>
2017-11-10 23:14:10.985274 ---> Validation_loss: 0.331136
Step: 13310, Train_acc:0.902916
Step: 13310, Val_acc:0.839308
==================>
Step: 13320, Train_acc:0.898251
Step: 13320, Val_acc:0.887251
==================>
Step: 13330, Train_acc:0.900828
Step: 13330, Val_acc:0.852937
==================>
Step: 13340, Train_acc:0.896168
Step: 13340, Val_acc:0.836439
==================>
Step: 13350, Train_acc:0.920341
Step: 13350, Val_acc:0.845271
==================>
Step: 13360, Train_acc:0.918082
Step: 13360, Val_acc:0.872634
==================>
Step: 13370, Train_acc:0.952073
Step: 13370, Val_acc:0.824093
==================>
Step: 13380, Train_acc:0.901278
Step: 13380, Val_acc:0.865906
==================>
Step: 13390, Train_acc:0.913864
Step: 13390, Val_acc:0.826545
==================>
Step: 13400, Train_acc:0.914707
Step: 13400, Val_acc:0.870457
==================>
2017-11-10 23:16:47.495729 ---> Validation_loss: 0.284526
Step: 13410, Train_acc:0.909512
Step: 13410, Val_acc:0.855301
==================>
Step: 13420, Train_acc:0.888679
Step: 13420, Val_acc:0.85777
==================>
Step: 13430, Train_acc:0.901461
Step: 13430, Val_acc:0.888762
==================>
Step: 13440, Train_acc:0.941522
Step: 13440, Val_acc:0.883254
==================>
Step: 13450, Train_acc:0.908132
Step: 13450, Val_acc:0.87734
==================>
****************** Epochs completed: 4******************
Step: 13460, Train_acc:0.910255
Step: 13460, Val_acc:0.882889
==================>
Step: 13470, Train_acc:0.909182
Step: 13470, Val_acc:0.881924
==================>
Step: 13480, Train_acc:0.895461
Step: 13480, Val_acc:0.831931
==================>
Step: 13490, Train_acc:0.932593
Step: 13490, Val_acc:0.852179
==================>
Step: 13500, Train_acc:0.925874
Step: 13500, Val_acc:0.817157
==================>
****************** Epochs completed: 27******************
2017-11-10 23:19:23.848251 ---> Validation_loss: 0.254811
Step: 13510, Train_acc:0.87714
Step: 13510, Val_acc:0.861643
==================>
Step: 13520, Train_acc:0.922766
Step: 13520, Val_acc:0.83231
==================>
Step: 13530, Train_acc:0.912384
Step: 13530, Val_acc:0.819296
==================>
Step: 13540, Train_acc:0.896729
Step: 13540, Val_acc:0.861576
==================>
Step: 13550, Train_acc:0.914847
Step: 13550, Val_acc:0.874187
==================>
Step: 13560, Train_acc:0.921377
Step: 13560, Val_acc:0.909308
==================>
Step: 13570, Train_acc:0.923018
Step: 13570, Val_acc:0.827466
==================>
Step: 13580, Train_acc:0.905249
Step: 13580, Val_acc:0.830022
==================>
Step: 13590, Train_acc:0.949286
Step: 13590, Val_acc:0.862435
==================>
Step: 13600, Train_acc:0.914884
Step: 13600, Val_acc:0.872175
==================>
2017-11-10 23:21:59.697197 ---> Validation_loss: 0.347738
Step: 13610, Train_acc:0.92157
Step: 13610, Val_acc:0.854972
==================>
Step: 13620, Train_acc:0.931213
Step: 13620, Val_acc:0.861528
==================>
Step: 13630, Train_acc:0.919528
Step: 13630, Val_acc:0.907201
==================>
Step: 13640, Train_acc:0.901876
Step: 13640, Val_acc:0.861688
==================>
Step: 13650, Train_acc:0.906047
Step: 13650, Val_acc:0.804534
==================>
Step: 13660, Train_acc:0.934055
Step: 13660, Val_acc:0.87952
==================>
Step: 13670, Train_acc:0.929653
Step: 13670, Val_acc:0.85119
==================>
Step: 13680, Train_acc:0.904012
Step: 13680, Val_acc:0.837739
==================>
Step: 13690, Train_acc:0.902552
Step: 13690, Val_acc:0.859337
==================>
Step: 13700, Train_acc:0.930028
Step: 13700, Val_acc:0.88748
==================>
2017-11-10 23:24:35.725796 ---> Validation_loss: 0.261869
Step: 13710, Train_acc:0.935032
Step: 13710, Val_acc:0.84359
==================>
Step: 13720, Train_acc:0.916256
Step: 13720, Val_acc:0.859791
==================>
Step: 13730, Train_acc:0.933689
Step: 13730, Val_acc:0.891062
==================>
Step: 13740, Train_acc:0.926857
Step: 13740, Val_acc:0.832876
==================>
Step: 13750, Train_acc:0.931416
Step: 13750, Val_acc:0.854099
==================>
Step: 13760, Train_acc:0.903343
Step: 13760, Val_acc:0.857135
==================>
Step: 13770, Train_acc:0.939299
Step: 13770, Val_acc:0.863934
==================>
Step: 13780, Train_acc:0.926564
Step: 13780, Val_acc:0.867042
==================>
Step: 13790, Train_acc:0.939017
Step: 13790, Val_acc:0.856787
==================>
Step: 13800, Train_acc:0.929617
Step: 13800, Val_acc:0.844041
==================>
2017-11-10 23:27:12.161951 ---> Validation_loss: 0.288067
Step: 13810, Train_acc:0.929329
Step: 13810, Val_acc:0.838175
==================>
Step: 13820, Train_acc:0.928948
Step: 13820, Val_acc:0.841311
==================>
Step: 13830, Train_acc:0.919176
Step: 13830, Val_acc:0.851891
==================>
Step: 13840, Train_acc:0.92074
Step: 13840, Val_acc:0.838746
==================>
Step: 13850, Train_acc:0.914368
Step: 13850, Val_acc:0.850758
==================>
Step: 13860, Train_acc:0.918273
Step: 13860, Val_acc:0.859811
==================>
Step: 13870, Train_acc:0.921864
Step: 13870, Val_acc:0.917007
==================>
Step: 13880, Train_acc:0.919208
Step: 13880, Val_acc:0.825201
==================>
Step: 13890, Train_acc:0.921877
Step: 13890, Val_acc:0.869908
==================>
Step: 13900, Train_acc:0.936584
Step: 13900, Val_acc:0.847924
==================>
2017-11-10 23:29:48.629396 ---> Validation_loss: 0.358543
Step: 13910, Train_acc:0.927327
Step: 13910, Val_acc:0.891497
==================>
Step: 13920, Train_acc:0.89209
Step: 13920, Val_acc:0.893807
==================>
Step: 13930, Train_acc:0.907229
Step: 13930, Val_acc:0.861718
==================>
Step: 13940, Train_acc:0.908324
Step: 13940, Val_acc:0.865963
==================>
Step: 13950, Train_acc:0.915674
Step: 13950, Val_acc:0.828064
==================>
Step: 13960, Train_acc:0.921613
Step: 13960, Val_acc:0.868796
==================>
Step: 13970, Train_acc:0.927828
Step: 13970, Val_acc:0.844255
==================>
Step: 13980, Train_acc:0.897003
Step: 13980, Val_acc:0.893649
==================>
Step: 13990, Train_acc:0.908737
Step: 13990, Val_acc:0.881752
==================>
Step: 14000, Train_acc:0.913638
Step: 14000, Val_acc:0.87281
==================>
****************** Epochs completed: 28******************
2017-11-10 23:32:24.584673 ---> Validation_loss: 0.28453
Step: 14010, Train_acc:0.909751
Step: 14010, Val_acc:0.834773
==================>
Step: 14020, Train_acc:0.927031
Step: 14020, Val_acc:0.850151
==================>
Step: 14030, Train_acc:0.928647
Step: 14030, Val_acc:0.839894
==================>
Step: 14040, Train_acc:0.907051
Step: 14040, Val_acc:0.856034
==================>
Step: 14050, Train_acc:0.92157
Step: 14050, Val_acc:0.842277
==================>
Step: 14060, Train_acc:0.90433
Step: 14060, Val_acc:0.875095
==================>
Step: 14070, Train_acc:0.895698
Step: 14070, Val_acc:0.861992
==================>
Step: 14080, Train_acc:0.930544
Step: 14080, Val_acc:0.895859
==================>
Step: 14090, Train_acc:0.93418
Step: 14090, Val_acc:0.892064
==================>
Step: 14100, Train_acc:0.893884
Step: 14100, Val_acc:0.859517
==================>
2017-11-10 23:35:00.779535 ---> Validation_loss: 0.306935
Step: 14110, Train_acc:0.92621
Step: 14110, Val_acc:0.840841
==================>
Step: 14120, Train_acc:0.931953
Step: 14120, Val_acc:0.829337
==================>
Step: 14130, Train_acc:0.931451
Step: 14130, Val_acc:0.84214
==================>
Step: 14140, Train_acc:0.894653
Step: 14140, Val_acc:0.884639
==================>
Step: 14150, Train_acc:0.925048
Step: 14150, Val_acc:0.819573
==================>
Step: 14160, Train_acc:0.896555
Step: 14160, Val_acc:0.883296
==================>
Step: 14170, Train_acc:0.934995
Step: 14170, Val_acc:0.864014
==================>
Step: 14180, Train_acc:0.925675
Step: 14180, Val_acc:0.84885
==================>
Step: 14190, Train_acc:0.933109
Step: 14190, Val_acc:0.818468
==================>
Step: 14200, Train_acc:0.910559
Step: 14200, Val_acc:0.859215
==================>
2017-11-10 23:37:37.141638 ---> Validation_loss: 0.288264
Step: 14210, Train_acc:0.914135
Step: 14210, Val_acc:0.850066
==================>
Step: 14220, Train_acc:0.934408
Step: 14220, Val_acc:0.850294
==================>
Step: 14230, Train_acc:0.924067
Step: 14230, Val_acc:0.877119
==================>
Step: 14240, Train_acc:0.905963
Step: 14240, Val_acc:0.869695
==================>
Step: 14250, Train_acc:0.909298
Step: 14250, Val_acc:0.861422
==================>
Step: 14260, Train_acc:0.912571
Step: 14260, Val_acc:0.870974
==================>
Step: 14270, Train_acc:0.945474
Step: 14270, Val_acc:0.866572
==================>
Step: 14280, Train_acc:0.922013
Step: 14280, Val_acc:0.877144
==================>
Step: 14290, Train_acc:0.921144
Step: 14290, Val_acc:0.883724
==================>
Step: 14300, Train_acc:0.887842
Step: 14300, Val_acc:0.888131
==================>
2017-11-10 23:40:13.502567 ---> Validation_loss: 0.377464
Step: 14310, Train_acc:0.921766
Step: 14310, Val_acc:0.838593
==================>
Step: 14320, Train_acc:0.898406
Step: 14320, Val_acc:0.858683
==================>
Step: 14330, Train_acc:0.913094
Step: 14330, Val_acc:0.825167
==================>
Step: 14340, Train_acc:0.938909
Step: 14340, Val_acc:0.912495
==================>
Step: 14350, Train_acc:0.932653
Step: 14350, Val_acc:0.835964
==================>
Step: 14360, Train_acc:0.910496
Step: 14360, Val_acc:0.859114
==================>
Step: 14370, Train_acc:0.910212
Step: 14370, Val_acc:0.856677
==================>
Step: 14380, Train_acc:0.934663
Step: 14380, Val_acc:0.856666
==================>
Step: 14390, Train_acc:0.925756
Step: 14390, Val_acc:0.832446
==================>
Step: 14400, Train_acc:0.9233
Step: 14400, Val_acc:0.86064
==================>
2017-11-10 23:42:49.979598 ---> Validation_loss: 0.286385
Step: 14410, Train_acc:0.948052
Step: 14410, Val_acc:0.895005
==================>
Step: 14420, Train_acc:0.900693
Step: 14420, Val_acc:0.859916
==================>
Step: 14430, Train_acc:0.909935
Step: 14430, Val_acc:0.842733
==================>
Step: 14440, Train_acc:0.946886
Step: 14440, Val_acc:0.869963
==================>
Step: 14450, Train_acc:0.938187
Step: 14450, Val_acc:0.823524
==================>
Step: 14460, Train_acc:0.922593
Step: 14460, Val_acc:0.869711
==================>
Step: 14470, Train_acc:0.911112
Step: 14470, Val_acc:0.835645
==================>
Step: 14480, Train_acc:0.939208
Step: 14480, Val_acc:0.839991
==================>
Step: 14490, Train_acc:0.908502
Step: 14490, Val_acc:0.818015
==================>
Step: 14500, Train_acc:0.929988
Step: 14500, Val_acc:0.850548
==================>
****************** Epochs completed: 29******************
2017-11-10 23:45:26.448499 ---> Validation_loss: 0.370068
Step: 14510, Train_acc:0.916515
Step: 14510, Val_acc:0.820647
==================>
Step: 14520, Train_acc:0.924586
Step: 14520, Val_acc:0.901736
==================>
Step: 14530, Train_acc:0.908694
Step: 14530, Val_acc:0.828613
==================>
Step: 14540, Train_acc:0.914146
Step: 14540, Val_acc:0.844937
==================>
Step: 14550, Train_acc:0.909993
Step: 14550, Val_acc:0.890819
==================>
Step: 14560, Train_acc:0.922079
Step: 14560, Val_acc:0.836504
==================>
Step: 14570, Train_acc:0.89958
Step: 14570, Val_acc:0.874269
==================>
Step: 14580, Train_acc:0.92835
Step: 14580, Val_acc:0.873274
==================>
Step: 14590, Train_acc:0.943798
Step: 14590, Val_acc:0.867299
==================>
Step: 14600, Train_acc:0.902445
Step: 14600, Val_acc:0.906511
==================>
2017-11-10 23:48:02.982103 ---> Validation_loss: 0.266709
Step: 14610, Train_acc:0.918037
Step: 14610, Val_acc:0.895442
==================>
Step: 14620, Train_acc:0.92313
Step: 14620, Val_acc:0.868269
==================>
Step: 14630, Train_acc:0.904891
Step: 14630, Val_acc:0.831139
==================>
Step: 14640, Train_acc:0.935186
Step: 14640, Val_acc:0.893289
==================>
Step: 14650, Train_acc:0.899086
Step: 14650, Val_acc:0.856
==================>
Step: 14660, Train_acc:0.92589
Step: 14660, Val_acc:0.85478
==================>
Step: 14670, Train_acc:0.93704
Step: 14670, Val_acc:0.879105
==================>
Step: 14680, Train_acc:0.919802
Step: 14680, Val_acc:0.81656
==================>
Step: 14690, Train_acc:0.927024
Step: 14690, Val_acc:0.828942
==================>
Step: 14700, Train_acc:0.928199
Step: 14700, Val_acc:0.884633
==================>
2017-11-10 23:50:39.293073 ---> Validation_loss: 0.253703
Step: 14710, Train_acc:0.907999
Step: 14710, Val_acc:0.849308
==================>
Step: 14720, Train_acc:0.934126
Step: 14720, Val_acc:0.856675
==================>
Step: 14730, Train_acc:0.904268
Step: 14730, Val_acc:0.837428
==================>
Step: 14740, Train_acc:0.937406
Step: 14740, Val_acc:0.837364
==================>
Step: 14750, Train_acc:0.925769
Step: 14750, Val_acc:0.856687
==================>
Step: 14760, Train_acc:0.910099
Step: 14760, Val_acc:0.889517
==================>
Step: 14770, Train_acc:0.919486
Step: 14770, Val_acc:0.869512
==================>
Step: 14780, Train_acc:0.915282
Step: 14780, Val_acc:0.922163
==================>
Step: 14790, Train_acc:0.923683
Step: 14790, Val_acc:0.842568
==================>
Step: 14800, Train_acc:0.952217
Step: 14800, Val_acc:0.910717
==================>
2017-11-10 23:53:15.791799 ---> Validation_loss: 0.341904
Step: 14810, Train_acc:0.944023
Step: 14810, Val_acc:0.83188
==================>
Step: 14820, Train_acc:0.897333
Step: 14820, Val_acc:0.895352
==================>
Step: 14830, Train_acc:0.938002
Step: 14830, Val_acc:0.869835
==================>
Step: 14840, Train_acc:0.936809
Step: 14840, Val_acc:0.914551
==================>
Step: 14850, Train_acc:0.933329
Step: 14850, Val_acc:0.868761
==================>
Step: 14860, Train_acc:0.946759
Step: 14860, Val_acc:0.857136
==================>
Step: 14870, Train_acc:0.90196
Step: 14870, Val_acc:0.853693
==================>
Step: 14880, Train_acc:0.930375
Step: 14880, Val_acc:0.873966
==================>
Step: 14890, Train_acc:0.949608
Step: 14890, Val_acc:0.812896
==================>
Step: 14900, Train_acc:0.919606
Step: 14900, Val_acc:0.842769
==================>
2017-11-10 23:55:51.773860 ---> Validation_loss: 0.255251
Step: 14910, Train_acc:0.919065
Step: 14910, Val_acc:0.8699
==================>
Step: 14920, Train_acc:0.904103
Step: 14920, Val_acc:0.822634
==================>
Step: 14930, Train_acc:0.93829
Step: 14930, Val_acc:0.873269
==================>
Step: 14940, Train_acc:0.922859
Step: 14940, Val_acc:0.851134
==================>
Step: 14950, Train_acc:0.933209
Step: 14950, Val_acc:0.882349
==================>
Step: 14960, Train_acc:0.909742
Step: 14960, Val_acc:0.869949
==================>
Step: 14970, Train_acc:0.925536
Step: 14970, Val_acc:0.805896
==================>
Step: 14980, Train_acc:0.914241
Step: 14980, Val_acc:0.864772
==================>
Step: 14990, Train_acc:0.91424
Step: 14990, Val_acc:0.890758
==================>
Step: 15000, Train_acc:0.924495
Step: 15000, Val_acc:0.825056
==================>
****************** Epochs completed: 30******************
2017-11-10 23:58:28.433338 ---> Validation_loss: 0.22595
Step: 15010, Train_acc:0.892927
Step: 15010, Val_acc:0.894994
==================>
Step: 15020, Train_acc:0.912053
Step: 15020, Val_acc:0.852412
==================>
Step: 15030, Train_acc:0.897089
Step: 15030, Val_acc:0.845454
==================>
Step: 15040, Train_acc:0.910101
Step: 15040, Val_acc:0.862721
==================>
Step: 15050, Train_acc:0.910128
Step: 15050, Val_acc:0.861903
==================>
Step: 15060, Train_acc:0.920688
Step: 15060, Val_acc:0.910631
==================>
Step: 15070, Train_acc:0.904703
Step: 15070, Val_acc:0.849187
==================>
Step: 15080, Train_acc:0.937007
Step: 15080, Val_acc:0.864576
==================>
Step: 15090, Train_acc:0.934739
Step: 15090, Val_acc:0.874401
==================>
Step: 15100, Train_acc:0.937651
Step: 15100, Val_acc:0.842373
==================>
2017-11-11 00:01:04.703520 ---> Validation_loss: 0.334632
Step: 15110, Train_acc:0.913953
Step: 15110, Val_acc:0.882994
==================>
Step: 15120, Train_acc:0.932949
Step: 15120, Val_acc:0.85699
==================>
Step: 15130, Train_acc:0.945406
Step: 15130, Val_acc:0.868135
==================>
Step: 15140, Train_acc:0.908673
Step: 15140, Val_acc:0.826079
==================>
Step: 15150, Train_acc:0.919414
Step: 15150, Val_acc:0.833906
==================>
Step: 15160, Train_acc:0.926162
Step: 15160, Val_acc:0.900896
==================>
Step: 15170, Train_acc:0.908015
Step: 15170, Val_acc:0.891885
==================>
Step: 15180, Train_acc:0.902364
Step: 15180, Val_acc:0.837142
==================>
Step: 15190, Train_acc:0.940215
Step: 15190, Val_acc:0.885714
==================>
Step: 15200, Train_acc:0.921499
Step: 15200, Val_acc:0.862662
==================>
2017-11-11 00:03:41.841024 ---> Validation_loss: 0.335906
Step: 15210, Train_acc:0.90597
Step: 15210, Val_acc:0.849525
==================>
Step: 15220, Train_acc:0.917708
Step: 15220, Val_acc:0.806216
==================>
Step: 15230, Train_acc:0.917285
Step: 15230, Val_acc:0.839254
==================>
Step: 15240, Train_acc:0.922443
Step: 15240, Val_acc:0.883514
==================>
Step: 15250, Train_acc:0.913562
Step: 15250, Val_acc:0.863961
==================>
Step: 15260, Train_acc:0.928975
Step: 15260, Val_acc:0.874303
==================>
Step: 15270, Train_acc:0.927074
Step: 15270, Val_acc:0.861129
==================>
Step: 15280, Train_acc:0.927346
Step: 15280, Val_acc:0.84089
==================>
Step: 15290, Train_acc:0.929692
Step: 15290, Val_acc:0.844088
==================>
Step: 15300, Train_acc:0.912628
Step: 15300, Val_acc:0.919774
==================>
2017-11-11 00:06:18.337395 ---> Validation_loss: 0.351833
Step: 15310, Train_acc:0.939605
Step: 15310, Val_acc:0.849927
==================>
Step: 15320, Train_acc:0.919637
Step: 15320, Val_acc:0.882882
==================>
Step: 15330, Train_acc:0.90517
Step: 15330, Val_acc:0.869719
==================>
Step: 15340, Train_acc:0.914729
Step: 15340, Val_acc:0.844758
==================>
Step: 15350, Train_acc:0.916238
Step: 15350, Val_acc:0.880203
==================>
Step: 15360, Train_acc:0.925207
Step: 15360, Val_acc:0.898376
==================>
Step: 15370, Train_acc:0.918357
Step: 15370, Val_acc:0.876779
==================>
Step: 15380, Train_acc:0.906456
Step: 15380, Val_acc:0.878999
==================>
Step: 15390, Train_acc:0.926555
Step: 15390, Val_acc:0.821859
==================>
Step: 15400, Train_acc:0.910581
Step: 15400, Val_acc:0.86349
==================>
2017-11-11 00:08:54.535790 ---> Validation_loss: 0.241445
Step: 15410, Train_acc:0.922585
Step: 15410, Val_acc:0.818081
==================>
Step: 15420, Train_acc:0.912333
Step: 15420, Val_acc:0.855769
==================>
Step: 15430, Train_acc:0.915311
Step: 15430, Val_acc:0.882837
==================>
Step: 15440, Train_acc:0.915436
Step: 15440, Val_acc:0.858899
==================>
Step: 15450, Train_acc:0.914965
Step: 15450, Val_acc:0.848158
==================>
Step: 15460, Train_acc:0.944208
Step: 15460, Val_acc:0.870489
==================>
Step: 15470, Train_acc:0.941527
Step: 15470, Val_acc:0.909347
==================>
Step: 15480, Train_acc:0.936042
Step: 15480, Val_acc:0.869941
==================>
Step: 15490, Train_acc:0.919703
Step: 15490, Val_acc:0.885115
==================>
Step: 15500, Train_acc:0.934626
Step: 15500, Val_acc:0.844457
==================>
****************** Epochs completed: 31******************
2017-11-11 00:11:31.343573 ---> Validation_loss: 0.324557
Step: 15510, Train_acc:0.932801
Step: 15510, Val_acc:0.862198
==================>
Step: 15520, Train_acc:0.924522
Step: 15520, Val_acc:0.877223
==================>
Step: 15530, Train_acc:0.904248
Step: 15530, Val_acc:0.836364
==================>
Step: 15540, Train_acc:0.93454
Step: 15540, Val_acc:0.848885
==================>
Step: 15550, Train_acc:0.901537
Step: 15550, Val_acc:0.88687
==================>
Step: 15560, Train_acc:0.938372
Step: 15560, Val_acc:0.847349
==================>
Step: 15570, Train_acc:0.92572
Step: 15570, Val_acc:0.868495
==================>
Step: 15580, Train_acc:0.913904
Step: 15580, Val_acc:0.835901
==================>
Step: 15590, Train_acc:0.935737
Step: 15590, Val_acc:0.910754
==================>
Step: 15600, Train_acc:0.928657
Step: 15600, Val_acc:0.912885
==================>
2017-11-11 00:14:08.171626 ---> Validation_loss: 0.359783
Step: 15610, Train_acc:0.944363
Step: 15610, Val_acc:0.898722
==================>
Step: 15620, Train_acc:0.921871
Step: 15620, Val_acc:0.849614
==================>
Step: 15630, Train_acc:0.91139
Step: 15630, Val_acc:0.856514
==================>
Step: 15640, Train_acc:0.871234
Step: 15640, Val_acc:0.862327
==================>
Step: 15650, Train_acc:0.935802
Step: 15650, Val_acc:0.842806
==================>
Step: 15660, Train_acc:0.925525
Step: 15660, Val_acc:0.89025
==================>
Step: 15670, Train_acc:0.935918
Step: 15670, Val_acc:0.842919
==================>
Step: 15680, Train_acc:0.920197
Step: 15680, Val_acc:0.84481
==================>
Step: 15690, Train_acc:0.930989
Step: 15690, Val_acc:0.844636
==================>
Step: 15700, Train_acc:0.933715
Step: 15700, Val_acc:0.861583
==================>
2017-11-11 00:16:44.595756 ---> Validation_loss: 0.302456
Step: 15710, Train_acc:0.914606
Step: 15710, Val_acc:0.873667
==================>
Step: 15720, Train_acc:0.912924
Step: 15720, Val_acc:0.904084
==================>
Step: 15730, Train_acc:0.906938
Step: 15730, Val_acc:0.81694
==================>
Step: 15740, Train_acc:0.926295
Step: 15740, Val_acc:0.858945
==================>
Step: 15750, Train_acc:0.921055
Step: 15750, Val_acc:0.927852
==================>
Step: 15760, Train_acc:0.94168
Step: 15760, Val_acc:0.837393
==================>
Step: 15770, Train_acc:0.939154
Step: 15770, Val_acc:0.879144
==================>
Step: 15780, Train_acc:0.924036
Step: 15780, Val_acc:0.848701
==================>
Step: 15790, Train_acc:0.91532
Step: 15790, Val_acc:0.864519
==================>
Step: 15800, Train_acc:0.914183
Step: 15800, Val_acc:0.843566
==================>
2017-11-11 00:19:21.072311 ---> Validation_loss: 0.217186
Step: 15810, Train_acc:0.934929
Step: 15810, Val_acc:0.839548
==================>
Step: 15820, Train_acc:0.927238
Step: 15820, Val_acc:0.862561
==================>
Step: 15830, Train_acc:0.913242
Step: 15830, Val_acc:0.855754
==================>
Step: 15840, Train_acc:0.937533
Step: 15840, Val_acc:0.870394
==================>
Step: 15850, Train_acc:0.901873
Step: 15850, Val_acc:0.865944
==================>
Step: 15860, Train_acc:0.90537
Step: 15860, Val_acc:0.876774
==================>
Step: 15870, Train_acc:0.925409
Step: 15870, Val_acc:0.849976
==================>
Step: 15880, Train_acc:0.913456
Step: 15880, Val_acc:0.843684
==================>
Step: 15890, Train_acc:0.905978
Step: 15890, Val_acc:0.838461
==================>
Step: 15900, Train_acc:0.935248
Step: 15900, Val_acc:0.84162
==================>
2017-11-11 00:21:57.460658 ---> Validation_loss: 0.316606
Step: 15910, Train_acc:0.939178
Step: 15910, Val_acc:0.873104
==================>
Step: 15920, Train_acc:0.943717
Step: 15920, Val_acc:0.84502
==================>
Step: 15930, Train_acc:0.905509
Step: 15930, Val_acc:0.875299
==================>
Step: 15940, Train_acc:0.914489
Step: 15940, Val_acc:0.895448
==================>
Step: 15950, Train_acc:0.933981
Step: 15950, Val_acc:0.861858
==================>
Step: 15960, Train_acc:0.917095
Step: 15960, Val_acc:0.847943
==================>
Step: 15970, Train_acc:0.907024
Step: 15970, Val_acc:0.834507
==================>
Step: 15980, Train_acc:0.908312
Step: 15980, Val_acc:0.862817
==================>
Step: 15990, Train_acc:0.930433
Step: 15990, Val_acc:0.822218
==================>
Step: 16000, Train_acc:0.92906
Step: 16000, Val_acc:0.844485
==================>
****************** Epochs completed: 32******************
2017-11-11 00:24:33.965665 ---> Validation_loss: 0.212631
Step: 16010, Train_acc:0.932963
Step: 16010, Val_acc:0.876964
==================>
Step: 16020, Train_acc:0.944066
Step: 16020, Val_acc:0.873268
==================>
Step: 16030, Train_acc:0.917988
Step: 16030, Val_acc:0.848696
==================>
Step: 16040, Train_acc:0.913746
Step: 16040, Val_acc:0.907684
==================>
Step: 16050, Train_acc:0.934325
Step: 16050, Val_acc:0.806367
==================>
Step: 16060, Train_acc:0.915789
Step: 16060, Val_acc:0.898407
==================>
Step: 16070, Train_acc:0.907196
Step: 16070, Val_acc:0.866374
==================>
Step: 16080, Train_acc:0.932643
Step: 16080, Val_acc:0.872437
==================>
Step: 16090, Train_acc:0.910608
Step: 16090, Val_acc:0.833898
==================>
Step: 16100, Train_acc:0.933975
Step: 16100, Val_acc:0.878691
==================>
2017-11-11 00:27:10.730240 ---> Validation_loss: 0.333714
Step: 16110, Train_acc:0.905961
Step: 16110, Val_acc:0.886295
==================>
Step: 16120, Train_acc:0.953896
Step: 16120, Val_acc:0.887633
==================>
Step: 16130, Train_acc:0.894896
Step: 16130, Val_acc:0.878826
==================>
Step: 16140, Train_acc:0.904147
Step: 16140, Val_acc:0.855981
==================>
Step: 16150, Train_acc:0.940623
Step: 16150, Val_acc:0.856482
==================>
Step: 16160, Train_acc:0.916492
Step: 16160, Val_acc:0.858894
==================>
Step: 16170, Train_acc:0.916859
Step: 16170, Val_acc:0.861367
==================>
Step: 16180, Train_acc:0.927571
Step: 16180, Val_acc:0.849144
==================>
Step: 16190, Train_acc:0.917938
Step: 16190, Val_acc:0.881077
==================>
Step: 16200, Train_acc:0.931591
Step: 16200, Val_acc:0.873467
==================>
2017-11-11 00:29:47.258331 ---> Validation_loss: 0.375077
Step: 16210, Train_acc:0.922399
Step: 16210, Val_acc:0.84986
==================>
Step: 16220, Train_acc:0.906235
Step: 16220, Val_acc:0.877758
==================>
Step: 16230, Train_acc:0.940474
Step: 16230, Val_acc:0.881307
==================>
Step: 16240, Train_acc:0.899019
Step: 16240, Val_acc:0.848989
==================>
Step: 16250, Train_acc:0.891421
Step: 16250, Val_acc:0.855863
==================>
Step: 16260, Train_acc:0.924321
Step: 16260, Val_acc:0.854828
==================>
Step: 16270, Train_acc:0.925892
Step: 16270, Val_acc:0.847573
==================>
Step: 16280, Train_acc:0.935223
Step: 16280, Val_acc:0.860166
==================>
Step: 16290, Train_acc:0.935978
Step: 16290, Val_acc:0.886779
==================>
Step: 16300, Train_acc:0.939838
Step: 16300, Val_acc:0.876523
==================>
2017-11-11 00:32:24.034344 ---> Validation_loss: 0.265322
Step: 16310, Train_acc:0.917601
Step: 16310, Val_acc:0.855354
==================>
Step: 16320, Train_acc:0.871395
Step: 16320, Val_acc:0.889315
==================>
Step: 16330, Train_acc:0.927443
Step: 16330, Val_acc:0.87572
==================>
Step: 16340, Train_acc:0.927653
Step: 16340, Val_acc:0.88627
==================>
Step: 16350, Train_acc:0.942777
Step: 16350, Val_acc:0.849426
==================>
Step: 16360, Train_acc:0.947568
Step: 16360, Val_acc:0.84377
==================>
Step: 16370, Train_acc:0.923198
Step: 16370, Val_acc:0.867396
==================>
Step: 16380, Train_acc:0.916947
Step: 16380, Val_acc:0.855298
==================>
Step: 16390, Train_acc:0.921414
Step: 16390, Val_acc:0.838885
==================>
Step: 16400, Train_acc:0.928423
Step: 16400, Val_acc:0.854258
==================>
2017-11-11 00:35:00.266746 ---> Validation_loss: 0.246951
Step: 16410, Train_acc:0.940491
Step: 16410, Val_acc:0.929917
==================>
Step: 16420, Train_acc:0.948062
Step: 16420, Val_acc:0.836652
==================>
Step: 16430, Train_acc:0.926714
Step: 16430, Val_acc:0.924607
==================>
Step: 16440, Train_acc:0.918206
Step: 16440, Val_acc:0.873674
==================>
Step: 16450, Train_acc:0.904611
Step: 16450, Val_acc:0.865438
==================>
Step: 16460, Train_acc:0.906931
Step: 16460, Val_acc:0.873718
==================>
Step: 16470, Train_acc:0.915176
Step: 16470, Val_acc:0.846226
==================>
Step: 16480, Train_acc:0.93869
Step: 16480, Val_acc:0.838038
==================>
Step: 16490, Train_acc:0.927157
Step: 16490, Val_acc:0.862211
==================>
Step: 16500, Train_acc:0.939003
Step: 16500, Val_acc:0.862504
==================>
****************** Epochs completed: 33******************
2017-11-11 00:37:37.037790 ---> Validation_loss: 0.296528
Step: 16510, Train_acc:0.934761
Step: 16510, Val_acc:0.818317
==================>
Step: 16520, Train_acc:0.92045
Step: 16520, Val_acc:0.871733
==================>
Step: 16530, Train_acc:0.938777
Step: 16530, Val_acc:0.898579
==================>
Step: 16540, Train_acc:0.920521
Step: 16540, Val_acc:0.877762
==================>
Step: 16550, Train_acc:0.923961
Step: 16550, Val_acc:0.841064
==================>
Step: 16560, Train_acc:0.939427
Step: 16560, Val_acc:0.822726
==================>
Step: 16570, Train_acc:0.935322
Step: 16570, Val_acc:0.866525
==================>
Step: 16580, Train_acc:0.916636
Step: 16580, Val_acc:0.88532
==================>
Step: 16590, Train_acc:0.9172
Step: 16590, Val_acc:0.885919
==================>
Step: 16600, Train_acc:0.908215
Step: 16600, Val_acc:0.88547
==================>
2017-11-11 00:40:13.640989 ---> Validation_loss: 0.330396
Step: 16610, Train_acc:0.927291
Step: 16610, Val_acc:0.848466
==================>
Step: 16620, Train_acc:0.922386
Step: 16620, Val_acc:0.869634
==================>
Step: 16630, Train_acc:0.924873
Step: 16630, Val_acc:0.872177
==================>
Step: 16640, Train_acc:0.938947
Step: 16640, Val_acc:0.880579
==================>
Step: 16650, Train_acc:0.923491
Step: 16650, Val_acc:0.856
==================>
Step: 16660, Train_acc:0.900642
Step: 16660, Val_acc:0.889253
==================>
Step: 16670, Train_acc:0.901873
Step: 16670, Val_acc:0.883115
==================>
Step: 16680, Train_acc:0.913116
Step: 16680, Val_acc:0.814205
==================>
Step: 16690, Train_acc:0.940566
Step: 16690, Val_acc:0.891659
==================>
Step: 16700, Train_acc:0.937816
Step: 16700, Val_acc:0.914529
==================>
2017-11-11 00:42:50.240352 ---> Validation_loss: 0.199999
Step: 16710, Train_acc:0.916063
Step: 16710, Val_acc:0.878814
==================>
Step: 16720, Train_acc:0.931914
Step: 16720, Val_acc:0.869404
==================>
Step: 16730, Train_acc:0.934846
Step: 16730, Val_acc:0.880417
==================>
Step: 16740, Train_acc:0.954102
Step: 16740, Val_acc:0.855361
==================>
Step: 16750, Train_acc:0.922378
Step: 16750, Val_acc:0.926792
==================>
Step: 16760, Train_acc:0.924994
Step: 16760, Val_acc:0.84802
==================>
Step: 16770, Train_acc:0.916613
Step: 16770, Val_acc:0.844091
==================>
Step: 16780, Train_acc:0.916669
Step: 16780, Val_acc:0.859501
==================>
Step: 16790, Train_acc:0.930979
Step: 16790, Val_acc:0.883369
==================>
Step: 16800, Train_acc:0.930311
Step: 16800, Val_acc:0.840643
==================>
2017-11-11 00:45:26.753267 ---> Validation_loss: 0.317512
Step: 16810, Train_acc:0.913617
Step: 16810, Val_acc:0.888779
==================>
****************** Epochs completed: 5******************
Step: 16820, Train_acc:0.931013
Step: 16820, Val_acc:0.896144
==================>
Step: 16830, Train_acc:0.960791
Step: 16830, Val_acc:0.882151
==================>
Step: 16840, Train_acc:0.938011
Step: 16840, Val_acc:0.883048
==================>
Step: 16850, Train_acc:0.9433
Step: 16850, Val_acc:0.893169
==================>
Step: 16860, Train_acc:0.944254
Step: 16860, Val_acc:0.872306
==================>
Step: 16870, Train_acc:0.92066
Step: 16870, Val_acc:0.877959
==================>
Step: 16880, Train_acc:0.932645
Step: 16880, Val_acc:0.885631
==================>
Step: 16890, Train_acc:0.929894
Step: 16890, Val_acc:0.908916
==================>
Step: 16900, Train_acc:0.926188
Step: 16900, Val_acc:0.880928
==================>
2017-11-11 00:48:03.217587 ---> Validation_loss: 0.256908
Step: 16910, Train_acc:0.926852
Step: 16910, Val_acc:0.857562
==================>
Step: 16920, Train_acc:0.9354
Step: 16920, Val_acc:0.903981
==================>
Step: 16930, Train_acc:0.939346
Step: 16930, Val_acc:0.900994
==================>
Step: 16940, Train_acc:0.937512
Step: 16940, Val_acc:0.906128
==================>
Step: 16950, Train_acc:0.966936
Step: 16950, Val_acc:0.866052
==================>
Step: 16960, Train_acc:0.930347
Step: 16960, Val_acc:0.855583
==================>
Step: 16970, Train_acc:0.918787
Step: 16970, Val_acc:0.899459
==================>
Step: 16980, Train_acc:0.938239
Step: 16980, Val_acc:0.903442
==================>
Step: 16990, Train_acc:0.923886
Step: 16990, Val_acc:0.860271
==================>
Step: 17000, Train_acc:0.928379
Step: 17000, Val_acc:0.887632
==================>
****************** Epochs completed: 34******************
2017-11-11 00:50:39.792260 ---> Validation_loss: 0.230998
Step: 17010, Train_acc:0.930243
Step: 17010, Val_acc:0.864486
==================>
Step: 17020, Train_acc:0.933177
Step: 17020, Val_acc:0.842649
==================>
Step: 17030, Train_acc:0.926882
Step: 17030, Val_acc:0.873527
==================>
Step: 17040, Train_acc:0.937207
Step: 17040, Val_acc:0.882532
==================>
Step: 17050, Train_acc:0.92379
Step: 17050, Val_acc:0.849912
==================>
Step: 17060, Train_acc:0.932032
Step: 17060, Val_acc:0.873489
==================>
Step: 17070, Train_acc:0.932482
Step: 17070, Val_acc:0.87444
==================>
Step: 17080, Train_acc:0.928729
Step: 17080, Val_acc:0.889766
==================>
Step: 17090, Train_acc:0.918613
Step: 17090, Val_acc:0.898362
==================>
Step: 17100, Train_acc:0.957114
Step: 17100, Val_acc:0.8774
==================>
2017-11-11 00:53:16.024177 ---> Validation_loss: 0.244515
Step: 17110, Train_acc:0.946006
Step: 17110, Val_acc:0.841963
==================>
Step: 17120, Train_acc:0.928398
Step: 17120, Val_acc:0.855061
==================>
Step: 17130, Train_acc:0.908314
Step: 17130, Val_acc:0.877427
==================>
Step: 17140, Train_acc:0.955734
Step: 17140, Val_acc:0.890063
==================>
Step: 17150, Train_acc:0.942018
Step: 17150, Val_acc:0.887959
==================>
Step: 17160, Train_acc:0.927977
Step: 17160, Val_acc:0.853851
==================>
Step: 17170, Train_acc:0.929657
Step: 17170, Val_acc:0.887971
==================>
Step: 17180, Train_acc:0.946567
Step: 17180, Val_acc:0.870857
==================>
Step: 17190, Train_acc:0.931343
Step: 17190, Val_acc:0.926171
==================>
Step: 17200, Train_acc:0.924082
Step: 17200, Val_acc:0.863386
==================>
2017-11-11 00:55:52.618962 ---> Validation_loss: 0.27819
Step: 17210, Train_acc:0.917434
Step: 17210, Val_acc:0.858435
==================>
Step: 17220, Train_acc:0.919468
Step: 17220, Val_acc:0.897538
==================>
Step: 17230, Train_acc:0.948091
Step: 17230, Val_acc:0.904703
==================>
Step: 17240, Train_acc:0.933839
Step: 17240, Val_acc:0.833796
==================>
Step: 17250, Train_acc:0.955126
Step: 17250, Val_acc:0.877693
==================>
Step: 17260, Train_acc:0.921414
Step: 17260, Val_acc:0.865601
==================>
Step: 17270, Train_acc:0.939657
Step: 17270, Val_acc:0.864342
==================>
Step: 17280, Train_acc:0.929929
Step: 17280, Val_acc:0.888502
==================>
Step: 17290, Train_acc:0.928987
Step: 17290, Val_acc:0.859045
==================>
Step: 17300, Train_acc:0.934595
Step: 17300, Val_acc:0.834211
==================>
2017-11-11 00:58:29.154016 ---> Validation_loss: 0.353539
Step: 17310, Train_acc:0.929607
Step: 17310, Val_acc:0.864762
==================>
Step: 17320, Train_acc:0.946238
Step: 17320, Val_acc:0.900613
==================>
Step: 17330, Train_acc:0.938901
Step: 17330, Val_acc:0.871967
==================>
Step: 17340, Train_acc:0.92939
Step: 17340, Val_acc:0.882444
==================>
Step: 17350, Train_acc:0.959923
Step: 17350, Val_acc:0.885522
==================>
Step: 17360, Train_acc:0.953135
Step: 17360, Val_acc:0.847666
==================>
Step: 17370, Train_acc:0.920612
Step: 17370, Val_acc:0.871035
==================>
Step: 17380, Train_acc:0.919402
Step: 17380, Val_acc:0.859495
==================>
Step: 17390, Train_acc:0.944683
Step: 17390, Val_acc:0.848801
==================>
Step: 17400, Train_acc:0.911813
Step: 17400, Val_acc:0.87515
==================>
2017-11-11 01:01:05.711378 ---> Validation_loss: 0.321598
Step: 17410, Train_acc:0.94417
Step: 17410, Val_acc:0.894949
==================>
Step: 17420, Train_acc:0.928986
Step: 17420, Val_acc:0.903385
==================>
Step: 17430, Train_acc:0.9261
Step: 17430, Val_acc:0.856985
==================>
Step: 17440, Train_acc:0.950449
Step: 17440, Val_acc:0.891781
==================>
Step: 17450, Train_acc:0.926431
Step: 17450, Val_acc:0.877455
==================>
Step: 17460, Train_acc:0.941127
Step: 17460, Val_acc:0.869077
==================>
Step: 17470, Train_acc:0.921169
Step: 17470, Val_acc:0.846843
==================>
Step: 17480, Train_acc:0.931952
Step: 17480, Val_acc:0.87345
==================>
Step: 17490, Train_acc:0.923409
Step: 17490, Val_acc:0.832865
==================>
Step: 17500, Train_acc:0.939027
Step: 17500, Val_acc:0.88967
==================>
****************** Epochs completed: 35******************
2017-11-11 01:03:42.206951 ---> Validation_loss: 0.304286
Step: 17510, Train_acc:0.931394
Step: 17510, Val_acc:0.852894
==================>
Step: 17520, Train_acc:0.945081
Step: 17520, Val_acc:0.872301
==================>
Step: 17530, Train_acc:0.940018
Step: 17530, Val_acc:0.88676
==================>
Step: 17540, Train_acc:0.936012
Step: 17540, Val_acc:0.889584
==================>
Step: 17550, Train_acc:0.952776
Step: 17550, Val_acc:0.87094
==================>
Step: 17560, Train_acc:0.937048
Step: 17560, Val_acc:0.852477
==================>
Step: 17570, Train_acc:0.93354
Step: 17570, Val_acc:0.87515
==================>
Step: 17580, Train_acc:0.928804
Step: 17580, Val_acc:0.857323
==================>
Step: 17590, Train_acc:0.950763
Step: 17590, Val_acc:0.851342
==================>
Step: 17600, Train_acc:0.937163
Step: 17600, Val_acc:0.864618
==================>
2017-11-11 01:06:18.424455 ---> Validation_loss: 0.283306
Step: 17610, Train_acc:0.94212
Step: 17610, Val_acc:0.887571
==================>
Step: 17620, Train_acc:0.943843
Step: 17620, Val_acc:0.889959
==================>
Step: 17630, Train_acc:0.926448
Step: 17630, Val_acc:0.901798
==================>
Step: 17640, Train_acc:0.936851
Step: 17640, Val_acc:0.868662
==================>
Step: 17650, Train_acc:0.942946
Step: 17650, Val_acc:0.880283
==================>
Step: 17660, Train_acc:0.915914
Step: 17660, Val_acc:0.845903
==================>
Step: 17670, Train_acc:0.920448
Step: 17670, Val_acc:0.858876
==================>
Step: 17680, Train_acc:0.930275
Step: 17680, Val_acc:0.869897
==================>
Step: 17690, Train_acc:0.946846
Step: 17690, Val_acc:0.89907
==================>
Step: 17700, Train_acc:0.934092
Step: 17700, Val_acc:0.84806
==================>
2017-11-11 01:08:54.635735 ---> Validation_loss: 0.212519
Step: 17710, Train_acc:0.907373
Step: 17710, Val_acc:0.884866
==================>
Step: 17720, Train_acc:0.947352
Step: 17720, Val_acc:0.864884
==================>
Step: 17730, Train_acc:0.924785
Step: 17730, Val_acc:0.864745
==================>
Step: 17740, Train_acc:0.924817
Step: 17740, Val_acc:0.816422
==================>
Step: 17750, Train_acc:0.926112
Step: 17750, Val_acc:0.859174
==================>
Step: 17760, Train_acc:0.943245
Step: 17760, Val_acc:0.85476
==================>
Step: 17770, Train_acc:0.92915
Step: 17770, Val_acc:0.817928
==================>
Step: 17780, Train_acc:0.917367
Step: 17780, Val_acc:0.864463
==================>
Step: 17790, Train_acc:0.931355
Step: 17790, Val_acc:0.874568
==================>
Step: 17800, Train_acc:0.949556
Step: 17800, Val_acc:0.829745
==================>
2017-11-11 01:11:31.230064 ---> Validation_loss: 0.327765
Step: 17810, Train_acc:0.931875
Step: 17810, Val_acc:0.856655
==================>
Step: 17820, Train_acc:0.948511
Step: 17820, Val_acc:0.801466
==================>
Step: 17830, Train_acc:0.938862
Step: 17830, Val_acc:0.903553
==================>
Step: 17840, Train_acc:0.947994
Step: 17840, Val_acc:0.869069
==================>
Step: 17850, Train_acc:0.935199
Step: 17850, Val_acc:0.85275
==================>
Step: 17860, Train_acc:0.941825
Step: 17860, Val_acc:0.884001
==================>
Step: 17870, Train_acc:0.930807
Step: 17870, Val_acc:0.889167
==================>
Step: 17880, Train_acc:0.912747
Step: 17880, Val_acc:0.875594
==================>
Step: 17890, Train_acc:0.93303
Step: 17890, Val_acc:0.874709
==================>
Step: 17900, Train_acc:0.919436
Step: 17900, Val_acc:0.864272
==================>
2017-11-11 01:14:07.507310 ---> Validation_loss: 0.251007
Step: 17910, Train_acc:0.950293
Step: 17910, Val_acc:0.830736
==================>
Step: 17920, Train_acc:0.944714
Step: 17920, Val_acc:0.901698
==================>
Step: 17930, Train_acc:0.923395
Step: 17930, Val_acc:0.857084
==================>
Step: 17940, Train_acc:0.910753
Step: 17940, Val_acc:0.899214
==================>
Step: 17950, Train_acc:0.936741
Step: 17950, Val_acc:0.831327
==================>
Step: 17960, Train_acc:0.934102
Step: 17960, Val_acc:0.899266
==================>
Step: 17970, Train_acc:0.932734
Step: 17970, Val_acc:0.905773
==================>
Step: 17980, Train_acc:0.92052
Step: 17980, Val_acc:0.853655
==================>
Step: 17990, Train_acc:0.931224
Step: 17990, Val_acc:0.901218
==================>
Step: 18000, Train_acc:0.952228
Step: 18000, Val_acc:0.883759
==================>
****************** Epochs completed: 36******************
2017-11-11 01:16:44.430563 ---> Validation_loss: 0.348187
Step: 18010, Train_acc:0.954076
Step: 18010, Val_acc:0.869681
==================>
Step: 18020, Train_acc:0.937048
Step: 18020, Val_acc:0.885497
==================>
Step: 18030, Train_acc:0.947456
Step: 18030, Val_acc:0.894939
==================>
Step: 18040, Train_acc:0.952343
Step: 18040, Val_acc:0.853123
==================>
Step: 18050, Train_acc:0.942959
Step: 18050, Val_acc:0.857382
==================>
Step: 18060, Train_acc:0.953444
Step: 18060, Val_acc:0.905123
==================>
Step: 18070, Train_acc:0.934792
Step: 18070, Val_acc:0.900205
==================>
Step: 18080, Train_acc:0.929183
Step: 18080, Val_acc:0.848314
==================>
Step: 18090, Train_acc:0.946885
Step: 18090, Val_acc:0.905723
==================>
Step: 18100, Train_acc:0.936241
Step: 18100, Val_acc:0.868702
==================>
2017-11-11 01:19:21.226575 ---> Validation_loss: 0.263208
Step: 18110, Train_acc:0.952319
Step: 18110, Val_acc:0.875133
==================>
Step: 18120, Train_acc:0.951343
Step: 18120, Val_acc:0.859269
==================>
Step: 18130, Train_acc:0.949839
Step: 18130, Val_acc:0.874177
==================>
Step: 18140, Train_acc:0.947155
Step: 18140, Val_acc:0.872686
==================>
Step: 18150, Train_acc:0.958142
Step: 18150, Val_acc:0.888738
==================>
Step: 18160, Train_acc:0.955446
Step: 18160, Val_acc:0.856748
==================>
Step: 18170, Train_acc:0.947341
Step: 18170, Val_acc:0.828093
==================>
Step: 18180, Train_acc:0.934691
Step: 18180, Val_acc:0.86243
==================>
Step: 18190, Train_acc:0.939316
Step: 18190, Val_acc:0.914864
==================>
Step: 18200, Train_acc:0.922059
Step: 18200, Val_acc:0.913353
==================>
2017-11-11 01:21:57.694877 ---> Validation_loss: 0.224417
Step: 18210, Train_acc:0.967126
Step: 18210, Val_acc:0.863163
==================>
Step: 18220, Train_acc:0.951117
Step: 18220, Val_acc:0.843959
==================>
Step: 18230, Train_acc:0.931558
Step: 18230, Val_acc:0.888379
==================>
Step: 18240, Train_acc:0.927322
Step: 18240, Val_acc:0.875335
==================>
Step: 18250, Train_acc:0.921989
Step: 18250, Val_acc:0.830684
==================>
Step: 18260, Train_acc:0.945974
Step: 18260, Val_acc:0.85109
==================>
Step: 18270, Train_acc:0.94507
Step: 18270, Val_acc:0.86276
==================>
Step: 18280, Train_acc:0.900743
Step: 18280, Val_acc:0.868359
==================>
Step: 18290, Train_acc:0.937886
Step: 18290, Val_acc:0.86804
==================>
Step: 18300, Train_acc:0.934114
Step: 18300, Val_acc:0.887002
==================>
2017-11-11 01:24:34.268879 ---> Validation_loss: 0.275215
Step: 18310, Train_acc:0.934485
Step: 18310, Val_acc:0.885038
==================>
Step: 18320, Train_acc:0.941547
Step: 18320, Val_acc:0.884359
==================>
Step: 18330, Train_acc:0.911458
Step: 18330, Val_acc:0.883311
==================>
Step: 18340, Train_acc:0.894386
Step: 18340, Val_acc:0.893481
==================>
Step: 18350, Train_acc:0.948539
Step: 18350, Val_acc:0.853262
==================>
Step: 18360, Train_acc:0.944423
Step: 18360, Val_acc:0.88778
==================>
Step: 18370, Train_acc:0.955478
Step: 18370, Val_acc:0.861608
==================>
Step: 18380, Train_acc:0.938713
Step: 18380, Val_acc:0.860767
==================>
Step: 18390, Train_acc:0.930518
Step: 18390, Val_acc:0.915215
==================>
Step: 18400, Train_acc:0.944756
Step: 18400, Val_acc:0.893762
==================>
2017-11-11 01:27:10.988741 ---> Validation_loss: 0.266482
Step: 18410, Train_acc:0.948647
Step: 18410, Val_acc:0.863878
==================>
Step: 18420, Train_acc:0.910227
Step: 18420, Val_acc:0.921223
==================>
Step: 18430, Train_acc:0.944462
Step: 18430, Val_acc:0.88671
==================>
Step: 18440, Train_acc:0.921976
Step: 18440, Val_acc:0.852242
==================>
Step: 18450, Train_acc:0.936425
Step: 18450, Val_acc:0.868346
==================>
Step: 18460, Train_acc:0.950472
Step: 18460, Val_acc:0.883027
==================>
Step: 18470, Train_acc:0.951885
Step: 18470, Val_acc:0.882885
==================>
Step: 18480, Train_acc:0.930004
Step: 18480, Val_acc:0.875679
==================>
Step: 18490, Train_acc:0.947264
Step: 18490, Val_acc:0.856035
==================>
Step: 18500, Train_acc:0.934213
Step: 18500, Val_acc:0.886427
==================>
****************** Epochs completed: 37******************
2017-11-11 01:29:47.999969 ---> Validation_loss: 0.270584
Step: 18510, Train_acc:0.95014
Step: 18510, Val_acc:0.892653
==================>
Step: 18520, Train_acc:0.93937
Step: 18520, Val_acc:0.884301
==================>
Step: 18530, Train_acc:0.928544
Step: 18530, Val_acc:0.847095
==================>
Step: 18540, Train_acc:0.931346
Step: 18540, Val_acc:0.882039
==================>
Step: 18550, Train_acc:0.93434
Step: 18550, Val_acc:0.89189
==================>
Step: 18560, Train_acc:0.93651
Step: 18560, Val_acc:0.848617
==================>
Step: 18570, Train_acc:0.929697
Step: 18570, Val_acc:0.867396
==================>
Step: 18580, Train_acc:0.942122
Step: 18580, Val_acc:0.893184
==================>
Step: 18590, Train_acc:0.932327
Step: 18590, Val_acc:0.905673
==================>
Step: 18600, Train_acc:0.923362
Step: 18600, Val_acc:0.846443
==================>
2017-11-11 01:32:24.595196 ---> Validation_loss: 0.23013
Step: 18610, Train_acc:0.925242
Step: 18610, Val_acc:0.902617
==================>
Step: 18620, Train_acc:0.946226
Step: 18620, Val_acc:0.903546
==================>
Step: 18630, Train_acc:0.919005
Step: 18630, Val_acc:0.893994
==================>
Step: 18640, Train_acc:0.927795
Step: 18640, Val_acc:0.914031
==================>
Step: 18650, Train_acc:0.922069
Step: 18650, Val_acc:0.87854
==================>
Step: 18660, Train_acc:0.944656
Step: 18660, Val_acc:0.866588
==================>
Step: 18670, Train_acc:0.938873
Step: 18670, Val_acc:0.875669
==================>
Step: 18680, Train_acc:0.940823
Step: 18680, Val_acc:0.883886
==================>
Step: 18690, Train_acc:0.940887
Step: 18690, Val_acc:0.900956
==================>
Step: 18700, Train_acc:0.918409
Step: 18700, Val_acc:0.901617
==================>
2017-11-11 01:35:01.435160 ---> Validation_loss: 0.320555
Step: 18710, Train_acc:0.907007
Step: 18710, Val_acc:0.870349
==================>
Step: 18720, Train_acc:0.911942
Step: 18720, Val_acc:0.844252
==================>
Step: 18730, Train_acc:0.939479
Step: 18730, Val_acc:0.868551
==================>
Step: 18740, Train_acc:0.930614
Step: 18740, Val_acc:0.861766
==================>
Step: 18750, Train_acc:0.928966
Step: 18750, Val_acc:0.900218
==================>
Step: 18760, Train_acc:0.932323
Step: 18760, Val_acc:0.877825
==================>
Step: 18770, Train_acc:0.93833
Step: 18770, Val_acc:0.900308
==================>
Step: 18780, Train_acc:0.940151
Step: 18780, Val_acc:0.904387
==================>
Step: 18790, Train_acc:0.962045
Step: 18790, Val_acc:0.877524
==================>
Step: 18800, Train_acc:0.949446
Step: 18800, Val_acc:0.882758
==================>
2017-11-11 01:37:38.111069 ---> Validation_loss: 0.270907
Step: 18810, Train_acc:0.937859
Step: 18810, Val_acc:0.898751
==================>
Step: 18820, Train_acc:0.925706
Step: 18820, Val_acc:0.837968
==================>
Step: 18830, Train_acc:0.925076
Step: 18830, Val_acc:0.873473
==================>
Step: 18840, Train_acc:0.940674
Step: 18840, Val_acc:0.869753
==================>
Step: 18850, Train_acc:0.935056
Step: 18850, Val_acc:0.885508
==================>
Step: 18860, Train_acc:0.946075
Step: 18860, Val_acc:0.866042
==================>
Step: 18870, Train_acc:0.948755
Step: 18870, Val_acc:0.869479
==================>
Step: 18880, Train_acc:0.912449
Step: 18880, Val_acc:0.888191
==================>
Step: 18890, Train_acc:0.934095
Step: 18890, Val_acc:0.893173
==================>
Step: 18900, Train_acc:0.945381
Step: 18900, Val_acc:0.856616
==================>
2017-11-11 01:40:14.683224 ---> Validation_loss: 0.247132
Step: 18910, Train_acc:0.937659
Step: 18910, Val_acc:0.878055
==================>
Step: 18920, Train_acc:0.927484
Step: 18920, Val_acc:0.850083
==================>
Step: 18930, Train_acc:0.936576
Step: 18930, Val_acc:0.864176
==================>
Step: 18940, Train_acc:0.939268
Step: 18940, Val_acc:0.875955
==================>
Step: 18950, Train_acc:0.938721
Step: 18950, Val_acc:0.85498
==================>
Step: 18960, Train_acc:0.938614
Step: 18960, Val_acc:0.844138
==================>
Step: 18970, Train_acc:0.942527
Step: 18970, Val_acc:0.843734
==================>
Step: 18980, Train_acc:0.928231
Step: 18980, Val_acc:0.868795
==================>
Step: 18990, Train_acc:0.934899
Step: 18990, Val_acc:0.906978
==================>
Step: 19000, Train_acc:0.908649
Step: 19000, Val_acc:0.897489
==================>
****************** Epochs completed: 38******************
2017-11-11 01:42:51.414678 ---> Validation_loss: 0.259636
Step: 19010, Train_acc:0.924204
Step: 19010, Val_acc:0.895569
==================>
Step: 19020, Train_acc:0.939934
Step: 19020, Val_acc:0.858937
==================>
Step: 19030, Train_acc:0.931403
Step: 19030, Val_acc:0.912059
==================>
Step: 19040, Train_acc:0.956041
Step: 19040, Val_acc:0.856415
==================>
Step: 19050, Train_acc:0.933191
Step: 19050, Val_acc:0.871703
==================>
Step: 19060, Train_acc:0.946134
Step: 19060, Val_acc:0.84661
==================>
Step: 19070, Train_acc:0.928323
Step: 19070, Val_acc:0.867229
==================>
Step: 19080, Train_acc:0.938801
Step: 19080, Val_acc:0.880851
==================>
Step: 19090, Train_acc:0.949867
Step: 19090, Val_acc:0.855923
==================>
Step: 19100, Train_acc:0.936082
Step: 19100, Val_acc:0.864873
==================>
2017-11-11 01:45:28.028480 ---> Validation_loss: 0.346332
Step: 19110, Train_acc:0.940382
Step: 19110, Val_acc:0.902423
==================>
Step: 19120, Train_acc:0.921296
Step: 19120, Val_acc:0.87563
==================>
Step: 19130, Train_acc:0.927552
Step: 19130, Val_acc:0.901739
==================>
Step: 19140, Train_acc:0.919182
Step: 19140, Val_acc:0.902938
==================>
Step: 19150, Train_acc:0.940514
Step: 19150, Val_acc:0.910563
==================>
Step: 19160, Train_acc:0.942386
Step: 19160, Val_acc:0.876381
==================>
Step: 19170, Train_acc:0.943865
Step: 19170, Val_acc:0.905598
==================>
Step: 19180, Train_acc:0.93942
Step: 19180, Val_acc:0.887568
==================>
Step: 19190, Train_acc:0.971947
Step: 19190, Val_acc:0.864491
==================>
Step: 19200, Train_acc:0.940328
Step: 19200, Val_acc:0.907366
==================>
2017-11-11 01:48:04.425191 ---> Validation_loss: 0.234376
Step: 19210, Train_acc:0.931982
Step: 19210, Val_acc:0.835381
==================>
Step: 19220, Train_acc:0.92298
Step: 19220, Val_acc:0.872268
==================>
Step: 19230, Train_acc:0.931771
Step: 19230, Val_acc:0.89444
==================>
Step: 19240, Train_acc:0.938037
Step: 19240, Val_acc:0.868076
==================>
Step: 19250, Train_acc:0.947809
Step: 19250, Val_acc:0.889313
==================>
Step: 19260, Train_acc:0.928051
Step: 19260, Val_acc:0.928639
==================>
Step: 19270, Train_acc:0.933193
Step: 19270, Val_acc:0.840879
==================>
Step: 19280, Train_acc:0.936344
Step: 19280, Val_acc:0.85434
==================>
Step: 19290, Train_acc:0.947562
Step: 19290, Val_acc:0.847162
==================>
Step: 19300, Train_acc:0.93204
Step: 19300, Val_acc:0.824828
==================>
2017-11-11 01:50:40.765458 ---> Validation_loss: 0.269633
Step: 19310, Train_acc:0.952164
Step: 19310, Val_acc:0.882996
==================>
Step: 19320, Train_acc:0.943105
Step: 19320, Val_acc:0.887455
==================>
Step: 19330, Train_acc:0.934912
Step: 19330, Val_acc:0.878549
==================>
Step: 19340, Train_acc:0.927784
Step: 19340, Val_acc:0.894441
==================>
Step: 19350, Train_acc:0.933829
Step: 19350, Val_acc:0.882135
==================>
Step: 19360, Train_acc:0.916728
Step: 19360, Val_acc:0.822642
==================>
Step: 19370, Train_acc:0.944161
Step: 19370, Val_acc:0.87777
==================>
Step: 19380, Train_acc:0.947228
Step: 19380, Val_acc:0.857413
==================>
Step: 19390, Train_acc:0.942512
Step: 19390, Val_acc:0.862319
==================>
Step: 19400, Train_acc:0.944503
Step: 19400, Val_acc:0.864778
==================>
2017-11-11 01:53:17.114502 ---> Validation_loss: 0.275054
Step: 19410, Train_acc:0.938993
Step: 19410, Val_acc:0.900175
==================>
Step: 19420, Train_acc:0.933041
Step: 19420, Val_acc:0.865591
==================>
Step: 19430, Train_acc:0.95849
Step: 19430, Val_acc:0.854855
==================>
Step: 19440, Train_acc:0.942562
Step: 19440, Val_acc:0.873893
==================>
Step: 19450, Train_acc:0.948995
Step: 19450, Val_acc:0.898331
==================>
Step: 19460, Train_acc:0.919847
Step: 19460, Val_acc:0.853293
==================>
Step: 19470, Train_acc:0.93707
Step: 19470, Val_acc:0.901973
==================>
Step: 19480, Train_acc:0.944799
Step: 19480, Val_acc:0.902155
==================>
Step: 19490, Train_acc:0.94402
Step: 19490, Val_acc:0.879811
==================>
Step: 19500, Train_acc:0.921534
Step: 19500, Val_acc:0.854729
==================>
****************** Epochs completed: 39******************
2017-11-11 01:55:53.277714 ---> Validation_loss: 0.318363
Step: 19510, Train_acc:0.950986
Step: 19510, Val_acc:0.864579
==================>
Step: 19520, Train_acc:0.934974
Step: 19520, Val_acc:0.870814
==================>
Step: 19530, Train_acc:0.923093
Step: 19530, Val_acc:0.875469
==================>
Step: 19540, Train_acc:0.942102
Step: 19540, Val_acc:0.878346
==================>
Step: 19550, Train_acc:0.931733
Step: 19550, Val_acc:0.885869
==================>
Step: 19560, Train_acc:0.930548
Step: 19560, Val_acc:0.840552
==================>
Step: 19570, Train_acc:0.940958
Step: 19570, Val_acc:0.874907
==================>
Step: 19580, Train_acc:0.93925
Step: 19580, Val_acc:0.868489
==================>
Step: 19590, Train_acc:0.949041
Step: 19590, Val_acc:0.908931
==================>
Step: 19600, Train_acc:0.959514
Step: 19600, Val_acc:0.879313
==================>
2017-11-11 01:58:29.797314 ---> Validation_loss: 0.282249
Step: 19610, Train_acc:0.931759
Step: 19610, Val_acc:0.870215
==================>
Step: 19620, Train_acc:0.944025
Step: 19620, Val_acc:0.892411
==================>
Step: 19630, Train_acc:0.930247
Step: 19630, Val_acc:0.901735
==================>
Step: 19640, Train_acc:0.941226
Step: 19640, Val_acc:0.883572
==================>
Step: 19650, Train_acc:0.931946
Step: 19650, Val_acc:0.869275
==================>
Step: 19660, Train_acc:0.925209
Step: 19660, Val_acc:0.901184
==================>
Step: 19670, Train_acc:0.928848
Step: 19670, Val_acc:0.884554
==================>
Step: 19680, Train_acc:0.936785
Step: 19680, Val_acc:0.917632
==================>
Step: 19690, Train_acc:0.943153
Step: 19690, Val_acc:0.875862
==================>
Step: 19700, Train_acc:0.938696
Step: 19700, Val_acc:0.878442
==================>
2017-11-11 02:01:06.096732 ---> Validation_loss: 0.242401
Step: 19710, Train_acc:0.960217
Step: 19710, Val_acc:0.859487
==================>
Step: 19720, Train_acc:0.933336
Step: 19720, Val_acc:0.886302
==================>
Step: 19730, Train_acc:0.950519
Step: 19730, Val_acc:0.841593
==================>
Step: 19740, Train_acc:0.932538
Step: 19740, Val_acc:0.872916
==================>
Step: 19750, Train_acc:0.945919
Step: 19750, Val_acc:0.928083
==================>
Step: 19760, Train_acc:0.938735
Step: 19760, Val_acc:0.892682
==================>
Step: 19770, Train_acc:0.92437
Step: 19770, Val_acc:0.813713
==================>
Step: 19780, Train_acc:0.9492
Step: 19780, Val_acc:0.92833
==================>
Step: 19790, Train_acc:0.942848
Step: 19790, Val_acc:0.880315
==================>
Step: 19800, Train_acc:0.943541
Step: 19800, Val_acc:0.833192
==================>
2017-11-11 02:03:42.498516 ---> Validation_loss: 0.297729
Step: 19810, Train_acc:0.946541
Step: 19810, Val_acc:0.880018
==================>
Step: 19820, Train_acc:0.953219
Step: 19820, Val_acc:0.884099
==================>
Step: 19830, Train_acc:0.950186
Step: 19830, Val_acc:0.882191
==================>
Step: 19840, Train_acc:0.933397
Step: 19840, Val_acc:0.873842
==================>
Step: 19850, Train_acc:0.939996
Step: 19850, Val_acc:0.879403
==================>
Step: 19860, Train_acc:0.927738
Step: 19860, Val_acc:0.885968
==================>
Step: 19870, Train_acc:0.943862
Step: 19870, Val_acc:0.861089
==================>
Step: 19880, Train_acc:0.939816
Step: 19880, Val_acc:0.887321
==================>
Step: 19890, Train_acc:0.945508
Step: 19890, Val_acc:0.867799
==================>
Step: 19900, Train_acc:0.914259
Step: 19900, Val_acc:0.860116
==================>
2017-11-11 02:06:18.675166 ---> Validation_loss: 0.262129
Step: 19910, Train_acc:0.933008
Step: 19910, Val_acc:0.874191
==================>
Step: 19920, Train_acc:0.931053
Step: 19920, Val_acc:0.874357
==================>
Step: 19930, Train_acc:0.950618
Step: 19930, Val_acc:0.881565
==================>
Step: 19940, Train_acc:0.942589
Step: 19940, Val_acc:0.886002
==================>
Step: 19950, Train_acc:0.912303
Step: 19950, Val_acc:0.858982
==================>
Step: 19960, Train_acc:0.932353
Step: 19960, Val_acc:0.855822
==================>
Step: 19970, Train_acc:0.945093
Step: 19970, Val_acc:0.865847
==================>
Step: 19980, Train_acc:0.919012
Step: 19980, Val_acc:0.886614
==================>
Step: 19990, Train_acc:0.943621
Step: 19990, Val_acc:0.877405
==================>
Step: 20000, Train_acc:0.92699
Step: 20000, Val_acc:0.87824
==================>
****************** Epochs completed: 40******************
2017-11-11 02:08:55.071931 ---> Validation_loss: 0.216518
Step: 20010, Train_acc:0.933429
Step: 20010, Val_acc:0.884944
==================>
Step: 20020, Train_acc:0.959075
Step: 20020, Val_acc:0.914425
==================>
Step: 20030, Train_acc:0.936167
Step: 20030, Val_acc:0.884399
==================>
Step: 20040, Train_acc:0.939608
Step: 20040, Val_acc:0.892472
==================>
Step: 20050, Train_acc:0.937563
Step: 20050, Val_acc:0.85983
==================>
Step: 20060, Train_acc:0.94087
Step: 20060, Val_acc:0.9014
==================>
Step: 20070, Train_acc:0.941521
Step: 20070, Val_acc:0.886187
==================>
Step: 20080, Train_acc:0.928789
Step: 20080, Val_acc:0.848464
==================>
Step: 20090, Train_acc:0.909639
Step: 20090, Val_acc:0.901266
==================>
Step: 20100, Train_acc:0.930988
Step: 20100, Val_acc:0.863986
==================>
2017-11-11 02:11:31.372758 ---> Validation_loss: 0.234208
Step: 20110, Train_acc:0.94233
Step: 20110, Val_acc:0.852638
==================>
Step: 20120, Train_acc:0.954059
Step: 20120, Val_acc:0.857921
==================>
Step: 20130, Train_acc:0.95095
Step: 20130, Val_acc:0.891082
==================>
Step: 20140, Train_acc:0.930944
Step: 20140, Val_acc:0.865923
==================>
Step: 20150, Train_acc:0.932598
Step: 20150, Val_acc:0.880521
==================>
Step: 20160, Train_acc:0.942928
Step: 20160, Val_acc:0.884246
==================>
Step: 20170, Train_acc:0.941343
Step: 20170, Val_acc:0.844876
==================>
Step: 20180, Train_acc:0.926075
Step: 20180, Val_acc:0.869407
==================>
****************** Epochs completed: 6******************
Step: 20190, Train_acc:0.930873
Step: 20190, Val_acc:0.870242
==================>
Step: 20200, Train_acc:0.928583
Step: 20200, Val_acc:0.908104
==================>
2017-11-11 02:14:07.900841 ---> Validation_loss: 0.257796
Step: 20210, Train_acc:0.91887
Step: 20210, Val_acc:0.870083
==================>
Step: 20220, Train_acc:0.932997
Step: 20220, Val_acc:0.890842
==================>
Step: 20230, Train_acc:0.953914
Step: 20230, Val_acc:0.8699
==================>
Step: 20240, Train_acc:0.931884
Step: 20240, Val_acc:0.89493
==================>
Step: 20250, Train_acc:0.954977
Step: 20250, Val_acc:0.840455
==================>
Step: 20260, Train_acc:0.945795
Step: 20260, Val_acc:0.874
==================>
Step: 20270, Train_acc:0.946897
Step: 20270, Val_acc:0.879663
==================>
Step: 20280, Train_acc:0.946886
Step: 20280, Val_acc:0.899359
==================>
Step: 20290, Train_acc:0.959275
Step: 20290, Val_acc:0.878961
==================>
Step: 20300, Train_acc:0.948501
Step: 20300, Val_acc:0.856909
==================>
2017-11-11 02:16:43.728585 ---> Validation_loss: 0.255325
Step: 20310, Train_acc:0.923564
Step: 20310, Val_acc:0.905116
==================>
Step: 20320, Train_acc:0.929005
Step: 20320, Val_acc:0.874482
==================>
Step: 20330, Train_acc:0.941985
Step: 20330, Val_acc:0.887053
==================>
Step: 20340, Train_acc:0.946478
Step: 20340, Val_acc:0.878198
==================>
Step: 20350, Train_acc:0.950238
Step: 20350, Val_acc:0.905211
==================>
Step: 20360, Train_acc:0.935789
Step: 20360, Val_acc:0.877365
==================>
Step: 20370, Train_acc:0.953201
Step: 20370, Val_acc:0.939503
==================>
Step: 20380, Train_acc:0.954792
Step: 20380, Val_acc:0.873585
==================>
Step: 20390, Train_acc:0.948497
Step: 20390, Val_acc:0.891189
==================>
Step: 20400, Train_acc:0.94291
Step: 20400, Val_acc:0.904703
==================>
2017-11-11 02:19:19.941403 ---> Validation_loss: 0.349416
Step: 20410, Train_acc:0.954615
Step: 20410, Val_acc:0.900007
==================>
Step: 20420, Train_acc:0.943956
Step: 20420, Val_acc:0.890103
==================>
Step: 20430, Train_acc:0.950428
Step: 20430, Val_acc:0.846229
==================>
Step: 20440, Train_acc:0.95309
Step: 20440, Val_acc:0.851101
==================>
Step: 20450, Train_acc:0.958156
Step: 20450, Val_acc:0.856978
==================>
Step: 20460, Train_acc:0.952703
Step: 20460, Val_acc:0.870864
==================>
Step: 20470, Train_acc:0.958518
Step: 20470, Val_acc:0.87005
==================>
Step: 20480, Train_acc:0.946739
Step: 20480, Val_acc:0.866576
==================>
Step: 20490, Train_acc:0.933713
Step: 20490, Val_acc:0.885061
==================>
Step: 20500, Train_acc:0.94938
Step: 20500, Val_acc:0.874687
==================>
****************** Epochs completed: 41******************
2017-11-11 02:21:56.333564 ---> Validation_loss: 0.22302
Step: 20510, Train_acc:0.941825
Step: 20510, Val_acc:0.890216
==================>
Step: 20520, Train_acc:0.937073
Step: 20520, Val_acc:0.883672
==================>
Step: 20530, Train_acc:0.920446
Step: 20530, Val_acc:0.900936
==================>
Step: 20540, Train_acc:0.951007
Step: 20540, Val_acc:0.928795
==================>
Step: 20550, Train_acc:0.949222
Step: 20550, Val_acc:0.914194
==================>
Step: 20560, Train_acc:0.943734
Step: 20560, Val_acc:0.885344
==================>
Step: 20570, Train_acc:0.942417
Step: 20570, Val_acc:0.895726
==================>
Step: 20580, Train_acc:0.954722
Step: 20580, Val_acc:0.896619
==================>
Step: 20590, Train_acc:0.95155
Step: 20590, Val_acc:0.890518
==================>
Step: 20600, Train_acc:0.951736
Step: 20600, Val_acc:0.864281
==================>
2017-11-11 02:24:32.221540 ---> Validation_loss: 0.41535
Step: 20610, Train_acc:0.930367
Step: 20610, Val_acc:0.86165
==================>
Step: 20620, Train_acc:0.934791
Step: 20620, Val_acc:0.849464
==================>
Step: 20630, Train_acc:0.939183
Step: 20630, Val_acc:0.88655
==================>
Step: 20640, Train_acc:0.956499
Step: 20640, Val_acc:0.876676
==================>
Step: 20650, Train_acc:0.950708
Step: 20650, Val_acc:0.90402
==================>
Step: 20660, Train_acc:0.924436
Step: 20660, Val_acc:0.917509
==================>
Step: 20670, Train_acc:0.938998
Step: 20670, Val_acc:0.908712
==================>
Step: 20680, Train_acc:0.931774
Step: 20680, Val_acc:0.875353
==================>
Step: 20690, Train_acc:0.926073
Step: 20690, Val_acc:0.870347
==================>
Step: 20700, Train_acc:0.952113
Step: 20700, Val_acc:0.890267
==================>
2017-11-11 02:27:08.840173 ---> Validation_loss: 0.272772
Step: 20710, Train_acc:0.94189
Step: 20710, Val_acc:0.887405
==================>
Step: 20720, Train_acc:0.93225
Step: 20720, Val_acc:0.867459
==================>
Step: 20730, Train_acc:0.944666
Step: 20730, Val_acc:0.874353
==================>
Step: 20740, Train_acc:0.938389
Step: 20740, Val_acc:0.855964
==================>
Step: 20750, Train_acc:0.938365
Step: 20750, Val_acc:0.888965
==================>
Step: 20760, Train_acc:0.95314
Step: 20760, Val_acc:0.912751
==================>
Step: 20770, Train_acc:0.941868
Step: 20770, Val_acc:0.877117
==================>
Step: 20780, Train_acc:0.923553
Step: 20780, Val_acc:0.909149
==================>
Step: 20790, Train_acc:0.918217
Step: 20790, Val_acc:0.930732
==================>
Step: 20800, Train_acc:0.942358
Step: 20800, Val_acc:0.869364
==================>
2017-11-11 02:29:45.331771 ---> Validation_loss: 0.310803
Step: 20810, Train_acc:0.956416
Step: 20810, Val_acc:0.873221
==================>
Step: 20820, Train_acc:0.948306
Step: 20820, Val_acc:0.903851
==================>
Step: 20830, Train_acc:0.956208
Step: 20830, Val_acc:0.884673
==================>
Step: 20840, Train_acc:0.944645
Step: 20840, Val_acc:0.850957
==================>
Step: 20850, Train_acc:0.95069
Step: 20850, Val_acc:0.871182
==================>
Step: 20860, Train_acc:0.948629
Step: 20860, Val_acc:0.894906
==================>
Step: 20870, Train_acc:0.960302
Step: 20870, Val_acc:0.872554
==================>
Step: 20880, Train_acc:0.949589
Step: 20880, Val_acc:0.880176
==================>
Step: 20890, Train_acc:0.93865
Step: 20890, Val_acc:0.89057
==================>
Step: 20900, Train_acc:0.954543
Step: 20900, Val_acc:0.906244
==================>
2017-11-11 02:32:21.886212 ---> Validation_loss: 0.159052
Step: 20910, Train_acc:0.903788
Step: 20910, Val_acc:0.879598
==================>
Step: 20920, Train_acc:0.959463
Step: 20920, Val_acc:0.862255
==================>
Step: 20930, Train_acc:0.948334
Step: 20930, Val_acc:0.90306
==================>
Step: 20940, Train_acc:0.955961
Step: 20940, Val_acc:0.856575
==================>
Step: 20950, Train_acc:0.949801
Step: 20950, Val_acc:0.857368
==================>
Step: 20960, Train_acc:0.9565
Step: 20960, Val_acc:0.91094
==================>
Step: 20970, Train_acc:0.946479
Step: 20970, Val_acc:0.909876
==================>
Step: 20980, Train_acc:0.942842
Step: 20980, Val_acc:0.83733
==================>
Step: 20990, Train_acc:0.948344
Step: 20990, Val_acc:0.907755
==================>
Step: 21000, Train_acc:0.977457
Step: 21000, Val_acc:0.869094
==================>
****************** Epochs completed: 42******************
2017-11-11 02:34:58.060600 ---> Validation_loss: 0.30016
Step: 21010, Train_acc:0.922321
Step: 21010, Val_acc:0.901506
==================>
Step: 21020, Train_acc:0.943317
Step: 21020, Val_acc:0.885809
==================>
Step: 21030, Train_acc:0.948229
Step: 21030, Val_acc:0.877853
==================>
Step: 21040, Train_acc:0.939834
Step: 21040, Val_acc:0.900314
==================>
Step: 21050, Train_acc:0.934482
Step: 21050, Val_acc:0.864607
==================>
Step: 21060, Train_acc:0.943491
Step: 21060, Val_acc:0.919111
==================>
Step: 21070, Train_acc:0.952892
Step: 21070, Val_acc:0.884095
==================>
Step: 21080, Train_acc:0.949708
Step: 21080, Val_acc:0.898265
==================>
Step: 21090, Train_acc:0.950154
Step: 21090, Val_acc:0.88892
==================>
Step: 21100, Train_acc:0.968131
Step: 21100, Val_acc:0.848435
==================>
2017-11-11 02:37:34.423152 ---> Validation_loss: 0.229436
Step: 21110, Train_acc:0.938212
Step: 21110, Val_acc:0.894692
==================>
Step: 21120, Train_acc:0.94321
Step: 21120, Val_acc:0.88132
==================>
Step: 21130, Train_acc:0.938332
Step: 21130, Val_acc:0.877969
==================>
Step: 21140, Train_acc:0.943481
Step: 21140, Val_acc:0.885187
==================>
Step: 21150, Train_acc:0.947924
Step: 21150, Val_acc:0.920276
==================>
Step: 21160, Train_acc:0.948126
Step: 21160, Val_acc:0.881617
==================>
Step: 21170, Train_acc:0.938608
Step: 21170, Val_acc:0.889498
==================>
Step: 21180, Train_acc:0.925226
Step: 21180, Val_acc:0.889109
==================>
Step: 21190, Train_acc:0.937218
Step: 21190, Val_acc:0.895218
==================>
Step: 21200, Train_acc:0.931427
Step: 21200, Val_acc:0.897043
==================>
2017-11-11 02:40:10.672048 ---> Validation_loss: 0.246902
Step: 21210, Train_acc:0.947109
Step: 21210, Val_acc:0.889239
==================>
Step: 21220, Train_acc:0.943242
Step: 21220, Val_acc:0.909598
==================>
Step: 21230, Train_acc:0.939597
Step: 21230, Val_acc:0.831993
==================>
Step: 21240, Train_acc:0.929901
Step: 21240, Val_acc:0.875341
==================>
Step: 21250, Train_acc:0.940376
Step: 21250, Val_acc:0.900232
==================>
Step: 21260, Train_acc:0.950049
Step: 21260, Val_acc:0.879287
==================>
Step: 21270, Train_acc:0.946138
Step: 21270, Val_acc:0.866085
==================>
Step: 21280, Train_acc:0.953904
Step: 21280, Val_acc:0.905085
==================>
Step: 21290, Train_acc:0.952338
Step: 21290, Val_acc:0.849264
==================>
Step: 21300, Train_acc:0.949567
Step: 21300, Val_acc:0.904491
==================>
2017-11-11 02:42:47.026785 ---> Validation_loss: 0.283864
Step: 21310, Train_acc:0.918555
Step: 21310, Val_acc:0.857022
==================>
Step: 21320, Train_acc:0.942975
Step: 21320, Val_acc:0.862939
==================>
Step: 21330, Train_acc:0.936689
Step: 21330, Val_acc:0.911361
==================>
Step: 21340, Train_acc:0.968733
Step: 21340, Val_acc:0.882681
==================>
Step: 21350, Train_acc:0.936694
Step: 21350, Val_acc:0.893508
==================>
Step: 21360, Train_acc:0.9517
Step: 21360, Val_acc:0.871907
==================>
Step: 21370, Train_acc:0.96574
Step: 21370, Val_acc:0.886547
==================>
Step: 21380, Train_acc:0.93803
Step: 21380, Val_acc:0.883657
==================>
Step: 21390, Train_acc:0.944218
Step: 21390, Val_acc:0.833513
==================>
Step: 21400, Train_acc:0.942964
Step: 21400, Val_acc:0.912975
==================>
2017-11-11 02:45:23.209964 ---> Validation_loss: 0.275199
Step: 21410, Train_acc:0.94557
Step: 21410, Val_acc:0.918263
==================>
Step: 21420, Train_acc:0.962949
Step: 21420, Val_acc:0.8711
==================>
Step: 21430, Train_acc:0.949944
Step: 21430, Val_acc:0.899613
==================>
Step: 21440, Train_acc:0.941853
Step: 21440, Val_acc:0.866024
==================>
Step: 21450, Train_acc:0.942374
Step: 21450, Val_acc:0.88719
==================>
Step: 21460, Train_acc:0.934446
Step: 21460, Val_acc:0.907561
==================>
Step: 21470, Train_acc:0.941635
Step: 21470, Val_acc:0.86865
==================>
Step: 21480, Train_acc:0.932856
Step: 21480, Val_acc:0.913602
==================>
Step: 21490, Train_acc:0.94418
Step: 21490, Val_acc:0.883611
==================>
Step: 21500, Train_acc:0.95526
Step: 21500, Val_acc:0.881278
==================>
****************** Epochs completed: 43******************
2017-11-11 02:47:59.844761 ---> Validation_loss: 0.33556
Step: 21510, Train_acc:0.929857
Step: 21510, Val_acc:0.887322
==================>
Step: 21520, Train_acc:0.956919
Step: 21520, Val_acc:0.918306
==================>
Step: 21530, Train_acc:0.93236
Step: 21530, Val_acc:0.876239
==================>
Step: 21540, Train_acc:0.937777
Step: 21540, Val_acc:0.852205
==================>
Step: 21550, Train_acc:0.941989
Step: 21550, Val_acc:0.861681
==================>
Step: 21560, Train_acc:0.951235
Step: 21560, Val_acc:0.893237
==================>
Step: 21570, Train_acc:0.957123
Step: 21570, Val_acc:0.868104
==================>
Step: 21580, Train_acc:0.949357
Step: 21580, Val_acc:0.913254
==================>
Step: 21590, Train_acc:0.952872
Step: 21590, Val_acc:0.903865
==================>
Step: 21600, Train_acc:0.947759
Step: 21600, Val_acc:0.8937
==================>
2017-11-11 02:50:35.989871 ---> Validation_loss: 0.230431
Step: 21610, Train_acc:0.929335
Step: 21610, Val_acc:0.821808
==================>
Step: 21620, Train_acc:0.951327
Step: 21620, Val_acc:0.824366
==================>
Step: 21630, Train_acc:0.95334
Step: 21630, Val_acc:0.894935
==================>
Step: 21640, Train_acc:0.951687
Step: 21640, Val_acc:0.886145
==================>
Step: 21650, Train_acc:0.93278
Step: 21650, Val_acc:0.840522
==================>
Step: 21660, Train_acc:0.937263
Step: 21660, Val_acc:0.835623
==================>
Step: 21670, Train_acc:0.952816
Step: 21670, Val_acc:0.874689
==================>
Step: 21680, Train_acc:0.953604
Step: 21680, Val_acc:0.91457
==================>
Step: 21690, Train_acc:0.942274
Step: 21690, Val_acc:0.862954
==================>
Step: 21700, Train_acc:0.92962
Step: 21700, Val_acc:0.85827
==================>
2017-11-11 02:53:12.088766 ---> Validation_loss: 0.316168
Step: 21710, Train_acc:0.9499
Step: 21710, Val_acc:0.909774
==================>
Step: 21720, Train_acc:0.947089
Step: 21720, Val_acc:0.885231
==================>
Step: 21730, Train_acc:0.950272
Step: 21730, Val_acc:0.87036
==================>
Step: 21740, Train_acc:0.937438
Step: 21740, Val_acc:0.857729
==================>
Step: 21750, Train_acc:0.942056
Step: 21750, Val_acc:0.887004
==================>
Step: 21760, Train_acc:0.951871
Step: 21760, Val_acc:0.891263
==================>
Step: 21770, Train_acc:0.963046
Step: 21770, Val_acc:0.921931
==================>
Step: 21780, Train_acc:0.945801
Step: 21780, Val_acc:0.892091
==================>
Step: 21790, Train_acc:0.948972
Step: 21790, Val_acc:0.873804
==================>
Step: 21800, Train_acc:0.930468
Step: 21800, Val_acc:0.903964
==================>
2017-11-11 02:55:48.357928 ---> Validation_loss: 0.149163
Step: 21810, Train_acc:0.954377
Step: 21810, Val_acc:0.895068
==================>
Step: 21820, Train_acc:0.95183
Step: 21820, Val_acc:0.878959
==================>
Step: 21830, Train_acc:0.945635
Step: 21830, Val_acc:0.926937
==================>
Step: 21840, Train_acc:0.935688
Step: 21840, Val_acc:0.86504
==================>
Step: 21850, Train_acc:0.959772
Step: 21850, Val_acc:0.902897
==================>
Step: 21860, Train_acc:0.930389
Step: 21860, Val_acc:0.850647
==================>
Step: 21870, Train_acc:0.955104
Step: 21870, Val_acc:0.877057
==================>
Step: 21880, Train_acc:0.942921
Step: 21880, Val_acc:0.89359
==================>
Step: 21890, Train_acc:0.931611
Step: 21890, Val_acc:0.871134
==================>
Step: 21900, Train_acc:0.938124
Step: 21900, Val_acc:0.887057
==================>
2017-11-11 02:58:24.945527 ---> Validation_loss: 0.290966
Step: 21910, Train_acc:0.945876
Step: 21910, Val_acc:0.857764
==================>
Step: 21920, Train_acc:0.931222
Step: 21920, Val_acc:0.860343
==================>
Step: 21930, Train_acc:0.933812
Step: 21930, Val_acc:0.879742
==================>
Step: 21940, Train_acc:0.945222
Step: 21940, Val_acc:0.879951
==================>
Step: 21950, Train_acc:0.952697
Step: 21950, Val_acc:0.920361
==================>
Step: 21960, Train_acc:0.948746
Step: 21960, Val_acc:0.871323
==================>
Step: 21970, Train_acc:0.941743
Step: 21970, Val_acc:0.900747
==================>
Step: 21980, Train_acc:0.942502
Step: 21980, Val_acc:0.872549
==================>
Step: 21990, Train_acc:0.95715
Step: 21990, Val_acc:0.862465
==================>
Step: 22000, Train_acc:0.959065
Step: 22000, Val_acc:0.869216
==================>
****************** Epochs completed: 44******************
2017-11-11 03:01:01.333216 ---> Validation_loss: 0.217751
Step: 22010, Train_acc:0.934675
Step: 22010, Val_acc:0.904774
==================>
Step: 22020, Train_acc:0.956865
Step: 22020, Val_acc:0.890117
==================>
Step: 22030, Train_acc:0.936476
Step: 22030, Val_acc:0.874689
==================>
Step: 22040, Train_acc:0.949729
Step: 22040, Val_acc:0.871838
==================>
Step: 22050, Train_acc:0.930388
Step: 22050, Val_acc:0.890719
==================>
Step: 22060, Train_acc:0.944093
Step: 22060, Val_acc:0.884159
==================>
Step: 22070, Train_acc:0.956213
Step: 22070, Val_acc:0.867061
==================>
Step: 22080, Train_acc:0.951521
Step: 22080, Val_acc:0.862029
==================>
Step: 22090, Train_acc:0.961597
Step: 22090, Val_acc:0.865571
==================>
Step: 22100, Train_acc:0.956653
Step: 22100, Val_acc:0.897156
==================>
2017-11-11 03:03:37.366952 ---> Validation_loss: 0.266024
Step: 22110, Train_acc:0.922367
Step: 22110, Val_acc:0.916255
==================>
Step: 22120, Train_acc:0.933854
Step: 22120, Val_acc:0.89856
==================>
Step: 22130, Train_acc:0.954001
Step: 22130, Val_acc:0.881222
==================>
Step: 22140, Train_acc:0.935988
Step: 22140, Val_acc:0.915687
==================>
Step: 22150, Train_acc:0.951711
Step: 22150, Val_acc:0.865028
==================>
Step: 22160, Train_acc:0.945161
Step: 22160, Val_acc:0.862153
==================>
Step: 22170, Train_acc:0.95913
Step: 22170, Val_acc:0.9087
==================>
Step: 22180, Train_acc:0.949751
Step: 22180, Val_acc:0.866771
==================>
Step: 22190, Train_acc:0.952296
Step: 22190, Val_acc:0.856852
==================>
Step: 22200, Train_acc:0.943566
Step: 22200, Val_acc:0.83679
==================>
2017-11-11 03:06:13.814572 ---> Validation_loss: 0.275559
Step: 22210, Train_acc:0.939573
Step: 22210, Val_acc:0.851785
==================>
Step: 22220, Train_acc:0.923867
Step: 22220, Val_acc:0.894144
==================>
Step: 22230, Train_acc:0.942708
Step: 22230, Val_acc:0.889026
==================>
Step: 22240, Train_acc:0.942419
Step: 22240, Val_acc:0.877915
==================>
Step: 22250, Train_acc:0.935244
Step: 22250, Val_acc:0.878784
==================>
Step: 22260, Train_acc:0.946876
Step: 22260, Val_acc:0.901473
==================>
Step: 22270, Train_acc:0.959047
Step: 22270, Val_acc:0.880138
==================>
Step: 22280, Train_acc:0.938512
Step: 22280, Val_acc:0.865807
==================>
Step: 22290, Train_acc:0.940333
Step: 22290, Val_acc:0.890624
==================>
Step: 22300, Train_acc:0.950648
Step: 22300, Val_acc:0.901119
==================>
2017-11-11 03:08:50.114682 ---> Validation_loss: 0.217939
Step: 22310, Train_acc:0.925408
Step: 22310, Val_acc:0.882886
==================>
Step: 22320, Train_acc:0.94952
Step: 22320, Val_acc:0.901191
==================>
Step: 22330, Train_acc:0.93634
Step: 22330, Val_acc:0.915015
==================>
Step: 22340, Train_acc:0.948645
Step: 22340, Val_acc:0.870963
==================>
Step: 22350, Train_acc:0.948614
Step: 22350, Val_acc:0.878438
==================>
Step: 22360, Train_acc:0.96489
Step: 22360, Val_acc:0.896653
==================>
Step: 22370, Train_acc:0.948994
Step: 22370, Val_acc:0.862687
==================>
Step: 22380, Train_acc:0.935079
Step: 22380, Val_acc:0.878009
==================>
Step: 22390, Train_acc:0.937631
Step: 22390, Val_acc:0.88359
==================>
Step: 22400, Train_acc:0.942853
Step: 22400, Val_acc:0.909232
==================>
2017-11-11 03:11:26.625096 ---> Validation_loss: 0.295767
Step: 22410, Train_acc:0.942117
Step: 22410, Val_acc:0.920234
==================>
Step: 22420, Train_acc:0.942535
Step: 22420, Val_acc:0.902629
==================>
Step: 22430, Train_acc:0.951735
Step: 22430, Val_acc:0.883872
==================>
Step: 22440, Train_acc:0.952228
Step: 22440, Val_acc:0.915682
==================>
Step: 22450, Train_acc:0.958866
Step: 22450, Val_acc:0.8892
==================>
Step: 22460, Train_acc:0.949598
Step: 22460, Val_acc:0.89234
==================>
Step: 22470, Train_acc:0.947434
Step: 22470, Val_acc:0.892972
==================>
Step: 22480, Train_acc:0.943796
Step: 22480, Val_acc:0.880482
==================>
Step: 22490, Train_acc:0.945106
Step: 22490, Val_acc:0.861777
==================>
Step: 22500, Train_acc:0.958049
Step: 22500, Val_acc:0.866251
==================>
****************** Epochs completed: 45******************
2017-11-11 03:14:02.949193 ---> Validation_loss: 0.265351
Step: 22510, Train_acc:0.926906
Step: 22510, Val_acc:0.91752
==================>
Step: 22520, Train_acc:0.961501
Step: 22520, Val_acc:0.890931
==================>
Step: 22530, Train_acc:0.936619
Step: 22530, Val_acc:0.873363
==================>
Step: 22540, Train_acc:0.955052
Step: 22540, Val_acc:0.925729
==================>
Step: 22550, Train_acc:0.936367
Step: 22550, Val_acc:0.862123
==================>
Step: 22560, Train_acc:0.940782
Step: 22560, Val_acc:0.904652
==================>
Step: 22570, Train_acc:0.944886
Step: 22570, Val_acc:0.894396
==================>
Step: 22580, Train_acc:0.933585
Step: 22580, Val_acc:0.89382
==================>
Step: 22590, Train_acc:0.953959
Step: 22590, Val_acc:0.836384
==================>
Step: 22600, Train_acc:0.958022
Step: 22600, Val_acc:0.911813
==================>
2017-11-11 03:16:39.619406 ---> Validation_loss: 0.287567
Step: 22610, Train_acc:0.947001
Step: 22610, Val_acc:0.857562
==================>
Step: 22620, Train_acc:0.967462
Step: 22620, Val_acc:0.852328
==================>
Step: 22630, Train_acc:0.95522
Step: 22630, Val_acc:0.903423
==================>
Step: 22640, Train_acc:0.953717
Step: 22640, Val_acc:0.882601
==================>
Step: 22650, Train_acc:0.935443
Step: 22650, Val_acc:0.909061
==================>
Step: 22660, Train_acc:0.941405
Step: 22660, Val_acc:0.890217
==================>
Step: 22670, Train_acc:0.938107
Step: 22670, Val_acc:0.919583
==================>
Step: 22680, Train_acc:0.932671
Step: 22680, Val_acc:0.899658
==================>
Step: 22690, Train_acc:0.953424
Step: 22690, Val_acc:0.906563
==================>
Step: 22700, Train_acc:0.951609
Step: 22700, Val_acc:0.871558
==================>
2017-11-11 03:19:16.137061 ---> Validation_loss: 0.298806
Step: 22710, Train_acc:0.943374
Step: 22710, Val_acc:0.900536
==================>
Step: 22720, Train_acc:0.957627
Step: 22720, Val_acc:0.865696
==================>
Step: 22730, Train_acc:0.952129
Step: 22730, Val_acc:0.874548
==================>
Step: 22740, Train_acc:0.932318
Step: 22740, Val_acc:0.884883
==================>
Step: 22750, Train_acc:0.952737
Step: 22750, Val_acc:0.868835
==================>
Step: 22760, Train_acc:0.948552
Step: 22760, Val_acc:0.850818
==================>
Step: 22770, Train_acc:0.938741
Step: 22770, Val_acc:0.902537
==================>
Step: 22780, Train_acc:0.948997
Step: 22780, Val_acc:0.85939
==================>
Step: 22790, Train_acc:0.959816
Step: 22790, Val_acc:0.880094
==================>
Step: 22800, Train_acc:0.94265
Step: 22800, Val_acc:0.836659
==================>
2017-11-11 03:21:52.540126 ---> Validation_loss: 0.247223
Step: 22810, Train_acc:0.935579
Step: 22810, Val_acc:0.876971
==================>
Step: 22820, Train_acc:0.949735
Step: 22820, Val_acc:0.873021
==================>
Step: 22830, Train_acc:0.941937
Step: 22830, Val_acc:0.858519
==================>
Step: 22840, Train_acc:0.931241
Step: 22840, Val_acc:0.913291
==================>
Step: 22850, Train_acc:0.945953
Step: 22850, Val_acc:0.867323
==================>
Step: 22860, Train_acc:0.954565
Step: 22860, Val_acc:0.901431
==================>
Step: 22870, Train_acc:0.93505
Step: 22870, Val_acc:0.863783
==================>
Step: 22880, Train_acc:0.937471
Step: 22880, Val_acc:0.900742
==================>
Step: 22890, Train_acc:0.95329
Step: 22890, Val_acc:0.917454
==================>
Step: 22900, Train_acc:0.958008
Step: 22900, Val_acc:0.883754
==================>
2017-11-11 03:24:28.855369 ---> Validation_loss: 0.189022
Step: 22910, Train_acc:0.947207
Step: 22910, Val_acc:0.843627
==================>
Step: 22920, Train_acc:0.956937
Step: 22920, Val_acc:0.88306
==================>
Step: 22930, Train_acc:0.937791
Step: 22930, Val_acc:0.912858
==================>
Step: 22940, Train_acc:0.943751
Step: 22940, Val_acc:0.883645
==================>
Step: 22950, Train_acc:0.954645
Step: 22950, Val_acc:0.847397
==================>
Step: 22960, Train_acc:0.949143
Step: 22960, Val_acc:0.864634
==================>
Step: 22970, Train_acc:0.956383
Step: 22970, Val_acc:0.883005
==================>
Step: 22980, Train_acc:0.937379
Step: 22980, Val_acc:0.892433
==================>
Step: 22990, Train_acc:0.945846
Step: 22990, Val_acc:0.876801
==================>
Step: 23000, Train_acc:0.957831
Step: 23000, Val_acc:0.887744
==================>
****************** Epochs completed: 46******************
2017-11-11 03:27:05.632921 ---> Validation_loss: 0.299136
Step: 23010, Train_acc:0.947898
Step: 23010, Val_acc:0.868876
==================>
Step: 23020, Train_acc:0.961466
Step: 23020, Val_acc:0.91161
==================>
Step: 23030, Train_acc:0.941044
Step: 23030, Val_acc:0.90292
==================>
Step: 23040, Train_acc:0.955461
Step: 23040, Val_acc:0.865228
==================>
Step: 23050, Train_acc:0.954651
Step: 23050, Val_acc:0.866559
==================>
Step: 23060, Train_acc:0.934418
Step: 23060, Val_acc:0.90684
==================>
Step: 23070, Train_acc:0.935579
Step: 23070, Val_acc:0.909904
==================>
Step: 23080, Train_acc:0.956875
Step: 23080, Val_acc:0.912384
==================>
Step: 23090, Train_acc:0.941134
Step: 23090, Val_acc:0.867367
==================>
Step: 23100, Train_acc:0.942385
Step: 23100, Val_acc:0.908763
==================>
2017-11-11 03:29:42.202091 ---> Validation_loss: 0.314681
Step: 23110, Train_acc:0.963622
Step: 23110, Val_acc:0.897611
==================>
Step: 23120, Train_acc:0.942093
Step: 23120, Val_acc:0.864055
==================>
Step: 23130, Train_acc:0.936482
Step: 23130, Val_acc:0.917751
==================>
Step: 23140, Train_acc:0.966802
Step: 23140, Val_acc:0.877853
==================>
Step: 23150, Train_acc:0.952694
Step: 23150, Val_acc:0.897899
==================>
Step: 23160, Train_acc:0.947903
Step: 23160, Val_acc:0.908156
==================>
Step: 23170, Train_acc:0.944943
Step: 23170, Val_acc:0.848026
==================>
Step: 23180, Train_acc:0.94428
Step: 23180, Val_acc:0.903209
==================>
Step: 23190, Train_acc:0.944324
Step: 23190, Val_acc:0.909479
==================>
Step: 23200, Train_acc:0.939131
Step: 23200, Val_acc:0.835701
==================>
2017-11-11 03:32:18.656952 ---> Validation_loss: 0.221822
Step: 23210, Train_acc:0.940748
Step: 23210, Val_acc:0.869316
==================>
Step: 23220, Train_acc:0.942087
Step: 23220, Val_acc:0.867096
==================>
Step: 23230, Train_acc:0.938896
Step: 23230, Val_acc:0.88297
==================>
Step: 23240, Train_acc:0.942314
Step: 23240, Val_acc:0.906498
==================>
Step: 23250, Train_acc:0.946586
Step: 23250, Val_acc:0.88483
==================>
Step: 23260, Train_acc:0.957272
Step: 23260, Val_acc:0.878275
==================>
Step: 23270, Train_acc:0.942858
Step: 23270, Val_acc:0.893741
==================>
Step: 23280, Train_acc:0.942356
Step: 23280, Val_acc:0.883976
==================>
Step: 23290, Train_acc:0.947751
Step: 23290, Val_acc:0.85865
==================>
Step: 23300, Train_acc:0.935941
Step: 23300, Val_acc:0.903807
==================>
2017-11-11 03:34:55.183520 ---> Validation_loss: 0.204492
Step: 23310, Train_acc:0.947593
Step: 23310, Val_acc:0.882469
==================>
Step: 23320, Train_acc:0.964092
Step: 23320, Val_acc:0.87999
==================>
Step: 23330, Train_acc:0.936821
Step: 23330, Val_acc:0.903466
==================>
Step: 23340, Train_acc:0.961887
Step: 23340, Val_acc:0.909661
==================>
Step: 23350, Train_acc:0.952678
Step: 23350, Val_acc:0.923676
==================>
Step: 23360, Train_acc:0.951032
Step: 23360, Val_acc:0.877554
==================>
Step: 23370, Train_acc:0.949971
Step: 23370, Val_acc:0.862632
==================>
Step: 23380, Train_acc:0.956508
Step: 23380, Val_acc:0.887778
==================>
Step: 23390, Train_acc:0.954769
Step: 23390, Val_acc:0.905397
==================>
Step: 23400, Train_acc:0.948844
Step: 23400, Val_acc:0.943801
==================>
2017-11-11 03:37:31.639516 ---> Validation_loss: 0.208231
Step: 23410, Train_acc:0.957468
Step: 23410, Val_acc:0.889519
==================>
Step: 23420, Train_acc:0.922788
Step: 23420, Val_acc:0.881896
==================>
Step: 23430, Train_acc:0.940712
Step: 23430, Val_acc:0.901052
==================>
Step: 23440, Train_acc:0.955864
Step: 23440, Val_acc:0.918289
==================>
Step: 23450, Train_acc:0.950927
Step: 23450, Val_acc:0.90481
==================>
Step: 23460, Train_acc:0.962662
Step: 23460, Val_acc:0.89249
==================>
Step: 23470, Train_acc:0.947002
Step: 23470, Val_acc:0.920529
==================>
Step: 23480, Train_acc:0.952816
Step: 23480, Val_acc:0.936848
==================>
Step: 23490, Train_acc:0.949723
Step: 23490, Val_acc:0.887513
==================>
Step: 23500, Train_acc:0.94455
Step: 23500, Val_acc:0.890309
==================>
****************** Epochs completed: 47******************
2017-11-11 03:40:07.956188 ---> Validation_loss: 0.253686
Step: 23510, Train_acc:0.954491
Step: 23510, Val_acc:0.90384
==================>
Step: 23520, Train_acc:0.971475
Step: 23520, Val_acc:0.895421
==================>
Step: 23530, Train_acc:0.944358
Step: 23530, Val_acc:0.878729
==================>
Step: 23540, Train_acc:0.941531
Step: 23540, Val_acc:0.91302
==================>
****************** Epochs completed: 7******************
Step: 23550, Train_acc:0.960254
Step: 23550, Val_acc:0.916204
==================>
Step: 23560, Train_acc:0.953748
Step: 23560, Val_acc:0.893229
==================>
Step: 23570, Train_acc:0.951184
Step: 23570, Val_acc:0.884059
==================>
Step: 23580, Train_acc:0.952434
Step: 23580, Val_acc:0.924664
==================>
Step: 23590, Train_acc:0.95279
Step: 23590, Val_acc:0.927426
==================>
Step: 23600, Train_acc:0.954102
Step: 23600, Val_acc:0.872793
==================>
2017-11-11 03:42:44.587779 ---> Validation_loss: 0.311622
Step: 23610, Train_acc:0.955808
Step: 23610, Val_acc:0.938336
==================>
Step: 23620, Train_acc:0.942544
Step: 23620, Val_acc:0.880853
==================>
Step: 23630, Train_acc:0.962981
Step: 23630, Val_acc:0.879143
==================>
Step: 23640, Train_acc:0.933906
Step: 23640, Val_acc:0.917424
==================>
Step: 23650, Train_acc:0.963134
Step: 23650, Val_acc:0.911008
==================>
Step: 23660, Train_acc:0.934186
Step: 23660, Val_acc:0.899636
==================>
Step: 23670, Train_acc:0.944583
Step: 23670, Val_acc:0.906885
==================>
Step: 23680, Train_acc:0.955049
Step: 23680, Val_acc:0.884894
==================>
Step: 23690, Train_acc:0.944985
Step: 23690, Val_acc:0.873164
==================>
Step: 23700, Train_acc:0.953512
Step: 23700, Val_acc:0.884687
==================>
2017-11-11 03:45:21.049699 ---> Validation_loss: 0.222346
Step: 23710, Train_acc:0.960482
Step: 23710, Val_acc:0.858512
==================>
Step: 23720, Train_acc:0.953246
Step: 23720, Val_acc:0.904884
==================>
Step: 23730, Train_acc:0.952983
Step: 23730, Val_acc:0.902059
==================>
Step: 23740, Train_acc:0.963416
Step: 23740, Val_acc:0.886838
==================>
Step: 23750, Train_acc:0.938423
Step: 23750, Val_acc:0.905197
==================>
Step: 23760, Train_acc:0.950293
Step: 23760, Val_acc:0.925747
==================>
Step: 23770, Train_acc:0.956567
Step: 23770, Val_acc:0.90295
==================>
Step: 23780, Train_acc:0.950768
Step: 23780, Val_acc:0.874491
==================>
Step: 23790, Train_acc:0.95957
Step: 23790, Val_acc:0.897607
==================>
Step: 23800, Train_acc:0.950177
Step: 23800, Val_acc:0.932488
==================>
2017-11-11 03:47:57.687680 ---> Validation_loss: 0.15531
Step: 23810, Train_acc:0.967976
Step: 23810, Val_acc:0.89043
==================>
Step: 23820, Train_acc:0.959868
Step: 23820, Val_acc:0.885826
==================>
Step: 23830, Train_acc:0.960149
Step: 23830, Val_acc:0.912412
==================>
Step: 23840, Train_acc:0.955422
Step: 23840, Val_acc:0.899489
==================>
Step: 23850, Train_acc:0.938068
Step: 23850, Val_acc:0.857173
==================>
Step: 23860, Train_acc:0.95884
Step: 23860, Val_acc:0.890663
==================>
Step: 23870, Train_acc:0.960208
Step: 23870, Val_acc:0.90348
==================>
Step: 23880, Train_acc:0.947213
Step: 23880, Val_acc:0.885947
==================>
Step: 23890, Train_acc:0.950419
Step: 23890, Val_acc:0.873933
==================>
Step: 23900, Train_acc:0.966393
Step: 23900, Val_acc:0.899315
==================>
2017-11-11 03:50:34.115324 ---> Validation_loss: 0.288435
Step: 23910, Train_acc:0.948901
Step: 23910, Val_acc:0.90895
==================>
Step: 23920, Train_acc:0.951198
Step: 23920, Val_acc:0.884581
==================>
Step: 23930, Train_acc:0.941177
Step: 23930, Val_acc:0.88334
==================>
Step: 23940, Train_acc:0.962174
Step: 23940, Val_acc:0.880663
==================>
Step: 23950, Train_acc:0.956908
Step: 23950, Val_acc:0.890758
==================>
Step: 23960, Train_acc:0.952285
Step: 23960, Val_acc:0.898551
==================>
Step: 23970, Train_acc:0.920133
Step: 23970, Val_acc:0.858427
==================>
Step: 23980, Train_acc:0.935018
Step: 23980, Val_acc:0.864401
==================>
Step: 23990, Train_acc:0.93282
Step: 23990, Val_acc:0.867654
==================>
Step: 24000, Train_acc:0.953235
Step: 24000, Val_acc:0.932964
==================>
****************** Epochs completed: 48******************
2017-11-11 03:53:10.631364 ---> Validation_loss: 0.185283
Step: 24010, Train_acc:0.94933
Step: 24010, Val_acc:0.924103
==================>
Step: 24020, Train_acc:0.947002
Step: 24020, Val_acc:0.914989
==================>
Step: 24030, Train_acc:0.956431
Step: 24030, Val_acc:0.910305
==================>
Step: 24040, Train_acc:0.962604
Step: 24040, Val_acc:0.875076
==================>
Step: 24050, Train_acc:0.960555
Step: 24050, Val_acc:0.866066
==================>
Step: 24060, Train_acc:0.954421
Step: 24060, Val_acc:0.901547
==================>
Step: 24070, Train_acc:0.953225
Step: 24070, Val_acc:0.87083
==================>
Step: 24080, Train_acc:0.952368
Step: 24080, Val_acc:0.908048
==================>
Step: 24090, Train_acc:0.959115
Step: 24090, Val_acc:0.872157
==================>
Step: 24100, Train_acc:0.955543
Step: 24100, Val_acc:0.906334
==================>
2017-11-11 03:55:47.196314 ---> Validation_loss: 0.348616
Step: 24110, Train_acc:0.943577
Step: 24110, Val_acc:0.906212
==================>
Step: 24120, Train_acc:0.963525
Step: 24120, Val_acc:0.875303
==================>
Step: 24130, Train_acc:0.953052
Step: 24130, Val_acc:0.893834
==================>
Step: 24140, Train_acc:0.955104
Step: 24140, Val_acc:0.850054
==================>
Step: 24150, Train_acc:0.954352
Step: 24150, Val_acc:0.920273
==================>
Step: 24160, Train_acc:0.959064
Step: 24160, Val_acc:0.905615
==================>
Step: 24170, Train_acc:0.978267
Step: 24170, Val_acc:0.86843
==================>
Step: 24180, Train_acc:0.954059
Step: 24180, Val_acc:0.90832
==================>
Step: 24190, Train_acc:0.964935
Step: 24190, Val_acc:0.893654
==================>
Step: 24200, Train_acc:0.965167
Step: 24200, Val_acc:0.895518
==================>
2017-11-11 03:58:23.973570 ---> Validation_loss: 0.239952
Step: 24210, Train_acc:0.939219
Step: 24210, Val_acc:0.898807
==================>
Step: 24220, Train_acc:0.951859
Step: 24220, Val_acc:0.896749
==================>
Step: 24230, Train_acc:0.946677
Step: 24230, Val_acc:0.889518
==================>
Step: 24240, Train_acc:0.936659
Step: 24240, Val_acc:0.902993
==================>
Step: 24250, Train_acc:0.957051
Step: 24250, Val_acc:0.925953
==================>
Step: 24260, Train_acc:0.954869
Step: 24260, Val_acc:0.933712
==================>
Step: 24270, Train_acc:0.950472
Step: 24270, Val_acc:0.885897
==================>
Step: 24280, Train_acc:0.951945
Step: 24280, Val_acc:0.895256
==================>
Step: 24290, Train_acc:0.948151
Step: 24290, Val_acc:0.914288
==================>
Step: 24300, Train_acc:0.948029
Step: 24300, Val_acc:0.871793
==================>
2017-11-11 04:01:00.402308 ---> Validation_loss: 0.278392
Step: 24310, Train_acc:0.942649
Step: 24310, Val_acc:0.875276
==================>
Step: 24320, Train_acc:0.951838
Step: 24320, Val_acc:0.880951
==================>
Step: 24330, Train_acc:0.937686
Step: 24330, Val_acc:0.883663
==================>
Step: 24340, Train_acc:0.934939
Step: 24340, Val_acc:0.901172
==================>
Step: 24350, Train_acc:0.939843
Step: 24350, Val_acc:0.888477
==================>
Step: 24360, Train_acc:0.946389
Step: 24360, Val_acc:0.894183
==================>
Step: 24370, Train_acc:0.960853
Step: 24370, Val_acc:0.870536
==================>
Step: 24380, Train_acc:0.936929
Step: 24380, Val_acc:0.864156
==================>
Step: 24390, Train_acc:0.952924
Step: 24390, Val_acc:0.911711
==================>
Step: 24400, Train_acc:0.942838
Step: 24400, Val_acc:0.869288
==================>
2017-11-11 04:03:36.998679 ---> Validation_loss: 0.222994
Step: 24410, Train_acc:0.938364
Step: 24410, Val_acc:0.945913
==================>
Step: 24420, Train_acc:0.944988
Step: 24420, Val_acc:0.856235
==================>
Step: 24430, Train_acc:0.949111
Step: 24430, Val_acc:0.920481
==================>
Step: 24440, Train_acc:0.956385
Step: 24440, Val_acc:0.909147
==================>
Step: 24450, Train_acc:0.963958
Step: 24450, Val_acc:0.869387
==================>
Step: 24460, Train_acc:0.931514
Step: 24460, Val_acc:0.906698
==================>
Step: 24470, Train_acc:0.945992
Step: 24470, Val_acc:0.88326
==================>
Step: 24480, Train_acc:0.960491
Step: 24480, Val_acc:0.867705
==================>
Step: 24490, Train_acc:0.960111
Step: 24490, Val_acc:0.913185
==================>
Step: 24500, Train_acc:0.957432
Step: 24500, Val_acc:0.892954
==================>
****************** Epochs completed: 49******************
2017-11-11 04:06:13.645920 ---> Validation_loss: 0.185237
Step: 24510, Train_acc:0.951736
Step: 24510, Val_acc:0.890927
==================>
Step: 24520, Train_acc:0.953385
Step: 24520, Val_acc:0.878345
==================>
Step: 24530, Train_acc:0.944207
Step: 24530, Val_acc:0.912461
==================>
Step: 24540, Train_acc:0.945147
Step: 24540, Val_acc:0.895217
==================>
Step: 24550, Train_acc:0.945704
Step: 24550, Val_acc:0.876464
==================>
Step: 24560, Train_acc:0.945428
Step: 24560, Val_acc:0.887699
==================>
Step: 24570, Train_acc:0.945645
Step: 24570, Val_acc:0.879919
==================>
Step: 24580, Train_acc:0.955645
Step: 24580, Val_acc:0.848934
==================>
Step: 24590, Train_acc:0.960897
Step: 24590, Val_acc:0.904797
==================>
Step: 24600, Train_acc:0.959407
Step: 24600, Val_acc:0.880707
==================>
2017-11-11 04:08:50.196953 ---> Validation_loss: 0.260455
Step: 24610, Train_acc:0.956417
Step: 24610, Val_acc:0.866345
==================>
Step: 24620, Train_acc:0.947299
Step: 24620, Val_acc:0.894345
==================>
Step: 24630, Train_acc:0.947075
Step: 24630, Val_acc:0.88392
==================>
Step: 24640, Train_acc:0.96076
Step: 24640, Val_acc:0.906705
==================>
Step: 24650, Train_acc:0.955408
Step: 24650, Val_acc:0.929824
==================>
Step: 24660, Train_acc:0.940153
Step: 24660, Val_acc:0.875691
==================>
Step: 24670, Train_acc:0.951514
Step: 24670, Val_acc:0.877478
==================>
Step: 24680, Train_acc:0.957955
Step: 24680, Val_acc:0.921207
==================>
Step: 24690, Train_acc:0.958872
Step: 24690, Val_acc:0.891423
==================>
Step: 24700, Train_acc:0.952109
Step: 24700, Val_acc:0.902775
==================>
2017-11-11 04:11:26.432477 ---> Validation_loss: 0.283881
Step: 24710, Train_acc:0.949463
Step: 24710, Val_acc:0.912104
==================>
Step: 24720, Train_acc:0.954719
Step: 24720, Val_acc:0.87109
==================>
Step: 24730, Train_acc:0.950038
Step: 24730, Val_acc:0.921115
==================>
Step: 24740, Train_acc:0.949343
Step: 24740, Val_acc:0.859395
==================>
Step: 24750, Train_acc:0.953477
Step: 24750, Val_acc:0.890525
==================>
Step: 24760, Train_acc:0.949835
Step: 24760, Val_acc:0.907282
==================>
Step: 24770, Train_acc:0.961989
Step: 24770, Val_acc:0.887263
==================>
Step: 24780, Train_acc:0.945043
Step: 24780, Val_acc:0.893236
==================>
Step: 24790, Train_acc:0.939661
Step: 24790, Val_acc:0.874813
==================>
Step: 24800, Train_acc:0.94512
Step: 24800, Val_acc:0.870001
==================>
2017-11-11 04:14:02.590535 ---> Validation_loss: 0.287187
Step: 24810, Train_acc:0.951627
Step: 24810, Val_acc:0.927231
==================>
Step: 24820, Train_acc:0.948591
Step: 24820, Val_acc:0.88574
==================>
Step: 24830, Train_acc:0.951573
Step: 24830, Val_acc:0.907074
==================>
Step: 24840, Train_acc:0.9373
Step: 24840, Val_acc:0.902245
==================>
Step: 24850, Train_acc:0.947697
Step: 24850, Val_acc:0.885306
==================>
Step: 24860, Train_acc:0.964016
Step: 24860, Val_acc:0.888181
==================>
Step: 24870, Train_acc:0.964261
Step: 24870, Val_acc:0.893562
==================>
Step: 24880, Train_acc:0.960731
Step: 24880, Val_acc:0.887521
==================>
Step: 24890, Train_acc:0.935826
Step: 24890, Val_acc:0.901052
==================>
Step: 24900, Train_acc:0.95868
Step: 24900, Val_acc:0.924915
==================>
2017-11-11 04:16:39.016492 ---> Validation_loss: 0.180977
Step: 24910, Train_acc:0.9636
Step: 24910, Val_acc:0.892288
==================>
Step: 24920, Train_acc:0.938173
Step: 24920, Val_acc:0.859556
==================>
Step: 24930, Train_acc:0.943472
Step: 24930, Val_acc:0.906718
==================>
Step: 24940, Train_acc:0.953109
Step: 24940, Val_acc:0.884338
==================>
Step: 24950, Train_acc:0.956899
Step: 24950, Val_acc:0.867438
==================>
Step: 24960, Train_acc:0.953778
Step: 24960, Val_acc:0.903867
==================>
Step: 24970, Train_acc:0.951403
Step: 24970, Val_acc:0.919927
==================>
Step: 24980, Train_acc:0.972395
Step: 24980, Val_acc:0.904645
==================>
Step: 24990, Train_acc:0.943945
Step: 24990, Val_acc:0.906373
==================>
Step: 25000, Train_acc:0.941238
Step: 25000, Val_acc:0.892227
==================>
****************** Epochs completed: 50******************
2017-11-11 04:19:15.599590 ---> Validation_loss: 0.2168
Step: 25010, Train_acc:0.944163
Step: 25010, Val_acc:0.876572
==================>
Step: 25020, Train_acc:0.952144
Step: 25020, Val_acc:0.909767
==================>
Step: 25030, Train_acc:0.953007
Step: 25030, Val_acc:0.900374
==================>
Step: 25040, Train_acc:0.962056
Step: 25040, Val_acc:0.888546
==================>
Step: 25050, Train_acc:0.946503
Step: 25050, Val_acc:0.91472
==================>
Step: 25060, Train_acc:0.936526
Step: 25060, Val_acc:0.906093
==================>
Step: 25070, Train_acc:0.948394
Step: 25070, Val_acc:0.906833
==================>
Step: 25080, Train_acc:0.949311
Step: 25080, Val_acc:0.896476
==================>
Step: 25090, Train_acc:0.962462
Step: 25090, Val_acc:0.900441
==================>
Step: 25100, Train_acc:0.966758
Step: 25100, Val_acc:0.929325
==================>
2017-11-11 04:21:51.935102 ---> Validation_loss: 0.212396
Step: 25110, Train_acc:0.942174
Step: 25110, Val_acc:0.868381
==================>
Step: 25120, Train_acc:0.954946
Step: 25120, Val_acc:0.908616
==================>
Step: 25130, Train_acc:0.956006
Step: 25130, Val_acc:0.899348
==================>
Step: 25140, Train_acc:0.953783
Step: 25140, Val_acc:0.878828
==================>
Step: 25150, Train_acc:0.948386
Step: 25150, Val_acc:0.900519
==================>
Step: 25160, Train_acc:0.946875
Step: 25160, Val_acc:0.897562
==================>
Step: 25170, Train_acc:0.931437
Step: 25170, Val_acc:0.88575
==================>
Step: 25180, Train_acc:0.953555
Step: 25180, Val_acc:0.893527
==================>
Step: 25190, Train_acc:0.932653
Step: 25190, Val_acc:0.890133
==================>
Step: 25200, Train_acc:0.944606
Step: 25200, Val_acc:0.899319
==================>
2017-11-11 04:24:28.454352 ---> Validation_loss: 0.193778
Step: 25210, Train_acc:0.929105
Step: 25210, Val_acc:0.93585
==================>
Step: 25220, Train_acc:0.948176
Step: 25220, Val_acc:0.888351
==================>
Step: 25230, Train_acc:0.960511
Step: 25230, Val_acc:0.881516
==================>
Step: 25240, Train_acc:0.961392
Step: 25240, Val_acc:0.9214
==================>
Step: 25250, Train_acc:0.954265
Step: 25250, Val_acc:0.910372
==================>
Step: 25260, Train_acc:0.958677
Step: 25260, Val_acc:0.906885
==================>
Step: 25270, Train_acc:0.943793
Step: 25270, Val_acc:0.875653
==================>
Step: 25280, Train_acc:0.951702
Step: 25280, Val_acc:0.863682
==================>
Step: 25290, Train_acc:0.963455
Step: 25290, Val_acc:0.896926
==================>
Step: 25300, Train_acc:0.925479
Step: 25300, Val_acc:0.887145
==================>
2017-11-11 04:27:04.875883 ---> Validation_loss: 0.366032
Step: 25310, Train_acc:0.967571
Step: 25310, Val_acc:0.878243
==================>
Step: 25320, Train_acc:0.959788
Step: 25320, Val_acc:0.935973
==================>
Step: 25330, Train_acc:0.962626
Step: 25330, Val_acc:0.873136
==================>
Step: 25340, Train_acc:0.960486
Step: 25340, Val_acc:0.900504
==================>
Step: 25350, Train_acc:0.955739
Step: 25350, Val_acc:0.897865
==================>
Step: 25360, Train_acc:0.960148
Step: 25360, Val_acc:0.911046
==================>
Step: 25370, Train_acc:0.947086
Step: 25370, Val_acc:0.932339
==================>
Step: 25380, Train_acc:0.946458
Step: 25380, Val_acc:0.890812
==================>
Step: 25390, Train_acc:0.953867
Step: 25390, Val_acc:0.933422
==================>
Step: 25400, Train_acc:0.967872
Step: 25400, Val_acc:0.873555
==================>
2017-11-11 04:29:41.494392 ---> Validation_loss: 0.262779
Step: 25410, Train_acc:0.946343
Step: 25410, Val_acc:0.936042
==================>
Step: 25420, Train_acc:0.968679
Step: 25420, Val_acc:0.858384
==================>
Step: 25430, Train_acc:0.952718
Step: 25430, Val_acc:0.917432
==================>
Step: 25440, Train_acc:0.943651
Step: 25440, Val_acc:0.88744
==================>
Step: 25450, Train_acc:0.96804
Step: 25450, Val_acc:0.920157
==================>
Step: 25460, Train_acc:0.959335
Step: 25460, Val_acc:0.923213
==================>
Step: 25470, Train_acc:0.941647
Step: 25470, Val_acc:0.909871
==================>
Step: 25480, Train_acc:0.941847
Step: 25480, Val_acc:0.891565
==================>
Step: 25490, Train_acc:0.940558
Step: 25490, Val_acc:0.8813
==================>
Step: 25500, Train_acc:0.964268
Step: 25500, Val_acc:0.898662
==================>
****************** Epochs completed: 51******************
2017-11-11 04:32:17.696559 ---> Validation_loss: 0.205304
Step: 25510, Train_acc:0.945409
Step: 25510, Val_acc:0.870861
==================>
Step: 25520, Train_acc:0.953917
Step: 25520, Val_acc:0.894285
==================>
Step: 25530, Train_acc:0.954475
Step: 25530, Val_acc:0.885829
==================>
Step: 25540, Train_acc:0.950659
Step: 25540, Val_acc:0.88797
==================>
Step: 25550, Train_acc:0.946864
Step: 25550, Val_acc:0.896306
==================>
Step: 25560, Train_acc:0.943433
Step: 25560, Val_acc:0.921211
==================>
Step: 25570, Train_acc:0.959987
Step: 25570, Val_acc:0.868683
==================>
Step: 25580, Train_acc:0.945513
Step: 25580, Val_acc:0.875558
==================>
Step: 25590, Train_acc:0.953561
Step: 25590, Val_acc:0.898556
==================>
Step: 25600, Train_acc:0.977205
Step: 25600, Val_acc:0.859568
==================>
2017-11-11 04:34:54.358938 ---> Validation_loss: 0.214408
Step: 25610, Train_acc:0.961437
Step: 25610, Val_acc:0.882355
==================>
Step: 25620, Train_acc:0.948347
Step: 25620, Val_acc:0.922538
==================>
Step: 25630, Train_acc:0.964038
Step: 25630, Val_acc:0.876644
==================>
Step: 25640, Train_acc:0.964926
Step: 25640, Val_acc:0.870704
==================>
Step: 25650, Train_acc:0.954867
Step: 25650, Val_acc:0.883505
==================>
Step: 25660, Train_acc:0.953375
Step: 25660, Val_acc:0.924686
==================>
Step: 25670, Train_acc:0.956619
Step: 25670, Val_acc:0.886353
==================>
Step: 25680, Train_acc:0.94777
Step: 25680, Val_acc:0.870642
==================>
Step: 25690, Train_acc:0.948718
Step: 25690, Val_acc:0.916262
==================>
Step: 25700, Train_acc:0.951166
Step: 25700, Val_acc:0.917091
==================>
2017-11-11 04:37:30.628823 ---> Validation_loss: 0.295806
Step: 25710, Train_acc:0.964705
Step: 25710, Val_acc:0.888511
==================>
Step: 25720, Train_acc:0.940845
Step: 25720, Val_acc:0.892112
==================>
Step: 25730, Train_acc:0.964999
Step: 25730, Val_acc:0.930414
==================>
Step: 25740, Train_acc:0.956619
Step: 25740, Val_acc:0.916382
==================>
Step: 25750, Train_acc:0.938876
Step: 25750, Val_acc:0.892314
==================>
Step: 25760, Train_acc:0.952792
Step: 25760, Val_acc:0.913997
==================>
Step: 25770, Train_acc:0.958058
Step: 25770, Val_acc:0.883097
==================>
Step: 25780, Train_acc:0.94877
Step: 25780, Val_acc:0.924244
==================>
Step: 25790, Train_acc:0.968016
Step: 25790, Val_acc:0.900424
==================>
Step: 25800, Train_acc:0.918776
Step: 25800, Val_acc:0.885393
==================>
2017-11-11 04:40:06.897531 ---> Validation_loss: 0.222858
Step: 25810, Train_acc:0.959946
Step: 25810, Val_acc:0.883673
==================>
Step: 25820, Train_acc:0.964341
Step: 25820, Val_acc:0.917028
==================>
Step: 25830, Train_acc:0.947838
Step: 25830, Val_acc:0.911984
==================>
Step: 25840, Train_acc:0.952187
Step: 25840, Val_acc:0.885095
==================>
Step: 25850, Train_acc:0.945865
Step: 25850, Val_acc:0.929166
==================>
Step: 25860, Train_acc:0.962161
Step: 25860, Val_acc:0.861776
==================>
Step: 25870, Train_acc:0.944592
Step: 25870, Val_acc:0.882969
==================>
Step: 25880, Train_acc:0.947881
Step: 25880, Val_acc:0.90728
==================>
Step: 25890, Train_acc:0.957706
Step: 25890, Val_acc:0.923414
==================>
Step: 25900, Train_acc:0.953163
Step: 25900, Val_acc:0.878225
==================>
2017-11-11 04:42:43.668525 ---> Validation_loss: 0.273423
Step: 25910, Train_acc:0.959286
Step: 25910, Val_acc:0.873783
==================>
Step: 25920, Train_acc:0.940415
Step: 25920, Val_acc:0.911693
==================>
Step: 25930, Train_acc:0.969489
Step: 25930, Val_acc:0.876003
==================>
Step: 25940, Train_acc:0.958823
Step: 25940, Val_acc:0.890706
==================>
Step: 25950, Train_acc:0.952026
Step: 25950, Val_acc:0.860289
==================>
Step: 25960, Train_acc:0.94899
Step: 25960, Val_acc:0.871437
==================>
Step: 25970, Train_acc:0.963566
Step: 25970, Val_acc:0.859159
==================>
Step: 25980, Train_acc:0.943214
Step: 25980, Val_acc:0.924065
==================>
Step: 25990, Train_acc:0.952455
Step: 25990, Val_acc:0.894602
==================>
Step: 26000, Train_acc:0.940668
Step: 26000, Val_acc:0.86996
==================>
****************** Epochs completed: 52******************
2017-11-11 04:45:20.656769 ---> Validation_loss: 0.228412
Step: 26010, Train_acc:0.945244
Step: 26010, Val_acc:0.911157
==================>
Step: 26020, Train_acc:0.958468
Step: 26020, Val_acc:0.884271
==================>
Step: 26030, Train_acc:0.95152
Step: 26030, Val_acc:0.889417
==================>
Step: 26040, Train_acc:0.95714
Step: 26040, Val_acc:0.915977
==================>
Step: 26050, Train_acc:0.955256
Step: 26050, Val_acc:0.902441
==================>
Step: 26060, Train_acc:0.964099
Step: 26060, Val_acc:0.902191
==================>
Step: 26070, Train_acc:0.945875
Step: 26070, Val_acc:0.901597
==================>
Step: 26080, Train_acc:0.954972
Step: 26080, Val_acc:0.88675
==================>
Step: 26090, Train_acc:0.957091
Step: 26090, Val_acc:0.901066
==================>
Step: 26100, Train_acc:0.939945
Step: 26100, Val_acc:0.869443
==================>
2017-11-11 04:47:57.207842 ---> Validation_loss: 0.267894
Step: 26110, Train_acc:0.959006
Step: 26110, Val_acc:0.909825
==================>
Step: 26120, Train_acc:0.956809
Step: 26120, Val_acc:0.926875
==================>
Step: 26130, Train_acc:0.969384
Step: 26130, Val_acc:0.84776
==================>
Step: 26140, Train_acc:0.965255
Step: 26140, Val_acc:0.866389
==================>
Step: 26150, Train_acc:0.969384
Step: 26150, Val_acc:0.908717
==================>
Step: 26160, Train_acc:0.946375
Step: 26160, Val_acc:0.894341
==================>
Step: 26170, Train_acc:0.962717
Step: 26170, Val_acc:0.896398
==================>
Step: 26180, Train_acc:0.967822
Step: 26180, Val_acc:0.864312
==================>
Step: 26190, Train_acc:0.956521
Step: 26190, Val_acc:0.923218
==================>
Step: 26200, Train_acc:0.946045
Step: 26200, Val_acc:0.903253
==================>
2017-11-11 04:50:33.858832 ---> Validation_loss: 0.223676
Step: 26210, Train_acc:0.957408
Step: 26210, Val_acc:0.867627
==================>
Step: 26220, Train_acc:0.938181
Step: 26220, Val_acc:0.87438
==================>
Step: 26230, Train_acc:0.95647
Step: 26230, Val_acc:0.903389
==================>
Step: 26240, Train_acc:0.956221
Step: 26240, Val_acc:0.89
==================>
Step: 26250, Train_acc:0.965559
Step: 26250, Val_acc:0.919498
==================>
Step: 26260, Train_acc:0.959027
Step: 26260, Val_acc:0.876387
==================>
Step: 26270, Train_acc:0.958033
Step: 26270, Val_acc:0.862357
==================>
Step: 26280, Train_acc:0.940295
Step: 26280, Val_acc:0.892371
==================>
Step: 26290, Train_acc:0.946089
Step: 26290, Val_acc:0.899076
==================>
Step: 26300, Train_acc:0.954391
Step: 26300, Val_acc:0.884185
==================>
2017-11-11 04:53:10.373490 ---> Validation_loss: 0.216839
Step: 26310, Train_acc:0.947743
Step: 26310, Val_acc:0.901202
==================>
Step: 26320, Train_acc:0.948398
Step: 26320, Val_acc:0.925865
==================>
Step: 26330, Train_acc:0.958849
Step: 26330, Val_acc:0.939631
==================>
Step: 26340, Train_acc:0.955234
Step: 26340, Val_acc:0.907861
==================>
Step: 26350, Train_acc:0.947156
Step: 26350, Val_acc:0.87093
==================>
Step: 26360, Train_acc:0.957439
Step: 26360, Val_acc:0.855869
==================>
Step: 26370, Train_acc:0.950087
Step: 26370, Val_acc:0.900502
==================>
Step: 26380, Train_acc:0.938152
Step: 26380, Val_acc:0.873964
==================>
Step: 26390, Train_acc:0.946005
Step: 26390, Val_acc:0.879302
==================>
Step: 26400, Train_acc:0.944071
Step: 26400, Val_acc:0.916217
==================>
2017-11-11 04:55:47.225344 ---> Validation_loss: 0.289926
Step: 26410, Train_acc:0.951824
Step: 26410, Val_acc:0.897303
==================>
Step: 26420, Train_acc:0.944644
Step: 26420, Val_acc:0.874968
==================>
Step: 26430, Train_acc:0.950477
Step: 26430, Val_acc:0.895831
==================>
Step: 26440, Train_acc:0.943886
Step: 26440, Val_acc:0.936171
==================>
Step: 26450, Train_acc:0.952417
Step: 26450, Val_acc:0.869573
==================>
Step: 26460, Train_acc:0.950859
Step: 26460, Val_acc:0.905054
==================>
Step: 26470, Train_acc:0.95556
Step: 26470, Val_acc:0.873571
==================>
Step: 26480, Train_acc:0.96061
Step: 26480, Val_acc:0.908218
==================>
Step: 26490, Train_acc:0.952701
Step: 26490, Val_acc:0.932595
==================>
Step: 26500, Train_acc:0.95644
Step: 26500, Val_acc:0.890542
==================>
****************** Epochs completed: 53******************
2017-11-11 04:58:23.899332 ---> Validation_loss: 0.319772
Step: 26510, Train_acc:0.957881
Step: 26510, Val_acc:0.923507
==================>
Step: 26520, Train_acc:0.95738
Step: 26520, Val_acc:0.895678
==================>
Step: 26530, Train_acc:0.960671
Step: 26530, Val_acc:0.886852
==================>
Step: 26540, Train_acc:0.946346
Step: 26540, Val_acc:0.88605
==================>
Step: 26550, Train_acc:0.950781
Step: 26550, Val_acc:0.855732
==================>
Step: 26560, Train_acc:0.954519
Step: 26560, Val_acc:0.903512
==================>
Step: 26570, Train_acc:0.931594
Step: 26570, Val_acc:0.914888
==================>
Step: 26580, Train_acc:0.961028
Step: 26580, Val_acc:0.888873
==================>
Step: 26590, Train_acc:0.958197
Step: 26590, Val_acc:0.935322
==================>
Step: 26600, Train_acc:0.947765
Step: 26600, Val_acc:0.938555
==================>
2017-11-11 05:01:00.398976 ---> Validation_loss: 0.23676
Step: 26610, Train_acc:0.953472
Step: 26610, Val_acc:0.893463
==================>
Step: 26620, Train_acc:0.94167
Step: 26620, Val_acc:0.922909
==================>
Step: 26630, Train_acc:0.944536
Step: 26630, Val_acc:0.886482
==================>
Step: 26640, Train_acc:0.943888
Step: 26640, Val_acc:0.87937
==================>
Step: 26650, Train_acc:0.954045
Step: 26650, Val_acc:0.859163
==================>
Step: 26660, Train_acc:0.953634
Step: 26660, Val_acc:0.905955
==================>
Step: 26670, Train_acc:0.96181
Step: 26670, Val_acc:0.910874
==================>
Step: 26680, Train_acc:0.949917
Step: 26680, Val_acc:0.906418
==================>
Step: 26690, Train_acc:0.945375
Step: 26690, Val_acc:0.907423
==================>
Step: 26700, Train_acc:0.938058
Step: 26700, Val_acc:0.900934
==================>
2017-11-11 05:03:37.041360 ---> Validation_loss: 0.178566
Step: 26710, Train_acc:0.941815
Step: 26710, Val_acc:0.886581
==================>
Step: 26720, Train_acc:0.959659
Step: 26720, Val_acc:0.908374
==================>
Step: 26730, Train_acc:0.953448
Step: 26730, Val_acc:0.863019
==================>
Step: 26740, Train_acc:0.954977
Step: 26740, Val_acc:0.894167
==================>
Step: 26750, Train_acc:0.958448
Step: 26750, Val_acc:0.898712
==================>
Step: 26760, Train_acc:0.958601
Step: 26760, Val_acc:0.914093
==================>
Step: 26770, Train_acc:0.956659
Step: 26770, Val_acc:0.917282
==================>
Step: 26780, Train_acc:0.952093
Step: 26780, Val_acc:0.882799
==================>
Step: 26790, Train_acc:0.95413
Step: 26790, Val_acc:0.915042
==================>
Step: 26800, Train_acc:0.957379
Step: 26800, Val_acc:0.920653
==================>
2017-11-11 05:06:13.540082 ---> Validation_loss: 0.212928
Step: 26810, Train_acc:0.96025
Step: 26810, Val_acc:0.891979
==================>
Step: 26820, Train_acc:0.956152
Step: 26820, Val_acc:0.866337
==================>
Step: 26830, Train_acc:0.951198
Step: 26830, Val_acc:0.895275
==================>
Step: 26840, Train_acc:0.945287
Step: 26840, Val_acc:0.906333
==================>
Step: 26850, Train_acc:0.953829
Step: 26850, Val_acc:0.911472
==================>
Step: 26860, Train_acc:0.952123
Step: 26860, Val_acc:0.904363
==================>
Step: 26870, Train_acc:0.951536
Step: 26870, Val_acc:0.872198
==================>
Step: 26880, Train_acc:0.966948
Step: 26880, Val_acc:0.872627
==================>
Step: 26890, Train_acc:0.961982
Step: 26890, Val_acc:0.875245
==================>
Step: 26900, Train_acc:0.963209
Step: 26900, Val_acc:0.917421
==================>
2017-11-11 05:08:50.162809 ---> Validation_loss: 0.251405
Step: 26910, Train_acc:0.949775
Step: 26910, Val_acc:0.892542
==================>
****************** Epochs completed: 8******************
Step: 26920, Train_acc:0.96431
Step: 26920, Val_acc:0.908159
==================>
Step: 26930, Train_acc:0.940846
Step: 26930, Val_acc:0.922563
==================>
Step: 26940, Train_acc:0.959972
Step: 26940, Val_acc:0.891611
==================>
Step: 26950, Train_acc:0.963236
Step: 26950, Val_acc:0.909949
==================>
Step: 26960, Train_acc:0.959728
Step: 26960, Val_acc:0.879535
==================>
Step: 26970, Train_acc:0.948823
Step: 26970, Val_acc:0.893488
==================>
Step: 26980, Train_acc:0.952622
Step: 26980, Val_acc:0.927444
==================>
Step: 26990, Train_acc:0.955322
Step: 26990, Val_acc:0.910172
==================>
Step: 27000, Train_acc:0.956622
Step: 27000, Val_acc:0.92401
==================>
****************** Epochs completed: 54******************
2017-11-11 05:11:26.005551 ---> Validation_loss: 0.228108
Step: 27010, Train_acc:0.945605
Step: 27010, Val_acc:0.867395
==================>
Step: 27020, Train_acc:0.953666
Step: 27020, Val_acc:0.887238
==================>
Step: 27030, Train_acc:0.954291
Step: 27030, Val_acc:0.885558
==================>
Step: 27040, Train_acc:0.958234
Step: 27040, Val_acc:0.900967
==================>
Step: 27050, Train_acc:0.954196
Step: 27050, Val_acc:0.880817
==================>
Step: 27060, Train_acc:0.959001
Step: 27060, Val_acc:0.876832
==================>
Step: 27070, Train_acc:0.95025
Step: 27070, Val_acc:0.907574
==================>
Step: 27080, Train_acc:0.960638
Step: 27080, Val_acc:0.890037
==================>
Step: 27090, Train_acc:0.95807
Step: 27090, Val_acc:0.899064
==================>
Step: 27100, Train_acc:0.964775
Step: 27100, Val_acc:0.903274
==================>
2017-11-11 05:14:01.666907 ---> Validation_loss: 0.289592
Step: 27110, Train_acc:0.956471
Step: 27110, Val_acc:0.916616
==================>
Step: 27120, Train_acc:0.967797
Step: 27120, Val_acc:0.904525
==================>
Step: 27130, Train_acc:0.96718
Step: 27130, Val_acc:0.878491
==================>
Step: 27140, Train_acc:0.961354
Step: 27140, Val_acc:0.925231
==================>
Step: 27150, Train_acc:0.946802
Step: 27150, Val_acc:0.886459
==================>
Step: 27160, Train_acc:0.947723
Step: 27160, Val_acc:0.921897
==================>
Step: 27170, Train_acc:0.956725
Step: 27170, Val_acc:0.90192
==================>
Step: 27180, Train_acc:0.953149
Step: 27180, Val_acc:0.910731
==================>
Step: 27190, Train_acc:0.964789
Step: 27190, Val_acc:0.879276
==================>
Step: 27200, Train_acc:0.952972
Step: 27200, Val_acc:0.910192
==================>
2017-11-11 05:16:37.962284 ---> Validation_loss: 0.153993
Step: 27210, Train_acc:0.964288
Step: 27210, Val_acc:0.872242
==================>
Step: 27220, Train_acc:0.965376
Step: 27220, Val_acc:0.918356
==================>
Step: 27230, Train_acc:0.952753
Step: 27230, Val_acc:0.887638
==================>
Step: 27240, Train_acc:0.966615
Step: 27240, Val_acc:0.9328
==================>
Step: 27250, Train_acc:0.961802
Step: 27250, Val_acc:0.881986
==================>
Step: 27260, Train_acc:0.965221
Step: 27260, Val_acc:0.92579
==================>
Step: 27270, Train_acc:0.973386
Step: 27270, Val_acc:0.899127
==================>
Step: 27280, Train_acc:0.942859
Step: 27280, Val_acc:0.884968
==================>
Step: 27290, Train_acc:0.948116
Step: 27290, Val_acc:0.919386
==================>
Step: 27300, Train_acc:0.966533
Step: 27300, Val_acc:0.896504
==================>
2017-11-11 05:19:14.117464 ---> Validation_loss: 0.233613
Step: 27310, Train_acc:0.961077
Step: 27310, Val_acc:0.925388
==================>
Step: 27320, Train_acc:0.959879
Step: 27320, Val_acc:0.865164
==================>
Step: 27330, Train_acc:0.957285
Step: 27330, Val_acc:0.907782
==================>
Step: 27340, Train_acc:0.960946
Step: 27340, Val_acc:0.912352
==================>
Step: 27350, Train_acc:0.953926
Step: 27350, Val_acc:0.905107
==================>
Step: 27360, Train_acc:0.953676
Step: 27360, Val_acc:0.875997
==================>
Step: 27370, Train_acc:0.965963
Step: 27370, Val_acc:0.884687
==================>
Step: 27380, Train_acc:0.966234
Step: 27380, Val_acc:0.931246
==================>
Step: 27390, Train_acc:0.964783
Step: 27390, Val_acc:0.91749
==================>
Step: 27400, Train_acc:0.949019
Step: 27400, Val_acc:0.915896
==================>
2017-11-11 05:21:50.344440 ---> Validation_loss: 0.313188
Step: 27410, Train_acc:0.970065
Step: 27410, Val_acc:0.922677
==================>
Step: 27420, Train_acc:0.962238
Step: 27420, Val_acc:0.847653
==================>
Step: 27430, Train_acc:0.95678
Step: 27430, Val_acc:0.917576
==================>
Step: 27440, Train_acc:0.951133
Step: 27440, Val_acc:0.914064
==================>
Step: 27450, Train_acc:0.95438
Step: 27450, Val_acc:0.936736
==================>
Step: 27460, Train_acc:0.953613
Step: 27460, Val_acc:0.902139
==================>
Step: 27470, Train_acc:0.956807
Step: 27470, Val_acc:0.898927
==================>
Step: 27480, Train_acc:0.95498
Step: 27480, Val_acc:0.913499
==================>
Step: 27490, Train_acc:0.96426
Step: 27490, Val_acc:0.897238
==================>
Step: 27500, Train_acc:0.953558
Step: 27500, Val_acc:0.924662
==================>
****************** Epochs completed: 55******************
2017-11-11 05:24:26.632294 ---> Validation_loss: 0.237081
Step: 27510, Train_acc:0.976226
Step: 27510, Val_acc:0.920198
==================>
Step: 27520, Train_acc:0.962277
Step: 27520, Val_acc:0.93613
==================>
Step: 27530, Train_acc:0.963462
Step: 27530, Val_acc:0.891075
==================>
Step: 27540, Train_acc:0.947103
Step: 27540, Val_acc:0.907548
==================>
Step: 27550, Train_acc:0.953712
Step: 27550, Val_acc:0.90176
==================>
Step: 27560, Train_acc:0.963014
Step: 27560, Val_acc:0.932625
==================>
Step: 27570, Train_acc:0.956807
Step: 27570, Val_acc:0.898557
==================>
Step: 27580, Train_acc:0.95618
Step: 27580, Val_acc:0.875964
==================>
Step: 27590, Train_acc:0.951361
Step: 27590, Val_acc:0.912823
==================>
Step: 27600, Train_acc:0.947661
Step: 27600, Val_acc:0.902513
==================>
2017-11-11 05:27:03.479918 ---> Validation_loss: 0.177817
Step: 27610, Train_acc:0.940194
Step: 27610, Val_acc:0.888563
==================>
Step: 27620, Train_acc:0.957073
Step: 27620, Val_acc:0.906653
==================>
Step: 27630, Train_acc:0.951201
Step: 27630, Val_acc:0.912194
==================>
Step: 27640, Train_acc:0.970172
Step: 27640, Val_acc:0.874596
==================>
Step: 27650, Train_acc:0.949607
Step: 27650, Val_acc:0.893217
==================>
Step: 27660, Train_acc:0.95485
Step: 27660, Val_acc:0.923927
==================>
Step: 27670, Train_acc:0.952032
Step: 27670, Val_acc:0.916531
==================>
Step: 27680, Train_acc:0.960038
Step: 27680, Val_acc:0.904126
==================>
Step: 27690, Train_acc:0.966498
Step: 27690, Val_acc:0.923741
==================>
Step: 27700, Train_acc:0.926671
Step: 27700, Val_acc:0.946147
==================>
2017-11-11 05:29:39.698190 ---> Validation_loss: 0.229687
Step: 27710, Train_acc:0.950702
Step: 27710, Val_acc:0.918356
==================>
Step: 27720, Train_acc:0.961438
Step: 27720, Val_acc:0.861273
==================>
Step: 27730, Train_acc:0.963292
Step: 27730, Val_acc:0.895206
==================>
Step: 27740, Train_acc:0.95262
Step: 27740, Val_acc:0.875243
==================>
Step: 27750, Train_acc:0.965016
Step: 27750, Val_acc:0.860614
==================>
Step: 27760, Train_acc:0.969125
Step: 27760, Val_acc:0.88918
==================>
Step: 27770, Train_acc:0.948998
Step: 27770, Val_acc:0.898247
==================>
Step: 27780, Train_acc:0.962341
Step: 27780, Val_acc:0.896583
==================>
Step: 27790, Train_acc:0.964924
Step: 27790, Val_acc:0.901832
==================>
Step: 27800, Train_acc:0.952236
Step: 27800, Val_acc:0.902688
==================>
2017-11-11 05:32:16.018110 ---> Validation_loss: 0.227508
Step: 27810, Train_acc:0.951987
Step: 27810, Val_acc:0.927566
==================>
Step: 27820, Train_acc:0.960543
Step: 27820, Val_acc:0.899252
==================>
Step: 27830, Train_acc:0.969022
Step: 27830, Val_acc:0.903088
==================>
Step: 27840, Train_acc:0.953655
Step: 27840, Val_acc:0.935334
==================>
Step: 27850, Train_acc:0.968813
Step: 27850, Val_acc:0.879788
==================>
Step: 27860, Train_acc:0.964392
Step: 27860, Val_acc:0.909104
==================>
Step: 27870, Train_acc:0.959313
Step: 27870, Val_acc:0.89184
==================>
Step: 27880, Train_acc:0.948932
Step: 27880, Val_acc:0.876094
==================>
Step: 27890, Train_acc:0.961077
Step: 27890, Val_acc:0.906357
==================>
Step: 27900, Train_acc:0.959063
Step: 27900, Val_acc:0.912319
==================>
2017-11-11 05:34:52.393035 ---> Validation_loss: 0.272415
Step: 27910, Train_acc:0.963313
Step: 27910, Val_acc:0.925962
==================>
Step: 27920, Train_acc:0.968999
Step: 27920, Val_acc:0.928746
==================>
Step: 27930, Train_acc:0.939573
Step: 27930, Val_acc:0.906009
==================>
Step: 27940, Train_acc:0.969634
Step: 27940, Val_acc:0.834667
==================>
Step: 27950, Train_acc:0.953821
Step: 27950, Val_acc:0.936566
==================>
Step: 27960, Train_acc:0.964255
Step: 27960, Val_acc:0.896285
==================>
Step: 27970, Train_acc:0.957332
Step: 27970, Val_acc:0.894971
==================>
Step: 27980, Train_acc:0.959186
Step: 27980, Val_acc:0.899287
==================>
Step: 27990, Train_acc:0.966963
Step: 27990, Val_acc:0.925353
==================>
Step: 28000, Train_acc:0.953876
Step: 28000, Val_acc:0.872507
==================>
****************** Epochs completed: 56******************
2017-11-11 05:37:29.112624 ---> Validation_loss: 0.271296
Step: 28010, Train_acc:0.962799
Step: 28010, Val_acc:0.903007
==================>
Step: 28020, Train_acc:0.96499
Step: 28020, Val_acc:0.885594
==================>
Step: 28030, Train_acc:0.954445
Step: 28030, Val_acc:0.895166
==================>
Step: 28040, Train_acc:0.960103
Step: 28040, Val_acc:0.893215
==================>
Step: 28050, Train_acc:0.961251
Step: 28050, Val_acc:0.901847
==================>
Step: 28060, Train_acc:0.964188
Step: 28060, Val_acc:0.89866
==================>
Step: 28070, Train_acc:0.96095
Step: 28070, Val_acc:0.873896
==================>
Step: 28080, Train_acc:0.95764
Step: 28080, Val_acc:0.918983
==================>
Step: 28090, Train_acc:0.962328
Step: 28090, Val_acc:0.886387
==================>
Step: 28100, Train_acc:0.964615
Step: 28100, Val_acc:0.883082
==================>
2017-11-11 05:40:05.794548 ---> Validation_loss: 0.178017
Step: 28110, Train_acc:0.943904
Step: 28110, Val_acc:0.899349
==================>
Step: 28120, Train_acc:0.95843
Step: 28120, Val_acc:0.896665
==================>
Step: 28130, Train_acc:0.945613
Step: 28130, Val_acc:0.904979
==================>
Step: 28140, Train_acc:0.953717
Step: 28140, Val_acc:0.897014
==================>
Step: 28150, Train_acc:0.964794
Step: 28150, Val_acc:0.884261
==================>
Step: 28160, Train_acc:0.956349
Step: 28160, Val_acc:0.894528
==================>
Step: 28170, Train_acc:0.967657
Step: 28170, Val_acc:0.927079
==================>
Step: 28180, Train_acc:0.957867
Step: 28180, Val_acc:0.923933
==================>
Step: 28190, Train_acc:0.963192
Step: 28190, Val_acc:0.899061
==================>
Step: 28200, Train_acc:0.95245
Step: 28200, Val_acc:0.921206
==================>
2017-11-11 05:42:42.425295 ---> Validation_loss: 0.261606
Step: 28210, Train_acc:0.965122
Step: 28210, Val_acc:0.91179
==================>
Step: 28220, Train_acc:0.961685
Step: 28220, Val_acc:0.911062
==================>
Step: 28230, Train_acc:0.951511
Step: 28230, Val_acc:0.900613
==================>
Step: 28240, Train_acc:0.953479
Step: 28240, Val_acc:0.90428
==================>
Step: 28250, Train_acc:0.961265
Step: 28250, Val_acc:0.929847
==================>
Step: 28260, Train_acc:0.951145
Step: 28260, Val_acc:0.921233
==================>
Step: 28270, Train_acc:0.948776
Step: 28270, Val_acc:0.929829
==================>
Step: 28280, Train_acc:0.946359
Step: 28280, Val_acc:0.918236
==================>
Step: 28290, Train_acc:0.945076
Step: 28290, Val_acc:0.905731
==================>
Step: 28300, Train_acc:0.961605
Step: 28300, Val_acc:0.897339
==================>
2017-11-11 05:45:18.985230 ---> Validation_loss: 0.261555
Step: 28310, Train_acc:0.94541
Step: 28310, Val_acc:0.903516
==================>
Step: 28320, Train_acc:0.967877
Step: 28320, Val_acc:0.899728
==================>
Step: 28330, Train_acc:0.967041
Step: 28330, Val_acc:0.921953
==================>
Step: 28340, Train_acc:0.95074
Step: 28340, Val_acc:0.891422
==================>
Step: 28350, Train_acc:0.961742
Step: 28350, Val_acc:0.904521
==================>
Step: 28360, Train_acc:0.947288
Step: 28360, Val_acc:0.913735
==================>
Step: 28370, Train_acc:0.96637
Step: 28370, Val_acc:0.8865
==================>
Step: 28380, Train_acc:0.959481
Step: 28380, Val_acc:0.893705
==================>
Step: 28390, Train_acc:0.938532
Step: 28390, Val_acc:0.86807
==================>
Step: 28400, Train_acc:0.951223
Step: 28400, Val_acc:0.911727
==================>
2017-11-11 05:47:55.493580 ---> Validation_loss: 0.183221
Step: 28410, Train_acc:0.973065
Step: 28410, Val_acc:0.919696
==================>
Step: 28420, Train_acc:0.966525
Step: 28420, Val_acc:0.884749
==================>
Step: 28430, Train_acc:0.969556
Step: 28430, Val_acc:0.874078
==================>
Step: 28440, Train_acc:0.951709
Step: 28440, Val_acc:0.909005
==================>
Step: 28450, Train_acc:0.947535
Step: 28450, Val_acc:0.907822
==================>
Step: 28460, Train_acc:0.9634
Step: 28460, Val_acc:0.913904
==================>
Step: 28470, Train_acc:0.959369
Step: 28470, Val_acc:0.892399
==================>
Step: 28480, Train_acc:0.961669
Step: 28480, Val_acc:0.887964
==================>
Step: 28490, Train_acc:0.960896
Step: 28490, Val_acc:0.921634
==================>
Step: 28500, Train_acc:0.96006
Step: 28500, Val_acc:0.919797
==================>
****************** Epochs completed: 57******************
2017-11-11 05:50:31.735411 ---> Validation_loss: 0.162897
Step: 28510, Train_acc:0.9636
Step: 28510, Val_acc:0.891438
==================>
Step: 28520, Train_acc:0.953301
Step: 28520, Val_acc:0.870099
==================>
Step: 28530, Train_acc:0.946714
Step: 28530, Val_acc:0.883561
==================>
Step: 28540, Train_acc:0.961238
Step: 28540, Val_acc:0.886599
==================>
Step: 28550, Train_acc:0.964888
Step: 28550, Val_acc:0.917788
==================>
Step: 28560, Train_acc:0.958953
Step: 28560, Val_acc:0.89171
==================>
Step: 28570, Train_acc:0.954844
Step: 28570, Val_acc:0.891698
==================>
Step: 28580, Train_acc:0.956539
Step: 28580, Val_acc:0.884369
==================>
Step: 28590, Train_acc:0.947131
Step: 28590, Val_acc:0.910729
==================>
Step: 28600, Train_acc:0.959137
Step: 28600, Val_acc:0.916728
==================>
2017-11-11 05:53:08.169427 ---> Validation_loss: 0.271748
Step: 28610, Train_acc:0.96634
Step: 28610, Val_acc:0.878871
==================>
Step: 28620, Train_acc:0.959945
Step: 28620, Val_acc:0.898003
==================>
Step: 28630, Train_acc:0.963354
Step: 28630, Val_acc:0.895312
==================>
Step: 28640, Train_acc:0.967766
Step: 28640, Val_acc:0.859963
==================>
Step: 28650, Train_acc:0.957723
Step: 28650, Val_acc:0.902827
==================>
Step: 28660, Train_acc:0.953553
Step: 28660, Val_acc:0.916561
==================>
Step: 28670, Train_acc:0.948628
Step: 28670, Val_acc:0.870977
==================>
Step: 28680, Train_acc:0.970953
Step: 28680, Val_acc:0.918909
==================>
Step: 28690, Train_acc:0.952537
Step: 28690, Val_acc:0.925504
==================>
Step: 28700, Train_acc:0.952982
Step: 28700, Val_acc:0.909989
==================>
2017-11-11 05:55:44.721547 ---> Validation_loss: 0.238184
Step: 28710, Train_acc:0.955809
Step: 28710, Val_acc:0.873215
==================>
Step: 28720, Train_acc:0.953413
Step: 28720, Val_acc:0.882196
==================>
Step: 28730, Train_acc:0.956267
Step: 28730, Val_acc:0.902292
==================>
Step: 28740, Train_acc:0.960194
Step: 28740, Val_acc:0.943984
==================>
Step: 28750, Train_acc:0.947834
Step: 28750, Val_acc:0.880903
==================>
Step: 28760, Train_acc:0.950127
Step: 28760, Val_acc:0.891427
==================>
Step: 28770, Train_acc:0.95402
Step: 28770, Val_acc:0.863016
==================>
Step: 28780, Train_acc:0.951803
Step: 28780, Val_acc:0.883136
==================>
Step: 28790, Train_acc:0.956914
Step: 28790, Val_acc:0.89708
==================>
Step: 28800, Train_acc:0.940862
Step: 28800, Val_acc:0.900554
==================>
2017-11-11 05:58:21.043501 ---> Validation_loss: 0.251099
Step: 28810, Train_acc:0.965092
Step: 28810, Val_acc:0.890013
==================>
Step: 28820, Train_acc:0.96577
Step: 28820, Val_acc:0.901648
==================>
Step: 28830, Train_acc:0.962086
Step: 28830, Val_acc:0.920192
==================>
Step: 28840, Train_acc:0.953148
Step: 28840, Val_acc:0.913689
==================>
Step: 28850, Train_acc:0.968484
Step: 28850, Val_acc:0.907019
==================>
Step: 28860, Train_acc:0.950704
Step: 28860, Val_acc:0.897007
==================>
Step: 28870, Train_acc:0.96527
Step: 28870, Val_acc:0.869965
==================>
Step: 28880, Train_acc:0.938152
Step: 28880, Val_acc:0.931954
==================>
Step: 28890, Train_acc:0.946483
Step: 28890, Val_acc:0.924447
==================>
Step: 28900, Train_acc:0.950315
Step: 28900, Val_acc:0.882573
==================>
2017-11-11 06:00:57.502378 ---> Validation_loss: 0.280665
Step: 28910, Train_acc:0.946833
Step: 28910, Val_acc:0.883176
==================>
Step: 28920, Train_acc:0.958093
Step: 28920, Val_acc:0.883358
==================>
Step: 28930, Train_acc:0.959705
Step: 28930, Val_acc:0.875885
==================>
Step: 28940, Train_acc:0.952592
Step: 28940, Val_acc:0.899142
==================>
Step: 28950, Train_acc:0.948843
Step: 28950, Val_acc:0.906383
==================>
Step: 28960, Train_acc:0.964456
Step: 28960, Val_acc:0.900033
==================>
Step: 28970, Train_acc:0.949911
Step: 28970, Val_acc:0.907394
==================>
Step: 28980, Train_acc:0.960347
Step: 28980, Val_acc:0.906688
==================>
Step: 28990, Train_acc:0.953215
Step: 28990, Val_acc:0.901339
==================>
Step: 29000, Train_acc:0.959598
Step: 29000, Val_acc:0.906868
==================>
****************** Epochs completed: 58******************
2017-11-11 06:03:34.209520 ---> Validation_loss: 0.287512
Step: 29010, Train_acc:0.955734
Step: 29010, Val_acc:0.925952
==================>
Step: 29020, Train_acc:0.959012
Step: 29020, Val_acc:0.9234
==================>
Step: 29030, Train_acc:0.954617
Step: 29030, Val_acc:0.91483
==================>
Step: 29040, Train_acc:0.969543
Step: 29040, Val_acc:0.928369
==================>
Step: 29050, Train_acc:0.957983
Step: 29050, Val_acc:0.871202
==================>
Step: 29060, Train_acc:0.964521
Step: 29060, Val_acc:0.88122
==================>
Step: 29070, Train_acc:0.966357
Step: 29070, Val_acc:0.896567
==================>
Step: 29080, Train_acc:0.964441
Step: 29080, Val_acc:0.919822
==================>
Step: 29090, Train_acc:0.961783
Step: 29090, Val_acc:0.908182
==================>
Step: 29100, Train_acc:0.950436
Step: 29100, Val_acc:0.929508
==================>
2017-11-11 06:06:10.546998 ---> Validation_loss: 0.173663
Step: 29110, Train_acc:0.957502
Step: 29110, Val_acc:0.915316
==================>
Step: 29120, Train_acc:0.967527
Step: 29120, Val_acc:0.912346
==================>
Step: 29130, Train_acc:0.947318
Step: 29130, Val_acc:0.897966
==================>
Step: 29140, Train_acc:0.968049
Step: 29140, Val_acc:0.922019
==================>
Step: 29150, Train_acc:0.943162
Step: 29150, Val_acc:0.901442
==================>
Step: 29160, Train_acc:0.952361
Step: 29160, Val_acc:0.884067
==================>
Step: 29170, Train_acc:0.961381
Step: 29170, Val_acc:0.910808
==================>
Step: 29180, Train_acc:0.963508
Step: 29180, Val_acc:0.905016
==================>
Step: 29190, Train_acc:0.961945
Step: 29190, Val_acc:0.911631
==================>
Step: 29200, Train_acc:0.964353
Step: 29200, Val_acc:0.921599
==================>
2017-11-11 06:08:46.857312 ---> Validation_loss: 0.235894
Step: 29210, Train_acc:0.94412
Step: 29210, Val_acc:0.894689
==================>
Step: 29220, Train_acc:0.945248
Step: 29220, Val_acc:0.917531
==================>
Step: 29230, Train_acc:0.956046
Step: 29230, Val_acc:0.876866
==================>
Step: 29240, Train_acc:0.949548
Step: 29240, Val_acc:0.899435
==================>
Step: 29250, Train_acc:0.948118
Step: 29250, Val_acc:0.93052
==================>
Step: 29260, Train_acc:0.962673
Step: 29260, Val_acc:0.911383
==================>
Step: 29270, Train_acc:0.95423
Step: 29270, Val_acc:0.880541
==================>
Step: 29280, Train_acc:0.956661
Step: 29280, Val_acc:0.904944
==================>
Step: 29290, Train_acc:0.958926
Step: 29290, Val_acc:0.931669
==================>
Step: 29300, Train_acc:0.947621
Step: 29300, Val_acc:0.900905
==================>
2017-11-11 06:11:23.172489 ---> Validation_loss: 0.240692
Step: 29310, Train_acc:0.954377
Step: 29310, Val_acc:0.904335
==================>
Step: 29320, Train_acc:0.967008
Step: 29320, Val_acc:0.903563
==================>
Step: 29330, Train_acc:0.950746
Step: 29330, Val_acc:0.911832
==================>
Step: 29340, Train_acc:0.957451
Step: 29340, Val_acc:0.919075
==================>
Step: 29350, Train_acc:0.965637
Step: 29350, Val_acc:0.864453
==================>
Step: 29360, Train_acc:0.95528
Step: 29360, Val_acc:0.886416
==================>
Step: 29370, Train_acc:0.959746
Step: 29370, Val_acc:0.909758
==================>
Step: 29380, Train_acc:0.95931
Step: 29380, Val_acc:0.889515
==================>
Step: 29390, Train_acc:0.964346
Step: 29390, Val_acc:0.935725
==================>
Step: 29400, Train_acc:0.960004
Step: 29400, Val_acc:0.903197
==================>
2017-11-11 06:13:59.632830 ---> Validation_loss: 0.185865
Step: 29410, Train_acc:0.953375
Step: 29410, Val_acc:0.898372
==================>
Step: 29420, Train_acc:0.95278
Step: 29420, Val_acc:0.920317
==================>
Step: 29430, Train_acc:0.962218
Step: 29430, Val_acc:0.907697
==================>
Step: 29440, Train_acc:0.95056
Step: 29440, Val_acc:0.923612
==================>
Step: 29450, Train_acc:0.952098
Step: 29450, Val_acc:0.889325
==================>
Step: 29460, Train_acc:0.96002
Step: 29460, Val_acc:0.924027
==================>
Step: 29470, Train_acc:0.950852
Step: 29470, Val_acc:0.910874
==================>
Step: 29480, Train_acc:0.955995
Step: 29480, Val_acc:0.923862
==================>
Step: 29490, Train_acc:0.954192
Step: 29490, Val_acc:0.90334
==================>
Step: 29500, Train_acc:0.954728
Step: 29500, Val_acc:0.891871
==================>
****************** Epochs completed: 59******************
2017-11-11 06:16:36.220678 ---> Validation_loss: 0.201773
Step: 29510, Train_acc:0.959407
Step: 29510, Val_acc:0.885033
==================>
Step: 29520, Train_acc:0.950601
Step: 29520, Val_acc:0.911666
==================>
Step: 29530, Train_acc:0.957839
Step: 29530, Val_acc:0.896862
==================>
Step: 29540, Train_acc:0.940774
Step: 29540, Val_acc:0.880378
==================>
Step: 29550, Train_acc:0.951375
Step: 29550, Val_acc:0.8948
==================>
Step: 29560, Train_acc:0.952195
Step: 29560, Val_acc:0.925066
==================>
Step: 29570, Train_acc:0.967163
Step: 29570, Val_acc:0.895653
==================>
Step: 29580, Train_acc:0.967103
Step: 29580, Val_acc:0.909685
==================>
Step: 29590, Train_acc:0.962231
Step: 29590, Val_acc:0.9153
==================>
Step: 29600, Train_acc:0.959586
Step: 29600, Val_acc:0.90408
==================>
2017-11-11 06:19:12.844556 ---> Validation_loss: 0.252811
Step: 29610, Train_acc:0.940886
Step: 29610, Val_acc:0.906278
==================>
Step: 29620, Train_acc:0.959622
Step: 29620, Val_acc:0.906014
==================>
Step: 29630, Train_acc:0.969139
Step: 29630, Val_acc:0.938849
==================>
Step: 29640, Train_acc:0.950524
Step: 29640, Val_acc:0.929586
==================>
Step: 29650, Train_acc:0.970859
Step: 29650, Val_acc:0.895669
==================>
Step: 29660, Train_acc:0.960591
Step: 29660, Val_acc:0.895758
==================>
Step: 29670, Train_acc:0.95958
Step: 29670, Val_acc:0.899004
==================>
Step: 29680, Train_acc:0.962683
Step: 29680, Val_acc:0.930924
==================>
Step: 29690, Train_acc:0.965695
Step: 29690, Val_acc:0.907269
==================>
Step: 29700, Train_acc:0.947888
Step: 29700, Val_acc:0.887181
==================>
2017-11-11 06:21:48.724032 ---> Validation_loss: 0.238419
Step: 29710, Train_acc:0.945742
Step: 29710, Val_acc:0.928455
==================>
Step: 29720, Train_acc:0.952828
Step: 29720, Val_acc:0.877961
==================>
Step: 29730, Train_acc:0.973412
Step: 29730, Val_acc:0.941589
==================>
Step: 29740, Train_acc:0.958088
Step: 29740, Val_acc:0.891798
==================>
Step: 29750, Train_acc:0.961572
Step: 29750, Val_acc:0.887361
==================>
Step: 29760, Train_acc:0.962988
Step: 29760, Val_acc:0.883469
==================>
Step: 29770, Train_acc:0.953655
Step: 29770, Val_acc:0.88943
==================>
Step: 29780, Train_acc:0.949852
Step: 29780, Val_acc:0.899529
==================>
Step: 29790, Train_acc:0.96042
Step: 29790, Val_acc:0.895417
==================>
Step: 29800, Train_acc:0.958877
Step: 29800, Val_acc:0.905557
==================>
2017-11-11 06:24:25.164327 ---> Validation_loss: 0.196902
Step: 29810, Train_acc:0.964016
Step: 29810, Val_acc:0.922803
==================>
Step: 29820, Train_acc:0.964901
Step: 29820, Val_acc:0.908506
==================>
Step: 29830, Train_acc:0.954355
Step: 29830, Val_acc:0.883812
==================>
Step: 29840, Train_acc:0.936492
Step: 29840, Val_acc:0.879512
==================>
Step: 29850, Train_acc:0.96499
Step: 29850, Val_acc:0.905406
==================>
Step: 29860, Train_acc:0.955732
Step: 29860, Val_acc:0.91286
==================>
Step: 29870, Train_acc:0.952628
Step: 29870, Val_acc:0.904366
==================>
Step: 29880, Train_acc:0.943812
Step: 29880, Val_acc:0.906097
==================>
Step: 29890, Train_acc:0.96681
Step: 29890, Val_acc:0.902583
==================>
Step: 29900, Train_acc:0.954834
Step: 29900, Val_acc:0.907538
==================>
2017-11-11 06:27:01.504338 ---> Validation_loss: 0.269076
Step: 29910, Train_acc:0.94428
Step: 29910, Val_acc:0.894399
==================>
Step: 29920, Train_acc:0.954998
Step: 29920, Val_acc:0.89194
==================>
Step: 29930, Train_acc:0.954485
Step: 29930, Val_acc:0.934598
==================>
Step: 29940, Train_acc:0.931725
Step: 29940, Val_acc:0.906024
==================>
Step: 29950, Train_acc:0.962849
Step: 29950, Val_acc:0.871484
==================>
Step: 29960, Train_acc:0.950092
Step: 29960, Val_acc:0.938707
==================>
Step: 29970, Train_acc:0.947278
Step: 29970, Val_acc:0.904001
==================>
Step: 29980, Train_acc:0.953335
Step: 29980, Val_acc:0.890178
==================>
Step: 29990, Train_acc:0.958757
Step: 29990, Val_acc:0.935273
==================>
Step: 30000, Train_acc:0.950476
Step: 30000, Val_acc:0.93886
==================>
****************** Epochs completed: 60******************
2017-11-11 06:29:38.118377 ---> Validation_loss: 0.225884
Step: 30010, Train_acc:0.957228
Step: 30010, Val_acc:0.899464
==================>
Step: 30020, Train_acc:0.951361
Step: 30020, Val_acc:0.888264
==================>
Step: 30030, Train_acc:0.934723
Step: 30030, Val_acc:0.892629
==================>
Step: 30040, Train_acc:0.951041
Step: 30040, Val_acc:0.913174
==================>
Step: 30050, Train_acc:0.962057
Step: 30050, Val_acc:0.871156
==================>
Step: 30060, Train_acc:0.972325
Step: 30060, Val_acc:0.882878
==================>
Step: 30070, Train_acc:0.954319
Step: 30070, Val_acc:0.91302
==================>
Step: 30080, Train_acc:0.947952
Step: 30080, Val_acc:0.921984
==================>
Step: 30090, Train_acc:0.956818
Step: 30090, Val_acc:0.92188
==================>
Step: 30100, Train_acc:0.964679
Step: 30100, Val_acc:0.885868
==================>
2017-11-11 06:32:14.622596 ---> Validation_loss: 0.211578
Step: 30110, Train_acc:0.95976
Step: 30110, Val_acc:0.927415
==================>
Step: 30120, Train_acc:0.953272
Step: 30120, Val_acc:0.869373
==================>
Step: 30130, Train_acc:0.95423
Step: 30130, Val_acc:0.875851
==================>
Step: 30140, Train_acc:0.959574
Step: 30140, Val_acc:0.915836
==================>
Step: 30150, Train_acc:0.951102
Step: 30150, Val_acc:0.925609
==================>
Step: 30160, Train_acc:0.964508
Step: 30160, Val_acc:0.918445
==================>
Step: 30170, Train_acc:0.962791
Step: 30170, Val_acc:0.890255
==================>
Step: 30180, Train_acc:0.952764
Step: 30180, Val_acc:0.897933
==================>
Step: 30190, Train_acc:0.951484
Step: 30190, Val_acc:0.907621
==================>
Step: 30200, Train_acc:0.957455
Step: 30200, Val_acc:0.932842
==================>
2017-11-11 06:34:51.198068 ---> Validation_loss: 0.184236
Step: 30210, Train_acc:0.959032
Step: 30210, Val_acc:0.927026
==================>
Step: 30220, Train_acc:0.964312
Step: 30220, Val_acc:0.898999
==================>
Step: 30230, Train_acc:0.958461
Step: 30230, Val_acc:0.92168
==================>
Step: 30240, Train_acc:0.959307
Step: 30240, Val_acc:0.933307
==================>
Step: 30250, Train_acc:0.970575
Step: 30250, Val_acc:0.919301
==================>
Step: 30260, Train_acc:0.948462
Step: 30260, Val_acc:0.898298
==================>
Step: 30270, Train_acc:0.966947
Step: 30270, Val_acc:0.889845
==================>
****************** Epochs completed: 9******************
Step: 30280, Train_acc:0.961249
Step: 30280, Val_acc:0.874237
==================>
Step: 30290, Train_acc:0.958176
Step: 30290, Val_acc:0.909066
==================>
Step: 30300, Train_acc:0.963262
Step: 30300, Val_acc:0.892162
==================>
2017-11-11 06:37:27.455254 ---> Validation_loss: 0.283764
Step: 30310, Train_acc:0.971433
Step: 30310, Val_acc:0.906072
==================>
Step: 30320, Train_acc:0.968386
Step: 30320, Val_acc:0.88311
==================>
Step: 30330, Train_acc:0.964845
Step: 30330, Val_acc:0.879421
==================>
Step: 30340, Train_acc:0.954828
Step: 30340, Val_acc:0.890381
==================>
Step: 30350, Train_acc:0.950105
Step: 30350, Val_acc:0.899288
==================>
Step: 30360, Train_acc:0.962761
Step: 30360, Val_acc:0.906764
==================>
Step: 30370, Train_acc:0.960598
Step: 30370, Val_acc:0.895222
==================>
Step: 30380, Train_acc:0.952213
Step: 30380, Val_acc:0.901718
==================>
Step: 30390, Train_acc:0.961365
Step: 30390, Val_acc:0.865994
==================>
Step: 30400, Train_acc:0.953224
Step: 30400, Val_acc:0.920936
==================>
2017-11-11 06:40:03.984216 ---> Validation_loss: 0.230313
Step: 30410, Train_acc:0.950876
Step: 30410, Val_acc:0.903409
==================>
Step: 30420, Train_acc:0.970157
Step: 30420, Val_acc:0.917664
==================>
Step: 30430, Train_acc:0.962704
Step: 30430, Val_acc:0.879281
==================>
Step: 30440, Train_acc:0.951486
Step: 30440, Val_acc:0.910366
==================>
Step: 30450, Train_acc:0.962949
Step: 30450, Val_acc:0.906135
==================>
Step: 30460, Train_acc:0.955797
Step: 30460, Val_acc:0.898992
==================>
Step: 30470, Train_acc:0.960275
Step: 30470, Val_acc:0.939603
==================>
Step: 30480, Train_acc:0.958743
Step: 30480, Val_acc:0.904858
==================>
Step: 30490, Train_acc:0.958486
Step: 30490, Val_acc:0.914902
==================>
Step: 30500, Train_acc:0.963064
Step: 30500, Val_acc:0.883976
==================>
****************** Epochs completed: 61******************
2017-11-11 06:42:40.368211 ---> Validation_loss: 0.217023
Step: 30510, Train_acc:0.968428
Step: 30510, Val_acc:0.916653
==================>
Step: 30520, Train_acc:0.967064
Step: 30520, Val_acc:0.891838
==================>
Step: 30530, Train_acc:0.972423
Step: 30530, Val_acc:0.897819
==================>
Step: 30540, Train_acc:0.967356
Step: 30540, Val_acc:0.897925
==================>
Step: 30550, Train_acc:0.969836
Step: 30550, Val_acc:0.886168
==================>
Step: 30560, Train_acc:0.969061
Step: 30560, Val_acc:0.907188
==================>
Step: 30570, Train_acc:0.965195
Step: 30570, Val_acc:0.918589
==================>
Step: 30580, Train_acc:0.968259
Step: 30580, Val_acc:0.925104
==================>
Step: 30590, Train_acc:0.962822
Step: 30590, Val_acc:0.907401
==================>
Step: 30600, Train_acc:0.972471
Step: 30600, Val_acc:0.932185
==================>
2017-11-11 06:45:17.071890 ---> Validation_loss: 0.199367
Step: 30610, Train_acc:0.966647
Step: 30610, Val_acc:0.885615
==================>
Step: 30620, Train_acc:0.969375
Step: 30620, Val_acc:0.917324
==================>
Step: 30630, Train_acc:0.966714
Step: 30630, Val_acc:0.890427
==================>
Step: 30640, Train_acc:0.966335
Step: 30640, Val_acc:0.883208
==================>
Step: 30650, Train_acc:0.954917
Step: 30650, Val_acc:0.903773
==================>
Step: 30660, Train_acc:0.956776
Step: 30660, Val_acc:0.89517
==================>
Step: 30670, Train_acc:0.965111
Step: 30670, Val_acc:0.889758
==================>
Step: 30680, Train_acc:0.969523
Step: 30680, Val_acc:0.92239
==================>
Step: 30690, Train_acc:0.968074
Step: 30690, Val_acc:0.863505
==================>
Step: 30700, Train_acc:0.97785
Step: 30700, Val_acc:0.915564
==================>
2017-11-11 06:47:53.686527 ---> Validation_loss: 0.223198
Step: 30710, Train_acc:0.954725
Step: 30710, Val_acc:0.960419
==================>
Step: 30720, Train_acc:0.959639
Step: 30720, Val_acc:0.927235
==================>
Step: 30730, Train_acc:0.957343
Step: 30730, Val_acc:0.915105
==================>
Step: 30740, Train_acc:0.951713
Step: 30740, Val_acc:0.901855
==================>
Step: 30750, Train_acc:0.95931
Step: 30750, Val_acc:0.903989
==================>
Step: 30760, Train_acc:0.961311
Step: 30760, Val_acc:0.947341
==================>
Step: 30770, Train_acc:0.958081
Step: 30770, Val_acc:0.901069
==================>
Step: 30780, Train_acc:0.967444
Step: 30780, Val_acc:0.910779
==================>
Step: 30790, Train_acc:0.959351
Step: 30790, Val_acc:0.890127
==================>
Step: 30800, Train_acc:0.974792
Step: 30800, Val_acc:0.890712
==================>
2017-11-11 06:50:30.449520 ---> Validation_loss: 0.249851
Step: 30810, Train_acc:0.969324
Step: 30810, Val_acc:0.897612
==================>
Step: 30820, Train_acc:0.947068
Step: 30820, Val_acc:0.908505
==================>
Step: 30830, Train_acc:0.966962
Step: 30830, Val_acc:0.937185
==================>
Step: 30840, Train_acc:0.957371
Step: 30840, Val_acc:0.899764
==================>
Step: 30850, Train_acc:0.964385
Step: 30850, Val_acc:0.912748
==================>
Step: 30860, Train_acc:0.964415
Step: 30860, Val_acc:0.926521
==================>
Step: 30870, Train_acc:0.951062
Step: 30870, Val_acc:0.925754
==================>
Step: 30880, Train_acc:0.949115
Step: 30880, Val_acc:0.918995
==================>
Step: 30890, Train_acc:0.959972
Step: 30890, Val_acc:0.91019
==================>
Step: 30900, Train_acc:0.959614
Step: 30900, Val_acc:0.908988
==================>
2017-11-11 06:53:06.538626 ---> Validation_loss: 0.217454
Step: 30910, Train_acc:0.962601
Step: 30910, Val_acc:0.936873
==================>
Step: 30920, Train_acc:0.958585
Step: 30920, Val_acc:0.944725
==================>
Step: 30930, Train_acc:0.966486
Step: 30930, Val_acc:0.889933
==================>
Step: 30940, Train_acc:0.967678
Step: 30940, Val_acc:0.93103
==================>
Step: 30950, Train_acc:0.96382
Step: 30950, Val_acc:0.915573
==================>
Step: 30960, Train_acc:0.968295
Step: 30960, Val_acc:0.926022
==================>
Step: 30970, Train_acc:0.960887
Step: 30970, Val_acc:0.933621
==================>
Step: 30980, Train_acc:0.960183
Step: 30980, Val_acc:0.9238
==================>
Step: 30990, Train_acc:0.968282
Step: 30990, Val_acc:0.897
==================>
Step: 31000, Train_acc:0.96433
Step: 31000, Val_acc:0.916919
==================>
****************** Epochs completed: 62******************
2017-11-11 06:55:42.798723 ---> Validation_loss: 0.195621
Step: 31010, Train_acc:0.948743
Step: 31010, Val_acc:0.934481
==================>
Step: 31020, Train_acc:0.959801
Step: 31020, Val_acc:0.900728
==================>
Step: 31030, Train_acc:0.961871
Step: 31030, Val_acc:0.907544
==================>
Step: 31040, Train_acc:0.945253
Step: 31040, Val_acc:0.869503
==================>
Step: 31050, Train_acc:0.947821
Step: 31050, Val_acc:0.910267
==================>
Step: 31060, Train_acc:0.953969
Step: 31060, Val_acc:0.898292
==================>
Step: 31070, Train_acc:0.962272
Step: 31070, Val_acc:0.915172
==================>
Step: 31080, Train_acc:0.960966
Step: 31080, Val_acc:0.935066
==================>
Step: 31090, Train_acc:0.964231
Step: 31090, Val_acc:0.904231
==================>
Step: 31100, Train_acc:0.967308
Step: 31100, Val_acc:0.888131
==================>
2017-11-11 06:58:19.291356 ---> Validation_loss: 0.188755
Step: 31110, Train_acc:0.975232
Step: 31110, Val_acc:0.890311
==================>
Step: 31120, Train_acc:0.967906
Step: 31120, Val_acc:0.924043
==================>
Step: 31130, Train_acc:0.960354
Step: 31130, Val_acc:0.9138
==================>
Step: 31140, Train_acc:0.97181
Step: 31140, Val_acc:0.914624
==================>
Step: 31150, Train_acc:0.965758
Step: 31150, Val_acc:0.893678
==================>
Step: 31160, Train_acc:0.960371
Step: 31160, Val_acc:0.922146
==================>
Step: 31170, Train_acc:0.967324
Step: 31170, Val_acc:0.895072
==================>
Step: 31180, Train_acc:0.962242
Step: 31180, Val_acc:0.913541
==================>
Step: 31190, Train_acc:0.969639
Step: 31190, Val_acc:0.871018
==================>
Step: 31200, Train_acc:0.962617
Step: 31200, Val_acc:0.927155
==================>
2017-11-11 07:00:55.891931 ---> Validation_loss: 0.222709
Step: 31210, Train_acc:0.965614
Step: 31210, Val_acc:0.905764
==================>
Step: 31220, Train_acc:0.955504
Step: 31220, Val_acc:0.918503
==================>
Step: 31230, Train_acc:0.95667
Step: 31230, Val_acc:0.907428
==================>
Step: 31240, Train_acc:0.947559
Step: 31240, Val_acc:0.89395
==================>
Step: 31250, Train_acc:0.959886
Step: 31250, Val_acc:0.923717
==================>
Step: 31260, Train_acc:0.966086
Step: 31260, Val_acc:0.916012
==================>
Step: 31270, Train_acc:0.95411
Step: 31270, Val_acc:0.912946
==================>
Step: 31280, Train_acc:0.962634
Step: 31280, Val_acc:0.916736
==================>
Step: 31290, Train_acc:0.954626
Step: 31290, Val_acc:0.926681
==================>
Step: 31300, Train_acc:0.965555
Step: 31300, Val_acc:0.90494
==================>
2017-11-11 07:03:32.114528 ---> Validation_loss: 0.289136
Step: 31310, Train_acc:0.944167
Step: 31310, Val_acc:0.89801
==================>
Step: 31320, Train_acc:0.962607
Step: 31320, Val_acc:0.872578
==================>
Step: 31330, Train_acc:0.975577
Step: 31330, Val_acc:0.876536
==================>
Step: 31340, Train_acc:0.97283
Step: 31340, Val_acc:0.921018
==================>
Step: 31350, Train_acc:0.967712
Step: 31350, Val_acc:0.882075
==================>
Step: 31360, Train_acc:0.960061
Step: 31360, Val_acc:0.938331
==================>
Step: 31370, Train_acc:0.958563
Step: 31370, Val_acc:0.902601
==================>
Step: 31380, Train_acc:0.950999
Step: 31380, Val_acc:0.913136
==================>
Step: 31390, Train_acc:0.963239
Step: 31390, Val_acc:0.929751
==================>
Step: 31400, Train_acc:0.956494
Step: 31400, Val_acc:0.895306
==================>
2017-11-11 07:06:08.256637 ---> Validation_loss: 0.176503
Step: 31410, Train_acc:0.963525
Step: 31410, Val_acc:0.889157
==================>
Step: 31420, Train_acc:0.97043
Step: 31420, Val_acc:0.912958
==================>
Step: 31430, Train_acc:0.957827
Step: 31430, Val_acc:0.891969
==================>
Step: 31440, Train_acc:0.965514
Step: 31440, Val_acc:0.91163
==================>
Step: 31450, Train_acc:0.967384
Step: 31450, Val_acc:0.932048
==================>
Step: 31460, Train_acc:0.963346
Step: 31460, Val_acc:0.913018
==================>
Step: 31470, Train_acc:0.960931
Step: 31470, Val_acc:0.905071
==================>
Step: 31480, Train_acc:0.945339
Step: 31480, Val_acc:0.930073
==================>
Step: 31490, Train_acc:0.96629
Step: 31490, Val_acc:0.937673
==================>
Step: 31500, Train_acc:0.958851
Step: 31500, Val_acc:0.908514
==================>
****************** Epochs completed: 63******************
2017-11-11 07:08:44.822423 ---> Validation_loss: 0.275449
Step: 31510, Train_acc:0.963073
Step: 31510, Val_acc:0.916262
==================>
Step: 31520, Train_acc:0.960621
Step: 31520, Val_acc:0.916873
==================>
Step: 31530, Train_acc:0.960887
Step: 31530, Val_acc:0.90924
==================>
Step: 31540, Train_acc:0.951975
Step: 31540, Val_acc:0.910197
==================>
Step: 31550, Train_acc:0.974447
Step: 31550, Val_acc:0.905
==================>
Step: 31560, Train_acc:0.969271
Step: 31560, Val_acc:0.905566
==================>
Step: 31570, Train_acc:0.956422
Step: 31570, Val_acc:0.889064
==================>
Step: 31580, Train_acc:0.973131
Step: 31580, Val_acc:0.908206
==================>
Step: 31590, Train_acc:0.958153
Step: 31590, Val_acc:0.924602
==================>
Step: 31600, Train_acc:0.950592
Step: 31600, Val_acc:0.910859
==================>
2017-11-11 07:11:20.882316 ---> Validation_loss: 0.185538
Step: 31610, Train_acc:0.966805
Step: 31610, Val_acc:0.90036
==================>
Step: 31620, Train_acc:0.951437
Step: 31620, Val_acc:0.884714
==================>
Step: 31630, Train_acc:0.95577
Step: 31630, Val_acc:0.917632
==================>
Step: 31640, Train_acc:0.943973
Step: 31640, Val_acc:0.904669
==================>
Step: 31650, Train_acc:0.970798
Step: 31650, Val_acc:0.887406
==================>
Step: 31660, Train_acc:0.973394
Step: 31660, Val_acc:0.870947
==================>
Step: 31670, Train_acc:0.951388
Step: 31670, Val_acc:0.881791
==================>
Step: 31680, Train_acc:0.954869
Step: 31680, Val_acc:0.916471
==================>
Step: 31690, Train_acc:0.963739
Step: 31690, Val_acc:0.909712
==================>
Step: 31700, Train_acc:0.966252
Step: 31700, Val_acc:0.930336
==================>
2017-11-11 07:13:57.388546 ---> Validation_loss: 0.219116
Step: 31710, Train_acc:0.95891
Step: 31710, Val_acc:0.910891
==================>
Step: 31720, Train_acc:0.962795
Step: 31720, Val_acc:0.930521
==================>
Step: 31730, Train_acc:0.949458
Step: 31730, Val_acc:0.901118
==================>
Step: 31740, Train_acc:0.955262
Step: 31740, Val_acc:0.899303
==================>
Step: 31750, Train_acc:0.962028
Step: 31750, Val_acc:0.904133
==================>
Step: 31760, Train_acc:0.951835
Step: 31760, Val_acc:0.894233
==================>
Step: 31770, Train_acc:0.964331
Step: 31770, Val_acc:0.883339
==================>
Step: 31780, Train_acc:0.961527
Step: 31780, Val_acc:0.897052
==================>
Step: 31790, Train_acc:0.949207
Step: 31790, Val_acc:0.874172
==================>
Step: 31800, Train_acc:0.960181
Step: 31800, Val_acc:0.886
==================>
2017-11-11 07:16:33.652127 ---> Validation_loss: 0.221837
Step: 31810, Train_acc:0.969448
Step: 31810, Val_acc:0.932507
==================>
Step: 31820, Train_acc:0.955751
Step: 31820, Val_acc:0.892122
==================>
Step: 31830, Train_acc:0.965029
Step: 31830, Val_acc:0.929036
==================>
Step: 31840, Train_acc:0.970505
Step: 31840, Val_acc:0.914429
==================>
Step: 31850, Train_acc:0.960642
Step: 31850, Val_acc:0.927133
==================>
Step: 31860, Train_acc:0.964399
Step: 31860, Val_acc:0.903113
==================>
Step: 31870, Train_acc:0.959641
Step: 31870, Val_acc:0.89308
==================>
Step: 31880, Train_acc:0.96448
Step: 31880, Val_acc:0.918759
==================>
Step: 31890, Train_acc:0.964049
Step: 31890, Val_acc:0.907106
==================>
Step: 31900, Train_acc:0.970324
Step: 31900, Val_acc:0.89666
==================>
2017-11-11 07:19:10.356878 ---> Validation_loss: 0.216159
Step: 31910, Train_acc:0.952231
Step: 31910, Val_acc:0.916483
==================>
Step: 31920, Train_acc:0.969723
Step: 31920, Val_acc:0.857616
==================>
Step: 31930, Train_acc:0.967495
Step: 31930, Val_acc:0.929752
==================>
Step: 31940, Train_acc:0.957574
Step: 31940, Val_acc:0.905127
==================>
Step: 31950, Train_acc:0.975411
Step: 31950, Val_acc:0.881655
==================>
Step: 31960, Train_acc:0.970753
Step: 31960, Val_acc:0.872363
==================>
Step: 31970, Train_acc:0.965979
Step: 31970, Val_acc:0.892288
==================>
Step: 31980, Train_acc:0.958372
Step: 31980, Val_acc:0.938086
==================>
Step: 31990, Train_acc:0.952269
Step: 31990, Val_acc:0.898213
==================>
Step: 32000, Train_acc:0.958798
Step: 32000, Val_acc:0.920297
==================>
****************** Epochs completed: 64******************
2017-11-11 07:21:46.713156 ---> Validation_loss: 0.19763
Step: 32010, Train_acc:0.964399
Step: 32010, Val_acc:0.89505
==================>
Step: 32020, Train_acc:0.9617
Step: 32020, Val_acc:0.905865
==================>
Step: 32030, Train_acc:0.961259
Step: 32030, Val_acc:0.901357
==================>
Step: 32040, Train_acc:0.968722
Step: 32040, Val_acc:0.916199
==================>
Step: 32050, Train_acc:0.951686
Step: 32050, Val_acc:0.948297
==================>
Step: 32060, Train_acc:0.96588
Step: 32060, Val_acc:0.891841
==================>
Step: 32070, Train_acc:0.961417
Step: 32070, Val_acc:0.894531
==================>
Step: 32080, Train_acc:0.940071
Step: 32080, Val_acc:0.893694
==================>
Step: 32090, Train_acc:0.96448
Step: 32090, Val_acc:0.890989
==================>
Step: 32100, Train_acc:0.965459
Step: 32100, Val_acc:0.871831
==================>
2017-11-11 07:24:23.023055 ---> Validation_loss: 0.181961
Step: 32110, Train_acc:0.959296
Step: 32110, Val_acc:0.925507
==================>
Step: 32120, Train_acc:0.96441
Step: 32120, Val_acc:0.881167
==================>
Step: 32130, Train_acc:0.948138
Step: 32130, Val_acc:0.900776
==================>
Step: 32140, Train_acc:0.967983
Step: 32140, Val_acc:0.889499
==================>
Step: 32150, Train_acc:0.965112
Step: 32150, Val_acc:0.921433
==================>
Step: 32160, Train_acc:0.953864
Step: 32160, Val_acc:0.909779
==================>
Step: 32170, Train_acc:0.96594
Step: 32170, Val_acc:0.912251
==================>
Step: 32180, Train_acc:0.954044
Step: 32180, Val_acc:0.916337
==================>
Step: 32190, Train_acc:0.973324
Step: 32190, Val_acc:0.930122
==================>
Step: 32200, Train_acc:0.971125
Step: 32200, Val_acc:0.894233
==================>
2017-11-11 07:26:59.357834 ---> Validation_loss: 0.267356
Step: 32210, Train_acc:0.9638
Step: 32210, Val_acc:0.933914
==================>
Step: 32220, Train_acc:0.962078
Step: 32220, Val_acc:0.905433
==================>
Step: 32230, Train_acc:0.961862
Step: 32230, Val_acc:0.882074
==================>
Step: 32240, Train_acc:0.96145
Step: 32240, Val_acc:0.908636
==================>
Step: 32250, Train_acc:0.955536
Step: 32250, Val_acc:0.902282
==================>
Step: 32260, Train_acc:0.961913
Step: 32260, Val_acc:0.920018
==================>
Step: 32270, Train_acc:0.957903
Step: 32270, Val_acc:0.907288
==================>
Step: 32280, Train_acc:0.966326
Step: 32280, Val_acc:0.914167
==================>
Step: 32290, Train_acc:0.961888
Step: 32290, Val_acc:0.915565
==================>
Step: 32300, Train_acc:0.956705
Step: 32300, Val_acc:0.89032
==================>
2017-11-11 07:29:35.719671 ---> Validation_loss: 0.214178
Step: 32310, Train_acc:0.949797
Step: 32310, Val_acc:0.915442
==================>
Step: 32320, Train_acc:0.954686
Step: 32320, Val_acc:0.919069
==================>
Step: 32330, Train_acc:0.965402
Step: 32330, Val_acc:0.914692
==================>
Step: 32340, Train_acc:0.965349
Step: 32340, Val_acc:0.918358
==================>
Step: 32350, Train_acc:0.962871
Step: 32350, Val_acc:0.932455
==================>
Step: 32360, Train_acc:0.957701
Step: 32360, Val_acc:0.904874
==================>
Step: 32370, Train_acc:0.971006
Step: 32370, Val_acc:0.926842
==================>
Step: 32380, Train_acc:0.969498
Step: 32380, Val_acc:0.90421
==================>
Step: 32390, Train_acc:0.958496
Step: 32390, Val_acc:0.906874
==================>
Step: 32400, Train_acc:0.951692
Step: 32400, Val_acc:0.917622
==================>
2017-11-11 07:32:11.010324 ---> Validation_loss: 0.245625
Step: 32410, Train_acc:0.969124
Step: 32410, Val_acc:0.889104
==================>
Step: 32420, Train_acc:0.972639
Step: 32420, Val_acc:0.879071
==================>
Step: 32430, Train_acc:0.969298
Step: 32430, Val_acc:0.903953
==================>
Step: 32440, Train_acc:0.947683
Step: 32440, Val_acc:0.906068
==================>
Step: 32450, Train_acc:0.942023
Step: 32450, Val_acc:0.896334
==================>
Step: 32460, Train_acc:0.961295
Step: 32460, Val_acc:0.866017
==================>
Step: 32470, Train_acc:0.963815
Step: 32470, Val_acc:0.931038
==================>
Step: 32480, Train_acc:0.956222
Step: 32480, Val_acc:0.902988
==================>
Step: 32490, Train_acc:0.953284
Step: 32490, Val_acc:0.91239
==================>
Step: 32500, Train_acc:0.95942
Step: 32500, Val_acc:0.893656
==================>
****************** Epochs completed: 65******************
2017-11-11 07:34:45.943889 ---> Validation_loss: 0.193288
Step: 32510, Train_acc:0.960974
Step: 32510, Val_acc:0.895256
==================>
Step: 32520, Train_acc:0.961732
Step: 32520, Val_acc:0.90097
==================>
Step: 32530, Train_acc:0.980381
Step: 32530, Val_acc:0.919756
==================>
Step: 32540, Train_acc:0.964243
Step: 32540, Val_acc:0.927383
==================>
Step: 32550, Train_acc:0.959442
Step: 32550, Val_acc:0.935798
==================>
Step: 32560, Train_acc:0.955802
Step: 32560, Val_acc:0.904574
==================>
Step: 32570, Train_acc:0.957601
Step: 32570, Val_acc:0.931313
==================>
Step: 32580, Train_acc:0.964364
Step: 32580, Val_acc:0.905975
==================>
Step: 32590, Train_acc:0.953059
Step: 32590, Val_acc:0.906801
==================>
Step: 32600, Train_acc:0.951705
Step: 32600, Val_acc:0.888524
==================>
2017-11-11 07:37:21.072328 ---> Validation_loss: 0.260241
Step: 32610, Train_acc:0.949235
Step: 32610, Val_acc:0.925884
==================>
Step: 32620, Train_acc:0.944246
Step: 32620, Val_acc:0.914233
==================>
Step: 32630, Train_acc:0.955637
Step: 32630, Val_acc:0.900505
==================>
Step: 32640, Train_acc:0.944001
Step: 32640, Val_acc:0.921974
==================>
Step: 32650, Train_acc:0.96069
Step: 32650, Val_acc:0.924558
==================>
Step: 32660, Train_acc:0.971755
Step: 32660, Val_acc:0.903132
==================>
Step: 32670, Train_acc:0.96121
Step: 32670, Val_acc:0.924841
==================>
Step: 32680, Train_acc:0.958857
Step: 32680, Val_acc:0.922681
==================>
Step: 32690, Train_acc:0.958933
Step: 32690, Val_acc:0.883339
==================>
Step: 32700, Train_acc:0.97215
Step: 32700, Val_acc:0.89694
==================>
2017-11-11 07:39:56.168945 ---> Validation_loss: 0.216032
Step: 32710, Train_acc:0.96332
Step: 32710, Val_acc:0.898018
==================>
Step: 32720, Train_acc:0.963496
Step: 32720, Val_acc:0.91934
==================>
Step: 32730, Train_acc:0.959539
Step: 32730, Val_acc:0.915872
==================>
Step: 32740, Train_acc:0.972766
Step: 32740, Val_acc:0.900007
==================>
Step: 32750, Train_acc:0.968427
Step: 32750, Val_acc:0.931357
==================>
Step: 32760, Train_acc:0.968953
Step: 32760, Val_acc:0.912195
==================>
Step: 32770, Train_acc:0.956827
Step: 32770, Val_acc:0.915377
==================>
Step: 32780, Train_acc:0.966384
Step: 32780, Val_acc:0.907676
==================>
Step: 32790, Train_acc:0.97452
Step: 32790, Val_acc:0.941487
==================>
Step: 32800, Train_acc:0.954351
Step: 32800, Val_acc:0.90184
==================>
2017-11-11 07:42:31.387763 ---> Validation_loss: 0.21179
Step: 32810, Train_acc:0.968108
Step: 32810, Val_acc:0.883197
==================>
Step: 32820, Train_acc:0.96554
Step: 32820, Val_acc:0.924039
==================>
Step: 32830, Train_acc:0.958905
Step: 32830, Val_acc:0.910021
==================>
Step: 32840, Train_acc:0.958048
Step: 32840, Val_acc:0.926445
==================>
Step: 32850, Train_acc:0.967502
Step: 32850, Val_acc:0.94304
==================>
Step: 32860, Train_acc:0.972869
Step: 32860, Val_acc:0.879972
==================>
Step: 32870, Train_acc:0.96223
Step: 32870, Val_acc:0.887347
==================>
Step: 32880, Train_acc:0.96678
Step: 32880, Val_acc:0.88496
==================>
Step: 32890, Train_acc:0.961436
Step: 32890, Val_acc:0.897544
==================>
Step: 32900, Train_acc:0.964257
Step: 32900, Val_acc:0.894252
==================>
2017-11-11 07:45:06.351277 ---> Validation_loss: 0.226849
Step: 32910, Train_acc:0.958159
Step: 32910, Val_acc:0.929064
==================>
Step: 32920, Train_acc:0.969858
Step: 32920, Val_acc:0.915249
==================>
Step: 32930, Train_acc:0.95941
Step: 32930, Val_acc:0.892167
==================>
Step: 32940, Train_acc:0.958677
Step: 32940, Val_acc:0.91405
==================>
Step: 32950, Train_acc:0.966151
Step: 32950, Val_acc:0.906547
==================>
Step: 32960, Train_acc:0.969138
Step: 32960, Val_acc:0.910546
==================>
Step: 32970, Train_acc:0.969021
Step: 32970, Val_acc:0.875348
==================>
Step: 32980, Train_acc:0.966942
Step: 32980, Val_acc:0.930759
==================>
Step: 32990, Train_acc:0.958717
Step: 32990, Val_acc:0.918988
==================>
Step: 33000, Train_acc:0.959474
Step: 33000, Val_acc:0.895994
==================>
****************** Epochs completed: 66******************
2017-11-11 07:47:41.752747 ---> Validation_loss: 0.225217
Step: 33010, Train_acc:0.9655
Step: 33010, Val_acc:0.901887
==================>
Step: 33020, Train_acc:0.969666
Step: 33020, Val_acc:0.931716
==================>
Step: 33030, Train_acc:0.970356
Step: 33030, Val_acc:0.91442
==================>
Step: 33040, Train_acc:0.955695
Step: 33040, Val_acc:0.915354
==================>
Step: 33050, Train_acc:0.969258
Step: 33050, Val_acc:0.871097
==================>
Step: 33060, Train_acc:0.963197
Step: 33060, Val_acc:0.921521
==================>
Step: 33070, Train_acc:0.95429
Step: 33070, Val_acc:0.91465
==================>
Step: 33080, Train_acc:0.956332
Step: 33080, Val_acc:0.893591
==================>
Step: 33090, Train_acc:0.943843
Step: 33090, Val_acc:0.903459
==================>
Step: 33100, Train_acc:0.962059
Step: 33100, Val_acc:0.903632
==================>
2017-11-11 07:50:16.805565 ---> Validation_loss: 0.181978
Step: 33110, Train_acc:0.962258
Step: 33110, Val_acc:0.933364
==================>
Step: 33120, Train_acc:0.953599
Step: 33120, Val_acc:0.905284
==================>
Step: 33130, Train_acc:0.963668
Step: 33130, Val_acc:0.899977
==================>
Step: 33140, Train_acc:0.973267
Step: 33140, Val_acc:0.883252
==================>
Step: 33150, Train_acc:0.96594
Step: 33150, Val_acc:0.893966
==================>
Step: 33160, Train_acc:0.965315
Step: 33160, Val_acc:0.900709
==================>
Step: 33170, Train_acc:0.957935
Step: 33170, Val_acc:0.910511
==================>
Step: 33180, Train_acc:0.958768
Step: 33180, Val_acc:0.889001
==================>
Step: 33190, Train_acc:0.960189
Step: 33190, Val_acc:0.939016
==================>
Step: 33200, Train_acc:0.96842
Step: 33200, Val_acc:0.891763
==================>
2017-11-11 07:52:52.009002 ---> Validation_loss: 0.269212
Step: 33210, Train_acc:0.95095
Step: 33210, Val_acc:0.93026
==================>
Step: 33220, Train_acc:0.959138
Step: 33220, Val_acc:0.891714
==================>
Step: 33230, Train_acc:0.971665
Step: 33230, Val_acc:0.91519
==================>
Step: 33240, Train_acc:0.966953
Step: 33240, Val_acc:0.909885
==================>
Step: 33250, Train_acc:0.97972
Step: 33250, Val_acc:0.913073
==================>
Step: 33260, Train_acc:0.950714
Step: 33260, Val_acc:0.904928
==================>
Step: 33270, Train_acc:0.960876
Step: 33270, Val_acc:0.894216
==================>
Step: 33280, Train_acc:0.960413
Step: 33280, Val_acc:0.923536
==================>
Step: 33290, Train_acc:0.956718
Step: 33290, Val_acc:0.933213
==================>
Step: 33300, Train_acc:0.968055
Step: 33300, Val_acc:0.924142
==================>
2017-11-11 07:55:27.023954 ---> Validation_loss: 0.248687
Step: 33310, Train_acc:0.96005
Step: 33310, Val_acc:0.916899
==================>
Step: 33320, Train_acc:0.953464
Step: 33320, Val_acc:0.903489
==================>
Step: 33330, Train_acc:0.964918
Step: 33330, Val_acc:0.895514
==================>
Step: 33340, Train_acc:0.968516
Step: 33340, Val_acc:0.936834
==================>
Step: 33350, Train_acc:0.954353
Step: 33350, Val_acc:0.952456
==================>
Step: 33360, Train_acc:0.958893
Step: 33360, Val_acc:0.902974
==================>
Step: 33370, Train_acc:0.974944
Step: 33370, Val_acc:0.915934
==================>
Step: 33380, Train_acc:0.945004
Step: 33380, Val_acc:0.949943
==================>
Step: 33390, Train_acc:0.959806
Step: 33390, Val_acc:0.90744
==================>
Step: 33400, Train_acc:0.95772
Step: 33400, Val_acc:0.91541
==================>
2017-11-11 07:58:02.383166 ---> Validation_loss: 0.175942
Step: 33410, Train_acc:0.973779
Step: 33410, Val_acc:0.897657
==================>
Step: 33420, Train_acc:0.969175
Step: 33420, Val_acc:0.923894
==================>
Step: 33430, Train_acc:0.959745
Step: 33430, Val_acc:0.923988
==================>
Step: 33440, Train_acc:0.951343
Step: 33440, Val_acc:0.916111
==================>
Step: 33450, Train_acc:0.963215
Step: 33450, Val_acc:0.943105
==================>
Step: 33460, Train_acc:0.971106
Step: 33460, Val_acc:0.914052
==================>
Step: 33470, Train_acc:0.954667
Step: 33470, Val_acc:0.922793
==================>
Step: 33480, Train_acc:0.957462
Step: 33480, Val_acc:0.8804
==================>
Step: 33490, Train_acc:0.954749
Step: 33490, Val_acc:0.897667
==================>
Step: 33500, Train_acc:0.960999
Step: 33500, Val_acc:0.907023
==================>
****************** Epochs completed: 67******************
2017-11-11 08:00:37.564186 ---> Validation_loss: 0.344961
Step: 33510, Train_acc:0.976077
Step: 33510, Val_acc:0.923564
==================>
Step: 33520, Train_acc:0.954386
Step: 33520, Val_acc:0.904347
==================>
Step: 33530, Train_acc:0.960269
Step: 33530, Val_acc:0.922433
==================>
Step: 33540, Train_acc:0.962231
Step: 33540, Val_acc:0.914177
==================>
Step: 33550, Train_acc:0.959109
Step: 33550, Val_acc:0.913762
==================>
Step: 33560, Train_acc:0.958518
Step: 33560, Val_acc:0.92641
==================>
Step: 33570, Train_acc:0.955522
Step: 33570, Val_acc:0.891868
==================>
Step: 33580, Train_acc:0.955262
Step: 33580, Val_acc:0.909805
==================>
Step: 33590, Train_acc:0.970293
Step: 33590, Val_acc:0.905915
==================>
Step: 33600, Train_acc:0.967218
Step: 33600, Val_acc:0.863889
==================>
2017-11-11 08:03:12.608449 ---> Validation_loss: 0.180659
Step: 33610, Train_acc:0.96394
Step: 33610, Val_acc:0.915264
==================>
Step: 33620, Train_acc:0.95126
Step: 33620, Val_acc:0.931041
==================>
Step: 33630, Train_acc:0.967142
Step: 33630, Val_acc:0.92024
==================>
****************** Epochs completed: 10******************
Step: 33640, Train_acc:0.961996
Step: 33640, Val_acc:0.900353
==================>
Step: 33650, Train_acc:0.964823
Step: 33650, Val_acc:0.91183
==================>
Step: 33660, Train_acc:0.958669
Step: 33660, Val_acc:0.917218
==================>
Step: 33670, Train_acc:0.970587
Step: 33670, Val_acc:0.900585
==================>
Step: 33680, Train_acc:0.969745
Step: 33680, Val_acc:0.924841
==================>
Step: 33690, Train_acc:0.962954
Step: 33690, Val_acc:0.884335
==================>
Step: 33700, Train_acc:0.963063
Step: 33700, Val_acc:0.920369
==================>
2017-11-11 08:05:47.853745 ---> Validation_loss: 0.170513
Step: 33710, Train_acc:0.969126
Step: 33710, Val_acc:0.928461
==================>
Step: 33720, Train_acc:0.957687
Step: 33720, Val_acc:0.870837
==================>
Step: 33730, Train_acc:0.960608
Step: 33730, Val_acc:0.896425
==================>
Step: 33740, Train_acc:0.967875
Step: 33740, Val_acc:0.912928
==================>
Step: 33750, Train_acc:0.972781
Step: 33750, Val_acc:0.907605
==================>
Step: 33760, Train_acc:0.967574
Step: 33760, Val_acc:0.934485
==================>
Step: 33770, Train_acc:0.970515
Step: 33770, Val_acc:0.90375
==================>
Step: 33780, Train_acc:0.966212
Step: 33780, Val_acc:0.920865
==================>
Step: 33790, Train_acc:0.952584
Step: 33790, Val_acc:0.921998
==================>
Step: 33800, Train_acc:0.960281
Step: 33800, Val_acc:0.89405
==================>
2017-11-11 08:08:23.138488 ---> Validation_loss: 0.206283
Step: 33810, Train_acc:0.958418
Step: 33810, Val_acc:0.901343
==================>
Step: 33820, Train_acc:0.946764
Step: 33820, Val_acc:0.920018
==================>
Step: 33830, Train_acc:0.957924
Step: 33830, Val_acc:0.917617
==================>
Step: 33840, Train_acc:0.967356
Step: 33840, Val_acc:0.912233
==================>
Step: 33850, Train_acc:0.971499
Step: 33850, Val_acc:0.889734
==================>
Step: 33860, Train_acc:0.967229
Step: 33860, Val_acc:0.905896
==================>
Step: 33870, Train_acc:0.971901
Step: 33870, Val_acc:0.887001
==================>
Step: 33880, Train_acc:0.964283
Step: 33880, Val_acc:0.910554
==================>
Step: 33890, Train_acc:0.956537
Step: 33890, Val_acc:0.906119
==================>
Step: 33900, Train_acc:0.970227
Step: 33900, Val_acc:0.90578
==================>
2017-11-11 08:10:58.265217 ---> Validation_loss: 0.159131
Step: 33910, Train_acc:0.950626
Step: 33910, Val_acc:0.918698
==================>
Step: 33920, Train_acc:0.968199
Step: 33920, Val_acc:0.901871
==================>
Step: 33930, Train_acc:0.968799
Step: 33930, Val_acc:0.921954
==================>
Step: 33940, Train_acc:0.966377
Step: 33940, Val_acc:0.902383
==================>
Step: 33950, Train_acc:0.974622
Step: 33950, Val_acc:0.911223
==================>
Step: 33960, Train_acc:0.964508
Step: 33960, Val_acc:0.916829
==================>
Step: 33970, Train_acc:0.964412
Step: 33970, Val_acc:0.916353
==================>
Step: 33980, Train_acc:0.965179
Step: 33980, Val_acc:0.922128
==================>
Step: 33990, Train_acc:0.963197
Step: 33990, Val_acc:0.917695
==================>
Step: 34000, Train_acc:0.951576
Step: 34000, Val_acc:0.874313
==================>
****************** Epochs completed: 68******************
2017-11-11 08:13:33.270325 ---> Validation_loss: 0.160438
Step: 34010, Train_acc:0.961989
Step: 34010, Val_acc:0.914015
==================>
Step: 34020, Train_acc:0.975513
Step: 34020, Val_acc:0.898934
==================>
Step: 34030, Train_acc:0.939841
Step: 34030, Val_acc:0.925632
==================>
Step: 34040, Train_acc:0.957673
Step: 34040, Val_acc:0.911663
==================>
Step: 34050, Train_acc:0.958849
Step: 34050, Val_acc:0.895162
==================>
Step: 34060, Train_acc:0.972932
Step: 34060, Val_acc:0.91651
==================>
Step: 34070, Train_acc:0.967435
Step: 34070, Val_acc:0.919056
==================>
Step: 34080, Train_acc:0.955076
Step: 34080, Val_acc:0.88829
==================>
Step: 34090, Train_acc:0.96741
Step: 34090, Val_acc:0.920361
==================>
Step: 34100, Train_acc:0.958971
Step: 34100, Val_acc:0.913268
==================>
2017-11-11 08:16:08.438902 ---> Validation_loss: 0.200592
Step: 34110, Train_acc:0.967479
Step: 34110, Val_acc:0.881202
==================>
Step: 34120, Train_acc:0.965452
Step: 34120, Val_acc:0.906946
==================>
Step: 34130, Train_acc:0.96968
Step: 34130, Val_acc:0.902485
==================>
Step: 34140, Train_acc:0.976412
Step: 34140, Val_acc:0.927791
==================>
Step: 34150, Train_acc:0.964272
Step: 34150, Val_acc:0.916295
==================>
Step: 34160, Train_acc:0.958438
Step: 34160, Val_acc:0.933416
==================>
Step: 34170, Train_acc:0.96468
Step: 34170, Val_acc:0.930114
==================>
Step: 34180, Train_acc:0.965679
Step: 34180, Val_acc:0.927123
==================>
Step: 34190, Train_acc:0.968914
Step: 34190, Val_acc:0.905388
==================>
Step: 34200, Train_acc:0.966718
Step: 34200, Val_acc:0.919713
==================>
2017-11-11 08:18:43.617587 ---> Validation_loss: 0.244469
Step: 34210, Train_acc:0.961622
Step: 34210, Val_acc:0.901666
==================>
Step: 34220, Train_acc:0.974751
Step: 34220, Val_acc:0.907253
==================>
Step: 34230, Train_acc:0.961202
Step: 34230, Val_acc:0.875925
==================>
Step: 34240, Train_acc:0.97031
Step: 34240, Val_acc:0.906184
==================>
Step: 34250, Train_acc:0.972687
Step: 34250, Val_acc:0.929301
==================>
Step: 34260, Train_acc:0.972208
Step: 34260, Val_acc:0.907543
==================>
Step: 34270, Train_acc:0.971722
Step: 34270, Val_acc:0.893512
==================>
Step: 34280, Train_acc:0.956801
Step: 34280, Val_acc:0.91033
==================>
Step: 34290, Train_acc:0.961233
Step: 34290, Val_acc:0.888278
==================>
Step: 34300, Train_acc:0.964329
Step: 34300, Val_acc:0.899572
==================>
2017-11-11 08:21:18.757827 ---> Validation_loss: 0.15771
Step: 34310, Train_acc:0.95988
Step: 34310, Val_acc:0.915542
==================>
Step: 34320, Train_acc:0.959821
Step: 34320, Val_acc:0.914165
==================>
Step: 34330, Train_acc:0.971156
Step: 34330, Val_acc:0.934935
==================>
Step: 34340, Train_acc:0.977007
Step: 34340, Val_acc:0.91041
==================>
Step: 34350, Train_acc:0.971433
Step: 34350, Val_acc:0.929785
==================>
Step: 34360, Train_acc:0.961541
Step: 34360, Val_acc:0.926169
==================>
Step: 34370, Train_acc:0.964867
Step: 34370, Val_acc:0.91791
==================>
Step: 34380, Train_acc:0.968302
Step: 34380, Val_acc:0.896521
==================>
Step: 34390, Train_acc:0.961946
Step: 34390, Val_acc:0.899227
==================>
Step: 34400, Train_acc:0.972681
Step: 34400, Val_acc:0.91442
==================>
2017-11-11 08:23:53.827824 ---> Validation_loss: 0.275218
Step: 34410, Train_acc:0.955552
Step: 34410, Val_acc:0.88811
==================>
Step: 34420, Train_acc:0.948435
Step: 34420, Val_acc:0.903903
==================>
Step: 34430, Train_acc:0.960908
Step: 34430, Val_acc:0.939395
==================>
Step: 34440, Train_acc:0.968611
Step: 34440, Val_acc:0.930481
==================>
Step: 34450, Train_acc:0.962427
Step: 34450, Val_acc:0.919728
==================>
Step: 34460, Train_acc:0.974913
Step: 34460, Val_acc:0.917885
==================>
Step: 34470, Train_acc:0.966506
Step: 34470, Val_acc:0.912072
==================>
Step: 34480, Train_acc:0.974955
Step: 34480, Val_acc:0.897458
==================>
Step: 34490, Train_acc:0.949591
Step: 34490, Val_acc:0.906229
==================>
Step: 34500, Train_acc:0.963724
Step: 34500, Val_acc:0.933274
==================>
****************** Epochs completed: 69******************
2017-11-11 08:26:29.286441 ---> Validation_loss: 0.203111
Step: 34510, Train_acc:0.959844
Step: 34510, Val_acc:0.904252
==================>
Step: 34520, Train_acc:0.951083
Step: 34520, Val_acc:0.87241
==================>
Step: 34530, Train_acc:0.961389
Step: 34530, Val_acc:0.936534
==================>
Step: 34540, Train_acc:0.963616
Step: 34540, Val_acc:0.898508
==================>
Step: 34550, Train_acc:0.963068
Step: 34550, Val_acc:0.934025
==================>
Step: 34560, Train_acc:0.950168
Step: 34560, Val_acc:0.90809
==================>
Step: 34570, Train_acc:0.971803
Step: 34570, Val_acc:0.895582
==================>
Step: 34580, Train_acc:0.964614
Step: 34580, Val_acc:0.931156
==================>
Step: 34590, Train_acc:0.970179
Step: 34590, Val_acc:0.921515
==================>
Step: 34600, Train_acc:0.97755
Step: 34600, Val_acc:0.881227
==================>
2017-11-11 08:29:04.359011 ---> Validation_loss: 0.193976
Step: 34610, Train_acc:0.975408
Step: 34610, Val_acc:0.900521
==================>
Step: 34620, Train_acc:0.969218
Step: 34620, Val_acc:0.930549
==================>
Step: 34630, Train_acc:0.966582
Step: 34630, Val_acc:0.91442
==================>
Step: 34640, Train_acc:0.964019
Step: 34640, Val_acc:0.887717
==================>
Step: 34650, Train_acc:0.968337
Step: 34650, Val_acc:0.889886
==================>
Step: 34660, Train_acc:0.958823
Step: 34660, Val_acc:0.934469
==================>
Step: 34670, Train_acc:0.979889
Step: 34670, Val_acc:0.915643
==================>
Step: 34680, Train_acc:0.954263
Step: 34680, Val_acc:0.90001
==================>
Step: 34690, Train_acc:0.971543
Step: 34690, Val_acc:0.942133
==================>
Step: 34700, Train_acc:0.96227
Step: 34700, Val_acc:0.911395
==================>
2017-11-11 08:31:39.704523 ---> Validation_loss: 0.195245
Step: 34710, Train_acc:0.959734
Step: 34710, Val_acc:0.907179
==================>
Step: 34720, Train_acc:0.967406
Step: 34720, Val_acc:0.923035
==================>
Step: 34730, Train_acc:0.969366
Step: 34730, Val_acc:0.937729
==================>
Step: 34740, Train_acc:0.967388
Step: 34740, Val_acc:0.883031
==================>
Step: 34750, Train_acc:0.965814
Step: 34750, Val_acc:0.917399
==================>
Step: 34760, Train_acc:0.967927
Step: 34760, Val_acc:0.908873
==================>
Step: 34770, Train_acc:0.961221
Step: 34770, Val_acc:0.909885
==================>
Step: 34780, Train_acc:0.973372
Step: 34780, Val_acc:0.90495
==================>
Step: 34790, Train_acc:0.971528
Step: 34790, Val_acc:0.916293
==================>
Step: 34800, Train_acc:0.953004
Step: 34800, Val_acc:0.932435
==================>
2017-11-11 08:34:14.763788 ---> Validation_loss: 0.280731
Step: 34810, Train_acc:0.962244
Step: 34810, Val_acc:0.887937
==================>
Step: 34820, Train_acc:0.97656
Step: 34820, Val_acc:0.928008
==================>
Step: 34830, Train_acc:0.968544
Step: 34830, Val_acc:0.916781
==================>
Step: 34840, Train_acc:0.956252
Step: 34840, Val_acc:0.896818
==================>
Step: 34850, Train_acc:0.960464
Step: 34850, Val_acc:0.898354
==================>
Step: 34860, Train_acc:0.965334
Step: 34860, Val_acc:0.919081
==================>
Step: 34870, Train_acc:0.971543
Step: 34870, Val_acc:0.894846
==================>
Step: 34880, Train_acc:0.977042
Step: 34880, Val_acc:0.945874
==================>
Step: 34890, Train_acc:0.955527
Step: 34890, Val_acc:0.932178
==================>
Step: 34900, Train_acc:0.961681
Step: 34900, Val_acc:0.908031
==================>
2017-11-11 08:36:50.249005 ---> Validation_loss: 0.154727
Step: 34910, Train_acc:0.969414
Step: 34910, Val_acc:0.92417
==================>
Step: 34920, Train_acc:0.966364
Step: 34920, Val_acc:0.91715
==================>
Step: 34930, Train_acc:0.975344
Step: 34930, Val_acc:0.907245
==================>
Step: 34940, Train_acc:0.953422
Step: 34940, Val_acc:0.918282
==================>
Step: 34950, Train_acc:0.97349
Step: 34950, Val_acc:0.940197
==================>
Step: 34960, Train_acc:0.954456
Step: 34960, Val_acc:0.905093
==================>
Step: 34970, Train_acc:0.958651
Step: 34970, Val_acc:0.913947
==================>
Step: 34980, Train_acc:0.95806
Step: 34980, Val_acc:0.897946
==================>
Step: 34990, Train_acc:0.950349
Step: 34990, Val_acc:0.905382
==================>
Step: 35000, Train_acc:0.969656
Step: 35000, Val_acc:0.920824
==================>
****************** Epochs completed: 70******************
2017-11-11 08:39:25.464428 ---> Validation_loss: 0.137335
Step: 35010, Train_acc:0.974922
Step: 35010, Val_acc:0.914208
==================>
Step: 35020, Train_acc:0.964506
Step: 35020, Val_acc:0.923959
==================>
Step: 35030, Train_acc:0.959706
Step: 35030, Val_acc:0.917986
==================>
Step: 35040, Train_acc:0.96681
Step: 35040, Val_acc:0.931885
==================>
Step: 35050, Train_acc:0.961677
Step: 35050, Val_acc:0.897328
==================>
Step: 35060, Train_acc:0.968455
Step: 35060, Val_acc:0.902631
==================>
Step: 35070, Train_acc:0.960984
Step: 35070, Val_acc:0.904901
==================>
Step: 35080, Train_acc:0.959458
Step: 35080, Val_acc:0.883439
==================>
Step: 35090, Train_acc:0.956388
Step: 35090, Val_acc:0.941421
==================>
Step: 35100, Train_acc:0.968633
Step: 35100, Val_acc:0.898666
==================>
2017-11-11 08:42:00.630039 ---> Validation_loss: 0.253285
Step: 35110, Train_acc:0.955024
Step: 35110, Val_acc:0.928076
==================>
Step: 35120, Train_acc:0.966332
Step: 35120, Val_acc:0.93647
==================>
Step: 35130, Train_acc:0.957805
Step: 35130, Val_acc:0.891584
==================>
Step: 35140, Train_acc:0.960386
Step: 35140, Val_acc:0.893909
==================>
Step: 35150, Train_acc:0.961945
Step: 35150, Val_acc:0.922264
==================>
Step: 35160, Train_acc:0.968973
Step: 35160, Val_acc:0.890894
==================>
Step: 35170, Train_acc:0.971165
Step: 35170, Val_acc:0.90714
==================>
Step: 35180, Train_acc:0.96624
Step: 35180, Val_acc:0.91041
==================>
Step: 35190, Train_acc:0.965963
Step: 35190, Val_acc:0.900861
==================>
Step: 35200, Train_acc:0.972606
Step: 35200, Val_acc:0.926403
==================>
2017-11-11 08:44:35.899015 ---> Validation_loss: 0.25069
Step: 35210, Train_acc:0.965022
Step: 35210, Val_acc:0.9267
==================>
Step: 35220, Train_acc:0.967056
Step: 35220, Val_acc:0.906603
==================>
Step: 35230, Train_acc:0.972347
Step: 35230, Val_acc:0.912496
==================>
Step: 35240, Train_acc:0.95942
Step: 35240, Val_acc:0.896359
==================>
Step: 35250, Train_acc:0.971635
Step: 35250, Val_acc:0.909617
==================>
Step: 35260, Train_acc:0.948312
Step: 35260, Val_acc:0.926624
==================>
Step: 35270, Train_acc:0.954264
Step: 35270, Val_acc:0.942916
==================>
Step: 35280, Train_acc:0.964192
Step: 35280, Val_acc:0.896204
==================>
Step: 35290, Train_acc:0.963772
Step: 35290, Val_acc:0.914526
==================>
Step: 35300, Train_acc:0.967404
Step: 35300, Val_acc:0.940293
==================>
2017-11-11 08:47:11.010634 ---> Validation_loss: 0.191935
Step: 35310, Train_acc:0.958781
Step: 35310, Val_acc:0.925737
==================>
Step: 35320, Train_acc:0.959257
Step: 35320, Val_acc:0.882988
==================>
Step: 35330, Train_acc:0.968359
Step: 35330, Val_acc:0.921431
==================>
Step: 35340, Train_acc:0.975146
Step: 35340, Val_acc:0.922151
==================>
Step: 35350, Train_acc:0.966963
Step: 35350, Val_acc:0.935088
==================>
Step: 35360, Train_acc:0.973071
Step: 35360, Val_acc:0.931107
==================>
Step: 35370, Train_acc:0.963134
Step: 35370, Val_acc:0.908451
==================>
Step: 35380, Train_acc:0.968278
Step: 35380, Val_acc:0.90912
==================>
Step: 35390, Train_acc:0.969127
Step: 35390, Val_acc:0.881263
==================>
Step: 35400, Train_acc:0.962245
Step: 35400, Val_acc:0.943651
==================>
2017-11-11 08:49:46.241550 ---> Validation_loss: 0.204318
Step: 35410, Train_acc:0.954355
Step: 35410, Val_acc:0.899774
==================>
Step: 35420, Train_acc:0.969697
Step: 35420, Val_acc:0.924355
==================>
Step: 35430, Train_acc:0.968608
Step: 35430, Val_acc:0.917366
==================>
Step: 35440, Train_acc:0.967968
Step: 35440, Val_acc:0.892103
==================>
Step: 35450, Train_acc:0.978979
Step: 35450, Val_acc:0.927701
==================>
Step: 35460, Train_acc:0.961396
Step: 35460, Val_acc:0.909078
==================>
Step: 35470, Train_acc:0.965787
Step: 35470, Val_acc:0.892482
==================>
Step: 35480, Train_acc:0.952594
Step: 35480, Val_acc:0.904996
==================>
Step: 35490, Train_acc:0.970218
Step: 35490, Val_acc:0.92363
==================>
Step: 35500, Train_acc:0.948745
Step: 35500, Val_acc:0.918762
==================>
****************** Epochs completed: 71******************
2017-11-11 08:52:21.441895 ---> Validation_loss: 0.160659
Step: 35510, Train_acc:0.967792
Step: 35510, Val_acc:0.897231
==================>
Step: 35520, Train_acc:0.971759
Step: 35520, Val_acc:0.914236
==================>
Step: 35530, Train_acc:0.96688
Step: 35530, Val_acc:0.887792
==================>
Step: 35540, Train_acc:0.966046
Step: 35540, Val_acc:0.882356
==================>
Step: 35550, Train_acc:0.966776
Step: 35550, Val_acc:0.876324
==================>
Step: 35560, Train_acc:0.961829
Step: 35560, Val_acc:0.92995
==================>
Step: 35570, Train_acc:0.968634
Step: 35570, Val_acc:0.915453
==================>
Step: 35580, Train_acc:0.962458
Step: 35580, Val_acc:0.914454
==================>
Step: 35590, Train_acc:0.96694
Step: 35590, Val_acc:0.922299
==================>
Step: 35600, Train_acc:0.971865
Step: 35600, Val_acc:0.907711
==================>
2017-11-11 08:54:56.441924 ---> Validation_loss: 0.152044
Step: 35610, Train_acc:0.9711
Step: 35610, Val_acc:0.9192
==================>
Step: 35620, Train_acc:0.966548
Step: 35620, Val_acc:0.919039
==================>
Step: 35630, Train_acc:0.974242
Step: 35630, Val_acc:0.920247
==================>
Step: 35640, Train_acc:0.967902
Step: 35640, Val_acc:0.901841
==================>
Step: 35650, Train_acc:0.970154
Step: 35650, Val_acc:0.913087
==================>
Step: 35660, Train_acc:0.943624
Step: 35660, Val_acc:0.905966
==================>
Step: 35670, Train_acc:0.966942
Step: 35670, Val_acc:0.883332
==================>
Step: 35680, Train_acc:0.95933
Step: 35680, Val_acc:0.901516
==================>
Step: 35690, Train_acc:0.970807
Step: 35690, Val_acc:0.934128
==================>
Step: 35700, Train_acc:0.964926
Step: 35700, Val_acc:0.919833
==================>
2017-11-11 08:57:31.754481 ---> Validation_loss: 0.290031
Step: 35710, Train_acc:0.9664
Step: 35710, Val_acc:0.923168
==================>
Step: 35720, Train_acc:0.97323
Step: 35720, Val_acc:0.903298
==================>
Step: 35730, Train_acc:0.961688
Step: 35730, Val_acc:0.862134
==================>
Step: 35740, Train_acc:0.96464
Step: 35740, Val_acc:0.886248
==================>
Step: 35750, Train_acc:0.967563
Step: 35750, Val_acc:0.90752
==================>
Step: 35760, Train_acc:0.962571
Step: 35760, Val_acc:0.889202
==================>
Step: 35770, Train_acc:0.963805
Step: 35770, Val_acc:0.918002
==================>
Step: 35780, Train_acc:0.959493
Step: 35780, Val_acc:0.89532
==================>
Step: 35790, Train_acc:0.964572
Step: 35790, Val_acc:0.922756
==================>
Step: 35800, Train_acc:0.958229
Step: 35800, Val_acc:0.921434
==================>
2017-11-11 09:00:06.705567 ---> Validation_loss: 0.238896
Step: 35810, Train_acc:0.958132
Step: 35810, Val_acc:0.894037
==================>
Step: 35820, Train_acc:0.962209
Step: 35820, Val_acc:0.873275
==================>
Step: 35830, Train_acc:0.970453
Step: 35830, Val_acc:0.900359
==================>
Step: 35840, Train_acc:0.963805
Step: 35840, Val_acc:0.904039
==================>
Step: 35850, Train_acc:0.963608
Step: 35850, Val_acc:0.914559
==================>
Step: 35860, Train_acc:0.967749
Step: 35860, Val_acc:0.910352
==================>
Step: 35870, Train_acc:0.966804
Step: 35870, Val_acc:0.916945
==================>
Step: 35880, Train_acc:0.973059
Step: 35880, Val_acc:0.922895
==================>
Step: 35890, Train_acc:0.943503
Step: 35890, Val_acc:0.932592
==================>
Step: 35900, Train_acc:0.96661
Step: 35900, Val_acc:0.902848
==================>
2017-11-11 09:02:41.707757 ---> Validation_loss: 0.238867
Step: 35910, Train_acc:0.968062
Step: 35910, Val_acc:0.90226
==================>
Step: 35920, Train_acc:0.951567
Step: 35920, Val_acc:0.872903
==================>
Step: 35930, Train_acc:0.959805
Step: 35930, Val_acc:0.912926
==================>
Step: 35940, Train_acc:0.965959
Step: 35940, Val_acc:0.929116
==================>
Step: 35950, Train_acc:0.97407
Step: 35950, Val_acc:0.936464
==================>
Step: 35960, Train_acc:0.969498
Step: 35960, Val_acc:0.909095
==================>
Step: 35970, Train_acc:0.955516
Step: 35970, Val_acc:0.899387
==================>
Step: 35980, Train_acc:0.973776
Step: 35980, Val_acc:0.897384
==================>
Step: 35990, Train_acc:0.966917
Step: 35990, Val_acc:0.873357
==================>
Step: 36000, Train_acc:0.973849
Step: 36000, Val_acc:0.925353
==================>
****************** Epochs completed: 72******************
2017-11-11 09:05:17.040651 ---> Validation_loss: 0.232779
Step: 36010, Train_acc:0.965635
Step: 36010, Val_acc:0.943212
==================>
Step: 36020, Train_acc:0.969623
Step: 36020, Val_acc:0.910751
==================>
Step: 36030, Train_acc:0.973256
Step: 36030, Val_acc:0.893547
==================>
Step: 36040, Train_acc:0.958156
Step: 36040, Val_acc:0.917716
==================>
Step: 36050, Train_acc:0.963439
Step: 36050, Val_acc:0.906356
==================>
Step: 36060, Train_acc:0.976443
Step: 36060, Val_acc:0.924984
==================>
Step: 36070, Train_acc:0.953241
Step: 36070, Val_acc:0.8986
==================>
Step: 36080, Train_acc:0.969923
Step: 36080, Val_acc:0.923832
==================>
Step: 36090, Train_acc:0.95832
Step: 36090, Val_acc:0.920145
==================>
Step: 36100, Train_acc:0.962249
Step: 36100, Val_acc:0.938038
==================>
2017-11-11 09:07:52.138623 ---> Validation_loss: 0.184289
Step: 36110, Train_acc:0.968799
Step: 36110, Val_acc:0.925479
==================>
Step: 36120, Train_acc:0.955706
Step: 36120, Val_acc:0.906205
==================>
Step: 36130, Train_acc:0.974513
Step: 36130, Val_acc:0.935292
==================>
Step: 36140, Train_acc:0.953082
Step: 36140, Val_acc:0.929767
==================>
Step: 36150, Train_acc:0.956338
Step: 36150, Val_acc:0.8965
==================>
Step: 36160, Train_acc:0.963385
Step: 36160, Val_acc:0.92726
==================>
Step: 36170, Train_acc:0.969994
Step: 36170, Val_acc:0.924811
==================>
Step: 36180, Train_acc:0.965536
Step: 36180, Val_acc:0.878606
==================>
Step: 36190, Train_acc:0.970474
Step: 36190, Val_acc:0.896454
==================>
Step: 36200, Train_acc:0.964142
Step: 36200, Val_acc:0.914429
==================>
2017-11-11 09:10:27.400734 ---> Validation_loss: 0.142906
Step: 36210, Train_acc:0.970594
Step: 36210, Val_acc:0.901
==================>
Step: 36220, Train_acc:0.96455
Step: 36220, Val_acc:0.903418
==================>
Step: 36230, Train_acc:0.974146
Step: 36230, Val_acc:0.923256
==================>
Step: 36240, Train_acc:0.969792
Step: 36240, Val_acc:0.915295
==================>
Step: 36250, Train_acc:0.964473
Step: 36250, Val_acc:0.890666
==================>
Step: 36260, Train_acc:0.970477
Step: 36260, Val_acc:0.875122
==================>
Step: 36270, Train_acc:0.966509
Step: 36270, Val_acc:0.890468
==================>
Step: 36280, Train_acc:0.954525
Step: 36280, Val_acc:0.911746
==================>
Step: 36290, Train_acc:0.96817
Step: 36290, Val_acc:0.941807
==================>
Step: 36300, Train_acc:0.965446
Step: 36300, Val_acc:0.930638
==================>
2017-11-11 09:13:02.608827 ---> Validation_loss: 0.192135
Step: 36310, Train_acc:0.969198
Step: 36310, Val_acc:0.911025
==================>
Step: 36320, Train_acc:0.951171
Step: 36320, Val_acc:0.935374
==================>
Step: 36330, Train_acc:0.969066
Step: 36330, Val_acc:0.888608
==================>
Step: 36340, Train_acc:0.970779
Step: 36340, Val_acc:0.910011
==================>
Step: 36350, Train_acc:0.957411
Step: 36350, Val_acc:0.907825
==================>
Step: 36360, Train_acc:0.978269
Step: 36360, Val_acc:0.912609
==================>
Step: 36370, Train_acc:0.964037
Step: 36370, Val_acc:0.89976
==================>
Step: 36380, Train_acc:0.967488
Step: 36380, Val_acc:0.924797
==================>
Step: 36390, Train_acc:0.968065
Step: 36390, Val_acc:0.902543
==================>
Step: 36400, Train_acc:0.965273
Step: 36400, Val_acc:0.910696
==================>
2017-11-11 09:15:37.523757 ---> Validation_loss: 0.256645
Step: 36410, Train_acc:0.965576
Step: 36410, Val_acc:0.897228
==================>
Step: 36420, Train_acc:0.980858
Step: 36420, Val_acc:0.86951
==================>
Step: 36430, Train_acc:0.958649
Step: 36430, Val_acc:0.930693
==================>
Step: 36440, Train_acc:0.958707
Step: 36440, Val_acc:0.911442
==================>
Step: 36450, Train_acc:0.968146
Step: 36450, Val_acc:0.903055
==================>
Step: 36460, Train_acc:0.963005
Step: 36460, Val_acc:0.931041
==================>
Step: 36470, Train_acc:0.963055
Step: 36470, Val_acc:0.913652
==================>
Step: 36480, Train_acc:0.96074
Step: 36480, Val_acc:0.919095
==================>
Step: 36490, Train_acc:0.950675
Step: 36490, Val_acc:0.8997
==================>
Step: 36500, Train_acc:0.967765
Step: 36500, Val_acc:0.900308
==================>
****************** Epochs completed: 73******************
2017-11-11 09:18:12.673931 ---> Validation_loss: 0.189535
Step: 36510, Train_acc:0.966333
Step: 36510, Val_acc:0.873879
==================>
Step: 36520, Train_acc:0.958545
Step: 36520, Val_acc:0.90306
==================>
Step: 36530, Train_acc:0.975455
Step: 36530, Val_acc:0.920009
==================>
Step: 36540, Train_acc:0.966353
Step: 36540, Val_acc:0.911206
==================>
Step: 36550, Train_acc:0.962362
Step: 36550, Val_acc:0.864771
==================>
Step: 36560, Train_acc:0.944639
Step: 36560, Val_acc:0.919498
==================>
Step: 36570, Train_acc:0.977969
Step: 36570, Val_acc:0.907994
==================>
Step: 36580, Train_acc:0.968727
Step: 36580, Val_acc:0.937385
==================>
Step: 36590, Train_acc:0.970459
Step: 36590, Val_acc:0.909047
==================>
Step: 36600, Train_acc:0.971085
Step: 36600, Val_acc:0.907358
==================>
2017-11-11 09:20:47.878059 ---> Validation_loss: 0.207227
Step: 36610, Train_acc:0.955374
Step: 36610, Val_acc:0.908143
==================>
Step: 36620, Train_acc:0.955364
Step: 36620, Val_acc:0.943578
==================>
Step: 36630, Train_acc:0.982766
Step: 36630, Val_acc:0.861523
==================>
Step: 36640, Train_acc:0.957393
Step: 36640, Val_acc:0.897694
==================>
Step: 36650, Train_acc:0.974756
Step: 36650, Val_acc:0.926561
==================>
Step: 36660, Train_acc:0.966733
Step: 36660, Val_acc:0.909246
==================>
Step: 36670, Train_acc:0.959366
Step: 36670, Val_acc:0.909692
==================>
Step: 36680, Train_acc:0.956279
Step: 36680, Val_acc:0.898145
==================>
Step: 36690, Train_acc:0.9683
Step: 36690, Val_acc:0.906322
==================>
Step: 36700, Train_acc:0.974304
Step: 36700, Val_acc:0.902443
==================>
2017-11-11 09:23:23.227722 ---> Validation_loss: 0.211287
Step: 36710, Train_acc:0.971488
Step: 36710, Val_acc:0.897883
==================>
Step: 36720, Train_acc:0.972565
Step: 36720, Val_acc:0.93369
==================>
Step: 36730, Train_acc:0.970128
Step: 36730, Val_acc:0.935491
==================>
Step: 36740, Train_acc:0.961176
Step: 36740, Val_acc:0.899071
==================>
Step: 36750, Train_acc:0.974148
Step: 36750, Val_acc:0.92283
==================>
Step: 36760, Train_acc:0.962943
Step: 36760, Val_acc:0.946213
==================>
Step: 36770, Train_acc:0.966207
Step: 36770, Val_acc:0.926466
==================>
Step: 36780, Train_acc:0.950688
Step: 36780, Val_acc:0.904276
==================>
Step: 36790, Train_acc:0.96752
Step: 36790, Val_acc:0.929683
==================>
Step: 36800, Train_acc:0.964352
Step: 36800, Val_acc:0.903857
==================>
2017-11-11 09:25:58.552555 ---> Validation_loss: 0.295421
Step: 36810, Train_acc:0.961057
Step: 36810, Val_acc:0.926926
==================>
Step: 36820, Train_acc:0.958781
Step: 36820, Val_acc:0.937538
==================>
Step: 36830, Train_acc:0.956345
Step: 36830, Val_acc:0.926299
==================>
Step: 36840, Train_acc:0.961584
Step: 36840, Val_acc:0.90063
==================>
Step: 36850, Train_acc:0.968728
Step: 36850, Val_acc:0.906948
==================>
Step: 36860, Train_acc:0.970481
Step: 36860, Val_acc:0.895074
==================>
Step: 36870, Train_acc:0.974519
Step: 36870, Val_acc:0.922643
==================>
Step: 36880, Train_acc:0.957611
Step: 36880, Val_acc:0.919138
==================>
Step: 36890, Train_acc:0.966484
Step: 36890, Val_acc:0.91243
==================>
Step: 36900, Train_acc:0.965653
Step: 36900, Val_acc:0.914144
==================>
2017-11-11 09:28:34.015972 ---> Validation_loss: 0.178119
Step: 36910, Train_acc:0.963223
Step: 36910, Val_acc:0.918378
==================>
Step: 36920, Train_acc:0.960332
Step: 36920, Val_acc:0.874836
==================>
Step: 36930, Train_acc:0.964061
Step: 36930, Val_acc:0.909823
==================>
Step: 36940, Train_acc:0.959774
Step: 36940, Val_acc:0.918496
==================>
Step: 36950, Train_acc:0.960144
Step: 36950, Val_acc:0.931881
==================>
Step: 36960, Train_acc:0.965765
Step: 36960, Val_acc:0.916892
==================>
Step: 36970, Train_acc:0.963973
Step: 36970, Val_acc:0.928306
==================>
Step: 36980, Train_acc:0.944785
Step: 36980, Val_acc:0.905275
==================>
Step: 36990, Train_acc:0.963289
Step: 36990, Val_acc:0.910234
==================>
Step: 37000, Train_acc:0.967941
Step: 37000, Val_acc:0.92255
==================>
****************** Epochs completed: 74******************
2017-11-11 09:31:08.882986 ---> Validation_loss: 0.185623
****************** Epochs completed: 11******************
Step: 37010, Train_acc:0.969368
Step: 37010, Val_acc:0.888802
==================>
Step: 37020, Train_acc:0.961177
Step: 37020, Val_acc:0.930315
==================>
Step: 37030, Train_acc:0.97533
Step: 37030, Val_acc:0.906582
==================>
Step: 37040, Train_acc:0.963844
Step: 37040, Val_acc:0.949814
==================>
Step: 37050, Train_acc:0.975853
Step: 37050, Val_acc:0.886602
==================>
Step: 37060, Train_acc:0.965078
Step: 37060, Val_acc:0.90963
==================>
Step: 37070, Train_acc:0.975386
Step: 37070, Val_acc:0.898365
==================>
Step: 37080, Train_acc:0.969165
Step: 37080, Val_acc:0.904915
==================>
Step: 37090, Train_acc:0.96198
Step: 37090, Val_acc:0.936931
==================>
Step: 37100, Train_acc:0.968818
Step: 37100, Val_acc:0.882604
==================>
2017-11-11 09:33:43.827799 ---> Validation_loss: 0.213491
Step: 37110, Train_acc:0.967203
Step: 37110, Val_acc:0.93213
==================>
Step: 37120, Train_acc:0.965021
Step: 37120, Val_acc:0.892504
==================>
Step: 37130, Train_acc:0.963549
Step: 37130, Val_acc:0.914353
==================>
Step: 37140, Train_acc:0.961459
Step: 37140, Val_acc:0.898137
==================>
Step: 37150, Train_acc:0.973586
Step: 37150, Val_acc:0.885172
==================>
Step: 37160, Train_acc:0.962446
Step: 37160, Val_acc:0.910157
==================>
Step: 37170, Train_acc:0.9583
Step: 37170, Val_acc:0.903781
==================>
Step: 37180, Train_acc:0.959808
Step: 37180, Val_acc:0.902848
==================>
Step: 37190, Train_acc:0.974672
Step: 37190, Val_acc:0.920249
==================>
Step: 37200, Train_acc:0.965472
Step: 37200, Val_acc:0.908893
==================>
2017-11-11 09:36:18.278436 ---> Validation_loss: 0.155669
Step: 37210, Train_acc:0.970718
Step: 37210, Val_acc:0.898628
==================>
Step: 37220, Train_acc:0.972545
Step: 37220, Val_acc:0.884717
==================>
Step: 37230, Train_acc:0.961117
Step: 37230, Val_acc:0.94048
==================>
Step: 37240, Train_acc:0.964032
Step: 37240, Val_acc:0.901802
==================>
Step: 37250, Train_acc:0.965653
Step: 37250, Val_acc:0.926194
==================>
Step: 37260, Train_acc:0.96959
Step: 37260, Val_acc:0.904257
==================>
Step: 37270, Train_acc:0.972506
Step: 37270, Val_acc:0.916802
==================>
Step: 37280, Train_acc:0.975931
Step: 37280, Val_acc:0.901344
==================>
Step: 37290, Train_acc:0.974747
Step: 37290, Val_acc:0.911234
==================>
Step: 37300, Train_acc:0.965372
Step: 37300, Val_acc:0.897505
==================>
2017-11-11 09:38:53.044041 ---> Validation_loss: 0.254554
Step: 37310, Train_acc:0.961285
Step: 37310, Val_acc:0.912283
==================>
Step: 37320, Train_acc:0.967517
Step: 37320, Val_acc:0.884669
==================>
Step: 37330, Train_acc:0.963593
Step: 37330, Val_acc:0.911235
==================>
Step: 37340, Train_acc:0.962317
Step: 37340, Val_acc:0.930934
==================>
Step: 37350, Train_acc:0.96959
Step: 37350, Val_acc:0.937539
==================>
Step: 37360, Train_acc:0.953239
Step: 37360, Val_acc:0.950745
==================>
Step: 37370, Train_acc:0.970848
Step: 37370, Val_acc:0.90694
==================>
Step: 37380, Train_acc:0.964977
Step: 37380, Val_acc:0.932042
==================>
Step: 37390, Train_acc:0.96572
Step: 37390, Val_acc:0.903501
==================>
Step: 37400, Train_acc:0.968826
Step: 37400, Val_acc:0.931322
==================>
2017-11-11 09:41:27.878573 ---> Validation_loss: 0.25237
Step: 37410, Train_acc:0.961476
Step: 37410, Val_acc:0.937521
==================>
Step: 37420, Train_acc:0.972603
Step: 37420, Val_acc:0.925514
==================>
Step: 37430, Train_acc:0.97443
Step: 37430, Val_acc:0.933693
==================>
Step: 37440, Train_acc:0.961959
Step: 37440, Val_acc:0.937141
==================>
Step: 37450, Train_acc:0.970012
Step: 37450, Val_acc:0.889414
==================>
Step: 37460, Train_acc:0.955513
Step: 37460, Val_acc:0.896013
==================>
Step: 37470, Train_acc:0.966865
Step: 37470, Val_acc:0.934656
==================>
Step: 37480, Train_acc:0.964648
Step: 37480, Val_acc:0.935366
==================>
Step: 37490, Train_acc:0.967136
Step: 37490, Val_acc:0.92504
==================>
Step: 37500, Train_acc:0.967244
Step: 37500, Val_acc:0.902898
==================>
****************** Epochs completed: 75******************
2017-11-11 09:44:02.526219 ---> Validation_loss: 0.262606
Step: 37510, Train_acc:0.966511
Step: 37510, Val_acc:0.908962
==================>
Step: 37520, Train_acc:0.964475
Step: 37520, Val_acc:0.910928
==================>
Step: 37530, Train_acc:0.97094
Step: 37530, Val_acc:0.897832
==================>
Step: 37540, Train_acc:0.956758
Step: 37540, Val_acc:0.890029
==================>
Step: 37550, Train_acc:0.971709
Step: 37550, Val_acc:0.90368
==================>
Step: 37560, Train_acc:0.967364
Step: 37560, Val_acc:0.933489
==================>
Step: 37570, Train_acc:0.970166
Step: 37570, Val_acc:0.919347
==================>
Step: 37580, Train_acc:0.966804
Step: 37580, Val_acc:0.894994
==================>
Step: 37590, Train_acc:0.96188
Step: 37590, Val_acc:0.921516
==================>
Step: 37600, Train_acc:0.9726
Step: 37600, Val_acc:0.927228
==================>
2017-11-11 09:46:37.167699 ---> Validation_loss: 0.29928
Step: 37610, Train_acc:0.965898
Step: 37610, Val_acc:0.906167
==================>
Step: 37620, Train_acc:0.971128
Step: 37620, Val_acc:0.917559
==================>
Step: 37630, Train_acc:0.963832
Step: 37630, Val_acc:0.903923
==================>
Step: 37640, Train_acc:0.961876
Step: 37640, Val_acc:0.906624
==================>
Step: 37650, Train_acc:0.964102
Step: 37650, Val_acc:0.888611
==================>
Step: 37660, Train_acc:0.963318
Step: 37660, Val_acc:0.924381
==================>
Step: 37670, Train_acc:0.962462
Step: 37670, Val_acc:0.925647
==================>
Step: 37680, Train_acc:0.967001
Step: 37680, Val_acc:0.928685
==================>
Step: 37690, Train_acc:0.972649
Step: 37690, Val_acc:0.924747
==================>
Step: 37700, Train_acc:0.968035
Step: 37700, Val_acc:0.907441
==================>
2017-11-11 09:49:11.713327 ---> Validation_loss: 0.205611
Step: 37710, Train_acc:0.976388
Step: 37710, Val_acc:0.920967
==================>
Step: 37720, Train_acc:0.972107
Step: 37720, Val_acc:0.894755
==================>
Step: 37730, Train_acc:0.968777
Step: 37730, Val_acc:0.899047
==================>
Step: 37740, Train_acc:0.971964
Step: 37740, Val_acc:0.903057
==================>
Step: 37750, Train_acc:0.969758
Step: 37750, Val_acc:0.930595
==================>
Step: 37760, Train_acc:0.974652
Step: 37760, Val_acc:0.901516
==================>
Step: 37770, Train_acc:0.968956
Step: 37770, Val_acc:0.921704
==================>
Step: 37780, Train_acc:0.976244
Step: 37780, Val_acc:0.921165
==================>
Step: 37790, Train_acc:0.973665
Step: 37790, Val_acc:0.905959
==================>
Step: 37800, Train_acc:0.963458
Step: 37800, Val_acc:0.942694
==================>
2017-11-11 09:51:47.217360 ---> Validation_loss: 0.154178
Step: 37810, Train_acc:0.967865
Step: 37810, Val_acc:0.900992
==================>
Step: 37820, Train_acc:0.973623
Step: 37820, Val_acc:0.891698
==================>
Step: 37830, Train_acc:0.974055
Step: 37830, Val_acc:0.913261
==================>
Step: 37840, Train_acc:0.965121
Step: 37840, Val_acc:0.913556
==================>
Step: 37850, Train_acc:0.964221
Step: 37850, Val_acc:0.940313
==================>
Step: 37860, Train_acc:0.965747
Step: 37860, Val_acc:0.917927
==================>
Step: 37870, Train_acc:0.973971
Step: 37870, Val_acc:0.927277
==================>
Step: 37880, Train_acc:0.972896
Step: 37880, Val_acc:0.912312
==================>
Step: 37890, Train_acc:0.961881
Step: 37890, Val_acc:0.926483
==================>
Step: 37900, Train_acc:0.970679
Step: 37900, Val_acc:0.914399
==================>
2017-11-11 09:54:23.378880 ---> Validation_loss: 0.176697
Step: 37910, Train_acc:0.962354
Step: 37910, Val_acc:0.934681
==================>
Step: 37920, Train_acc:0.963649
Step: 37920, Val_acc:0.922041
==================>
Step: 37930, Train_acc:0.979651
Step: 37930, Val_acc:0.904203
==================>
Step: 37940, Train_acc:0.953257
Step: 37940, Val_acc:0.935725
==================>
Step: 37950, Train_acc:0.966945
Step: 37950, Val_acc:0.921936
==================>
Step: 37960, Train_acc:0.965446
Step: 37960, Val_acc:0.908818
==================>
Step: 37970, Train_acc:0.984203
Step: 37970, Val_acc:0.909954
==================>
Step: 37980, Train_acc:0.96953
Step: 37980, Val_acc:0.908795
==================>
Step: 37990, Train_acc:0.977472
Step: 37990, Val_acc:0.914049
==================>
Step: 38000, Train_acc:0.965873
Step: 38000, Val_acc:0.924468
==================>
****************** Epochs completed: 76******************
2017-11-11 09:56:59.503982 ---> Validation_loss: 0.188649
Step: 38010, Train_acc:0.970638
Step: 38010, Val_acc:0.876134
==================>
Step: 38020, Train_acc:0.97072
Step: 38020, Val_acc:0.924557
==================>
Step: 38030, Train_acc:0.964688
Step: 38030, Val_acc:0.937452
==================>
Step: 38040, Train_acc:0.964084
Step: 38040, Val_acc:0.914158
==================>
Step: 38050, Train_acc:0.969929
Step: 38050, Val_acc:0.916741
==================>
Step: 38060, Train_acc:0.968634
Step: 38060, Val_acc:0.935474
==================>
Step: 38070, Train_acc:0.97288
Step: 38070, Val_acc:0.867737
==================>
Step: 38080, Train_acc:0.971362
Step: 38080, Val_acc:0.909309
==================>
Step: 38090, Train_acc:0.962703
Step: 38090, Val_acc:0.923464
==================>
Step: 38100, Train_acc:0.961958
Step: 38100, Val_acc:0.918848
==================>
2017-11-11 09:59:35.609000 ---> Validation_loss: 0.180981
Step: 38110, Train_acc:0.963306
Step: 38110, Val_acc:0.890699
==================>
Step: 38120, Train_acc:0.966542
Step: 38120, Val_acc:0.927048
==================>
Step: 38130, Train_acc:0.972137
Step: 38130, Val_acc:0.930148
==================>
Step: 38140, Train_acc:0.967244
Step: 38140, Val_acc:0.918752
==================>
Step: 38150, Train_acc:0.976746
Step: 38150, Val_acc:0.933304
==================>
Step: 38160, Train_acc:0.965435
Step: 38160, Val_acc:0.904775
==================>
Step: 38170, Train_acc:0.963247
Step: 38170, Val_acc:0.922253
==================>
Step: 38180, Train_acc:0.96978
Step: 38180, Val_acc:0.91356
==================>
Step: 38190, Train_acc:0.969543
Step: 38190, Val_acc:0.90293
==================>
Step: 38200, Train_acc:0.972772
Step: 38200, Val_acc:0.915455
==================>
2017-11-11 10:02:11.872704 ---> Validation_loss: 0.243067
Step: 38210, Train_acc:0.96194
Step: 38210, Val_acc:0.875061
==================>
Step: 38220, Train_acc:0.961218
Step: 38220, Val_acc:0.895593
==================>
Step: 38230, Train_acc:0.96152
Step: 38230, Val_acc:0.891395
==================>
Step: 38240, Train_acc:0.977675
Step: 38240, Val_acc:0.865009
==================>
Step: 38250, Train_acc:0.972999
Step: 38250, Val_acc:0.915972
==================>
Step: 38260, Train_acc:0.971188
Step: 38260, Val_acc:0.903977
==================>
Step: 38270, Train_acc:0.959529
Step: 38270, Val_acc:0.931156
==================>
Step: 38280, Train_acc:0.973457
Step: 38280, Val_acc:0.893639
==================>
Step: 38290, Train_acc:0.961443
Step: 38290, Val_acc:0.939886
==================>
Step: 38300, Train_acc:0.968776
Step: 38300, Val_acc:0.920582
==================>
2017-11-11 10:04:47.883664 ---> Validation_loss: 0.21817
Step: 38310, Train_acc:0.966755
Step: 38310, Val_acc:0.921095
==================>
Step: 38320, Train_acc:0.973903
Step: 38320, Val_acc:0.891804
==================>
Step: 38330, Train_acc:0.967585
Step: 38330, Val_acc:0.910077
==================>
Step: 38340, Train_acc:0.957753
Step: 38340, Val_acc:0.910222
==================>
Step: 38350, Train_acc:0.966378
Step: 38350, Val_acc:0.901896
==================>
Step: 38360, Train_acc:0.957382
Step: 38360, Val_acc:0.917544
==================>
Step: 38370, Train_acc:0.970771
Step: 38370, Val_acc:0.912581
==================>
Step: 38380, Train_acc:0.973389
Step: 38380, Val_acc:0.896312
==================>
Step: 38390, Train_acc:0.964878
Step: 38390, Val_acc:0.875909
==================>
Step: 38400, Train_acc:0.970909
Step: 38400, Val_acc:0.9139
==================>
2017-11-11 10:07:23.909372 ---> Validation_loss: 0.203622
Step: 38410, Train_acc:0.971631
Step: 38410, Val_acc:0.927782
==================>
Step: 38420, Train_acc:0.969607
Step: 38420, Val_acc:0.913109
==================>
Step: 38430, Train_acc:0.969956
Step: 38430, Val_acc:0.88979
==================>
Step: 38440, Train_acc:0.964183
Step: 38440, Val_acc:0.911442
==================>
Step: 38450, Train_acc:0.967435
Step: 38450, Val_acc:0.907944
==================>
Step: 38460, Train_acc:0.974052
Step: 38460, Val_acc:0.892092
==================>
Step: 38470, Train_acc:0.9724
Step: 38470, Val_acc:0.912082
==================>
Step: 38480, Train_acc:0.973555
Step: 38480, Val_acc:0.938845
==================>
Step: 38490, Train_acc:0.969703
Step: 38490, Val_acc:0.911251
==================>
Step: 38500, Train_acc:0.960426
Step: 38500, Val_acc:0.910929
==================>
****************** Epochs completed: 77******************
2017-11-11 10:09:59.803757 ---> Validation_loss: 0.216625
Step: 38510, Train_acc:0.969971
Step: 38510, Val_acc:0.906387
==================>
Step: 38520, Train_acc:0.975568
Step: 38520, Val_acc:0.936478
==================>
Step: 38530, Train_acc:0.959181
Step: 38530, Val_acc:0.910791
==================>
Step: 38540, Train_acc:0.972267
Step: 38540, Val_acc:0.915499
==================>
Step: 38550, Train_acc:0.969749
Step: 38550, Val_acc:0.918571
==================>
Step: 38560, Train_acc:0.97234
Step: 38560, Val_acc:0.907878
==================>
Step: 38570, Train_acc:0.967655
Step: 38570, Val_acc:0.882383
==================>
Step: 38580, Train_acc:0.977831
Step: 38580, Val_acc:0.903895
==================>
Step: 38590, Train_acc:0.969574
Step: 38590, Val_acc:0.901749
==================>
Step: 38600, Train_acc:0.960905
Step: 38600, Val_acc:0.910793
==================>
2017-11-11 10:12:35.688601 ---> Validation_loss: 0.197978
Step: 38610, Train_acc:0.964911
Step: 38610, Val_acc:0.932174
==================>
Step: 38620, Train_acc:0.974261
Step: 38620, Val_acc:0.939392
==================>
Step: 38630, Train_acc:0.967856
Step: 38630, Val_acc:0.914897
==================>
Step: 38640, Train_acc:0.968713
Step: 38640, Val_acc:0.927946
==================>
Step: 38650, Train_acc:0.970979
Step: 38650, Val_acc:0.888219
==================>
Step: 38660, Train_acc:0.971624
Step: 38660, Val_acc:0.936487
==================>
Step: 38670, Train_acc:0.963357
Step: 38670, Val_acc:0.940797
==================>
Step: 38680, Train_acc:0.963949
Step: 38680, Val_acc:0.929314
==================>
Step: 38690, Train_acc:0.959769
Step: 38690, Val_acc:0.913846
==================>
Step: 38700, Train_acc:0.969202
Step: 38700, Val_acc:0.912959
==================>
2017-11-11 10:15:10.273974 ---> Validation_loss: 0.230796
Step: 38710, Train_acc:0.974663
Step: 38710, Val_acc:0.921185
==================>
Step: 38720, Train_acc:0.974302
Step: 38720, Val_acc:0.921697
==================>
Step: 38730, Train_acc:0.972067
Step: 38730, Val_acc:0.942681
==================>
Step: 38740, Train_acc:0.949418
Step: 38740, Val_acc:0.918176
==================>
Step: 38750, Train_acc:0.968164
Step: 38750, Val_acc:0.943921
==================>
Step: 38760, Train_acc:0.970032
Step: 38760, Val_acc:0.897954
==================>
Step: 38770, Train_acc:0.957921
Step: 38770, Val_acc:0.872292
==================>
Step: 38780, Train_acc:0.967614
Step: 38780, Val_acc:0.914829
==================>
Step: 38790, Train_acc:0.954866
Step: 38790, Val_acc:0.926537
==================>
Step: 38800, Train_acc:0.971115
Step: 38800, Val_acc:0.926243
==================>
2017-11-11 10:17:45.329664 ---> Validation_loss: 0.234203
Step: 38810, Train_acc:0.963899
Step: 38810, Val_acc:0.902424
==================>
Step: 38820, Train_acc:0.970956
Step: 38820, Val_acc:0.898243
==================>
Step: 38830, Train_acc:0.973359
Step: 38830, Val_acc:0.9159
==================>
Step: 38840, Train_acc:0.973287
Step: 38840, Val_acc:0.917366
==================>
Step: 38850, Train_acc:0.966188
Step: 38850, Val_acc:0.933788
==================>
Step: 38860, Train_acc:0.966074
Step: 38860, Val_acc:0.919526
==================>
Step: 38870, Train_acc:0.960807
Step: 38870, Val_acc:0.917413
==================>
Step: 38880, Train_acc:0.966818
Step: 38880, Val_acc:0.920778
==================>
Step: 38890, Train_acc:0.961184
Step: 38890, Val_acc:0.925619
==================>
Step: 38900, Train_acc:0.967158
Step: 38900, Val_acc:0.891126
==================>
2017-11-11 10:20:21.256626 ---> Validation_loss: 0.206461
Step: 38910, Train_acc:0.963787
Step: 38910, Val_acc:0.896233
==================>
Step: 38920, Train_acc:0.966271
Step: 38920, Val_acc:0.880084
==================>
Step: 38930, Train_acc:0.96493
Step: 38930, Val_acc:0.897954
==================>
Step: 38940, Train_acc:0.962526
Step: 38940, Val_acc:0.890115
==================>
Step: 38950, Train_acc:0.961072
Step: 38950, Val_acc:0.906859
==================>
Step: 38960, Train_acc:0.967628
Step: 38960, Val_acc:0.931257
==================>
Step: 38970, Train_acc:0.970563
Step: 38970, Val_acc:0.881141
==================>
Step: 38980, Train_acc:0.97556
Step: 38980, Val_acc:0.919178
==================>
Step: 38990, Train_acc:0.966632
Step: 38990, Val_acc:0.92123
==================>
Step: 39000, Train_acc:0.970798
Step: 39000, Val_acc:0.911943
==================>
****************** Epochs completed: 78******************
2017-11-11 10:22:57.555314 ---> Validation_loss: 0.158338
Step: 39010, Train_acc:0.965359
Step: 39010, Val_acc:0.929576
==================>
Step: 39020, Train_acc:0.965646
Step: 39020, Val_acc:0.931084
==================>
Step: 39030, Train_acc:0.956056
Step: 39030, Val_acc:0.915518
==================>
Step: 39040, Train_acc:0.966971
Step: 39040, Val_acc:0.913772
==================>
Step: 39050, Train_acc:0.961266
Step: 39050, Val_acc:0.915489
==================>
Step: 39060, Train_acc:0.971599
Step: 39060, Val_acc:0.919288
==================>
Step: 39070, Train_acc:0.972894
Step: 39070, Val_acc:0.882538
==================>
Step: 39080, Train_acc:0.968992
Step: 39080, Val_acc:0.917363
==================>
Step: 39090, Train_acc:0.96192
Step: 39090, Val_acc:0.912733
==================>
Step: 39100, Train_acc:0.960859
Step: 39100, Val_acc:0.910902
==================>
2017-11-11 10:25:33.783631 ---> Validation_loss: 0.177548
Step: 39110, Train_acc:0.96703
Step: 39110, Val_acc:0.938373
==================>
Step: 39120, Train_acc:0.966345
Step: 39120, Val_acc:0.908402
==================>
Step: 39130, Train_acc:0.968134
Step: 39130, Val_acc:0.894135
==================>
Step: 39140, Train_acc:0.97437
Step: 39140, Val_acc:0.922638
==================>
Step: 39150, Train_acc:0.971577
Step: 39150, Val_acc:0.898438
==================>
Step: 39160, Train_acc:0.967946
Step: 39160, Val_acc:0.924581
==================>
Step: 39170, Train_acc:0.961681
Step: 39170, Val_acc:0.927261
==================>
Step: 39180, Train_acc:0.960465
Step: 39180, Val_acc:0.93571
==================>
Step: 39190, Train_acc:0.968125
Step: 39190, Val_acc:0.893862
==================>
Step: 39200, Train_acc:0.962207
Step: 39200, Val_acc:0.926306
==================>
2017-11-11 10:28:09.379743 ---> Validation_loss: 0.330121
Step: 39210, Train_acc:0.960139
Step: 39210, Val_acc:0.910548
==================>
Step: 39220, Train_acc:0.970817
Step: 39220, Val_acc:0.880391
==================>
Step: 39230, Train_acc:0.966055
Step: 39230, Val_acc:0.879196
==================>
Step: 39240, Train_acc:0.959288
Step: 39240, Val_acc:0.933717
==================>
Step: 39250, Train_acc:0.965481
Step: 39250, Val_acc:0.919352
==================>
Step: 39260, Train_acc:0.974913
Step: 39260, Val_acc:0.93064
==================>
Step: 39270, Train_acc:0.974631
Step: 39270, Val_acc:0.914581
==================>
Step: 39280, Train_acc:0.969014
Step: 39280, Val_acc:0.915574
==================>
Step: 39290, Train_acc:0.975721
Step: 39290, Val_acc:0.908943
==================>
Step: 39300, Train_acc:0.964839
Step: 39300, Val_acc:0.927727
==================>
2017-11-11 10:30:44.824815 ---> Validation_loss: 0.209671
Step: 39310, Train_acc:0.96386
Step: 39310, Val_acc:0.925212
==================>
Step: 39320, Train_acc:0.969889
Step: 39320, Val_acc:0.931693
==================>
Step: 39330, Train_acc:0.969406
Step: 39330, Val_acc:0.922942
==================>
Step: 39340, Train_acc:0.967795
Step: 39340, Val_acc:0.89406
==================>
Step: 39350, Train_acc:0.968799
Step: 39350, Val_acc:0.937778
==================>
Step: 39360, Train_acc:0.975398
Step: 39360, Val_acc:0.919341
==================>
Step: 39370, Train_acc:0.975085
Step: 39370, Val_acc:0.920419
==================>
Step: 39380, Train_acc:0.976007
Step: 39380, Val_acc:0.899875
==================>
Step: 39390, Train_acc:0.96152
Step: 39390, Val_acc:0.911953
==================>
Step: 39400, Train_acc:0.959824
Step: 39400, Val_acc:0.920038
==================>
2017-11-11 10:33:20.305773 ---> Validation_loss: 0.188282
Step: 39410, Train_acc:0.956571
Step: 39410, Val_acc:0.907732
==================>
Step: 39420, Train_acc:0.970242
Step: 39420, Val_acc:0.914073
==================>
Step: 39430, Train_acc:0.962421
Step: 39430, Val_acc:0.914613
==================>
Step: 39440, Train_acc:0.971146
Step: 39440, Val_acc:0.902255
==================>
Step: 39450, Train_acc:0.960105
Step: 39450, Val_acc:0.912781
==================>
Step: 39460, Train_acc:0.975297
Step: 39460, Val_acc:0.920619
==================>
Step: 39470, Train_acc:0.974974
Step: 39470, Val_acc:0.916814
==================>
Step: 39480, Train_acc:0.963044
Step: 39480, Val_acc:0.908939
==================>
Step: 39490, Train_acc:0.961925
Step: 39490, Val_acc:0.904641
==================>
Step: 39500, Train_acc:0.967596
Step: 39500, Val_acc:0.905315
==================>
****************** Epochs completed: 79******************
2017-11-11 10:35:56.362989 ---> Validation_loss: 0.21579
Step: 39510, Train_acc:0.975647
Step: 39510, Val_acc:0.891246
==================>
Step: 39520, Train_acc:0.964962
Step: 39520, Val_acc:0.916466
==================>
Step: 39530, Train_acc:0.976565
Step: 39530, Val_acc:0.920886
==================>
Step: 39540, Train_acc:0.962915
Step: 39540, Val_acc:0.90452
==================>
Step: 39550, Train_acc:0.956503
Step: 39550, Val_acc:0.925818
==================>
Step: 39560, Train_acc:0.960175
Step: 39560, Val_acc:0.93441
==================>
Step: 39570, Train_acc:0.951671
Step: 39570, Val_acc:0.922444
==================>
Step: 39580, Train_acc:0.973191
Step: 39580, Val_acc:0.891984
==================>
Step: 39590, Train_acc:0.974662
Step: 39590, Val_acc:0.921398
==================>
Step: 39600, Train_acc:0.961764
Step: 39600, Val_acc:0.935229
==================>
2017-11-11 10:38:31.990464 ---> Validation_loss: 0.219693
Step: 39610, Train_acc:0.959092
Step: 39610, Val_acc:0.899436
==================>
Step: 39620, Train_acc:0.973124
Step: 39620, Val_acc:0.94647
==================>
Step: 39630, Train_acc:0.9759
Step: 39630, Val_acc:0.918596
==================>
Step: 39640, Train_acc:0.965614
Step: 39640, Val_acc:0.912948
==================>
Step: 39650, Train_acc:0.97304
Step: 39650, Val_acc:0.907373
==================>
Step: 39660, Train_acc:0.964788
Step: 39660, Val_acc:0.930723
==================>
Step: 39670, Train_acc:0.960895
Step: 39670, Val_acc:0.896886
==================>
Step: 39680, Train_acc:0.965175
Step: 39680, Val_acc:0.931058
==================>
Step: 39690, Train_acc:0.965074
Step: 39690, Val_acc:0.921919
==================>
Step: 39700, Train_acc:0.965292
Step: 39700, Val_acc:0.928517
==================>
2017-11-11 10:41:07.773551 ---> Validation_loss: 0.224896
Step: 39710, Train_acc:0.964819
Step: 39710, Val_acc:0.905585
==================>
Step: 39720, Train_acc:0.966907
Step: 39720, Val_acc:0.884469
==================>
Step: 39730, Train_acc:0.956143
Step: 39730, Val_acc:0.901831
==================>
Step: 39740, Train_acc:0.965046
Step: 39740, Val_acc:0.891475
==================>
Step: 39750, Train_acc:0.960393
Step: 39750, Val_acc:0.897572
==================>
Step: 39760, Train_acc:0.972059
Step: 39760, Val_acc:0.941923
==================>
Step: 39770, Train_acc:0.958669
Step: 39770, Val_acc:0.929507
==================>
Step: 39780, Train_acc:0.973192
Step: 39780, Val_acc:0.88658
==================>
Step: 39790, Train_acc:0.97079
Step: 39790, Val_acc:0.886763
==================>
Step: 39800, Train_acc:0.963416
Step: 39800, Val_acc:0.939652
==================>
2017-11-11 10:43:43.627256 ---> Validation_loss: 0.0956006
Step: 39810, Train_acc:0.963887
Step: 39810, Val_acc:0.914204
==================>
Step: 39820, Train_acc:0.962264
Step: 39820, Val_acc:0.928317
==================>
Step: 39830, Train_acc:0.971804
Step: 39830, Val_acc:0.940283
==================>
Step: 39840, Train_acc:0.972383
Step: 39840, Val_acc:0.91085
==================>
Step: 39850, Train_acc:0.969269
Step: 39850, Val_acc:0.933054
==================>
Step: 39860, Train_acc:0.974526
Step: 39860, Val_acc:0.901433
==================>
Step: 39870, Train_acc:0.96421
Step: 39870, Val_acc:0.911025
==================>
Step: 39880, Train_acc:0.968219
Step: 39880, Val_acc:0.886229
==================>
Step: 39890, Train_acc:0.965637
Step: 39890, Val_acc:0.940991
==================>
Step: 39900, Train_acc:0.964192
Step: 39900, Val_acc:0.885881
==================>
2017-11-11 10:46:19.130249 ---> Validation_loss: 0.233915
Step: 39910, Train_acc:0.969614
Step: 39910, Val_acc:0.90959
==================>
Step: 39920, Train_acc:0.970995
Step: 39920, Val_acc:0.939823
==================>
Step: 39930, Train_acc:0.978717
Step: 39930, Val_acc:0.907291
==================>
Step: 39940, Train_acc:0.968433
Step: 39940, Val_acc:0.925753
==================>
Step: 39950, Train_acc:0.962877
Step: 39950, Val_acc:0.900439
==================>
Step: 39960, Train_acc:0.976387
Step: 39960, Val_acc:0.922844
==================>
Step: 39970, Train_acc:0.97345
Step: 39970, Val_acc:0.909337
==================>
Step: 39980, Train_acc:0.974266
Step: 39980, Val_acc:0.928466
==================>
Step: 39990, Train_acc:0.964224
Step: 39990, Val_acc:0.930435
==================>
Step: 40000, Train_acc:0.974327
Step: 40000, Val_acc:0.919318
==================>
****************** Epochs completed: 80******************
2017-11-11 10:48:55.064406 ---> Validation_loss: 0.178073
Step: 40010, Train_acc:0.956873
Step: 40010, Val_acc:0.909386
==================>
Step: 40020, Train_acc:0.965289
Step: 40020, Val_acc:0.942502
==================>
Step: 40030, Train_acc:0.964147
Step: 40030, Val_acc:0.912939
==================>
Step: 40040, Train_acc:0.960852
Step: 40040, Val_acc:0.921626
==================>
Step: 40050, Train_acc:0.967922
Step: 40050, Val_acc:0.889795
==================>
Step: 40060, Train_acc:0.981003
Step: 40060, Val_acc:0.917338
==================>
Step: 40070, Train_acc:0.96577
Step: 40070, Val_acc:0.919774
==================>
Step: 40080, Train_acc:0.969447
Step: 40080, Val_acc:0.928428
==================>
Step: 40090, Train_acc:0.970123
Step: 40090, Val_acc:0.930142
==================>
Step: 40100, Train_acc:0.972412
Step: 40100, Val_acc:0.888989
==================>
2017-11-11 10:51:31.013398 ---> Validation_loss: 0.177835
Step: 40110, Train_acc:0.97192
Step: 40110, Val_acc:0.954551
==================>
Step: 40120, Train_acc:0.97082
Step: 40120, Val_acc:0.921866
==================>
Step: 40130, Train_acc:0.968649
Step: 40130, Val_acc:0.909213
==================>
Step: 40140, Train_acc:0.95797
Step: 40140, Val_acc:0.965277
==================>
Step: 40150, Train_acc:0.971184
Step: 40150, Val_acc:0.945402
==================>
Step: 40160, Train_acc:0.972987
Step: 40160, Val_acc:0.911428
==================>
Step: 40170, Train_acc:0.972133
Step: 40170, Val_acc:0.938398
==================>
Step: 40180, Train_acc:0.960654
Step: 40180, Val_acc:0.912351
==================>
Step: 40190, Train_acc:0.97179
Step: 40190, Val_acc:0.910439
==================>
Step: 40200, Train_acc:0.978413
Step: 40200, Val_acc:0.926779
==================>
2017-11-11 10:54:06.757391 ---> Validation_loss: 0.278967
Step: 40210, Train_acc:0.968811
Step: 40210, Val_acc:0.918365
==================>
Step: 40220, Train_acc:0.974192
Step: 40220, Val_acc:0.922351
==================>
Step: 40230, Train_acc:0.958435
Step: 40230, Val_acc:0.914537
==================>
Step: 40240, Train_acc:0.961959
Step: 40240, Val_acc:0.903962
==================>
Step: 40250, Train_acc:0.960615
Step: 40250, Val_acc:0.927728
==================>
Step: 40260, Train_acc:0.962489
Step: 40260, Val_acc:0.901769
==================>
Step: 40270, Train_acc:0.962417
Step: 40270, Val_acc:0.921091
==================>
Step: 40280, Train_acc:0.966992
Step: 40280, Val_acc:0.937485
==================>
Step: 40290, Train_acc:0.97854
Step: 40290, Val_acc:0.934215
==================>
Step: 40300, Train_acc:0.975382
Step: 40300, Val_acc:0.919539
==================>
2017-11-11 10:56:42.832114 ---> Validation_loss: 0.151054
Step: 40310, Train_acc:0.961674
Step: 40310, Val_acc:0.910839
==================>
Step: 40320, Train_acc:0.965842
Step: 40320, Val_acc:0.92298
==================>
Step: 40330, Train_acc:0.959767
Step: 40330, Val_acc:0.893052
==================>
Step: 40340, Train_acc:0.960426
Step: 40340, Val_acc:0.898969
==================>
Step: 40350, Train_acc:0.965051
Step: 40350, Val_acc:0.933743
==================>
Step: 40360, Train_acc:0.966741
Step: 40360, Val_acc:0.909229
==================>
****************** Epochs completed: 12******************
Step: 40370, Train_acc:0.960687
Step: 40370, Val_acc:0.900569
==================>
Step: 40380, Train_acc:0.978754
Step: 40380, Val_acc:0.955798
==================>
Step: 40390, Train_acc:0.967806
Step: 40390, Val_acc:0.8922
==================>
Step: 40400, Train_acc:0.966993
Step: 40400, Val_acc:0.913126
==================>
2017-11-11 10:59:18.650287 ---> Validation_loss: 0.162381
Step: 40410, Train_acc:0.968552
Step: 40410, Val_acc:0.92618
==================>
Step: 40420, Train_acc:0.962946
Step: 40420, Val_acc:0.8863
==================>
Step: 40430, Train_acc:0.978213
Step: 40430, Val_acc:0.929436
==================>
Step: 40440, Train_acc:0.972585
Step: 40440, Val_acc:0.925834
==================>
Step: 40450, Train_acc:0.962758
Step: 40450, Val_acc:0.920168
==================>
Step: 40460, Train_acc:0.967361
Step: 40460, Val_acc:0.90371
==================>
Step: 40470, Train_acc:0.974813
Step: 40470, Val_acc:0.950394
==================>
Step: 40480, Train_acc:0.97562
Step: 40480, Val_acc:0.941256
==================>
Step: 40490, Train_acc:0.96859
Step: 40490, Val_acc:0.869952
==================>
Step: 40500, Train_acc:0.972339
Step: 40500, Val_acc:0.926287
==================>
****************** Epochs completed: 81******************
2017-11-11 11:01:54.973500 ---> Validation_loss: 0.207131
Step: 40510, Train_acc:0.970631
Step: 40510, Val_acc:0.917875
==================>
Step: 40520, Train_acc:0.976346
Step: 40520, Val_acc:0.926747
==================>
Step: 40530, Train_acc:0.965751
Step: 40530, Val_acc:0.932657
==================>
Step: 40540, Train_acc:0.968429
Step: 40540, Val_acc:0.935153
==================>
Step: 40550, Train_acc:0.962858
Step: 40550, Val_acc:0.912152
==================>
Step: 40560, Train_acc:0.98045
Step: 40560, Val_acc:0.915333
==================>
Step: 40570, Train_acc:0.970077
Step: 40570, Val_acc:0.928469
==================>
Step: 40580, Train_acc:0.961367
Step: 40580, Val_acc:0.918409
==================>
Step: 40590, Train_acc:0.972621
Step: 40590, Val_acc:0.932223
==================>
Step: 40600, Train_acc:0.954449
Step: 40600, Val_acc:0.912156
==================>
2017-11-11 11:04:31.264550 ---> Validation_loss: 0.153587
Step: 40610, Train_acc:0.968063
Step: 40610, Val_acc:0.920085
==================>
Step: 40620, Train_acc:0.972994
Step: 40620, Val_acc:0.926864
==================>
Step: 40630, Train_acc:0.982144
Step: 40630, Val_acc:0.936761
==================>
Step: 40640, Train_acc:0.971173
Step: 40640, Val_acc:0.92269
==================>
Step: 40650, Train_acc:0.971061
Step: 40650, Val_acc:0.937759
==================>
Step: 40660, Train_acc:0.971873
Step: 40660, Val_acc:0.952648
==================>
Step: 40670, Train_acc:0.972234
Step: 40670, Val_acc:0.913165
==================>
Step: 40680, Train_acc:0.964547
Step: 40680, Val_acc:0.91957
==================>
Step: 40690, Train_acc:0.964491
Step: 40690, Val_acc:0.934071
==================>
Step: 40700, Train_acc:0.969167
Step: 40700, Val_acc:0.914386
==================>
2017-11-11 11:07:07.260006 ---> Validation_loss: 0.200531
Step: 40710, Train_acc:0.975968
Step: 40710, Val_acc:0.950143
==================>
Step: 40720, Train_acc:0.965854
Step: 40720, Val_acc:0.898737
==================>
Step: 40730, Train_acc:0.969437
Step: 40730, Val_acc:0.901603
==================>
Step: 40740, Train_acc:0.975715
Step: 40740, Val_acc:0.91189
==================>
Step: 40750, Train_acc:0.964668
Step: 40750, Val_acc:0.935653
==================>
Step: 40760, Train_acc:0.970936
Step: 40760, Val_acc:0.922494
==================>
Step: 40770, Train_acc:0.970931
Step: 40770, Val_acc:0.919716
==================>
Step: 40780, Train_acc:0.967902
Step: 40780, Val_acc:0.935299
==================>
Step: 40790, Train_acc:0.960916
Step: 40790, Val_acc:0.906721
==================>
Step: 40800, Train_acc:0.974692
Step: 40800, Val_acc:0.93554
==================>
2017-11-11 11:09:43.417832 ---> Validation_loss: 0.209507
Step: 40810, Train_acc:0.975414
Step: 40810, Val_acc:0.917781
==================>
Step: 40820, Train_acc:0.9689
Step: 40820, Val_acc:0.931119
==================>
Step: 40830, Train_acc:0.975726
Step: 40830, Val_acc:0.940039
==================>
Step: 40840, Train_acc:0.968821
Step: 40840, Val_acc:0.898834
==================>
Step: 40850, Train_acc:0.971003
Step: 40850, Val_acc:0.88262
==================>
Step: 40860, Train_acc:0.974094
Step: 40860, Val_acc:0.913287
==================>
Step: 40870, Train_acc:0.977566
Step: 40870, Val_acc:0.907015
==================>
Step: 40880, Train_acc:0.973491
Step: 40880, Val_acc:0.89947
==================>
Step: 40890, Train_acc:0.958357
Step: 40890, Val_acc:0.927419
==================>
Step: 40900, Train_acc:0.975032
Step: 40900, Val_acc:0.908284
==================>
2017-11-11 11:12:19.359355 ---> Validation_loss: 0.161507
Step: 40910, Train_acc:0.963195
Step: 40910, Val_acc:0.892378
==================>
Step: 40920, Train_acc:0.965597
Step: 40920, Val_acc:0.925206
==================>
Step: 40930, Train_acc:0.973127
Step: 40930, Val_acc:0.907344
==================>
Step: 40940, Train_acc:0.964064
Step: 40940, Val_acc:0.917875
==================>
Step: 40950, Train_acc:0.982576
Step: 40950, Val_acc:0.943491
==================>
Step: 40960, Train_acc:0.969805
Step: 40960, Val_acc:0.937307
==================>
Step: 40970, Train_acc:0.973647
Step: 40970, Val_acc:0.926357
==================>
Step: 40980, Train_acc:0.960759
Step: 40980, Val_acc:0.932163
==================>
Step: 40990, Train_acc:0.975945
Step: 40990, Val_acc:0.872711
==================>
Step: 41000, Train_acc:0.968435
Step: 41000, Val_acc:0.908652
==================>
****************** Epochs completed: 82******************
2017-11-11 11:14:55.701731 ---> Validation_loss: 0.154743
Step: 41010, Train_acc:0.970255
Step: 41010, Val_acc:0.922371
==================>
Step: 41020, Train_acc:0.965663
Step: 41020, Val_acc:0.926934
==================>
Step: 41030, Train_acc:0.954805
Step: 41030, Val_acc:0.948096
==================>
Step: 41040, Train_acc:0.967273
Step: 41040, Val_acc:0.909188
==================>
Step: 41050, Train_acc:0.969467
Step: 41050, Val_acc:0.885592
==================>
Step: 41060, Train_acc:0.972828
Step: 41060, Val_acc:0.917611
==================>
Step: 41070, Train_acc:0.981274
Step: 41070, Val_acc:0.931754
==================>
Step: 41080, Train_acc:0.969257
Step: 41080, Val_acc:0.931384
==================>
Step: 41090, Train_acc:0.965082
Step: 41090, Val_acc:0.901213
==================>
Step: 41100, Train_acc:0.970255
Step: 41100, Val_acc:0.933733
==================>
2017-11-11 11:17:31.963605 ---> Validation_loss: 0.209596
Step: 41110, Train_acc:0.965137
Step: 41110, Val_acc:0.957299
==================>
Step: 41120, Train_acc:0.967662
Step: 41120, Val_acc:0.918556
==================>
Step: 41130, Train_acc:0.981157
Step: 41130, Val_acc:0.916742
==================>
Step: 41140, Train_acc:0.981658
Step: 41140, Val_acc:0.920789
==================>
Step: 41150, Train_acc:0.97007
Step: 41150, Val_acc:0.931566
==================>
Step: 41160, Train_acc:0.968246
Step: 41160, Val_acc:0.923983
==================>
Step: 41170, Train_acc:0.9695
Step: 41170, Val_acc:0.916405
==================>
Step: 41180, Train_acc:0.958862
Step: 41180, Val_acc:0.924573
==================>
Step: 41190, Train_acc:0.971477
Step: 41190, Val_acc:0.907876
==================>
Step: 41200, Train_acc:0.962345
Step: 41200, Val_acc:0.919659
==================>
2017-11-11 11:20:08.690981 ---> Validation_loss: 0.201227
Step: 41210, Train_acc:0.977183
Step: 41210, Val_acc:0.937286
==================>
Step: 41220, Train_acc:0.965802
Step: 41220, Val_acc:0.945062
==================>
Step: 41230, Train_acc:0.96559
Step: 41230, Val_acc:0.922998
==================>
Step: 41240, Train_acc:0.956583
Step: 41240, Val_acc:0.914033
==================>
Step: 41250, Train_acc:0.961177
Step: 41250, Val_acc:0.945366
==================>
Step: 41260, Train_acc:0.97925
Step: 41260, Val_acc:0.910201
==================>
Step: 41270, Train_acc:0.966638
Step: 41270, Val_acc:0.942936
==================>
Step: 41280, Train_acc:0.967499
Step: 41280, Val_acc:0.932679
==================>
Step: 41290, Train_acc:0.963644
Step: 41290, Val_acc:0.950653
==================>
Step: 41300, Train_acc:0.971449
Step: 41300, Val_acc:0.913954
==================>
2017-11-11 11:22:45.007302 ---> Validation_loss: 0.167049
Step: 41310, Train_acc:0.970074
Step: 41310, Val_acc:0.898918
==================>
Step: 41320, Train_acc:0.973064
Step: 41320, Val_acc:0.919225
==================>
Step: 41330, Train_acc:0.956749
Step: 41330, Val_acc:0.899951
==================>
Step: 41340, Train_acc:0.965762
Step: 41340, Val_acc:0.923291
==================>
Step: 41350, Train_acc:0.984335
Step: 41350, Val_acc:0.943125
==================>
Step: 41360, Train_acc:0.975188
Step: 41360, Val_acc:0.900095
==================>
Step: 41370, Train_acc:0.961648
Step: 41370, Val_acc:0.95848
==================>
Step: 41380, Train_acc:0.972472
Step: 41380, Val_acc:0.951375
==================>
Step: 41390, Train_acc:0.966498
Step: 41390, Val_acc:0.915588
==================>
Step: 41400, Train_acc:0.970179
Step: 41400, Val_acc:0.925801
==================>
2017-11-11 11:25:21.148932 ---> Validation_loss: 0.266502
Step: 41410, Train_acc:0.974683
Step: 41410, Val_acc:0.915515
==================>
Step: 41420, Train_acc:0.949219
Step: 41420, Val_acc:0.909357
==================>
Step: 41430, Train_acc:0.969691
Step: 41430, Val_acc:0.888162
==================>
Step: 41440, Train_acc:0.968261
Step: 41440, Val_acc:0.93675
==================>
Step: 41450, Train_acc:0.978678
Step: 41450, Val_acc:0.939076
==================>
Step: 41460, Train_acc:0.959564
Step: 41460, Val_acc:0.94182
==================>
Step: 41470, Train_acc:0.975345
Step: 41470, Val_acc:0.918088
==================>
Step: 41480, Train_acc:0.968574
Step: 41480, Val_acc:0.929282
==================>
Step: 41490, Train_acc:0.962954
Step: 41490, Val_acc:0.928751
==================>
Step: 41500, Train_acc:0.971509
Step: 41500, Val_acc:0.938209
==================>
****************** Epochs completed: 83******************
2017-11-11 11:27:57.436014 ---> Validation_loss: 0.216775
Step: 41510, Train_acc:0.976813
Step: 41510, Val_acc:0.927064
==================>
Step: 41520, Train_acc:0.967428
Step: 41520, Val_acc:0.910507
==================>
Step: 41530, Train_acc:0.975969
Step: 41530, Val_acc:0.888198
==================>
Step: 41540, Train_acc:0.958829
Step: 41540, Val_acc:0.936847
==================>
Step: 41550, Train_acc:0.973925
Step: 41550, Val_acc:0.933754
==================>
Step: 41560, Train_acc:0.977552
Step: 41560, Val_acc:0.911725
==================>
Step: 41570, Train_acc:0.967473
Step: 41570, Val_acc:0.921754
==================>
Step: 41580, Train_acc:0.967407
Step: 41580, Val_acc:0.904797
==================>
Step: 41590, Train_acc:0.971305
Step: 41590, Val_acc:0.921196
==================>
Step: 41600, Train_acc:0.971786
Step: 41600, Val_acc:0.909648
==================>
2017-11-11 11:30:34.262495 ---> Validation_loss: 0.176628
Step: 41610, Train_acc:0.964646
Step: 41610, Val_acc:0.932895
==================>
Step: 41620, Train_acc:0.967577
Step: 41620, Val_acc:0.912852
==================>
Step: 41630, Train_acc:0.972736
Step: 41630, Val_acc:0.910519
==================>
Step: 41640, Train_acc:0.976752
Step: 41640, Val_acc:0.912925
==================>
Step: 41650, Train_acc:0.969269
Step: 41650, Val_acc:0.883738
==================>
Step: 41660, Train_acc:0.966949
Step: 41660, Val_acc:0.910649
==================>
Step: 41670, Train_acc:0.973085
Step: 41670, Val_acc:0.932732
==================>
Step: 41680, Train_acc:0.963079
Step: 41680, Val_acc:0.922826
==================>
Step: 41690, Train_acc:0.972804
Step: 41690, Val_acc:0.917462
==================>
Step: 41700, Train_acc:0.962975
Step: 41700, Val_acc:0.929366
==================>
2017-11-11 11:33:10.445667 ---> Validation_loss: 0.174678
Step: 41710, Train_acc:0.958263
Step: 41710, Val_acc:0.915627
==================>
Step: 41720, Train_acc:0.972139
Step: 41720, Val_acc:0.903458
==================>
Step: 41730, Train_acc:0.976185
Step: 41730, Val_acc:0.925143
==================>
Step: 41740, Train_acc:0.967631
Step: 41740, Val_acc:0.942179
==================>
Step: 41750, Train_acc:0.966055
Step: 41750, Val_acc:0.91627
==================>
Step: 41760, Train_acc:0.961047
Step: 41760, Val_acc:0.922023
==================>
Step: 41770, Train_acc:0.969876
Step: 41770, Val_acc:0.917719
==================>
Step: 41780, Train_acc:0.975718
Step: 41780, Val_acc:0.906218
==================>
Step: 41790, Train_acc:0.974525
Step: 41790, Val_acc:0.922645
==================>
Step: 41800, Train_acc:0.978423
Step: 41800, Val_acc:0.891935
==================>
2017-11-11 11:35:46.603010 ---> Validation_loss: 0.246123
Step: 41810, Train_acc:0.972292
Step: 41810, Val_acc:0.907058
==================>
Step: 41820, Train_acc:0.974415
Step: 41820, Val_acc:0.923123
==================>
Step: 41830, Train_acc:0.968234
Step: 41830, Val_acc:0.903228
==================>
Step: 41840, Train_acc:0.973607
Step: 41840, Val_acc:0.901101
==================>
Step: 41850, Train_acc:0.970322
Step: 41850, Val_acc:0.929375
==================>
Step: 41860, Train_acc:0.965802
Step: 41860, Val_acc:0.923416
==================>
Step: 41870, Train_acc:0.976321
Step: 41870, Val_acc:0.915226
==================>
Step: 41880, Train_acc:0.968756
Step: 41880, Val_acc:0.924648
==================>
Step: 41890, Train_acc:0.969658
Step: 41890, Val_acc:0.933429
==================>
Step: 41900, Train_acc:0.975136
Step: 41900, Val_acc:0.902327
==================>
2017-11-11 11:38:23.049125 ---> Validation_loss: 0.182115
Step: 41910, Train_acc:0.966234
Step: 41910, Val_acc:0.91291
==================>
Step: 41920, Train_acc:0.973984
Step: 41920, Val_acc:0.940345
==================>
Step: 41930, Train_acc:0.971078
Step: 41930, Val_acc:0.908179
==================>
Step: 41940, Train_acc:0.977521
Step: 41940, Val_acc:0.900416
==================>
Step: 41950, Train_acc:0.976578
Step: 41950, Val_acc:0.929994
==================>
Step: 41960, Train_acc:0.967997
Step: 41960, Val_acc:0.937026
==================>
Step: 41970, Train_acc:0.972163
Step: 41970, Val_acc:0.926632
==================>
Step: 41980, Train_acc:0.97391
Step: 41980, Val_acc:0.89927
==================>
Step: 41990, Train_acc:0.966213
Step: 41990, Val_acc:0.912584
==================>
Step: 42000, Train_acc:0.982892
Step: 42000, Val_acc:0.919153
==================>
****************** Epochs completed: 84******************
2017-11-11 11:40:59.185668 ---> Validation_loss: 0.29555
Step: 42010, Train_acc:0.972583
Step: 42010, Val_acc:0.930775
==================>
Step: 42020, Train_acc:0.970233
Step: 42020, Val_acc:0.907314
==================>
Step: 42030, Train_acc:0.969878
Step: 42030, Val_acc:0.911818
==================>
Step: 42040, Train_acc:0.969032
Step: 42040, Val_acc:0.911412
==================>
Step: 42050, Train_acc:0.966388
Step: 42050, Val_acc:0.936574
==================>
Step: 42060, Train_acc:0.971786
Step: 42060, Val_acc:0.922217
==================>
Step: 42070, Train_acc:0.94728
Step: 42070, Val_acc:0.920203
==================>
Step: 42080, Train_acc:0.969343
Step: 42080, Val_acc:0.917025
==================>
Step: 42090, Train_acc:0.973042
Step: 42090, Val_acc:0.942992
==================>
Step: 42100, Train_acc:0.970802
Step: 42100, Val_acc:0.921199
==================>
2017-11-11 11:43:35.722808 ---> Validation_loss: 0.144366
Step: 42110, Train_acc:0.9648
Step: 42110, Val_acc:0.942875
==================>
Step: 42120, Train_acc:0.975878
Step: 42120, Val_acc:0.883032
==================>
Step: 42130, Train_acc:0.96967
Step: 42130, Val_acc:0.888691
==================>
Step: 42140, Train_acc:0.977622
Step: 42140, Val_acc:0.932965
==================>
Step: 42150, Train_acc:0.967084
Step: 42150, Val_acc:0.91433
==================>
Step: 42160, Train_acc:0.969329
Step: 42160, Val_acc:0.915525
==================>
Step: 42170, Train_acc:0.973063
Step: 42170, Val_acc:0.926018
==================>
Step: 42180, Train_acc:0.974619
Step: 42180, Val_acc:0.913857
==================>
Step: 42190, Train_acc:0.972301
Step: 42190, Val_acc:0.905839
==================>
Step: 42200, Train_acc:0.979066
Step: 42200, Val_acc:0.928123
==================>
2017-11-11 11:46:11.879131 ---> Validation_loss: 0.207655
Step: 42210, Train_acc:0.966061
Step: 42210, Val_acc:0.920355
==================>
Step: 42220, Train_acc:0.978085
Step: 42220, Val_acc:0.910272
==================>
Step: 42230, Train_acc:0.969844
Step: 42230, Val_acc:0.921034
==================>
Step: 42240, Train_acc:0.965183
Step: 42240, Val_acc:0.91761
==================>
Step: 42250, Train_acc:0.974926
Step: 42250, Val_acc:0.943032
==================>
Step: 42260, Train_acc:0.968893
Step: 42260, Val_acc:0.953009
==================>
Step: 42270, Train_acc:0.968781
Step: 42270, Val_acc:0.922836
==================>
Step: 42280, Train_acc:0.976328
Step: 42280, Val_acc:0.945145
==================>
Step: 42290, Train_acc:0.973301
Step: 42290, Val_acc:0.883814
==================>
Step: 42300, Train_acc:0.975186
Step: 42300, Val_acc:0.915325
==================>
2017-11-11 11:48:48.023591 ---> Validation_loss: 0.162428
Step: 42310, Train_acc:0.976685
Step: 42310, Val_acc:0.928929
==================>
Step: 42320, Train_acc:0.964408
Step: 42320, Val_acc:0.924974
==================>
Step: 42330, Train_acc:0.961697
Step: 42330, Val_acc:0.919961
==================>
Step: 42340, Train_acc:0.972579
Step: 42340, Val_acc:0.938705
==================>
Step: 42350, Train_acc:0.978947
Step: 42350, Val_acc:0.944418
==================>
Step: 42360, Train_acc:0.978162
Step: 42360, Val_acc:0.949191
==================>
Step: 42370, Train_acc:0.971953
Step: 42370, Val_acc:0.908123
==================>
Step: 42380, Train_acc:0.974611
Step: 42380, Val_acc:0.909573
==================>
Step: 42390, Train_acc:0.959988
Step: 42390, Val_acc:0.912518
==================>
Step: 42400, Train_acc:0.967389
Step: 42400, Val_acc:0.939583
==================>
2017-11-11 11:51:24.362474 ---> Validation_loss: 0.1684
Step: 42410, Train_acc:0.977947
Step: 42410, Val_acc:0.89748
==================>
Step: 42420, Train_acc:0.961121
Step: 42420, Val_acc:0.94187
==================>
Step: 42430, Train_acc:0.973389
Step: 42430, Val_acc:0.939605
==================>
Step: 42440, Train_acc:0.981421
Step: 42440, Val_acc:0.938737
==================>
Step: 42450, Train_acc:0.970907
Step: 42450, Val_acc:0.935621
==================>
Step: 42460, Train_acc:0.970565
Step: 42460, Val_acc:0.922883
==================>
Step: 42470, Train_acc:0.979064
Step: 42470, Val_acc:0.910461
==================>
Step: 42480, Train_acc:0.965562
Step: 42480, Val_acc:0.917983
==================>
Step: 42490, Train_acc:0.977241
Step: 42490, Val_acc:0.922588
==================>
Step: 42500, Train_acc:0.971139
Step: 42500, Val_acc:0.930995
==================>
****************** Epochs completed: 85******************
2017-11-11 11:54:00.783954 ---> Validation_loss: 0.168808
Step: 42510, Train_acc:0.967838
Step: 42510, Val_acc:0.931309
==================>
Step: 42520, Train_acc:0.961379
Step: 42520, Val_acc:0.923887
==================>
Step: 42530, Train_acc:0.980519
Step: 42530, Val_acc:0.932353
==================>
Step: 42540, Train_acc:0.975615
Step: 42540, Val_acc:0.914054
==================>
Step: 42550, Train_acc:0.971366
Step: 42550, Val_acc:0.92774
==================>
Step: 42560, Train_acc:0.960806
Step: 42560, Val_acc:0.916279
==================>
Step: 42570, Train_acc:0.965671
Step: 42570, Val_acc:0.906204
==================>
Step: 42580, Train_acc:0.974446
Step: 42580, Val_acc:0.894644
==================>
Step: 42590, Train_acc:0.965704
Step: 42590, Val_acc:0.926547
==================>
Step: 42600, Train_acc:0.969197
Step: 42600, Val_acc:0.916411
==================>
2017-11-11 11:56:37.033495 ---> Validation_loss: 0.267096
Step: 42610, Train_acc:0.964028
Step: 42610, Val_acc:0.9017
==================>
Step: 42620, Train_acc:0.976379
Step: 42620, Val_acc:0.920411
==================>
Step: 42630, Train_acc:0.97045
Step: 42630, Val_acc:0.93558
==================>
Step: 42640, Train_acc:0.966967
Step: 42640, Val_acc:0.93166
==================>
Step: 42650, Train_acc:0.96418
Step: 42650, Val_acc:0.9185
==================>
Step: 42660, Train_acc:0.967231
Step: 42660, Val_acc:0.907954
==================>
Step: 42670, Train_acc:0.970531
Step: 42670, Val_acc:0.909829
==================>
Step: 42680, Train_acc:0.973938
Step: 42680, Val_acc:0.91689
==================>
Step: 42690, Train_acc:0.957146
Step: 42690, Val_acc:0.912593
==================>
Step: 42700, Train_acc:0.966461
Step: 42700, Val_acc:0.92748
==================>
2017-11-11 11:59:13.518368 ---> Validation_loss: 0.207845
Step: 42710, Train_acc:0.972435
Step: 42710, Val_acc:0.940884
==================>
Step: 42720, Train_acc:0.972113
Step: 42720, Val_acc:0.908594
==================>
Step: 42730, Train_acc:0.965004
Step: 42730, Val_acc:0.926256
==================>
Step: 42740, Train_acc:0.966985
Step: 42740, Val_acc:0.929702
==================>
Step: 42750, Train_acc:0.970732
Step: 42750, Val_acc:0.928541
==================>
Step: 42760, Train_acc:0.975371
Step: 42760, Val_acc:0.922363
==================>
Step: 42770, Train_acc:0.961372
Step: 42770, Val_acc:0.916521
==================>
Step: 42780, Train_acc:0.973754
Step: 42780, Val_acc:0.907885
==================>
Step: 42790, Train_acc:0.96756
Step: 42790, Val_acc:0.937949
==================>
Step: 42800, Train_acc:0.959647
Step: 42800, Val_acc:0.898441
==================>
2017-11-11 12:01:49.949127 ---> Validation_loss: 0.156939
Step: 42810, Train_acc:0.969651
Step: 42810, Val_acc:0.92667
==================>
Step: 42820, Train_acc:0.974967
Step: 42820, Val_acc:0.937706
==================>
Step: 42830, Train_acc:0.971837
Step: 42830, Val_acc:0.952646
==================>
Step: 42840, Train_acc:0.975009
Step: 42840, Val_acc:0.922833
==================>
Step: 42850, Train_acc:0.973544
Step: 42850, Val_acc:0.92537
==================>
Step: 42860, Train_acc:0.964622
Step: 42860, Val_acc:0.917449
==================>
Step: 42870, Train_acc:0.96035
Step: 42870, Val_acc:0.927629
==================>
Step: 42880, Train_acc:0.960221
Step: 42880, Val_acc:0.938066
==================>
Step: 42890, Train_acc:0.974303
Step: 42890, Val_acc:0.908513
==================>
Step: 42900, Train_acc:0.980706
Step: 42900, Val_acc:0.917667
==================>
2017-11-11 12:04:26.284851 ---> Validation_loss: 0.192521
Step: 42910, Train_acc:0.970049
Step: 42910, Val_acc:0.904633
==================>
Step: 42920, Train_acc:0.973588
Step: 42920, Val_acc:0.936564
==================>
Step: 42930, Train_acc:0.966001
Step: 42930, Val_acc:0.874421
==================>
Step: 42940, Train_acc:0.967668
Step: 42940, Val_acc:0.924052
==================>
Step: 42950, Train_acc:0.967711
Step: 42950, Val_acc:0.899662
==================>
Step: 42960, Train_acc:0.958357
Step: 42960, Val_acc:0.946108
==================>
Step: 42970, Train_acc:0.965625
Step: 42970, Val_acc:0.91775
==================>
Step: 42980, Train_acc:0.971657
Step: 42980, Val_acc:0.907772
==================>
Step: 42990, Train_acc:0.970447
Step: 42990, Val_acc:0.942004
==================>
Step: 43000, Train_acc:0.973336
Step: 43000, Val_acc:0.920764
==================>
****************** Epochs completed: 86******************
2017-11-11 12:07:02.816345 ---> Validation_loss: 0.199215
Step: 43010, Train_acc:0.969835
Step: 43010, Val_acc:0.932692
==================>
Step: 43020, Train_acc:0.964326
Step: 43020, Val_acc:0.91786
==================>
Step: 43030, Train_acc:0.970248
Step: 43030, Val_acc:0.903278
==================>
Step: 43040, Train_acc:0.959016
Step: 43040, Val_acc:0.905028
==================>
Step: 43050, Train_acc:0.969191
Step: 43050, Val_acc:0.906056
==================>
Step: 43060, Train_acc:0.955734
Step: 43060, Val_acc:0.911355
==================>
Step: 43070, Train_acc:0.966702
Step: 43070, Val_acc:0.916471
==================>
Step: 43080, Train_acc:0.972047
Step: 43080, Val_acc:0.933535
==================>
Step: 43090, Train_acc:0.981489
Step: 43090, Val_acc:0.909253
==================>
Step: 43100, Train_acc:0.976665
Step: 43100, Val_acc:0.932567
==================>
2017-11-11 12:09:38.955542 ---> Validation_loss: 0.210053
Step: 43110, Train_acc:0.980355
Step: 43110, Val_acc:0.926174
==================>
Step: 43120, Train_acc:0.98205
Step: 43120, Val_acc:0.935267
==================>
Step: 43130, Train_acc:0.968317
Step: 43130, Val_acc:0.936487
==================>
Step: 43140, Train_acc:0.965941
Step: 43140, Val_acc:0.941691
==================>
Step: 43150, Train_acc:0.967169
Step: 43150, Val_acc:0.924557
==================>
Step: 43160, Train_acc:0.97246
Step: 43160, Val_acc:0.908456
==================>
Step: 43170, Train_acc:0.972354
Step: 43170, Val_acc:0.925548
==================>
Step: 43180, Train_acc:0.974844
Step: 43180, Val_acc:0.917511
==================>
Step: 43190, Train_acc:0.970443
Step: 43190, Val_acc:0.928416
==================>
Step: 43200, Train_acc:0.977007
Step: 43200, Val_acc:0.914791
==================>
2017-11-11 12:12:15.342003 ---> Validation_loss: 0.205017
Step: 43210, Train_acc:0.981183
Step: 43210, Val_acc:0.947029
==================>
Step: 43220, Train_acc:0.966135
Step: 43220, Val_acc:0.922466
==================>
Step: 43230, Train_acc:0.965194
Step: 43230, Val_acc:0.919392
==================>
Step: 43240, Train_acc:0.970148
Step: 43240, Val_acc:0.935637
==================>
Step: 43250, Train_acc:0.957797
Step: 43250, Val_acc:0.922399
==================>
Step: 43260, Train_acc:0.97337
Step: 43260, Val_acc:0.905189
==================>
Step: 43270, Train_acc:0.977695
Step: 43270, Val_acc:0.90318
==================>
Step: 43280, Train_acc:0.980625
Step: 43280, Val_acc:0.92947
==================>
Step: 43290, Train_acc:0.970157
Step: 43290, Val_acc:0.928215
==================>
Step: 43300, Train_acc:0.97651
Step: 43300, Val_acc:0.945714
==================>
2017-11-11 12:14:51.460498 ---> Validation_loss: 0.189623
Step: 43310, Train_acc:0.972999
Step: 43310, Val_acc:0.933253
==================>
Step: 43320, Train_acc:0.964315
Step: 43320, Val_acc:0.917764
==================>
Step: 43330, Train_acc:0.963746
Step: 43330, Val_acc:0.917646
==================>
Step: 43340, Train_acc:0.970911
Step: 43340, Val_acc:0.915983
==================>
Step: 43350, Train_acc:0.963361
Step: 43350, Val_acc:0.943271
==================>
Step: 43360, Train_acc:0.966469
Step: 43360, Val_acc:0.913632
==================>
Step: 43370, Train_acc:0.967461
Step: 43370, Val_acc:0.898566
==================>
Step: 43380, Train_acc:0.98125
Step: 43380, Val_acc:0.920465
==================>
Step: 43390, Train_acc:0.96693
Step: 43390, Val_acc:0.941252
==================>
Step: 43400, Train_acc:0.977318
Step: 43400, Val_acc:0.93438
==================>
2017-11-11 12:17:27.877626 ---> Validation_loss: 0.13955
Step: 43410, Train_acc:0.969092
Step: 43410, Val_acc:0.903572
==================>
Step: 43420, Train_acc:0.970999
Step: 43420, Val_acc:0.894651
==================>
Step: 43430, Train_acc:0.969247
Step: 43430, Val_acc:0.946113
==================>
Step: 43440, Train_acc:0.972268
Step: 43440, Val_acc:0.910051
==================>
Step: 43450, Train_acc:0.978011
Step: 43450, Val_acc:0.925726
==================>
Step: 43460, Train_acc:0.975089
Step: 43460, Val_acc:0.931116
==================>
Step: 43470, Train_acc:0.966382
Step: 43470, Val_acc:0.922222
==================>
Step: 43480, Train_acc:0.967769
Step: 43480, Val_acc:0.912885
==================>
Step: 43490, Train_acc:0.967678
Step: 43490, Val_acc:0.905128
==================>
Step: 43500, Train_acc:0.977082
Step: 43500, Val_acc:0.923922
==================>
****************** Epochs completed: 87******************
2017-11-11 12:20:04.156444 ---> Validation_loss: 0.155356
Step: 43510, Train_acc:0.965155
Step: 43510, Val_acc:0.935089
==================>
Step: 43520, Train_acc:0.966956
Step: 43520, Val_acc:0.913396
==================>
Step: 43530, Train_acc:0.95944
Step: 43530, Val_acc:0.94182
==================>
Step: 43540, Train_acc:0.972181
Step: 43540, Val_acc:0.902156
==================>
Step: 43550, Train_acc:0.975561
Step: 43550, Val_acc:0.930038
==================>
Step: 43560, Train_acc:0.973
Step: 43560, Val_acc:0.905136
==================>
Step: 43570, Train_acc:0.970931
Step: 43570, Val_acc:0.929102
==================>
Step: 43580, Train_acc:0.968082
Step: 43580, Val_acc:0.926949
==================>
Step: 43590, Train_acc:0.971494
Step: 43590, Val_acc:0.911942
==================>
Step: 43600, Train_acc:0.975514
Step: 43600, Val_acc:0.939978
==================>
2017-11-11 12:22:40.859542 ---> Validation_loss: 0.259851
Step: 43610, Train_acc:0.981481
Step: 43610, Val_acc:0.934199
==================>
Step: 43620, Train_acc:0.962308
Step: 43620, Val_acc:0.92975
==================>
Step: 43630, Train_acc:0.965039
Step: 43630, Val_acc:0.91886
==================>
Step: 43640, Train_acc:0.963917
Step: 43640, Val_acc:0.914738
==================>
Step: 43650, Train_acc:0.963705
Step: 43650, Val_acc:0.930414
==================>
Step: 43660, Train_acc:0.974387
Step: 43660, Val_acc:0.906045
==================>
Step: 43670, Train_acc:0.974199
Step: 43670, Val_acc:0.931154
==================>
Step: 43680, Train_acc:0.97646
Step: 43680, Val_acc:0.936392
==================>
Step: 43690, Train_acc:0.978854
Step: 43690, Val_acc:0.91963
==================>
Step: 43700, Train_acc:0.969429
Step: 43700, Val_acc:0.918558
==================>
2017-11-11 12:25:17.073090 ---> Validation_loss: 0.155973
Step: 43710, Train_acc:0.962493
Step: 43710, Val_acc:0.932612
==================>
Step: 43720, Train_acc:0.964362
Step: 43720, Val_acc:0.915116
==================>
Step: 43730, Train_acc:0.969058
Step: 43730, Val_acc:0.930533
==================>
****************** Epochs completed: 13******************
Step: 43740, Train_acc:0.969171
Step: 43740, Val_acc:0.940601
==================>
Step: 43750, Train_acc:0.9747
Step: 43750, Val_acc:0.921246
==================>
Step: 43760, Train_acc:0.981163
Step: 43760, Val_acc:0.941299
==================>
Step: 43770, Train_acc:0.973984
Step: 43770, Val_acc:0.903113
==================>
Step: 43780, Train_acc:0.962948
Step: 43780, Val_acc:0.920303
==================>
Step: 43790, Train_acc:0.979069
Step: 43790, Val_acc:0.929037
==================>
Step: 43800, Train_acc:0.972545
Step: 43800, Val_acc:0.912085
==================>
2017-11-11 12:27:53.093946 ---> Validation_loss: 0.222133
Step: 43810, Train_acc:0.969915
Step: 43810, Val_acc:0.919714
==================>
Step: 43820, Train_acc:0.96973
Step: 43820, Val_acc:0.935922
==================>
Step: 43830, Train_acc:0.975007
Step: 43830, Val_acc:0.909637
==================>
Step: 43840, Train_acc:0.96426
Step: 43840, Val_acc:0.934435
==================>
Step: 43850, Train_acc:0.975573
Step: 43850, Val_acc:0.922576
==================>
Step: 43860, Train_acc:0.962577
Step: 43860, Val_acc:0.924098
==================>
Step: 43870, Train_acc:0.968839
Step: 43870, Val_acc:0.919604
==================>
Step: 43880, Train_acc:0.976902
Step: 43880, Val_acc:0.901027
==================>
Step: 43890, Train_acc:0.974775
Step: 43890, Val_acc:0.943812
==================>
Step: 43900, Train_acc:0.973173
Step: 43900, Val_acc:0.894591
==================>
2017-11-11 12:30:29.178607 ---> Validation_loss: 0.177022
Step: 43910, Train_acc:0.945448
Step: 43910, Val_acc:0.937593
==================>
Step: 43920, Train_acc:0.972617
Step: 43920, Val_acc:0.900836
==================>
Step: 43930, Train_acc:0.977808
Step: 43930, Val_acc:0.922361
==================>
Step: 43940, Train_acc:0.979784
Step: 43940, Val_acc:0.918623
==================>
Step: 43950, Train_acc:0.970215
Step: 43950, Val_acc:0.923109
==================>
Step: 43960, Train_acc:0.973317
Step: 43960, Val_acc:0.908099
==================>
Step: 43970, Train_acc:0.967987
Step: 43970, Val_acc:0.907078
==================>
Step: 43980, Train_acc:0.967767
Step: 43980, Val_acc:0.919451
==================>
Step: 43990, Train_acc:0.968159
Step: 43990, Val_acc:0.917461
==================>
Step: 44000, Train_acc:0.969681
Step: 44000, Val_acc:0.919419
==================>
****************** Epochs completed: 88******************
2017-11-11 12:33:04.970605 ---> Validation_loss: 0.187273
Step: 44010, Train_acc:0.973136
Step: 44010, Val_acc:0.930789
==================>
Step: 44020, Train_acc:0.975819
Step: 44020, Val_acc:0.93781
==================>
Step: 44030, Train_acc:0.974503
Step: 44030, Val_acc:0.913427
==================>
Step: 44040, Train_acc:0.961754
Step: 44040, Val_acc:0.941353
==================>
Step: 44050, Train_acc:0.969608
Step: 44050, Val_acc:0.924441
==================>
Step: 44060, Train_acc:0.969844
Step: 44060, Val_acc:0.905383
==================>
Step: 44070, Train_acc:0.972047
Step: 44070, Val_acc:0.925549
==================>
Step: 44080, Train_acc:0.972784
Step: 44080, Val_acc:0.904504
==================>
Step: 44090, Train_acc:0.971605
Step: 44090, Val_acc:0.937317
==================>
Step: 44100, Train_acc:0.975317
Step: 44100, Val_acc:0.921338
==================>
2017-11-11 12:35:41.574061 ---> Validation_loss: 0.231104
Step: 44110, Train_acc:0.97145
Step: 44110, Val_acc:0.891738
==================>
Step: 44120, Train_acc:0.970837
Step: 44120, Val_acc:0.941262
==================>
Step: 44130, Train_acc:0.974601
Step: 44130, Val_acc:0.920441
==================>
Step: 44140, Train_acc:0.97859
Step: 44140, Val_acc:0.882957
==================>
Step: 44150, Train_acc:0.98017
Step: 44150, Val_acc:0.916361
==================>
Step: 44160, Train_acc:0.962133
Step: 44160, Val_acc:0.920461
==================>
Step: 44170, Train_acc:0.958639
Step: 44170, Val_acc:0.911276
==================>
Step: 44180, Train_acc:0.976505
Step: 44180, Val_acc:0.904785
==================>
Step: 44190, Train_acc:0.967006
Step: 44190, Val_acc:0.911571
==================>
Step: 44200, Train_acc:0.976479
Step: 44200, Val_acc:0.908281
==================>
2017-11-11 12:38:17.847424 ---> Validation_loss: 0.17737
Step: 44210, Train_acc:0.970143
Step: 44210, Val_acc:0.933248
==================>
Step: 44220, Train_acc:0.976489
Step: 44220, Val_acc:0.91278
==================>
Step: 44230, Train_acc:0.961311
Step: 44230, Val_acc:0.920884
==================>
Step: 44240, Train_acc:0.97141
Step: 44240, Val_acc:0.920342
==================>
Step: 44250, Train_acc:0.968885
Step: 44250, Val_acc:0.901488
==================>
Step: 44260, Train_acc:0.973999
Step: 44260, Val_acc:0.922136
==================>
Step: 44270, Train_acc:0.976978
Step: 44270, Val_acc:0.921118
==================>
Step: 44280, Train_acc:0.976272
Step: 44280, Val_acc:0.893826
==================>
Step: 44290, Train_acc:0.975092
Step: 44290, Val_acc:0.919508
==================>
Step: 44300, Train_acc:0.965294
Step: 44300, Val_acc:0.924647
==================>
2017-11-11 12:40:53.961810 ---> Validation_loss: 0.185332
Step: 44310, Train_acc:0.964236
Step: 44310, Val_acc:0.917092
==================>
Step: 44320, Train_acc:0.966058
Step: 44320, Val_acc:0.940544
==================>
Step: 44330, Train_acc:0.977496
Step: 44330, Val_acc:0.922946
==================>
Step: 44340, Train_acc:0.961946
Step: 44340, Val_acc:0.903922
==================>
Step: 44350, Train_acc:0.962653
Step: 44350, Val_acc:0.915247
==================>
Step: 44360, Train_acc:0.979739
Step: 44360, Val_acc:0.867742
==================>
Step: 44370, Train_acc:0.966827
Step: 44370, Val_acc:0.933944
==================>
Step: 44380, Train_acc:0.965256
Step: 44380, Val_acc:0.909009
==================>
Step: 44390, Train_acc:0.973489
Step: 44390, Val_acc:0.932218
==================>
Step: 44400, Train_acc:0.965422
Step: 44400, Val_acc:0.927849
==================>
2017-11-11 12:43:30.299875 ---> Validation_loss: 0.218713
Step: 44410, Train_acc:0.977725
Step: 44410, Val_acc:0.94869
==================>
Step: 44420, Train_acc:0.971262
Step: 44420, Val_acc:0.930358
==================>
Step: 44430, Train_acc:0.971576
Step: 44430, Val_acc:0.921685
==================>
Step: 44440, Train_acc:0.970161
Step: 44440, Val_acc:0.955792
==================>
Step: 44450, Train_acc:0.982517
Step: 44450, Val_acc:0.918596
==================>
Step: 44460, Train_acc:0.968817
Step: 44460, Val_acc:0.911724
==================>
Step: 44470, Train_acc:0.974014
Step: 44470, Val_acc:0.939053
==================>
Step: 44480, Train_acc:0.968158
Step: 44480, Val_acc:0.924784
==================>
Step: 44490, Train_acc:0.975487
Step: 44490, Val_acc:0.93587
==================>
Step: 44500, Train_acc:0.964785
Step: 44500, Val_acc:0.91871
==================>
****************** Epochs completed: 89******************
2017-11-11 12:46:06.895125 ---> Validation_loss: 0.183065
Step: 44510, Train_acc:0.97692
Step: 44510, Val_acc:0.922676
==================>
Step: 44520, Train_acc:0.968838
Step: 44520, Val_acc:0.921273
==================>
Step: 44530, Train_acc:0.961799
Step: 44530, Val_acc:0.942058
==================>
Step: 44540, Train_acc:0.979694
Step: 44540, Val_acc:0.906063
==================>
Step: 44550, Train_acc:0.967384
Step: 44550, Val_acc:0.931394
==================>
Step: 44560, Train_acc:0.973275
Step: 44560, Val_acc:0.919004
==================>
Step: 44570, Train_acc:0.973392
Step: 44570, Val_acc:0.928207
==================>
Step: 44580, Train_acc:0.970585
Step: 44580, Val_acc:0.920728
==================>
Step: 44590, Train_acc:0.971865
Step: 44590, Val_acc:0.917253
==================>
Step: 44600, Train_acc:0.962653
Step: 44600, Val_acc:0.876169
==================>
2017-11-11 12:48:43.016986 ---> Validation_loss: 0.256267
Step: 44610, Train_acc:0.974575
Step: 44610, Val_acc:0.924028
==================>
Step: 44620, Train_acc:0.967964
Step: 44620, Val_acc:0.921553
==================>
Step: 44630, Train_acc:0.970166
Step: 44630, Val_acc:0.951294
==================>
Step: 44640, Train_acc:0.977462
Step: 44640, Val_acc:0.923176
==================>
Step: 44650, Train_acc:0.960802
Step: 44650, Val_acc:0.947334
==================>
Step: 44660, Train_acc:0.972882
Step: 44660, Val_acc:0.919565
==================>
Step: 44670, Train_acc:0.978741
Step: 44670, Val_acc:0.910887
==================>
Step: 44680, Train_acc:0.984952
Step: 44680, Val_acc:0.937391
==================>
Step: 44690, Train_acc:0.983218
Step: 44690, Val_acc:0.931027
==================>
Step: 44700, Train_acc:0.9604
Step: 44700, Val_acc:0.93505
==================>
2017-11-11 12:51:19.630822 ---> Validation_loss: 0.180934
Step: 44710, Train_acc:0.970243
Step: 44710, Val_acc:0.915399
==================>
Step: 44720, Train_acc:0.964113
Step: 44720, Val_acc:0.930699
==================>
Step: 44730, Train_acc:0.971294
Step: 44730, Val_acc:0.905763
==================>
Step: 44740, Train_acc:0.976361
Step: 44740, Val_acc:0.933685
==================>
Step: 44750, Train_acc:0.972767
Step: 44750, Val_acc:0.919695
==================>
Step: 44760, Train_acc:0.96835
Step: 44760, Val_acc:0.916213
==================>
Step: 44770, Train_acc:0.971862
Step: 44770, Val_acc:0.923601
==================>
Step: 44780, Train_acc:0.968529
Step: 44780, Val_acc:0.893856
==================>
Step: 44790, Train_acc:0.963535
Step: 44790, Val_acc:0.914186
==================>
Step: 44800, Train_acc:0.965447
Step: 44800, Val_acc:0.912708
==================>
2017-11-11 12:53:55.795582 ---> Validation_loss: 0.208816
Step: 44810, Train_acc:0.974226
Step: 44810, Val_acc:0.927921
==================>
Step: 44820, Train_acc:0.972957
Step: 44820, Val_acc:0.915442
==================>
Step: 44830, Train_acc:0.964329
Step: 44830, Val_acc:0.94056
==================>
Step: 44840, Train_acc:0.968306
Step: 44840, Val_acc:0.930858
==================>
Step: 44850, Train_acc:0.982
Step: 44850, Val_acc:0.947024
==================>
Step: 44860, Train_acc:0.97463
Step: 44860, Val_acc:0.888654
==================>
Step: 44870, Train_acc:0.969576
Step: 44870, Val_acc:0.940535
==================>
Step: 44880, Train_acc:0.972996
Step: 44880, Val_acc:0.931755
==================>
Step: 44890, Train_acc:0.974709
Step: 44890, Val_acc:0.926746
==================>
Step: 44900, Train_acc:0.973987
Step: 44900, Val_acc:0.904434
==================>
2017-11-11 12:56:32.320333 ---> Validation_loss: 0.155057
Step: 44910, Train_acc:0.978031
Step: 44910, Val_acc:0.92139
==================>
Step: 44920, Train_acc:0.972708
Step: 44920, Val_acc:0.940834
==================>
Step: 44930, Train_acc:0.969502
Step: 44930, Val_acc:0.908409
==================>
Step: 44940, Train_acc:0.977057
Step: 44940, Val_acc:0.945416
==================>
Step: 44950, Train_acc:0.974631
Step: 44950, Val_acc:0.924138
==================>
Step: 44960, Train_acc:0.966161
Step: 44960, Val_acc:0.924862
==================>
Step: 44970, Train_acc:0.967174
Step: 44970, Val_acc:0.923746
==================>
Step: 44980, Train_acc:0.980947
Step: 44980, Val_acc:0.889436
==================>
Step: 44990, Train_acc:0.973464
Step: 44990, Val_acc:0.933179
==================>
Step: 45000, Train_acc:0.978098
Step: 45000, Val_acc:0.937698
==================>
****************** Epochs completed: 90******************
2017-11-11 12:59:08.946946 ---> Validation_loss: 0.222261
Step: 45010, Train_acc:0.977412
Step: 45010, Val_acc:0.917617
==================>
Step: 45020, Train_acc:0.968972
Step: 45020, Val_acc:0.937904
==================>
Step: 45030, Train_acc:0.975051
Step: 45030, Val_acc:0.904531
==================>
Step: 45040, Train_acc:0.974519
Step: 45040, Val_acc:0.94127
==================>
Step: 45050, Train_acc:0.968611
Step: 45050, Val_acc:0.904204
==================>
Step: 45060, Train_acc:0.959279
Step: 45060, Val_acc:0.893956
==================>
Step: 45070, Train_acc:0.972373
Step: 45070, Val_acc:0.904952
==================>
Step: 45080, Train_acc:0.963319
Step: 45080, Val_acc:0.946041
==================>
Step: 45090, Train_acc:0.971759
Step: 45090, Val_acc:0.942367
==================>
Step: 45100, Train_acc:0.962399
Step: 45100, Val_acc:0.946921
==================>
2017-11-11 13:01:45.739163 ---> Validation_loss: 0.266945
Step: 45110, Train_acc:0.963125
Step: 45110, Val_acc:0.910245
==================>
Step: 45120, Train_acc:0.977675
Step: 45120, Val_acc:0.924194
==================>
Step: 45130, Train_acc:0.97247
Step: 45130, Val_acc:0.931909
==================>
Step: 45140, Train_acc:0.970709
Step: 45140, Val_acc:0.902295
==================>
Step: 45150, Train_acc:0.966283
Step: 45150, Val_acc:0.894447
==================>
Step: 45160, Train_acc:0.968749
Step: 45160, Val_acc:0.924503
==================>
Step: 45170, Train_acc:0.984535
Step: 45170, Val_acc:0.916464
==================>
Step: 45180, Train_acc:0.965206
Step: 45180, Val_acc:0.904795
==================>
Step: 45190, Train_acc:0.971895
Step: 45190, Val_acc:0.928649
==================>
Step: 45200, Train_acc:0.976067
Step: 45200, Val_acc:0.933614
==================>
2017-11-11 13:04:21.929975 ---> Validation_loss: 0.13382
Step: 45210, Train_acc:0.963367
Step: 45210, Val_acc:0.944255
==================>
Step: 45220, Train_acc:0.969401
Step: 45220, Val_acc:0.911687
==================>
Step: 45230, Train_acc:0.975287
Step: 45230, Val_acc:0.919469
==================>
Step: 45240, Train_acc:0.978311
Step: 45240, Val_acc:0.923903
==================>
Step: 45250, Train_acc:0.971705
Step: 45250, Val_acc:0.904861
==================>
Step: 45260, Train_acc:0.973805
Step: 45260, Val_acc:0.92525
==================>
Step: 45270, Train_acc:0.970762
Step: 45270, Val_acc:0.927808
==================>
Step: 45280, Train_acc:0.973878
Step: 45280, Val_acc:0.923539
==================>
Step: 45290, Train_acc:0.972615
Step: 45290, Val_acc:0.938822
==================>
Step: 45300, Train_acc:0.969093
Step: 45300, Val_acc:0.896289
==================>
2017-11-11 13:06:58.065126 ---> Validation_loss: 0.126029
Step: 45310, Train_acc:0.972996
Step: 45310, Val_acc:0.929132
==================>
Step: 45320, Train_acc:0.974337
Step: 45320, Val_acc:0.909298
==================>
Step: 45330, Train_acc:0.964899
Step: 45330, Val_acc:0.936302
==================>
Step: 45340, Train_acc:0.972257
Step: 45340, Val_acc:0.904132
==================>
Step: 45350, Train_acc:0.975647
Step: 45350, Val_acc:0.929027
==================>
Step: 45360, Train_acc:0.971621
Step: 45360, Val_acc:0.925331
==================>
Step: 45370, Train_acc:0.976604
Step: 45370, Val_acc:0.918123
==================>
Step: 45380, Train_acc:0.982053
Step: 45380, Val_acc:0.912314
==================>
Step: 45390, Train_acc:0.9754
Step: 45390, Val_acc:0.931066
==================>
Step: 45400, Train_acc:0.970153
Step: 45400, Val_acc:0.929078
==================>
2017-11-11 13:09:34.731176 ---> Validation_loss: 0.351905
Step: 45410, Train_acc:0.970929
Step: 45410, Val_acc:0.919681
==================>
Step: 45420, Train_acc:0.979537
Step: 45420, Val_acc:0.948815
==================>
Step: 45430, Train_acc:0.97563
Step: 45430, Val_acc:0.922933
==================>
Step: 45440, Train_acc:0.970592
Step: 45440, Val_acc:0.918112
==================>
Step: 45450, Train_acc:0.973372
Step: 45450, Val_acc:0.906929
==================>
Step: 45460, Train_acc:0.970393
Step: 45460, Val_acc:0.928531
==================>
Step: 45470, Train_acc:0.965664
Step: 45470, Val_acc:0.928142
==================>
Step: 45480, Train_acc:0.959827
Step: 45480, Val_acc:0.91735
==================>
Step: 45490, Train_acc:0.970496
Step: 45490, Val_acc:0.907485
==================>
Step: 45500, Train_acc:0.969948
Step: 45500, Val_acc:0.90608
==================>
****************** Epochs completed: 91******************
2017-11-11 13:12:11.164007 ---> Validation_loss: 0.219821
Step: 45510, Train_acc:0.972509
Step: 45510, Val_acc:0.919786
==================>
Step: 45520, Train_acc:0.966017
Step: 45520, Val_acc:0.915317
==================>
Step: 45530, Train_acc:0.978352
Step: 45530, Val_acc:0.916884
==================>
Step: 45540, Train_acc:0.96939
Step: 45540, Val_acc:0.934963
==================>
Step: 45550, Train_acc:0.975996
Step: 45550, Val_acc:0.884491
==================>
Step: 45560, Train_acc:0.970099
Step: 45560, Val_acc:0.938434
==================>
Step: 45570, Train_acc:0.967709
Step: 45570, Val_acc:0.894437
==================>
Step: 45580, Train_acc:0.970356
Step: 45580, Val_acc:0.930941
==================>
Step: 45590, Train_acc:0.969602
Step: 45590, Val_acc:0.937493
==================>
Step: 45600, Train_acc:0.969021
Step: 45600, Val_acc:0.940084
==================>
2017-11-11 13:14:47.697897 ---> Validation_loss: 0.196123
Step: 45610, Train_acc:0.981265
Step: 45610, Val_acc:0.931348
==================>
Step: 45620, Train_acc:0.969706
Step: 45620, Val_acc:0.930505
==================>
Step: 45630, Train_acc:0.971819
Step: 45630, Val_acc:0.934567
==================>
Step: 45640, Train_acc:0.974341
Step: 45640, Val_acc:0.936543
==================>
Step: 45650, Train_acc:0.968579
Step: 45650, Val_acc:0.938877
==================>
Step: 45660, Train_acc:0.969525
Step: 45660, Val_acc:0.93584
==================>
Step: 45670, Train_acc:0.968531
Step: 45670, Val_acc:0.946749
==================>
Step: 45680, Train_acc:0.971914
Step: 45680, Val_acc:0.943886
==================>
Step: 45690, Train_acc:0.965625
Step: 45690, Val_acc:0.925627
==================>
Step: 45700, Train_acc:0.975459
Step: 45700, Val_acc:0.932939
==================>
2017-11-11 13:17:24.268308 ---> Validation_loss: 0.196106
Step: 45710, Train_acc:0.974623
Step: 45710, Val_acc:0.922119
==================>
Step: 45720, Train_acc:0.977472
Step: 45720, Val_acc:0.933004
==================>
Step: 45730, Train_acc:0.96241
Step: 45730, Val_acc:0.939722
==================>
Step: 45740, Train_acc:0.979448
Step: 45740, Val_acc:0.901938
==================>
Step: 45750, Train_acc:0.971267
Step: 45750, Val_acc:0.921777
==================>
Step: 45760, Train_acc:0.972621
Step: 45760, Val_acc:0.934882
==================>
Step: 45770, Train_acc:0.962103
Step: 45770, Val_acc:0.935819
==================>
Step: 45780, Train_acc:0.971061
Step: 45780, Val_acc:0.937388
==================>
Step: 45790, Train_acc:0.977728
Step: 45790, Val_acc:0.945582
==================>
Step: 45800, Train_acc:0.973314
Step: 45800, Val_acc:0.929924
==================>
2017-11-11 13:20:00.523323 ---> Validation_loss: 0.164411
Step: 45810, Train_acc:0.972588
Step: 45810, Val_acc:0.914276
==================>
Step: 45820, Train_acc:0.975017
Step: 45820, Val_acc:0.916677
==================>
Step: 45830, Train_acc:0.980134
Step: 45830, Val_acc:0.916786
==================>
Step: 45840, Train_acc:0.970282
Step: 45840, Val_acc:0.928307
==================>
Step: 45850, Train_acc:0.972651
Step: 45850, Val_acc:0.94351
==================>
Step: 45860, Train_acc:0.974624
Step: 45860, Val_acc:0.936956
==================>
Step: 45870, Train_acc:0.967941
Step: 45870, Val_acc:0.940785
==================>
Step: 45880, Train_acc:0.971815
Step: 45880, Val_acc:0.943975
==================>
Step: 45890, Train_acc:0.969491
Step: 45890, Val_acc:0.927045
==================>
Step: 45900, Train_acc:0.97505
Step: 45900, Val_acc:0.934601
==================>
2017-11-11 13:22:36.725788 ---> Validation_loss: 0.166284
Step: 45910, Train_acc:0.972302
Step: 45910, Val_acc:0.917141
==================>
Step: 45920, Train_acc:0.963853
Step: 45920, Val_acc:0.927886
==================>
Step: 45930, Train_acc:0.972777
Step: 45930, Val_acc:0.940226
==================>
Step: 45940, Train_acc:0.96736
Step: 45940, Val_acc:0.918241
==================>
Step: 45950, Train_acc:0.974172
Step: 45950, Val_acc:0.942848
==================>
Step: 45960, Train_acc:0.967219
Step: 45960, Val_acc:0.90368
==================>
Step: 45970, Train_acc:0.972594
Step: 45970, Val_acc:0.900051
==================>
Step: 45980, Train_acc:0.97681
Step: 45980, Val_acc:0.930973
==================>
Step: 45990, Train_acc:0.977322
Step: 45990, Val_acc:0.919954
==================>
Step: 46000, Train_acc:0.974984
Step: 46000, Val_acc:0.932612
==================>
****************** Epochs completed: 92******************
2017-11-11 13:25:13.354388 ---> Validation_loss: 0.12411
Step: 46010, Train_acc:0.976915
Step: 46010, Val_acc:0.922845
==================>
Step: 46020, Train_acc:0.97715
Step: 46020, Val_acc:0.915892
==================>
Step: 46030, Train_acc:0.966591
Step: 46030, Val_acc:0.915167
==================>
Step: 46040, Train_acc:0.976699
Step: 46040, Val_acc:0.934487
==================>
Step: 46050, Train_acc:0.976058
Step: 46050, Val_acc:0.932014
==================>
Step: 46060, Train_acc:0.971772
Step: 46060, Val_acc:0.92616
==================>
Step: 46070, Train_acc:0.97499
Step: 46070, Val_acc:0.925046
==================>
Step: 46080, Train_acc:0.971949
Step: 46080, Val_acc:0.934626
==================>
Step: 46090, Train_acc:0.963478
Step: 46090, Val_acc:0.920671
==================>
Step: 46100, Train_acc:0.966012
Step: 46100, Val_acc:0.943923
==================>
2017-11-11 13:27:50.507308 ---> Validation_loss: 0.204998
Step: 46110, Train_acc:0.973171
Step: 46110, Val_acc:0.928278
==================>
Step: 46120, Train_acc:0.972383
Step: 46120, Val_acc:0.920604
==================>
Step: 46130, Train_acc:0.971326
Step: 46130, Val_acc:0.932332
==================>
Step: 46140, Train_acc:0.975325
Step: 46140, Val_acc:0.929985
==================>
Step: 46150, Train_acc:0.967954
Step: 46150, Val_acc:0.929268
==================>
Step: 46160, Train_acc:0.969523
Step: 46160, Val_acc:0.925895
==================>
Step: 46170, Train_acc:0.97934
Step: 46170, Val_acc:0.921689
==================>
Step: 46180, Train_acc:0.961636
Step: 46180, Val_acc:0.939984
==================>
Step: 46190, Train_acc:0.971392
Step: 46190, Val_acc:0.917991
==================>
Step: 46200, Train_acc:0.965688
Step: 46200, Val_acc:0.925504
==================>
2017-11-11 13:30:28.136371 ---> Validation_loss: 0.172194
Step: 46210, Train_acc:0.970399
Step: 46210, Val_acc:0.917732
==================>
Step: 46220, Train_acc:0.966371
Step: 46220, Val_acc:0.913358
==================>
Step: 46230, Train_acc:0.976188
Step: 46230, Val_acc:0.916348
==================>
Step: 46240, Train_acc:0.975311
Step: 46240, Val_acc:0.921337
==================>
Step: 46250, Train_acc:0.974146
Step: 46250, Val_acc:0.927472
==================>
Step: 46260, Train_acc:0.960106
Step: 46260, Val_acc:0.917443
==================>
Step: 46270, Train_acc:0.973092
Step: 46270, Val_acc:0.914309
==================>
Step: 46280, Train_acc:0.976857
Step: 46280, Val_acc:0.937214
==================>
Step: 46290, Train_acc:0.974427
Step: 46290, Val_acc:0.907511
==================>
Step: 46300, Train_acc:0.977573
Step: 46300, Val_acc:0.919238
==================>
2017-11-11 13:33:04.137075 ---> Validation_loss: 0.226874
Step: 46310, Train_acc:0.973727
Step: 46310, Val_acc:0.896631
==================>
Step: 46320, Train_acc:0.96753
Step: 46320, Val_acc:0.926544
==================>
Step: 46330, Train_acc:0.974545
Step: 46330, Val_acc:0.945977
==================>
Step: 46340, Train_acc:0.975823
Step: 46340, Val_acc:0.910946
==================>
Step: 46350, Train_acc:0.973451
Step: 46350, Val_acc:0.916797
==================>
Step: 46360, Train_acc:0.974348
Step: 46360, Val_acc:0.905433
==================>
Step: 46370, Train_acc:0.968132
Step: 46370, Val_acc:0.941067
==================>
Step: 46380, Train_acc:0.97766
Step: 46380, Val_acc:0.914847
==================>
Step: 46390, Train_acc:0.961759
Step: 46390, Val_acc:0.916822
==================>
Step: 46400, Train_acc:0.967942
Step: 46400, Val_acc:0.927087
==================>
2017-11-11 13:35:41.170838 ---> Validation_loss: 0.203003
Step: 46410, Train_acc:0.975283
Step: 46410, Val_acc:0.936649
==================>
Step: 46420, Train_acc:0.974028
Step: 46420, Val_acc:0.941112
==================>
Step: 46430, Train_acc:0.979742
Step: 46430, Val_acc:0.904357
==================>
Step: 46440, Train_acc:0.972266
Step: 46440, Val_acc:0.898773
==================>
Step: 46450, Train_acc:0.970668
Step: 46450, Val_acc:0.929982
==================>
Step: 46460, Train_acc:0.97286
Step: 46460, Val_acc:0.907467
==================>
Step: 46470, Train_acc:0.966713
Step: 46470, Val_acc:0.934642
==================>
Step: 46480, Train_acc:0.964639
Step: 46480, Val_acc:0.912208
==================>
Step: 46490, Train_acc:0.96871
Step: 46490, Val_acc:0.92848
==================>
Step: 46500, Train_acc:0.976694
Step: 46500, Val_acc:0.886815
==================>
****************** Epochs completed: 93******************
2017-11-11 13:38:18.222815 ---> Validation_loss: 0.195866
Step: 46510, Train_acc:0.965145
Step: 46510, Val_acc:0.914189
==================>
Step: 46520, Train_acc:0.964375
Step: 46520, Val_acc:0.91771
==================>
Step: 46530, Train_acc:0.971512
Step: 46530, Val_acc:0.86093
==================>
Step: 46540, Train_acc:0.962014
Step: 46540, Val_acc:0.871763
==================>
Step: 46550, Train_acc:0.982354
Step: 46550, Val_acc:0.93823
==================>
Step: 46560, Train_acc:0.97694
Step: 46560, Val_acc:0.916013
==================>
Step: 46570, Train_acc:0.955494
Step: 46570, Val_acc:0.944102
==================>
Step: 46580, Train_acc:0.969441
Step: 46580, Val_acc:0.917678
==================>
Step: 46590, Train_acc:0.959803
Step: 46590, Val_acc:0.957245
==================>
Step: 46600, Train_acc:0.969176
Step: 46600, Val_acc:0.929091
==================>
2017-11-11 13:40:55.711253 ---> Validation_loss: 0.216059
Step: 46610, Train_acc:0.984606
Step: 46610, Val_acc:0.925284
==================>
Step: 46620, Train_acc:0.974426
Step: 46620, Val_acc:0.926274
==================>
Step: 46630, Train_acc:0.971046
Step: 46630, Val_acc:0.927479
==================>
Step: 46640, Train_acc:0.964192
Step: 46640, Val_acc:0.923783
==================>
Step: 46650, Train_acc:0.976394
Step: 46650, Val_acc:0.908568
==================>
Step: 46660, Train_acc:0.964608
Step: 46660, Val_acc:0.914154
==================>
Step: 46670, Train_acc:0.971898
Step: 46670, Val_acc:0.949509
==================>
Step: 46680, Train_acc:0.971058
Step: 46680, Val_acc:0.896442
==================>
Step: 46690, Train_acc:0.97168
Step: 46690, Val_acc:0.92256
==================>
Step: 46700, Train_acc:0.975718
Step: 46700, Val_acc:0.919351
==================>
2017-11-11 13:43:32.492052 ---> Validation_loss: 0.175252
Step: 46710, Train_acc:0.977023
Step: 46710, Val_acc:0.940535
==================>
Step: 46720, Train_acc:0.964642
Step: 46720, Val_acc:0.909827
==================>
Step: 46730, Train_acc:0.971593
Step: 46730, Val_acc:0.931766
==================>
Step: 46740, Train_acc:0.976447
Step: 46740, Val_acc:0.915432
==================>
Step: 46750, Train_acc:0.966447
Step: 46750, Val_acc:0.940144
==================>
Step: 46760, Train_acc:0.965398
Step: 46760, Val_acc:0.936012
==================>
Step: 46770, Train_acc:0.969739
Step: 46770, Val_acc:0.911544
==================>
Step: 46780, Train_acc:0.965443
Step: 46780, Val_acc:0.928573
==================>
Step: 46790, Train_acc:0.966649
Step: 46790, Val_acc:0.949099
==================>
Step: 46800, Train_acc:0.968252
Step: 46800, Val_acc:0.943135
==================>
2017-11-11 13:46:09.736044 ---> Validation_loss: 0.221688
Step: 46810, Train_acc:0.97684
Step: 46810, Val_acc:0.920356
==================>
Step: 46820, Train_acc:0.980607
Step: 46820, Val_acc:0.932651
==================>
Step: 46830, Train_acc:0.972179
Step: 46830, Val_acc:0.910221
==================>
Step: 46840, Train_acc:0.970823
Step: 46840, Val_acc:0.899957
==================>
Step: 46850, Train_acc:0.966077
Step: 46850, Val_acc:0.928469
==================>
Step: 46860, Train_acc:0.967814
Step: 46860, Val_acc:0.924458
==================>
Step: 46870, Train_acc:0.972203
Step: 46870, Val_acc:0.938295
==================>
Step: 46880, Train_acc:0.976881
Step: 46880, Val_acc:0.906566
==================>
Step: 46890, Train_acc:0.979275
Step: 46890, Val_acc:0.905713
==================>
Step: 46900, Train_acc:0.973331
Step: 46900, Val_acc:0.901884
==================>
2017-11-11 13:48:47.816127 ---> Validation_loss: 0.195662
Step: 46910, Train_acc:0.962096
Step: 46910, Val_acc:0.93364
==================>
Step: 46920, Train_acc:0.967909
Step: 46920, Val_acc:0.924043
==================>
Step: 46930, Train_acc:0.971047
Step: 46930, Val_acc:0.90974
==================>
Step: 46940, Train_acc:0.960061
Step: 46940, Val_acc:0.927109
==================>
Step: 46950, Train_acc:0.967775
Step: 46950, Val_acc:0.92572
==================>
Step: 46960, Train_acc:0.977863
Step: 46960, Val_acc:0.923784
==================>
Step: 46970, Train_acc:0.970962
Step: 46970, Val_acc:0.927659
==================>
Step: 46980, Train_acc:0.975913
Step: 46980, Val_acc:0.912122
==================>
Step: 46990, Train_acc:0.968481
Step: 46990, Val_acc:0.899939
==================>
Step: 47000, Train_acc:0.96342
Step: 47000, Val_acc:0.940789
==================>
****************** Epochs completed: 94******************
2017-11-11 13:51:24.947852 ---> Validation_loss: 0.207727
Step: 47010, Train_acc:0.969524
Step: 47010, Val_acc:0.913461
==================>
Step: 47020, Train_acc:0.96928
Step: 47020, Val_acc:0.931548
==================>
Step: 47030, Train_acc:0.980796
Step: 47030, Val_acc:0.925509
==================>
Step: 47040, Train_acc:0.97979
Step: 47040, Val_acc:0.919904
==================>
Step: 47050, Train_acc:0.971705
Step: 47050, Val_acc:0.939836
==================>
Step: 47060, Train_acc:0.976051
Step: 47060, Val_acc:0.940055
==================>
Step: 47070, Train_acc:0.975378
Step: 47070, Val_acc:0.898962
==================>
Step: 47080, Train_acc:0.976168
Step: 47080, Val_acc:0.937057
==================>
Step: 47090, Train_acc:0.96969
Step: 47090, Val_acc:0.91454
==================>
****************** Epochs completed: 14******************
Step: 47100, Train_acc:0.975071
Step: 47100, Val_acc:0.935386
==================>
2017-11-11 13:54:02.546097 ---> Validation_loss: 0.216743
Step: 47110, Train_acc:0.973776
Step: 47110, Val_acc:0.904354
==================>
Step: 47120, Train_acc:0.978665
Step: 47120, Val_acc:0.924226
==================>
Step: 47130, Train_acc:0.969315
Step: 47130, Val_acc:0.902731
==================>
Step: 47140, Train_acc:0.975521
Step: 47140, Val_acc:0.922245
==================>
Step: 47150, Train_acc:0.976864
Step: 47150, Val_acc:0.914775
==================>
Step: 47160, Train_acc:0.973335
Step: 47160, Val_acc:0.935969
==================>
Step: 47170, Train_acc:0.970522
Step: 47170, Val_acc:0.915999
==================>
Step: 47180, Train_acc:0.97067
Step: 47180, Val_acc:0.924702
==================>
Step: 47190, Train_acc:0.979631
Step: 47190, Val_acc:0.927867
==================>
Step: 47200, Train_acc:0.977645
Step: 47200, Val_acc:0.937787
==================>
2017-11-11 13:56:39.773131 ---> Validation_loss: 0.225628
Step: 47210, Train_acc:0.97708
Step: 47210, Val_acc:0.91387
==================>
Step: 47220, Train_acc:0.9847
Step: 47220, Val_acc:0.944503
==================>
Step: 47230, Train_acc:0.958427
Step: 47230, Val_acc:0.904834
==================>
Step: 47240, Train_acc:0.967252
Step: 47240, Val_acc:0.921257
==================>
Step: 47250, Train_acc:0.974003
Step: 47250, Val_acc:0.93764
==================>
Step: 47260, Train_acc:0.974556
Step: 47260, Val_acc:0.918508
==================>
Step: 47270, Train_acc:0.974216
Step: 47270, Val_acc:0.943441
==================>
Step: 47280, Train_acc:0.97637
Step: 47280, Val_acc:0.905958
==================>
Step: 47290, Train_acc:0.975151
Step: 47290, Val_acc:0.92321
==================>
Step: 47300, Train_acc:0.975367
Step: 47300, Val_acc:0.940623
==================>
2017-11-11 13:59:16.995072 ---> Validation_loss: 0.191631
Step: 47310, Train_acc:0.983728
Step: 47310, Val_acc:0.943876
==================>
Step: 47320, Train_acc:0.979518
Step: 47320, Val_acc:0.940543
==================>
Step: 47330, Train_acc:0.976012
Step: 47330, Val_acc:0.910056
==================>
Step: 47340, Train_acc:0.9787
Step: 47340, Val_acc:0.941061
==================>
Step: 47350, Train_acc:0.976588
Step: 47350, Val_acc:0.90688
==================>
Step: 47360, Train_acc:0.982729
Step: 47360, Val_acc:0.930073
==================>
Step: 47370, Train_acc:0.971392
Step: 47370, Val_acc:0.949861
==================>
Step: 47380, Train_acc:0.980012
Step: 47380, Val_acc:0.928441
==================>
Step: 47390, Train_acc:0.972544
Step: 47390, Val_acc:0.944043
==================>
Step: 47400, Train_acc:0.974203
Step: 47400, Val_acc:0.925538
==================>
2017-11-11 14:01:54.519585 ---> Validation_loss: 0.0864831
Step: 47410, Train_acc:0.979269
Step: 47410, Val_acc:0.91377
==================>
Step: 47420, Train_acc:0.972999
Step: 47420, Val_acc:0.895428
==================>
Step: 47430, Train_acc:0.962092
Step: 47430, Val_acc:0.957471
==================>
Step: 47440, Train_acc:0.975503
Step: 47440, Val_acc:0.917725
==================>
Step: 47450, Train_acc:0.982349
Step: 47450, Val_acc:0.935039
==================>
Step: 47460, Train_acc:0.979014
Step: 47460, Val_acc:0.9437
==================>
Step: 47470, Train_acc:0.975284
Step: 47470, Val_acc:0.963073
==================>
Step: 47480, Train_acc:0.974739
Step: 47480, Val_acc:0.923362
==================>
Step: 47490, Train_acc:0.980554
Step: 47490, Val_acc:0.911436
==================>
Step: 47500, Train_acc:0.967769
Step: 47500, Val_acc:0.918312
==================>
****************** Epochs completed: 95******************
2017-11-11 14:04:32.186798 ---> Validation_loss: 0.131375
Step: 47510, Train_acc:0.978436
Step: 47510, Val_acc:0.943198
==================>
Step: 47520, Train_acc:0.972936
Step: 47520, Val_acc:0.915017
==================>
Step: 47530, Train_acc:0.980347
Step: 47530, Val_acc:0.910068
==================>
Step: 47540, Train_acc:0.977065
Step: 47540, Val_acc:0.917323
==================>
Step: 47550, Train_acc:0.979348
Step: 47550, Val_acc:0.951365
==================>
Step: 47560, Train_acc:0.971038
Step: 47560, Val_acc:0.931876
==================>
Step: 47570, Train_acc:0.973314
Step: 47570, Val_acc:0.923671
==================>
Step: 47580, Train_acc:0.979468
Step: 47580, Val_acc:0.93733
==================>
Step: 47590, Train_acc:0.974419
Step: 47590, Val_acc:0.930393
==================>
Step: 47600, Train_acc:0.977614
Step: 47600, Val_acc:0.934659
==================>
2017-11-11 14:07:10.301764 ---> Validation_loss: 0.203917
Step: 47610, Train_acc:0.976063
Step: 47610, Val_acc:0.938741
==================>
Step: 47620, Train_acc:0.971853
Step: 47620, Val_acc:0.935719
==================>
Step: 47630, Train_acc:0.971344
Step: 47630, Val_acc:0.936403
==================>
Step: 47640, Train_acc:0.977806
Step: 47640, Val_acc:0.949128
==================>
Step: 47650, Train_acc:0.979598
Step: 47650, Val_acc:0.930902
==================>
Step: 47660, Train_acc:0.981918
Step: 47660, Val_acc:0.915289
==================>
Step: 47670, Train_acc:0.97832
Step: 47670, Val_acc:0.94754
==================>
Step: 47680, Train_acc:0.980188
Step: 47680, Val_acc:0.927964
==================>
Step: 47690, Train_acc:0.979456
Step: 47690, Val_acc:0.931427
==================>
Step: 47700, Train_acc:0.97459
Step: 47700, Val_acc:0.936674
==================>
2017-11-11 14:09:47.914294 ---> Validation_loss: 0.190111
Step: 47710, Train_acc:0.976832
Step: 47710, Val_acc:0.931227
==================>
Step: 47720, Train_acc:0.976555
Step: 47720, Val_acc:0.917992
==================>
Step: 47730, Train_acc:0.975815
Step: 47730, Val_acc:0.897368
==================>
Step: 47740, Train_acc:0.976084
Step: 47740, Val_acc:0.932501
==================>
Step: 47750, Train_acc:0.97227
Step: 47750, Val_acc:0.928417
==================>
Step: 47760, Train_acc:0.971943
Step: 47760, Val_acc:0.92588
==================>
Step: 47770, Train_acc:0.977186
Step: 47770, Val_acc:0.935894
==================>
Step: 47780, Train_acc:0.980736
Step: 47780, Val_acc:0.949556
==================>
Step: 47790, Train_acc:0.974158
Step: 47790, Val_acc:0.92708
==================>
Step: 47800, Train_acc:0.969459
Step: 47800, Val_acc:0.915188
==================>
2017-11-11 14:12:25.027264 ---> Validation_loss: 0.18315
Step: 47810, Train_acc:0.980347
Step: 47810, Val_acc:0.942813
==================>
Step: 47820, Train_acc:0.971448
Step: 47820, Val_acc:0.906807
==================>
Step: 47830, Train_acc:0.970782
Step: 47830, Val_acc:0.914159
==================>
Step: 47840, Train_acc:0.966833
Step: 47840, Val_acc:0.935388
==================>
Step: 47850, Train_acc:0.966024
Step: 47850, Val_acc:0.938268
==================>
Step: 47860, Train_acc:0.970725
Step: 47860, Val_acc:0.918195
==================>
Step: 47870, Train_acc:0.972944
Step: 47870, Val_acc:0.925642
==================>
Step: 47880, Train_acc:0.973544
Step: 47880, Val_acc:0.902821
==================>
Step: 47890, Train_acc:0.970184
Step: 47890, Val_acc:0.944415
==================>
Step: 47900, Train_acc:0.971964
Step: 47900, Val_acc:0.926266
==================>
2017-11-11 14:15:02.483345 ---> Validation_loss: 0.197915
Step: 47910, Train_acc:0.968239
Step: 47910, Val_acc:0.899999
==================>
Step: 47920, Train_acc:0.971727
Step: 47920, Val_acc:0.935835
==================>
Step: 47930, Train_acc:0.956385
Step: 47930, Val_acc:0.920842
==================>
Step: 47940, Train_acc:0.981249
Step: 47940, Val_acc:0.936638
==================>
Step: 47950, Train_acc:0.971764
Step: 47950, Val_acc:0.956655
==================>
Step: 47960, Train_acc:0.975761
Step: 47960, Val_acc:0.938964
==================>
Step: 47970, Train_acc:0.976539
Step: 47970, Val_acc:0.927856
==================>
Step: 47980, Train_acc:0.96724
Step: 47980, Val_acc:0.923739
==================>
Step: 47990, Train_acc:0.979553
Step: 47990, Val_acc:0.940609
==================>
Step: 48000, Train_acc:0.96864
Step: 48000, Val_acc:0.93459
==================>
****************** Epochs completed: 96******************
2017-11-11 14:17:39.182653 ---> Validation_loss: 0.266883
Step: 48010, Train_acc:0.975215
Step: 48010, Val_acc:0.923815
==================>
Step: 48020, Train_acc:0.973033
Step: 48020, Val_acc:0.921982
==================>
Step: 48030, Train_acc:0.969471
Step: 48030, Val_acc:0.940541
==================>
Step: 48040, Train_acc:0.969388
Step: 48040, Val_acc:0.93915
==================>
Step: 48050, Train_acc:0.979445
Step: 48050, Val_acc:0.9312
==================>
Step: 48060, Train_acc:0.972152
Step: 48060, Val_acc:0.941467
==================>
Step: 48070, Train_acc:0.973374
Step: 48070, Val_acc:0.911666
==================>
Step: 48080, Train_acc:0.970205
Step: 48080, Val_acc:0.934629
==================>
Step: 48090, Train_acc:0.97962
Step: 48090, Val_acc:0.933981
==================>
Step: 48100, Train_acc:0.976534
Step: 48100, Val_acc:0.91002
==================>
2017-11-11 14:20:15.962502 ---> Validation_loss: 0.149268
Step: 48110, Train_acc:0.972235
Step: 48110, Val_acc:0.904053
==================>
Step: 48120, Train_acc:0.971688
Step: 48120, Val_acc:0.927551
==================>
Step: 48130, Train_acc:0.976255
Step: 48130, Val_acc:0.930792
==================>
Step: 48140, Train_acc:0.97994
Step: 48140, Val_acc:0.933849
==================>
Step: 48150, Train_acc:0.976656
Step: 48150, Val_acc:0.930416
==================>
Step: 48160, Train_acc:0.976152
Step: 48160, Val_acc:0.902865
==================>
Step: 48170, Train_acc:0.969167
Step: 48170, Val_acc:0.924026
==================>
Step: 48180, Train_acc:0.976525
Step: 48180, Val_acc:0.930836
==================>
Step: 48190, Train_acc:0.975929
Step: 48190, Val_acc:0.914545
==================>
Step: 48200, Train_acc:0.973301
Step: 48200, Val_acc:0.942909
==================>
2017-11-11 14:22:52.996073 ---> Validation_loss: 0.139949
Step: 48210, Train_acc:0.979293
Step: 48210, Val_acc:0.915343
==================>
Step: 48220, Train_acc:0.971367
Step: 48220, Val_acc:0.908303
==================>
Step: 48230, Train_acc:0.973687
Step: 48230, Val_acc:0.895747
==================>
Step: 48240, Train_acc:0.965763
Step: 48240, Val_acc:0.906491
==================>
Step: 48250, Train_acc:0.978154
Step: 48250, Val_acc:0.930352
==================>
Step: 48260, Train_acc:0.982783
Step: 48260, Val_acc:0.919788
==================>
Step: 48270, Train_acc:0.979895
Step: 48270, Val_acc:0.895223
==================>
Step: 48280, Train_acc:0.97589
Step: 48280, Val_acc:0.927086
==================>
Step: 48290, Train_acc:0.976411
Step: 48290, Val_acc:0.905282
==================>
Step: 48300, Train_acc:0.970055
Step: 48300, Val_acc:0.910541
==================>
2017-11-11 14:25:30.059375 ---> Validation_loss: 0.194124
Step: 48310, Train_acc:0.975027
Step: 48310, Val_acc:0.922169
==================>
Step: 48320, Train_acc:0.974772
Step: 48320, Val_acc:0.925364
==================>
Step: 48330, Train_acc:0.963179
Step: 48330, Val_acc:0.924746
==================>
Step: 48340, Train_acc:0.983617
Step: 48340, Val_acc:0.949543
==================>
Step: 48350, Train_acc:0.968275
Step: 48350, Val_acc:0.944474
==================>
Step: 48360, Train_acc:0.970171
Step: 48360, Val_acc:0.931831
==================>
Step: 48370, Train_acc:0.97741
Step: 48370, Val_acc:0.929653
==================>
Step: 48380, Train_acc:0.978822
Step: 48380, Val_acc:0.93176
==================>
Step: 48390, Train_acc:0.98173
Step: 48390, Val_acc:0.901024
==================>
Step: 48400, Train_acc:0.981783
Step: 48400, Val_acc:0.906897
==================>
2017-11-11 14:28:07.434217 ---> Validation_loss: 0.133197
Step: 48410, Train_acc:0.975731
Step: 48410, Val_acc:0.918099
==================>
Step: 48420, Train_acc:0.973827
Step: 48420, Val_acc:0.919871
==================>
Step: 48430, Train_acc:0.968752
Step: 48430, Val_acc:0.926913
==================>
Step: 48440, Train_acc:0.969036
Step: 48440, Val_acc:0.921716
==================>
Step: 48450, Train_acc:0.974548
Step: 48450, Val_acc:0.927781
==================>
Step: 48460, Train_acc:0.974253
Step: 48460, Val_acc:0.878361
==================>
Step: 48470, Train_acc:0.972222
Step: 48470, Val_acc:0.943657
==================>
Step: 48480, Train_acc:0.972397
Step: 48480, Val_acc:0.928724
==================>
Step: 48490, Train_acc:0.978846
Step: 48490, Val_acc:0.955751
==================>
Step: 48500, Train_acc:0.976963
Step: 48500, Val_acc:0.937157
==================>
****************** Epochs completed: 97******************
2017-11-11 14:30:44.354277 ---> Validation_loss: 0.171338
Step: 48510, Train_acc:0.977518
Step: 48510, Val_acc:0.919601
==================>
Step: 48520, Train_acc:0.978153
Step: 48520, Val_acc:0.922341
==================>
Step: 48530, Train_acc:0.975781
Step: 48530, Val_acc:0.94257
==================>
Step: 48540, Train_acc:0.977166
Step: 48540, Val_acc:0.938768
==================>
Step: 48550, Train_acc:0.976604
Step: 48550, Val_acc:0.941147
==================>
Step: 48560, Train_acc:0.974524
Step: 48560, Val_acc:0.922941
==================>
Step: 48570, Train_acc:0.969596
Step: 48570, Val_acc:0.934132
==================>
Step: 48580, Train_acc:0.976953
Step: 48580, Val_acc:0.911431
==================>
Step: 48590, Train_acc:0.973262
Step: 48590, Val_acc:0.940594
==================>
Step: 48600, Train_acc:0.978086
Step: 48600, Val_acc:0.93847
==================>
2017-11-11 14:33:21.855238 ---> Validation_loss: 0.159111
Step: 48610, Train_acc:0.970989
Step: 48610, Val_acc:0.933853
==================>
Step: 48620, Train_acc:0.981744
Step: 48620, Val_acc:0.910634
==================>
Step: 48630, Train_acc:0.964021
Step: 48630, Val_acc:0.920103
==================>
Step: 48640, Train_acc:0.976884
Step: 48640, Val_acc:0.942269
==================>
Step: 48650, Train_acc:0.976398
Step: 48650, Val_acc:0.915784
==================>
Step: 48660, Train_acc:0.964366
Step: 48660, Val_acc:0.91908
==================>
Step: 48670, Train_acc:0.981118
Step: 48670, Val_acc:0.922444
==================>
Step: 48680, Train_acc:0.979784
Step: 48680, Val_acc:0.885531
==================>
Step: 48690, Train_acc:0.970649
Step: 48690, Val_acc:0.935635
==================>
Step: 48700, Train_acc:0.974235
Step: 48700, Val_acc:0.916217
==================>
2017-11-11 14:35:58.441457 ---> Validation_loss: 0.132283
Step: 48710, Train_acc:0.972056
Step: 48710, Val_acc:0.949857
==================>
Step: 48720, Train_acc:0.972539
Step: 48720, Val_acc:0.952378
==================>
Step: 48730, Train_acc:0.971541
Step: 48730, Val_acc:0.927515
==================>
Step: 48740, Train_acc:0.972561
Step: 48740, Val_acc:0.938011
==================>
Step: 48750, Train_acc:0.976389
Step: 48750, Val_acc:0.918489
==================>
Step: 48760, Train_acc:0.977646
Step: 48760, Val_acc:0.920164
==================>
Step: 48770, Train_acc:0.966802
Step: 48770, Val_acc:0.934065
==================>
Step: 48780, Train_acc:0.974552
Step: 48780, Val_acc:0.940618
==================>
Step: 48790, Train_acc:0.979155
Step: 48790, Val_acc:0.936879
==================>
Step: 48800, Train_acc:0.976025
Step: 48800, Val_acc:0.925839
==================>
2017-11-11 14:38:35.439325 ---> Validation_loss: 0.159257
Step: 48810, Train_acc:0.977388
Step: 48810, Val_acc:0.900918
==================>
Step: 48820, Train_acc:0.978912
Step: 48820, Val_acc:0.904313
==================>
Step: 48830, Train_acc:0.970496
Step: 48830, Val_acc:0.916992
==================>
Step: 48840, Train_acc:0.969303
Step: 48840, Val_acc:0.945524
==================>
Step: 48850, Train_acc:0.973325
Step: 48850, Val_acc:0.933953
==================>
Step: 48860, Train_acc:0.969819
Step: 48860, Val_acc:0.939613
==================>
Step: 48870, Train_acc:0.960355
Step: 48870, Val_acc:0.893558
==================>
Step: 48880, Train_acc:0.96489
Step: 48880, Val_acc:0.928229
==================>
Step: 48890, Train_acc:0.975248
Step: 48890, Val_acc:0.927534
==================>
Step: 48900, Train_acc:0.971013
Step: 48900, Val_acc:0.91798
==================>
2017-11-11 14:41:12.179316 ---> Validation_loss: 0.303046
Step: 48910, Train_acc:0.959773
Step: 48910, Val_acc:0.921409
==================>
Step: 48920, Train_acc:0.970332
Step: 48920, Val_acc:0.922571
==================>
Step: 48930, Train_acc:0.971707
Step: 48930, Val_acc:0.922476
==================>
Step: 48940, Train_acc:0.968065
Step: 48940, Val_acc:0.917697
==================>
Step: 48950, Train_acc:0.980363
Step: 48950, Val_acc:0.905731
==================>
Step: 48960, Train_acc:0.97703
Step: 48960, Val_acc:0.927836
==================>
Step: 48970, Train_acc:0.975387
Step: 48970, Val_acc:0.929092
==================>
Step: 48980, Train_acc:0.975707
Step: 48980, Val_acc:0.937028
==================>
Step: 48990, Train_acc:0.971491
Step: 48990, Val_acc:0.914518
==================>
Step: 49000, Train_acc:0.974636
Step: 49000, Val_acc:0.938322
==================>
****************** Epochs completed: 98******************
2017-11-11 14:43:49.340157 ---> Validation_loss: 0.163116
Step: 49010, Train_acc:0.965173
Step: 49010, Val_acc:0.931167
==================>
Step: 49020, Train_acc:0.972491
Step: 49020, Val_acc:0.922085
==================>
Step: 49030, Train_acc:0.971382
Step: 49030, Val_acc:0.933101
==================>
Step: 49040, Train_acc:0.96615
Step: 49040, Val_acc:0.930631
==================>
Step: 49050, Train_acc:0.965979
Step: 49050, Val_acc:0.910254
==================>
Step: 49060, Train_acc:0.977477
Step: 49060, Val_acc:0.950438
==================>
Step: 49070, Train_acc:0.971141
Step: 49070, Val_acc:0.920493
==================>
Step: 49080, Train_acc:0.965087
Step: 49080, Val_acc:0.929337
==================>
Step: 49090, Train_acc:0.969708
Step: 49090, Val_acc:0.910902
==================>
Step: 49100, Train_acc:0.975729
Step: 49100, Val_acc:0.914675
==================>
2017-11-11 14:46:26.406151 ---> Validation_loss: 0.141207
Step: 49110, Train_acc:0.966852
Step: 49110, Val_acc:0.944236
==================>
Step: 49120, Train_acc:0.972825
Step: 49120, Val_acc:0.955642
==================>
Step: 49130, Train_acc:0.964387
Step: 49130, Val_acc:0.941971
==================>
Step: 49140, Train_acc:0.979674
Step: 49140, Val_acc:0.924755
==================>
Step: 49150, Train_acc:0.971954
Step: 49150, Val_acc:0.932653
==================>
Step: 49160, Train_acc:0.971691
Step: 49160, Val_acc:0.958113
==================>
Step: 49170, Train_acc:0.97446
Step: 49170, Val_acc:0.938781
==================>
Step: 49180, Train_acc:0.967928
Step: 49180, Val_acc:0.917057
==================>
Step: 49190, Train_acc:0.978987
Step: 49190, Val_acc:0.949568
==================>
Step: 49200, Train_acc:0.962119
Step: 49200, Val_acc:0.93501
==================>
2017-11-11 14:49:04.204511 ---> Validation_loss: 0.21513
Step: 49210, Train_acc:0.975901
Step: 49210, Val_acc:0.934366
==================>
Step: 49220, Train_acc:0.97425
Step: 49220, Val_acc:0.916018
==================>
Step: 49230, Train_acc:0.970707
Step: 49230, Val_acc:0.912173
==================>
Step: 49240, Train_acc:0.977162
Step: 49240, Val_acc:0.941744
==================>
Step: 49250, Train_acc:0.972849
Step: 49250, Val_acc:0.938271
==================>
Step: 49260, Train_acc:0.97312
Step: 49260, Val_acc:0.92632
==================>
Step: 49270, Train_acc:0.971644
Step: 49270, Val_acc:0.940017
==================>
Step: 49280, Train_acc:0.961135
Step: 49280, Val_acc:0.933059
==================>
Step: 49290, Train_acc:0.968331
Step: 49290, Val_acc:0.929993
==================>
Step: 49300, Train_acc:0.977791
Step: 49300, Val_acc:0.913766
==================>
2017-11-11 14:51:41.421525 ---> Validation_loss: 0.191777
Step: 49310, Train_acc:0.96978
Step: 49310, Val_acc:0.931598
==================>
Step: 49320, Train_acc:0.963062
Step: 49320, Val_acc:0.913771
==================>
Step: 49330, Train_acc:0.979562
Step: 49330, Val_acc:0.937647
==================>
Step: 49340, Train_acc:0.964711
Step: 49340, Val_acc:0.916078
==================>
Step: 49350, Train_acc:0.976044
Step: 49350, Val_acc:0.909279
==================>
Step: 49360, Train_acc:0.965663
Step: 49360, Val_acc:0.929297
==================>
Step: 49370, Train_acc:0.971775
Step: 49370, Val_acc:0.903107
==================>
Step: 49380, Train_acc:0.977048
Step: 49380, Val_acc:0.93528
==================>
Step: 49390, Train_acc:0.977261
Step: 49390, Val_acc:0.929614
==================>
Step: 49400, Train_acc:0.972596
Step: 49400, Val_acc:0.926294
==================>
2017-11-11 14:54:18.629349 ---> Validation_loss: 0.190912
Step: 49410, Train_acc:0.972489
Step: 49410, Val_acc:0.934939
==================>
Step: 49420, Train_acc:0.96892
Step: 49420, Val_acc:0.914692
==================>
Step: 49430, Train_acc:0.973879
Step: 49430, Val_acc:0.913546
==================>
Step: 49440, Train_acc:0.975909
Step: 49440, Val_acc:0.934941
==================>
Step: 49450, Train_acc:0.972203
Step: 49450, Val_acc:0.914073
==================>
Step: 49460, Train_acc:0.974214
Step: 49460, Val_acc:0.90865
==================>
Step: 49470, Train_acc:0.968417
Step: 49470, Val_acc:0.916069
==================>
Step: 49480, Train_acc:0.971034
Step: 49480, Val_acc:0.901537
==================>
Step: 49490, Train_acc:0.97636
Step: 49490, Val_acc:0.93213
==================>
Step: 49500, Train_acc:0.977235
Step: 49500, Val_acc:0.924557
==================>
****************** Epochs completed: 99******************
2017-11-11 14:56:56.090408 ---> Validation_loss: 0.128111
Step: 49510, Train_acc:0.974655
Step: 49510, Val_acc:0.920596
==================>
Step: 49520, Train_acc:0.970005
Step: 49520, Val_acc:0.920543
==================>
Step: 49530, Train_acc:0.977961
Step: 49530, Val_acc:0.885521
==================>
Step: 49540, Train_acc:0.972797
Step: 49540, Val_acc:0.917098
==================>
Step: 49550, Train_acc:0.980505
Step: 49550, Val_acc:0.936032
==================>
Step: 49560, Train_acc:0.972358
Step: 49560, Val_acc:0.928273
==================>
Step: 49570, Train_acc:0.977522
Step: 49570, Val_acc:0.903334
==================>
Step: 49580, Train_acc:0.97822
Step: 49580, Val_acc:0.897875
==================>
Step: 49590, Train_acc:0.979083
Step: 49590, Val_acc:0.911752
==================>
Step: 49600, Train_acc:0.971687
Step: 49600, Val_acc:0.943363
==================>
2017-11-11 14:59:33.418366 ---> Validation_loss: 0.165785
Step: 49610, Train_acc:0.973339
Step: 49610, Val_acc:0.93285
==================>
Step: 49620, Train_acc:0.966165
Step: 49620, Val_acc:0.932502
==================>
Step: 49630, Train_acc:0.975995
Step: 49630, Val_acc:0.938214
==================>
Step: 49640, Train_acc:0.979228
Step: 49640, Val_acc:0.918352
==================>
Step: 49650, Train_acc:0.980655
Step: 49650, Val_acc:0.910004
==================>
Step: 49660, Train_acc:0.974552
Step: 49660, Val_acc:0.921852
==================>
Step: 49670, Train_acc:0.973385
Step: 49670, Val_acc:0.886238
==================>
Step: 49680, Train_acc:0.970115
Step: 49680, Val_acc:0.924631
==================>
Step: 49690, Train_acc:0.971636
Step: 49690, Val_acc:0.894875
==================>
Step: 49700, Train_acc:0.970853
Step: 49700, Val_acc:0.910641
==================>
2017-11-11 15:02:10.746277 ---> Validation_loss: 0.179801
Step: 49710, Train_acc:0.979772
Step: 49710, Val_acc:0.940211
==================>
Step: 49720, Train_acc:0.978506
Step: 49720, Val_acc:0.935737
==================>
Step: 49730, Train_acc:0.98158
Step: 49730, Val_acc:0.920336
==================>
Step: 49740, Train_acc:0.97554
Step: 49740, Val_acc:0.917792
==================>
Step: 49750, Train_acc:0.97499
Step: 49750, Val_acc:0.894971
==================>
Step: 49760, Train_acc:0.967228
Step: 49760, Val_acc:0.920719
==================>
Step: 49770, Train_acc:0.97631
Step: 49770, Val_acc:0.922123
==================>
Step: 49780, Train_acc:0.973059
Step: 49780, Val_acc:0.919973
==================>
Step: 49790, Train_acc:0.966266
Step: 49790, Val_acc:0.938474
==================>
Step: 49800, Train_acc:0.972297
Step: 49800, Val_acc:0.941854
==================>
2017-11-11 15:04:47.578897 ---> Validation_loss: 0.265239
Step: 49810, Train_acc:0.972491
Step: 49810, Val_acc:0.931779
==================>
Step: 49820, Train_acc:0.970962
Step: 49820, Val_acc:0.920957
==================>
Step: 49830, Train_acc:0.974891
Step: 49830, Val_acc:0.927489
==================>
Step: 49840, Train_acc:0.968738
Step: 49840, Val_acc:0.915518
==================>
Step: 49850, Train_acc:0.971981
Step: 49850, Val_acc:0.950481
==================>
Step: 49860, Train_acc:0.974601
Step: 49860, Val_acc:0.939351
==================>
Step: 49870, Train_acc:0.970151
Step: 49870, Val_acc:0.915326
==================>
Step: 49880, Train_acc:0.973429
Step: 49880, Val_acc:0.922445
==================>
Step: 49890, Train_acc:0.975281
Step: 49890, Val_acc:0.942594
==================>
Step: 49900, Train_acc:0.978893
Step: 49900, Val_acc:0.925159
==================>
2017-11-11 15:07:24.606959 ---> Validation_loss: 0.148025
Step: 49910, Train_acc:0.966127
Step: 49910, Val_acc:0.919585
==================>
Step: 49920, Train_acc:0.971976
Step: 49920, Val_acc:0.949552
==================>
Step: 49930, Train_acc:0.974049
Step: 49930, Val_acc:0.940974
==================>
Step: 49940, Train_acc:0.978213
Step: 49940, Val_acc:0.929822
==================>
Step: 49950, Train_acc:0.970808
Step: 49950, Val_acc:0.905841
==================>
Step: 49960, Train_acc:0.976923
Step: 49960, Val_acc:0.933303
==================>
Step: 49970, Train_acc:0.972544
Step: 49970, Val_acc:0.939137
==================>
Step: 49980, Train_acc:0.971359
Step: 49980, Val_acc:0.920663
==================>
Step: 49990, Train_acc:0.971724
Step: 49990, Val_acc:0.945778
==================>
Step: 50000, Train_acc:0.979764
Step: 50000, Val_acc:0.941569
==================>
****************** Epochs completed: 100******************
2017-11-11 15:10:01.301791 ---> Validation_loss: 0.222937
Step: 50010, Train_acc:0.9735
Step: 50010, Val_acc:0.935608
==================>
Step: 50020, Train_acc:0.978484
Step: 50020, Val_acc:0.911237
==================>
Step: 50030, Train_acc:0.968555
Step: 50030, Val_acc:0.949003
==================>
Step: 50040, Train_acc:0.969487
Step: 50040, Val_acc:0.919613
==================>
Step: 50050, Train_acc:0.977687
Step: 50050, Val_acc:0.911763
==================>
Step: 50060, Train_acc:0.96421
Step: 50060, Val_acc:0.93761
==================>
Step: 50070, Train_acc:0.97939
Step: 50070, Val_acc:0.947539
==================>
Step: 50080, Train_acc:0.980819
Step: 50080, Val_acc:0.908375
==================>
Step: 50090, Train_acc:0.97897
Step: 50090, Val_acc:0.937676
==================>
Step: 50100, Train_acc:0.977377
Step: 50100, Val_acc:0.938741
==================>
2017-11-11 15:12:38.328227 ---> Validation_loss: 0.114779
Step: 50110, Train_acc:0.977911
Step: 50110, Val_acc:0.92509
==================>
Step: 50120, Train_acc:0.971814
Step: 50120, Val_acc:0.921899
==================>
Step: 50130, Train_acc:0.973905
Step: 50130, Val_acc:0.939729
==================>
Step: 50140, Train_acc:0.973113
Step: 50140, Val_acc:0.907817
==================>
Step: 50150, Train_acc:0.968524
Step: 50150, Val_acc:0.905178
==================>
Step: 50160, Train_acc:0.966572
Step: 50160, Val_acc:0.925541
==================>
Step: 50170, Train_acc:0.969246
Step: 50170, Val_acc:0.933555
==================>
Step: 50180, Train_acc:0.971058
Step: 50180, Val_acc:0.93407
==================>
Step: 50190, Train_acc:0.973339
Step: 50190, Val_acc:0.927982
==================>
Step: 50200, Train_acc:0.978099
Step: 50200, Val_acc:0.920233
==================>
2017-11-11 15:15:15.128968 ---> Validation_loss: 0.243579
Step: 50210, Train_acc:0.972672
Step: 50210, Val_acc:0.912025
==================>
Step: 50220, Train_acc:0.977889
Step: 50220, Val_acc:0.925109
==================>
Step: 50230, Train_acc:0.97012
Step: 50230, Val_acc:0.927603
==================>
Step: 50240, Train_acc:0.981294
Step: 50240, Val_acc:0.924282
==================>
Step: 50250, Train_acc:0.976642
Step: 50250, Val_acc:0.930375
==================>
Step: 50260, Train_acc:0.975759
Step: 50260, Val_acc:0.939764
==================>
Step: 50270, Train_acc:0.966575
Step: 50270, Val_acc:0.923707
==================>
Step: 50280, Train_acc:0.968071
Step: 50280, Val_acc:0.925072
==================>
Step: 50290, Train_acc:0.977512
Step: 50290, Val_acc:0.933082
==================>
Step: 50300, Train_acc:0.968959
Step: 50300, Val_acc:0.927214
==================>
2017-11-11 15:17:52.071510 ---> Validation_loss: 0.148532
Step: 50310, Train_acc:0.976594
Step: 50310, Val_acc:0.922164
==================>
Step: 50320, Train_acc:0.979196
Step: 50320, Val_acc:0.950039
==================>
Step: 50330, Train_acc:0.965643
Step: 50330, Val_acc:0.936478
==================>
Step: 50340, Train_acc:0.974846
Step: 50340, Val_acc:0.951331
==================>
Step: 50350, Train_acc:0.973051
Step: 50350, Val_acc:0.931097
==================>
Step: 50360, Train_acc:0.974543
Step: 50360, Val_acc:0.912052
==================>
Step: 50370, Train_acc:0.970641
Step: 50370, Val_acc:0.93205
==================>
Step: 50380, Train_acc:0.982755
Step: 50380, Val_acc:0.933552
==================>
Step: 50390, Train_acc:0.980646
Step: 50390, Val_acc:0.928452
==================>
Step: 50400, Train_acc:0.978942
Step: 50400, Val_acc:0.93491
==================>
2017-11-11 15:20:28.948384 ---> Validation_loss: 0.224263
Step: 50410, Train_acc:0.968965
Step: 50410, Val_acc:0.924424
==================>
Step: 50420, Train_acc:0.975345
Step: 50420, Val_acc:0.940862
==================>
Step: 50430, Train_acc:0.977001
Step: 50430, Val_acc:0.892244
==================>
Step: 50440, Train_acc:0.97248
Step: 50440, Val_acc:0.927072
==================>
Step: 50450, Train_acc:0.975603
Step: 50450, Val_acc:0.930162
==================>
****************** Epochs completed: 15******************
Step: 50460, Train_acc:0.968826
Step: 50460, Val_acc:0.928466
==================>
Step: 50470, Train_acc:0.968726
Step: 50470, Val_acc:0.936311
==================>
Step: 50480, Train_acc:0.974458
Step: 50480, Val_acc:0.942783
==================>
Step: 50490, Train_acc:0.98225
Step: 50490, Val_acc:0.91731
==================>
Step: 50500, Train_acc:0.975552
Step: 50500, Val_acc:0.937733
==================>
****************** Epochs completed: 101******************
2017-11-11 15:23:05.309881 ---> Validation_loss: 0.150235
Step: 50510, Train_acc:0.979523
Step: 50510, Val_acc:0.949193
==================>
Step: 50520, Train_acc:0.974564
Step: 50520, Val_acc:0.899619
==================>
Step: 50530, Train_acc:0.977261
Step: 50530, Val_acc:0.933918
==================>
Step: 50540, Train_acc:0.976423
Step: 50540, Val_acc:0.897336
==================>
Step: 50550, Train_acc:0.970327
Step: 50550, Val_acc:0.912039
==================>
Step: 50560, Train_acc:0.981125
Step: 50560, Val_acc:0.91458
==================>
Step: 50570, Train_acc:0.976005
Step: 50570, Val_acc:0.921041
==================>
Step: 50580, Train_acc:0.972487
Step: 50580, Val_acc:0.918569
==================>
Step: 50590, Train_acc:0.977344
Step: 50590, Val_acc:0.923982
==================>
Step: 50600, Train_acc:0.979731
Step: 50600, Val_acc:0.937327
==================>
2017-11-11 15:25:41.829356 ---> Validation_loss: 0.140674
Step: 50610, Train_acc:0.967461
Step: 50610, Val_acc:0.895802
==================>
Step: 50620, Train_acc:0.983917
Step: 50620, Val_acc:0.928707
==================>
Step: 50630, Train_acc:0.975386
Step: 50630, Val_acc:0.936766
==================>
Step: 50640, Train_acc:0.978956
Step: 50640, Val_acc:0.920889
==================>
Step: 50650, Train_acc:0.986044
Step: 50650, Val_acc:0.932445
==================>
Step: 50660, Train_acc:0.981522
Step: 50660, Val_acc:0.951584
==================>
Step: 50670, Train_acc:0.978185
Step: 50670, Val_acc:0.909485
==================>
Step: 50680, Train_acc:0.978037
Step: 50680, Val_acc:0.93126
==================>
Step: 50690, Train_acc:0.97946
Step: 50690, Val_acc:0.932451
==================>
Step: 50700, Train_acc:0.972618
Step: 50700, Val_acc:0.935452
==================>
2017-11-11 15:28:18.021552 ---> Validation_loss: 0.165617
Step: 50710, Train_acc:0.977543
Step: 50710, Val_acc:0.911287
==================>
Step: 50720, Train_acc:0.970004
Step: 50720, Val_acc:0.938668
==================>
Step: 50730, Train_acc:0.976259
Step: 50730, Val_acc:0.914081
==================>
Step: 50740, Train_acc:0.97967
Step: 50740, Val_acc:0.92504
==================>
Step: 50750, Train_acc:0.978812
Step: 50750, Val_acc:0.943519
==================>
Step: 50760, Train_acc:0.982267
Step: 50760, Val_acc:0.928096
==================>
Step: 50770, Train_acc:0.977356
Step: 50770, Val_acc:0.922816
==================>
Step: 50780, Train_acc:0.977412
Step: 50780, Val_acc:0.906721
==================>
Step: 50790, Train_acc:0.972743
Step: 50790, Val_acc:0.939
==================>
Step: 50800, Train_acc:0.979438
Step: 50800, Val_acc:0.929244
==================>
2017-11-11 15:30:54.423090 ---> Validation_loss: 0.242953
Step: 50810, Train_acc:0.965217
Step: 50810, Val_acc:0.920386
==================>
Step: 50820, Train_acc:0.978522
Step: 50820, Val_acc:0.932455
==================>
Step: 50830, Train_acc:0.971587
Step: 50830, Val_acc:0.920501
==================>
Step: 50840, Train_acc:0.982286
Step: 50840, Val_acc:0.940842
==================>
Step: 50850, Train_acc:0.977246
Step: 50850, Val_acc:0.898478
==================>
Step: 50860, Train_acc:0.975214
Step: 50860, Val_acc:0.917529
==================>
Step: 50870, Train_acc:0.978453
Step: 50870, Val_acc:0.921235
==================>
Step: 50880, Train_acc:0.980958
Step: 50880, Val_acc:0.914365
==================>
Step: 50890, Train_acc:0.978623
Step: 50890, Val_acc:0.924073
==================>
Step: 50900, Train_acc:0.981638
Step: 50900, Val_acc:0.899984
==================>
2017-11-11 15:33:30.855214 ---> Validation_loss: 0.237493
Step: 50910, Train_acc:0.974446
Step: 50910, Val_acc:0.932999
==================>
Step: 50920, Train_acc:0.973035
Step: 50920, Val_acc:0.928984
==================>
Step: 50930, Train_acc:0.977996
Step: 50930, Val_acc:0.929005
==================>
Step: 50940, Train_acc:0.979358
Step: 50940, Val_acc:0.933248
==================>
Step: 50950, Train_acc:0.972131
Step: 50950, Val_acc:0.951609
==================>
Step: 50960, Train_acc:0.983278
Step: 50960, Val_acc:0.941365
==================>
Step: 50970, Train_acc:0.971499
Step: 50970, Val_acc:0.940588
==================>
Step: 50980, Train_acc:0.978202
Step: 50980, Val_acc:0.93825
==================>
Step: 50990, Train_acc:0.980531
Step: 50990, Val_acc:0.91802
==================>
Step: 51000, Train_acc:0.966427
Step: 51000, Val_acc:0.934977
==================>
****************** Epochs completed: 102******************
2017-11-11 15:36:07.390019 ---> Validation_loss: 0.186813
Step: 51010, Train_acc:0.974148
Step: 51010, Val_acc:0.896357
==================>
Step: 51020, Train_acc:0.979983
Step: 51020, Val_acc:0.920261
==================>
Step: 51030, Train_acc:0.969016
Step: 51030, Val_acc:0.928882
==================>
Step: 51040, Train_acc:0.971967
Step: 51040, Val_acc:0.941375
==================>
Step: 51050, Train_acc:0.972404
Step: 51050, Val_acc:0.926849
==================>
Step: 51060, Train_acc:0.965895
Step: 51060, Val_acc:0.906942
==================>
Step: 51070, Train_acc:0.979779
Step: 51070, Val_acc:0.919703
==================>
Step: 51080, Train_acc:0.970377
Step: 51080, Val_acc:0.896605
==================>
Step: 51090, Train_acc:0.977092
Step: 51090, Val_acc:0.914205
==================>
Step: 51100, Train_acc:0.977765
Step: 51100, Val_acc:0.9315
==================>
2017-11-11 15:38:43.818493 ---> Validation_loss: 0.137921
Step: 51110, Train_acc:0.967994
Step: 51110, Val_acc:0.923868
==================>
Step: 51120, Train_acc:0.976262
Step: 51120, Val_acc:0.925463
==================>
Step: 51130, Train_acc:0.970234
Step: 51130, Val_acc:0.930891
==================>
Step: 51140, Train_acc:0.978347
Step: 51140, Val_acc:0.949944
==================>
Step: 51150, Train_acc:0.972564
Step: 51150, Val_acc:0.951237
==================>
Step: 51160, Train_acc:0.978712
Step: 51160, Val_acc:0.940847
==================>
Step: 51170, Train_acc:0.97276
Step: 51170, Val_acc:0.947222
==================>
Step: 51180, Train_acc:0.972106
Step: 51180, Val_acc:0.933737
==================>
Step: 51190, Train_acc:0.969741
Step: 51190, Val_acc:0.904183
==================>
Step: 51200, Train_acc:0.979437
Step: 51200, Val_acc:0.948058
==================>
2017-11-11 15:41:20.311039 ---> Validation_loss: 0.204749
Step: 51210, Train_acc:0.973658
Step: 51210, Val_acc:0.941404
==================>
Step: 51220, Train_acc:0.977017
Step: 51220, Val_acc:0.904717
==================>
Step: 51230, Train_acc:0.979181
Step: 51230, Val_acc:0.924301
==================>
Step: 51240, Train_acc:0.977845
Step: 51240, Val_acc:0.942523
==================>
Step: 51250, Train_acc:0.981078
Step: 51250, Val_acc:0.915277
==================>
Step: 51260, Train_acc:0.977765
Step: 51260, Val_acc:0.912958
==================>
Step: 51270, Train_acc:0.974067
Step: 51270, Val_acc:0.925149
==================>
Step: 51280, Train_acc:0.972932
Step: 51280, Val_acc:0.951912
==================>
Step: 51290, Train_acc:0.977074
Step: 51290, Val_acc:0.930233
==================>
Step: 51300, Train_acc:0.97762
Step: 51300, Val_acc:0.927379
==================>
2017-11-11 15:43:56.703438 ---> Validation_loss: 0.168266
Step: 51310, Train_acc:0.97548
Step: 51310, Val_acc:0.923151
==================>
Step: 51320, Train_acc:0.973009
Step: 51320, Val_acc:0.917135
==================>
Step: 51330, Train_acc:0.976471
Step: 51330, Val_acc:0.945678
==================>
Step: 51340, Train_acc:0.974133
Step: 51340, Val_acc:0.90074
==================>
Step: 51350, Train_acc:0.976685
Step: 51350, Val_acc:0.92441
==================>
Step: 51360, Train_acc:0.98141
Step: 51360, Val_acc:0.935876
==================>
Step: 51370, Train_acc:0.969835
Step: 51370, Val_acc:0.946144
==================>
Step: 51380, Train_acc:0.980773
Step: 51380, Val_acc:0.928794
==================>
Step: 51390, Train_acc:0.971914
Step: 51390, Val_acc:0.937863
==================>
Step: 51400, Train_acc:0.972306
Step: 51400, Val_acc:0.916025
==================>
2017-11-11 15:46:33.373983 ---> Validation_loss: 0.181286
Step: 51410, Train_acc:0.966143
Step: 51410, Val_acc:0.89704
==================>
Step: 51420, Train_acc:0.978662
Step: 51420, Val_acc:0.942084
==================>
Step: 51430, Train_acc:0.970145
Step: 51430, Val_acc:0.936532
==================>
Step: 51440, Train_acc:0.957078
Step: 51440, Val_acc:0.928632
==================>
Step: 51450, Train_acc:0.96308
Step: 51450, Val_acc:0.927762
==================>
Step: 51460, Train_acc:0.972618
Step: 51460, Val_acc:0.92798
==================>
Step: 51470, Train_acc:0.982673
Step: 51470, Val_acc:0.935992
==================>
Step: 51480, Train_acc:0.976326
Step: 51480, Val_acc:0.913041
==================>
Step: 51490, Train_acc:0.975536
Step: 51490, Val_acc:0.929885
==================>
Step: 51500, Train_acc:0.978394
Step: 51500, Val_acc:0.929127
==================>
****************** Epochs completed: 103******************
2017-11-11 15:49:09.770717 ---> Validation_loss: 0.272563
Step: 51510, Train_acc:0.970118
Step: 51510, Val_acc:0.921809
==================>
Step: 51520, Train_acc:0.975914
Step: 51520, Val_acc:0.927859
==================>
Step: 51530, Train_acc:0.982137
Step: 51530, Val_acc:0.927841
==================>
Step: 51540, Train_acc:0.977264
Step: 51540, Val_acc:0.897859
==================>
Step: 51550, Train_acc:0.96673
Step: 51550, Val_acc:0.952433
==================>
Step: 51560, Train_acc:0.971941
Step: 51560, Val_acc:0.948877
==================>
Step: 51570, Train_acc:0.980013
Step: 51570, Val_acc:0.901257
==================>
Step: 51580, Train_acc:0.967848
Step: 51580, Val_acc:0.946814
==================>
Step: 51590, Train_acc:0.983236
Step: 51590, Val_acc:0.925709
==================>
Step: 51600, Train_acc:0.984028
Step: 51600, Val_acc:0.942988
==================>
2017-11-11 15:51:46.328094 ---> Validation_loss: 0.149914
Step: 51610, Train_acc:0.968359
Step: 51610, Val_acc:0.922911
==================>
Step: 51620, Train_acc:0.978026
Step: 51620, Val_acc:0.947119
==================>
Step: 51630, Train_acc:0.976769
Step: 51630, Val_acc:0.935898
==================>
Step: 51640, Train_acc:0.978722
Step: 51640, Val_acc:0.933076
==================>
Step: 51650, Train_acc:0.972201
Step: 51650, Val_acc:0.934606
==================>
Step: 51660, Train_acc:0.971188
Step: 51660, Val_acc:0.921477
==================>
Step: 51670, Train_acc:0.972659
Step: 51670, Val_acc:0.92219
==================>
Step: 51680, Train_acc:0.96746
Step: 51680, Val_acc:0.918903
==================>
Step: 51690, Train_acc:0.977559
Step: 51690, Val_acc:0.921707
==================>
Step: 51700, Train_acc:0.97095
Step: 51700, Val_acc:0.900914
==================>
2017-11-11 15:54:22.905165 ---> Validation_loss: 0.114847
Step: 51710, Train_acc:0.96998
Step: 51710, Val_acc:0.940244
==================>
Step: 51720, Train_acc:0.982354
Step: 51720, Val_acc:0.926658
==================>
Step: 51730, Train_acc:0.974876
Step: 51730, Val_acc:0.922941
==================>
Step: 51740, Train_acc:0.980261
Step: 51740, Val_acc:0.901412
==================>
Step: 51750, Train_acc:0.962615
Step: 51750, Val_acc:0.941312
==================>
Step: 51760, Train_acc:0.972157
Step: 51760, Val_acc:0.936909
==================>
Step: 51770, Train_acc:0.974966
Step: 51770, Val_acc:0.93099
==================>
Step: 51780, Train_acc:0.973271
Step: 51780, Val_acc:0.924983
==================>
Step: 51790, Train_acc:0.974172
Step: 51790, Val_acc:0.929076
==================>
Step: 51800, Train_acc:0.975155
Step: 51800, Val_acc:0.925591
==================>
2017-11-11 15:56:59.459668 ---> Validation_loss: 0.177714
Step: 51810, Train_acc:0.976866
Step: 51810, Val_acc:0.934851
==================>
Step: 51820, Train_acc:0.973826
Step: 51820, Val_acc:0.934395
==================>
Step: 51830, Train_acc:0.97618
Step: 51830, Val_acc:0.935066
==================>
Step: 51840, Train_acc:0.97382
Step: 51840, Val_acc:0.917173
==================>
Step: 51850, Train_acc:0.980623
Step: 51850, Val_acc:0.91819
==================>
Step: 51860, Train_acc:0.976035
Step: 51860, Val_acc:0.901473
==================>
Step: 51870, Train_acc:0.975881
Step: 51870, Val_acc:0.927671
==================>
Step: 51880, Train_acc:0.976096
Step: 51880, Val_acc:0.919543
==================>
Step: 51890, Train_acc:0.97282
Step: 51890, Val_acc:0.921713
==================>
Step: 51900, Train_acc:0.982114
Step: 51900, Val_acc:0.92093
==================>
2017-11-11 15:59:35.921626 ---> Validation_loss: 0.245656
Step: 51910, Train_acc:0.972395
Step: 51910, Val_acc:0.942375
==================>
Step: 51920, Train_acc:0.973724
Step: 51920, Val_acc:0.941311
==================>
Step: 51930, Train_acc:0.97318
Step: 51930, Val_acc:0.922059
==================>
Step: 51940, Train_acc:0.976005
Step: 51940, Val_acc:0.929712
==================>
Step: 51950, Train_acc:0.975037
Step: 51950, Val_acc:0.94432
==================>
Step: 51960, Train_acc:0.971681
Step: 51960, Val_acc:0.930562
==================>
Step: 51970, Train_acc:0.97943
Step: 51970, Val_acc:0.930349
==================>
Step: 51980, Train_acc:0.975419
Step: 51980, Val_acc:0.920258
==================>
Step: 51990, Train_acc:0.977042
Step: 51990, Val_acc:0.909846
==================>
Step: 52000, Train_acc:0.975625
Step: 52000, Val_acc:0.915333
==================>
****************** Epochs completed: 104******************
2017-11-11 16:02:12.608436 ---> Validation_loss: 0.192432
Step: 52010, Train_acc:0.972982
Step: 52010, Val_acc:0.928898
==================>
Step: 52020, Train_acc:0.979979
Step: 52020, Val_acc:0.937511
==================>
Step: 52030, Train_acc:0.974525
Step: 52030, Val_acc:0.956818
==================>
Step: 52040, Train_acc:0.974322
Step: 52040, Val_acc:0.926455
==================>
Step: 52050, Train_acc:0.966249
Step: 52050, Val_acc:0.917383
==================>
Step: 52060, Train_acc:0.973153
Step: 52060, Val_acc:0.9375
==================>
Step: 52070, Train_acc:0.96869
Step: 52070, Val_acc:0.935087
==================>
Step: 52080, Train_acc:0.973088
Step: 52080, Val_acc:0.929938
==================>
Step: 52090, Train_acc:0.969066
Step: 52090, Val_acc:0.940867
==================>
Step: 52100, Train_acc:0.971375
Step: 52100, Val_acc:0.899261
==================>
2017-11-11 16:04:49.077800 ---> Validation_loss: 0.158825
Step: 52110, Train_acc:0.979147
Step: 52110, Val_acc:0.92387
==================>
Step: 52120, Train_acc:0.965021
Step: 52120, Val_acc:0.926697
==================>
Step: 52130, Train_acc:0.968715
Step: 52130, Val_acc:0.943269
==================>
Step: 52140, Train_acc:0.976926
Step: 52140, Val_acc:0.918462
==================>
Step: 52150, Train_acc:0.975925
Step: 52150, Val_acc:0.924368
==================>
Step: 52160, Train_acc:0.969803
Step: 52160, Val_acc:0.922002
==================>
Step: 52170, Train_acc:0.976724
Step: 52170, Val_acc:0.937521
==================>
Step: 52180, Train_acc:0.979532
Step: 52180, Val_acc:0.931527
==================>
Step: 52190, Train_acc:0.981605
Step: 52190, Val_acc:0.938353
==================>
Step: 52200, Train_acc:0.971698
Step: 52200, Val_acc:0.947148
==================>
2017-11-11 16:07:25.967058 ---> Validation_loss: 0.151363
Step: 52210, Train_acc:0.974407
Step: 52210, Val_acc:0.936857
==================>
Step: 52220, Train_acc:0.972257
Step: 52220, Val_acc:0.934788
==================>
Step: 52230, Train_acc:0.966803
Step: 52230, Val_acc:0.922614
==================>
Step: 52240, Train_acc:0.976024
Step: 52240, Val_acc:0.943058
==================>
Step: 52250, Train_acc:0.977361
Step: 52250, Val_acc:0.91838
==================>
Step: 52260, Train_acc:0.978496
Step: 52260, Val_acc:0.939375
==================>
Step: 52270, Train_acc:0.978689
Step: 52270, Val_acc:0.930836
==================>
Step: 52280, Train_acc:0.980104
Step: 52280, Val_acc:0.896591
==================>
Step: 52290, Train_acc:0.971455
Step: 52290, Val_acc:0.925588
==================>
Step: 52300, Train_acc:0.970288
Step: 52300, Val_acc:0.918616
==================>
2017-11-11 16:10:02.581700 ---> Validation_loss: 0.197919
Step: 52310, Train_acc:0.978859
Step: 52310, Val_acc:0.94605
==================>
Step: 52320, Train_acc:0.967206
Step: 52320, Val_acc:0.921669
==================>
Step: 52330, Train_acc:0.975718
Step: 52330, Val_acc:0.919952
==================>
Step: 52340, Train_acc:0.973741
Step: 52340, Val_acc:0.905862
==================>
Step: 52350, Train_acc:0.973215
Step: 52350, Val_acc:0.93635
==================>
Step: 52360, Train_acc:0.975555
Step: 52360, Val_acc:0.933534
==================>
Step: 52370, Train_acc:0.975015
Step: 52370, Val_acc:0.94735
==================>
Step: 52380, Train_acc:0.974188
Step: 52380, Val_acc:0.94415
==================>
Step: 52390, Train_acc:0.971533
Step: 52390, Val_acc:0.932439
==================>
Step: 52400, Train_acc:0.978781
Step: 52400, Val_acc:0.936599
==================>
2017-11-11 16:12:39.392062 ---> Validation_loss: 0.247546
Step: 52410, Train_acc:0.969247
Step: 52410, Val_acc:0.914586
==================>
Step: 52420, Train_acc:0.971199
Step: 52420, Val_acc:0.918549
==================>
Step: 52430, Train_acc:0.975066
Step: 52430, Val_acc:0.910743
==================>
Step: 52440, Train_acc:0.972385
Step: 52440, Val_acc:0.93736
==================>
Step: 52450, Train_acc:0.97657
Step: 52450, Val_acc:0.91969
==================>
Step: 52460, Train_acc:0.978192
Step: 52460, Val_acc:0.930009
==================>
Step: 52470, Train_acc:0.97248
Step: 52470, Val_acc:0.940597
==================>
Step: 52480, Train_acc:0.96475
Step: 52480, Val_acc:0.942167
==================>
Step: 52490, Train_acc:0.980065
Step: 52490, Val_acc:0.939185
==================>
Step: 52500, Train_acc:0.963228
Step: 52500, Val_acc:0.942885
==================>
****************** Epochs completed: 105******************
2017-11-11 16:15:15.822898 ---> Validation_loss: 0.185293
Step: 52510, Train_acc:0.974397
Step: 52510, Val_acc:0.938239
==================>
Step: 52520, Train_acc:0.971857
Step: 52520, Val_acc:0.906088
==================>
Step: 52530, Train_acc:0.974401
Step: 52530, Val_acc:0.945338
==================>
Step: 52540, Train_acc:0.973408
Step: 52540, Val_acc:0.935823
==================>
Step: 52550, Train_acc:0.979902
Step: 52550, Val_acc:0.939009
==================>
Step: 52560, Train_acc:0.978018
Step: 52560, Val_acc:0.93398
==================>
Step: 52570, Train_acc:0.977325
Step: 52570, Val_acc:0.947007
==================>
Step: 52580, Train_acc:0.973872
Step: 52580, Val_acc:0.923759
==================>
Step: 52590, Train_acc:0.972184
Step: 52590, Val_acc:0.938344
==================>
Step: 52600, Train_acc:0.966273
Step: 52600, Val_acc:0.928497
==================>
2017-11-11 16:17:52.359495 ---> Validation_loss: 0.163626
Step: 52610, Train_acc:0.96879
Step: 52610, Val_acc:0.919298
==================>
Step: 52620, Train_acc:0.977238
Step: 52620, Val_acc:0.939672
==================>
Step: 52630, Train_acc:0.973954
Step: 52630, Val_acc:0.919177
==================>
Step: 52640, Train_acc:0.972662
Step: 52640, Val_acc:0.922186
==================>
Step: 52650, Train_acc:0.976537
Step: 52650, Val_acc:0.931381
==================>
Step: 52660, Train_acc:0.977804
Step: 52660, Val_acc:0.916722
==================>
Step: 52670, Train_acc:0.978463
Step: 52670, Val_acc:0.911884
==================>
Step: 52680, Train_acc:0.981549
Step: 52680, Val_acc:0.928472
==================>
Step: 52690, Train_acc:0.971311
Step: 52690, Val_acc:0.92252
==================>
Step: 52700, Train_acc:0.978091
Step: 52700, Val_acc:0.950884
==================>
2017-11-11 16:20:30.444171 ---> Validation_loss: 0.137034
Step: 52710, Train_acc:0.977318
Step: 52710, Val_acc:0.907235
==================>
Step: 52720, Train_acc:0.973578
Step: 52720, Val_acc:0.937688
==================>
Step: 52730, Train_acc:0.97212
Step: 52730, Val_acc:0.910339
==================>
Step: 52740, Train_acc:0.979388
Step: 52740, Val_acc:0.923434
==================>
Step: 52750, Train_acc:0.970022
Step: 52750, Val_acc:0.949485
==================>
Step: 52760, Train_acc:0.974084
Step: 52760, Val_acc:0.928146
==================>
Step: 52770, Train_acc:0.964684
Step: 52770, Val_acc:0.941949
==================>
Step: 52780, Train_acc:0.985894
Step: 52780, Val_acc:0.929706
==================>
Step: 52790, Train_acc:0.979711
Step: 52790, Val_acc:0.913249
==================>
Step: 52800, Train_acc:0.961748
Step: 52800, Val_acc:0.926655
==================>
2017-11-11 16:23:08.673234 ---> Validation_loss: 0.166788
Step: 52810, Train_acc:0.964271
Step: 52810, Val_acc:0.930214
==================>
Step: 52820, Train_acc:0.975046
Step: 52820, Val_acc:0.938619
==================>
Step: 52830, Train_acc:0.97738
Step: 52830, Val_acc:0.943481
==================>
Step: 52840, Train_acc:0.975006
Step: 52840, Val_acc:0.943392
==================>
Step: 52850, Train_acc:0.976653
Step: 52850, Val_acc:0.945081
==================>
Step: 52860, Train_acc:0.974882
Step: 52860, Val_acc:0.920823
==================>
Step: 52870, Train_acc:0.968101
Step: 52870, Val_acc:0.949324
==================>
Step: 52880, Train_acc:0.976837
Step: 52880, Val_acc:0.944768
==================>
Step: 52890, Train_acc:0.968514
Step: 52890, Val_acc:0.946536
==================>
Step: 52900, Train_acc:0.9763
Step: 52900, Val_acc:0.92338
==================>
2017-11-11 16:25:45.911533 ---> Validation_loss: 0.253433
Step: 52910, Train_acc:0.96072
Step: 52910, Val_acc:0.941001
==================>
Step: 52920, Train_acc:0.978788
Step: 52920, Val_acc:0.942654
==================>
Step: 52930, Train_acc:0.980604
Step: 52930, Val_acc:0.949999
==================>
Step: 52940, Train_acc:0.976185
Step: 52940, Val_acc:0.919819
==================>
Step: 52950, Train_acc:0.97446
Step: 52950, Val_acc:0.951741
==================>
Step: 52960, Train_acc:0.969663
Step: 52960, Val_acc:0.933524
==================>
Step: 52970, Train_acc:0.973707
Step: 52970, Val_acc:0.921829
==================>
Step: 52980, Train_acc:0.971056
Step: 52980, Val_acc:0.916439
==================>
Step: 52990, Train_acc:0.976406
Step: 52990, Val_acc:0.943658
==================>
Step: 53000, Train_acc:0.977852
Step: 53000, Val_acc:0.929132
==================>
****************** Epochs completed: 106******************
2017-11-11 16:28:22.611486 ---> Validation_loss: 0.24371
Step: 53010, Train_acc:0.975981
Step: 53010, Val_acc:0.941783
==================>
Step: 53020, Train_acc:0.974902
Step: 53020, Val_acc:0.92825
==================>
Step: 53030, Train_acc:0.965553
Step: 53030, Val_acc:0.911182
==================>
Step: 53040, Train_acc:0.978162
Step: 53040, Val_acc:0.906661
==================>
Step: 53050, Train_acc:0.974983
Step: 53050, Val_acc:0.950812
==================>
Step: 53060, Train_acc:0.97718
Step: 53060, Val_acc:0.932012
==================>
Step: 53070, Train_acc:0.978202
Step: 53070, Val_acc:0.950149
==================>
Step: 53080, Train_acc:0.967517
Step: 53080, Val_acc:0.917095
==================>
Step: 53090, Train_acc:0.975151
Step: 53090, Val_acc:0.92682
==================>
Step: 53100, Train_acc:0.965702
Step: 53100, Val_acc:0.921294
==================>
2017-11-11 16:30:59.390522 ---> Validation_loss: 0.180961
Step: 53110, Train_acc:0.975394
Step: 53110, Val_acc:0.93849
==================>
Step: 53120, Train_acc:0.977893
Step: 53120, Val_acc:0.939047
==================>
Step: 53130, Train_acc:0.980586
Step: 53130, Val_acc:0.921735
==================>
Step: 53140, Train_acc:0.971404
Step: 53140, Val_acc:0.933232
==================>
Step: 53150, Train_acc:0.972418
Step: 53150, Val_acc:0.933966
==================>
Step: 53160, Train_acc:0.988367
Step: 53160, Val_acc:0.929293
==================>
Step: 53170, Train_acc:0.979751
Step: 53170, Val_acc:0.941311
==================>
Step: 53180, Train_acc:0.965121
Step: 53180, Val_acc:0.92254
==================>
Step: 53190, Train_acc:0.974618
Step: 53190, Val_acc:0.938235
==================>
Step: 53200, Train_acc:0.979862
Step: 53200, Val_acc:0.915701
==================>
2017-11-11 16:33:36.448891 ---> Validation_loss: 0.165463
Step: 53210, Train_acc:0.977972
Step: 53210, Val_acc:0.941572
==================>
Step: 53220, Train_acc:0.982131
Step: 53220, Val_acc:0.9385
==================>
Step: 53230, Train_acc:0.979478
Step: 53230, Val_acc:0.939803
==================>
Step: 53240, Train_acc:0.970554
Step: 53240, Val_acc:0.936567
==================>
Step: 53250, Train_acc:0.970391
Step: 53250, Val_acc:0.928878
==================>
Step: 53260, Train_acc:0.974094
Step: 53260, Val_acc:0.937675
==================>
Step: 53270, Train_acc:0.971576
Step: 53270, Val_acc:0.916191
==================>
Step: 53280, Train_acc:0.971103
Step: 53280, Val_acc:0.945399
==================>
Step: 53290, Train_acc:0.97022
Step: 53290, Val_acc:0.955829
==================>
Step: 53300, Train_acc:0.975394
Step: 53300, Val_acc:0.931392
==================>
2017-11-11 16:36:13.090892 ---> Validation_loss: 0.15902
Step: 53310, Train_acc:0.972681
Step: 53310, Val_acc:0.95005
==================>
Step: 53320, Train_acc:0.973673
Step: 53320, Val_acc:0.941902
==================>
Step: 53330, Train_acc:0.978866
Step: 53330, Val_acc:0.933215
==================>
Step: 53340, Train_acc:0.97329
Step: 53340, Val_acc:0.935089
==================>
Step: 53350, Train_acc:0.975477
Step: 53350, Val_acc:0.929772
==================>
Step: 53360, Train_acc:0.972808
Step: 53360, Val_acc:0.942927
==================>
Step: 53370, Train_acc:0.975046
Step: 53370, Val_acc:0.931246
==================>
Step: 53380, Train_acc:0.969714
Step: 53380, Val_acc:0.922831
==================>
Step: 53390, Train_acc:0.979294
Step: 53390, Val_acc:0.924597
==================>
Step: 53400, Train_acc:0.974397
Step: 53400, Val_acc:0.945629
==================>
2017-11-11 16:38:50.400011 ---> Validation_loss: 0.133403
Step: 53410, Train_acc:0.970399
Step: 53410, Val_acc:0.935193
==================>
Step: 53420, Train_acc:0.978865
Step: 53420, Val_acc:0.939567
==================>
Step: 53430, Train_acc:0.976987
Step: 53430, Val_acc:0.93991
==================>
Step: 53440, Train_acc:0.977487
Step: 53440, Val_acc:0.933252
==================>
Step: 53450, Train_acc:0.979729
Step: 53450, Val_acc:0.933042
==================>
Step: 53460, Train_acc:0.981321
Step: 53460, Val_acc:0.905564
==================>
Step: 53470, Train_acc:0.975983
Step: 53470, Val_acc:0.929816
==================>
Step: 53480, Train_acc:0.977797
Step: 53480, Val_acc:0.913414
==================>
Step: 53490, Train_acc:0.966741
Step: 53490, Val_acc:0.92924
==================>
Step: 53500, Train_acc:0.978414
Step: 53500, Val_acc:0.924601
==================>
****************** Epochs completed: 107******************
2017-11-11 16:41:27.152568 ---> Validation_loss: 0.15147
Step: 53510, Train_acc:0.977587
Step: 53510, Val_acc:0.946639
==================>
Step: 53520, Train_acc:0.964846
Step: 53520, Val_acc:0.940853
==================>
Step: 53530, Train_acc:0.969553
Step: 53530, Val_acc:0.907039
==================>
Step: 53540, Train_acc:0.977942
Step: 53540, Val_acc:0.92082
==================>
Step: 53550, Train_acc:0.97842
Step: 53550, Val_acc:0.929247
==================>
Step: 53560, Train_acc:0.972025
Step: 53560, Val_acc:0.938614
==================>
Step: 53570, Train_acc:0.976165
Step: 53570, Val_acc:0.929438
==================>
Step: 53580, Train_acc:0.980079
Step: 53580, Val_acc:0.938644
==================>
Step: 53590, Train_acc:0.973278
Step: 53590, Val_acc:0.922089
==================>
Step: 53600, Train_acc:0.978333
Step: 53600, Val_acc:0.933414
==================>
2017-11-11 16:44:04.023753 ---> Validation_loss: 0.282191
Step: 53610, Train_acc:0.977872
Step: 53610, Val_acc:0.921473
==================>
Step: 53620, Train_acc:0.977401
Step: 53620, Val_acc:0.950729
==================>
Step: 53630, Train_acc:0.978824
Step: 53630, Val_acc:0.905579
==================>
Step: 53640, Train_acc:0.9797
Step: 53640, Val_acc:0.93391
==================>
Step: 53650, Train_acc:0.971672
Step: 53650, Val_acc:0.944025
==================>
Step: 53660, Train_acc:0.979673
Step: 53660, Val_acc:0.92858
==================>
Step: 53670, Train_acc:0.971514
Step: 53670, Val_acc:0.924231
==================>
Step: 53680, Train_acc:0.973408
Step: 53680, Val_acc:0.929847
==================>
Step: 53690, Train_acc:0.975112
Step: 53690, Val_acc:0.920261
==================>
Step: 53700, Train_acc:0.977439
Step: 53700, Val_acc:0.902042
==================>
2017-11-11 16:46:40.751545 ---> Validation_loss: 0.14392
Step: 53710, Train_acc:0.969446
Step: 53710, Val_acc:0.915026
==================>
Step: 53720, Train_acc:0.976888
Step: 53720, Val_acc:0.914795
==================>
Step: 53730, Train_acc:0.97599
Step: 53730, Val_acc:0.924449
==================>
Step: 53740, Train_acc:0.974138
Step: 53740, Val_acc:0.946008
==================>
Step: 53750, Train_acc:0.9801
Step: 53750, Val_acc:0.937604
==================>
Step: 53760, Train_acc:0.977318
Step: 53760, Val_acc:0.940836
==================>
Step: 53770, Train_acc:0.974286
Step: 53770, Val_acc:0.955811
==================>
Step: 53780, Train_acc:0.967734
Step: 53780, Val_acc:0.937568
==================>
Step: 53790, Train_acc:0.983906
Step: 53790, Val_acc:0.932185
==================>
Step: 53800, Train_acc:0.973602
Step: 53800, Val_acc:0.909351
==================>
2017-11-11 16:49:17.756417 ---> Validation_loss: 0.189585
Step: 53810, Train_acc:0.976713
Step: 53810, Val_acc:0.925868
==================>
Step: 53820, Train_acc:0.963207
Step: 53820, Val_acc:0.926748
==================>
****************** Epochs completed: 16******************
Step: 53830, Train_acc:0.983474
Step: 53830, Val_acc:0.935245
==================>
Step: 53840, Train_acc:0.970067
Step: 53840, Val_acc:0.940426
==================>
Step: 53850, Train_acc:0.981534
Step: 53850, Val_acc:0.947002
==================>
Step: 53860, Train_acc:0.974541
Step: 53860, Val_acc:0.918397
==================>
Step: 53870, Train_acc:0.984452
Step: 53870, Val_acc:0.94714
==================>
Step: 53880, Train_acc:0.977395
Step: 53880, Val_acc:0.948665
==================>
Step: 53890, Train_acc:0.979241
Step: 53890, Val_acc:0.950181
==================>
Step: 53900, Train_acc:0.980706
Step: 53900, Val_acc:0.942268
==================>
2017-11-11 16:51:54.954380 ---> Validation_loss: 0.127899
Step: 53910, Train_acc:0.980956
Step: 53910, Val_acc:0.933777
==================>
Step: 53920, Train_acc:0.971916
Step: 53920, Val_acc:0.933517
==================>
Step: 53930, Train_acc:0.978228
Step: 53930, Val_acc:0.936323
==================>
Step: 53940, Train_acc:0.98087
Step: 53940, Val_acc:0.941163
==================>
Step: 53950, Train_acc:0.983259
Step: 53950, Val_acc:0.943649
==================>
Step: 53960, Train_acc:0.976091
Step: 53960, Val_acc:0.937318
==================>
Step: 53970, Train_acc:0.976936
Step: 53970, Val_acc:0.918914
==================>
Step: 53980, Train_acc:0.974963
Step: 53980, Val_acc:0.936857
==================>
Step: 53990, Train_acc:0.975472
Step: 53990, Val_acc:0.921191
==================>
Step: 54000, Train_acc:0.974375
Step: 54000, Val_acc:0.942212
==================>
****************** Epochs completed: 108******************
2017-11-11 16:54:32.019901 ---> Validation_loss: 0.127273
Step: 54010, Train_acc:0.979509
Step: 54010, Val_acc:0.926951
==================>
Step: 54020, Train_acc:0.970493
Step: 54020, Val_acc:0.934049
==================>
Step: 54030, Train_acc:0.976212
Step: 54030, Val_acc:0.947483
==================>
Step: 54040, Train_acc:0.971954
Step: 54040, Val_acc:0.950114
==================>
Step: 54050, Train_acc:0.973768
Step: 54050, Val_acc:0.931406
==================>
Step: 54060, Train_acc:0.975579
Step: 54060, Val_acc:0.960759
==================>
Step: 54070, Train_acc:0.97015
Step: 54070, Val_acc:0.942773
==================>
Step: 54080, Train_acc:0.977296
Step: 54080, Val_acc:0.929044
==================>
Step: 54090, Train_acc:0.982769
Step: 54090, Val_acc:0.923136
==================>
Step: 54100, Train_acc:0.985073
Step: 54100, Val_acc:0.936432
==================>
2017-11-11 16:57:08.527461 ---> Validation_loss: 0.152747
Step: 54110, Train_acc:0.978348
Step: 54110, Val_acc:0.931305
==================>
Step: 54120, Train_acc:0.975479
Step: 54120, Val_acc:0.920204
==================>
Step: 54130, Train_acc:0.971693
Step: 54130, Val_acc:0.956637
==================>
Step: 54140, Train_acc:0.980726
Step: 54140, Val_acc:0.918253
==================>
Step: 54150, Train_acc:0.982277
Step: 54150, Val_acc:0.917308
==================>
Step: 54160, Train_acc:0.980463
Step: 54160, Val_acc:0.939584
==================>
Step: 54170, Train_acc:0.980395
Step: 54170, Val_acc:0.949054
==================>
Step: 54180, Train_acc:0.976323
Step: 54180, Val_acc:0.947587
==================>
Step: 54190, Train_acc:0.978562
Step: 54190, Val_acc:0.933394
==================>
Step: 54200, Train_acc:0.97153
Step: 54200, Val_acc:0.911687
==================>
2017-11-11 16:59:45.485986 ---> Validation_loss: 0.178007
Step: 54210, Train_acc:0.971436
Step: 54210, Val_acc:0.961156
==================>
Step: 54220, Train_acc:0.977679
Step: 54220, Val_acc:0.943179
==================>
Step: 54230, Train_acc:0.969933
Step: 54230, Val_acc:0.961125
==================>
Step: 54240, Train_acc:0.98124
Step: 54240, Val_acc:0.953088
==================>
Step: 54250, Train_acc:0.974071
Step: 54250, Val_acc:0.936748
==================>
Step: 54260, Train_acc:0.979406
Step: 54260, Val_acc:0.940332
==================>
Step: 54270, Train_acc:0.976831
Step: 54270, Val_acc:0.92447
==================>
Step: 54280, Train_acc:0.969164
Step: 54280, Val_acc:0.920425
==================>
Step: 54290, Train_acc:0.981965
Step: 54290, Val_acc:0.938534
==================>
Step: 54300, Train_acc:0.974539
Step: 54300, Val_acc:0.932986
==================>
2017-11-11 17:02:22.904029 ---> Validation_loss: 0.168637
Step: 54310, Train_acc:0.975244
Step: 54310, Val_acc:0.938671
==================>
Step: 54320, Train_acc:0.978417
Step: 54320, Val_acc:0.916796
==================>
Step: 54330, Train_acc:0.969259
Step: 54330, Val_acc:0.916337
==================>
Step: 54340, Train_acc:0.980582
Step: 54340, Val_acc:0.94519
==================>
Step: 54350, Train_acc:0.97344
Step: 54350, Val_acc:0.939048
==================>
Step: 54360, Train_acc:0.969668
Step: 54360, Val_acc:0.926241
==================>
Step: 54370, Train_acc:0.980042
Step: 54370, Val_acc:0.936785
==================>
Step: 54380, Train_acc:0.974512
Step: 54380, Val_acc:0.944823
==================>
Step: 54390, Train_acc:0.965164
Step: 54390, Val_acc:0.932455
==================>
Step: 54400, Train_acc:0.979696
Step: 54400, Val_acc:0.894415
==================>
2017-11-11 17:05:01.020871 ---> Validation_loss: 0.202553
Step: 54410, Train_acc:0.974882
Step: 54410, Val_acc:0.923472
==================>
Step: 54420, Train_acc:0.98125
Step: 54420, Val_acc:0.913249
==================>
Step: 54430, Train_acc:0.971844
Step: 54430, Val_acc:0.928583
==================>
Step: 54440, Train_acc:0.975856
Step: 54440, Val_acc:0.927947
==================>
Step: 54450, Train_acc:0.981173
Step: 54450, Val_acc:0.928785
==================>
Step: 54460, Train_acc:0.970314
Step: 54460, Val_acc:0.922482
==================>
Step: 54470, Train_acc:0.985908
Step: 54470, Val_acc:0.932416
==================>
Step: 54480, Train_acc:0.976884
Step: 54480, Val_acc:0.909028
==================>
Step: 54490, Train_acc:0.981619
Step: 54490, Val_acc:0.916519
==================>
Step: 54500, Train_acc:0.974063
Step: 54500, Val_acc:0.936656
==================>
****************** Epochs completed: 109******************
2017-11-11 17:07:37.871074 ---> Validation_loss: 0.159414
Step: 54510, Train_acc:0.982054
Step: 54510, Val_acc:0.945396
==================>
Step: 54520, Train_acc:0.976097
Step: 54520, Val_acc:0.917845
==================>
Step: 54530, Train_acc:0.979573
Step: 54530, Val_acc:0.882108
==================>
Step: 54540, Train_acc:0.980785
Step: 54540, Val_acc:0.94322
==================>
Step: 54550, Train_acc:0.978228
Step: 54550, Val_acc:0.936909
==================>
Step: 54560, Train_acc:0.976608
Step: 54560, Val_acc:0.9039
==================>
Step: 54570, Train_acc:0.98269
Step: 54570, Val_acc:0.929334
==================>
Step: 54580, Train_acc:0.967527
Step: 54580, Val_acc:0.919243
==================>
Step: 54590, Train_acc:0.980409
Step: 54590, Val_acc:0.928322
==================>
Step: 54600, Train_acc:0.97782
Step: 54600, Val_acc:0.938567
==================>
2017-11-11 17:10:14.240535 ---> Validation_loss: 0.173817
Step: 54610, Train_acc:0.975708
Step: 54610, Val_acc:0.936895
==================>
Step: 54620, Train_acc:0.979978
Step: 54620, Val_acc:0.93705
==================>
Step: 54630, Train_acc:0.979473
Step: 54630, Val_acc:0.927539
==================>
Step: 54640, Train_acc:0.980819
Step: 54640, Val_acc:0.940896
==================>
Step: 54650, Train_acc:0.971445
Step: 54650, Val_acc:0.910198
==================>
Step: 54660, Train_acc:0.973201
Step: 54660, Val_acc:0.913204
==================>
Step: 54670, Train_acc:0.97035
Step: 54670, Val_acc:0.933156
==================>
Step: 54680, Train_acc:0.978118
Step: 54680, Val_acc:0.933002
==================>
Step: 54690, Train_acc:0.979608
Step: 54690, Val_acc:0.928213
==================>
Step: 54700, Train_acc:0.977948
Step: 54700, Val_acc:0.91797
==================>
2017-11-11 17:12:50.726420 ---> Validation_loss: 0.179681
Step: 54710, Train_acc:0.97099
Step: 54710, Val_acc:0.932537
==================>
Step: 54720, Train_acc:0.973804
Step: 54720, Val_acc:0.921538
==================>
Step: 54730, Train_acc:0.979423
Step: 54730, Val_acc:0.943546
==================>
Step: 54740, Train_acc:0.978951
Step: 54740, Val_acc:0.940516
==================>
Step: 54750, Train_acc:0.97707
Step: 54750, Val_acc:0.930249
==================>
Step: 54760, Train_acc:0.983948
Step: 54760, Val_acc:0.934415
==================>
Step: 54770, Train_acc:0.978458
Step: 54770, Val_acc:0.936235
==================>
Step: 54780, Train_acc:0.975615
Step: 54780, Val_acc:0.925936
==================>
Step: 54790, Train_acc:0.971926
Step: 54790, Val_acc:0.909556
==================>
Step: 54800, Train_acc:0.976913
Step: 54800, Val_acc:0.949434
==================>
2017-11-11 17:15:27.157155 ---> Validation_loss: 0.182208
Step: 54810, Train_acc:0.979167
Step: 54810, Val_acc:0.91509
==================>
Step: 54820, Train_acc:0.97678
Step: 54820, Val_acc:0.941727
==================>
Step: 54830, Train_acc:0.979275
Step: 54830, Val_acc:0.959789
==================>
Step: 54840, Train_acc:0.985629
Step: 54840, Val_acc:0.932264
==================>
Step: 54850, Train_acc:0.977493
Step: 54850, Val_acc:0.92886
==================>
Step: 54860, Train_acc:0.98074
Step: 54860, Val_acc:0.918003
==================>
Step: 54870, Train_acc:0.979269
Step: 54870, Val_acc:0.924434
==================>
Step: 54880, Train_acc:0.976791
Step: 54880, Val_acc:0.93352
==================>
Step: 54890, Train_acc:0.972465
Step: 54890, Val_acc:0.931005
==================>
Step: 54900, Train_acc:0.965404
Step: 54900, Val_acc:0.931624
==================>
2017-11-11 17:18:03.935599 ---> Validation_loss: 0.192159
Step: 54910, Train_acc:0.981946
Step: 54910, Val_acc:0.937211
==================>
Step: 54920, Train_acc:0.984913
Step: 54920, Val_acc:0.921659
==================>
Step: 54930, Train_acc:0.979995
Step: 54930, Val_acc:0.940914
==================>
Step: 54940, Train_acc:0.964702
Step: 54940, Val_acc:0.905397
==================>
Step: 54950, Train_acc:0.973646
Step: 54950, Val_acc:0.938826
==================>
Step: 54960, Train_acc:0.9773
Step: 54960, Val_acc:0.945936
==================>
Step: 54970, Train_acc:0.977932
Step: 54970, Val_acc:0.947336
==================>
Step: 54980, Train_acc:0.970592
Step: 54980, Val_acc:0.94528
==================>
Step: 54990, Train_acc:0.981848
Step: 54990, Val_acc:0.935972
==================>
Step: 55000, Train_acc:0.98014
Step: 55000, Val_acc:0.911526
==================>
****************** Epochs completed: 110******************
2017-11-11 17:20:40.707808 ---> Validation_loss: 0.183146
Step: 55010, Train_acc:0.975762
Step: 55010, Val_acc:0.949938
==================>
Step: 55020, Train_acc:0.977336
Step: 55020, Val_acc:0.937826
==================>
Step: 55030, Train_acc:0.972908
Step: 55030, Val_acc:0.906534
==================>
Step: 55040, Train_acc:0.977664
Step: 55040, Val_acc:0.938926
==================>
Step: 55050, Train_acc:0.985148
Step: 55050, Val_acc:0.946078
==================>
Step: 55060, Train_acc:0.972816
Step: 55060, Val_acc:0.907427
==================>
Step: 55070, Train_acc:0.978425
Step: 55070, Val_acc:0.936472
==================>
Step: 55080, Train_acc:0.972509
Step: 55080, Val_acc:0.920663
==================>
Step: 55090, Train_acc:0.978138
Step: 55090, Val_acc:0.929343
==================>
Step: 55100, Train_acc:0.980677
Step: 55100, Val_acc:0.946069
==================>
2017-11-11 17:23:17.634659 ---> Validation_loss: 0.175465
Step: 55110, Train_acc:0.965571
Step: 55110, Val_acc:0.931707
==================>
Step: 55120, Train_acc:0.976434
Step: 55120, Val_acc:0.926512
==================>
Step: 55130, Train_acc:0.978704
Step: 55130, Val_acc:0.940184
==================>
Step: 55140, Train_acc:0.98155
Step: 55140, Val_acc:0.925458
==================>
Step: 55150, Train_acc:0.969817
Step: 55150, Val_acc:0.91224
==================>
Step: 55160, Train_acc:0.977346
Step: 55160, Val_acc:0.928815
==================>
Step: 55170, Train_acc:0.967958
Step: 55170, Val_acc:0.919116
==================>
Step: 55180, Train_acc:0.975452
Step: 55180, Val_acc:0.952581
==================>
Step: 55190, Train_acc:0.976553
Step: 55190, Val_acc:0.930911
==================>
Step: 55200, Train_acc:0.973262
Step: 55200, Val_acc:0.924214
==================>
2017-11-11 17:25:54.472153 ---> Validation_loss: 0.118309
Step: 55210, Train_acc:0.974982
Step: 55210, Val_acc:0.931423
==================>
Step: 55220, Train_acc:0.977803
Step: 55220, Val_acc:0.921669
==================>
Step: 55230, Train_acc:0.975221
Step: 55230, Val_acc:0.926976
==================>
Step: 55240, Train_acc:0.974272
Step: 55240, Val_acc:0.933153
==================>
Step: 55250, Train_acc:0.979415
Step: 55250, Val_acc:0.925693
==================>
Step: 55260, Train_acc:0.978263
Step: 55260, Val_acc:0.925569
==================>
Step: 55270, Train_acc:0.978943
Step: 55270, Val_acc:0.928119
==================>
Step: 55280, Train_acc:0.975214
Step: 55280, Val_acc:0.913081
==================>
Step: 55290, Train_acc:0.981998
Step: 55290, Val_acc:0.931951
==================>
Step: 55300, Train_acc:0.973507
Step: 55300, Val_acc:0.913481
==================>
2017-11-11 17:28:31.632614 ---> Validation_loss: 0.171042
Step: 55310, Train_acc:0.982145
Step: 55310, Val_acc:0.94026
==================>
Step: 55320, Train_acc:0.985966
Step: 55320, Val_acc:0.929233
==================>
Step: 55330, Train_acc:0.981813
Step: 55330, Val_acc:0.885033
==================>
Step: 55340, Train_acc:0.977441
Step: 55340, Val_acc:0.917596
==================>
Step: 55350, Train_acc:0.983641
Step: 55350, Val_acc:0.928027
==================>
Step: 55360, Train_acc:0.975963
Step: 55360, Val_acc:0.920248
==================>
Step: 55370, Train_acc:0.981417
Step: 55370, Val_acc:0.91416
==================>
Step: 55380, Train_acc:0.983711
Step: 55380, Val_acc:0.928921
==================>
Step: 55390, Train_acc:0.975861
Step: 55390, Val_acc:0.894261
==================>
Step: 55400, Train_acc:0.981246
Step: 55400, Val_acc:0.935762
==================>
2017-11-11 17:31:08.397363 ---> Validation_loss: 0.210347
Step: 55410, Train_acc:0.968752
Step: 55410, Val_acc:0.95022
==================>
Step: 55420, Train_acc:0.956162
Step: 55420, Val_acc:0.930828
==================>
Step: 55430, Train_acc:0.973121
Step: 55430, Val_acc:0.925983
==================>
Step: 55440, Train_acc:0.974576
Step: 55440, Val_acc:0.90978
==================>
Step: 55450, Train_acc:0.976475
Step: 55450, Val_acc:0.930345
==================>
Step: 55460, Train_acc:0.985861
Step: 55460, Val_acc:0.924612
==================>
Step: 55470, Train_acc:0.978958
Step: 55470, Val_acc:0.928331
==================>
Step: 55480, Train_acc:0.976559
Step: 55480, Val_acc:0.924283
==================>
Step: 55490, Train_acc:0.969572
Step: 55490, Val_acc:0.907268
==================>
Step: 55500, Train_acc:0.978965
Step: 55500, Val_acc:0.941532
==================>
****************** Epochs completed: 111******************
2017-11-11 17:33:45.370310 ---> Validation_loss: 0.129453
Step: 55510, Train_acc:0.979264
Step: 55510, Val_acc:0.930269
==================>
Step: 55520, Train_acc:0.982526
Step: 55520, Val_acc:0.905266
==================>
Step: 55530, Train_acc:0.969395
Step: 55530, Val_acc:0.902782
==================>
Step: 55540, Train_acc:0.980953
Step: 55540, Val_acc:0.903325
==================>
Step: 55550, Train_acc:0.972781
Step: 55550, Val_acc:0.941134
==================>
Step: 55560, Train_acc:0.980601
Step: 55560, Val_acc:0.913594
==================>
Step: 55570, Train_acc:0.978284
Step: 55570, Val_acc:0.941134
==================>
Step: 55580, Train_acc:0.98478
Step: 55580, Val_acc:0.935129
==================>
Step: 55590, Train_acc:0.974264
Step: 55590, Val_acc:0.9229
==================>
Step: 55600, Train_acc:0.981836
Step: 55600, Val_acc:0.898949
==================>
2017-11-11 17:36:22.362679 ---> Validation_loss: 0.112581
Step: 55610, Train_acc:0.975746
Step: 55610, Val_acc:0.938994
==================>
Step: 55620, Train_acc:0.974952
Step: 55620, Val_acc:0.912629
==================>
Step: 55630, Train_acc:0.980505
Step: 55630, Val_acc:0.922794
==================>
Step: 55640, Train_acc:0.977598
Step: 55640, Val_acc:0.962592
==================>
Step: 55650, Train_acc:0.979321
Step: 55650, Val_acc:0.944255
==================>
Step: 55660, Train_acc:0.977405
Step: 55660, Val_acc:0.919286
==================>
Step: 55670, Train_acc:0.984017
Step: 55670, Val_acc:0.950369
==================>
Step: 55680, Train_acc:0.97573
Step: 55680, Val_acc:0.922432
==================>
Step: 55690, Train_acc:0.974258
Step: 55690, Val_acc:0.94243
==================>
Step: 55700, Train_acc:0.977947
Step: 55700, Val_acc:0.922751
==================>
2017-11-11 17:38:59.229419 ---> Validation_loss: 0.202419
Step: 55710, Train_acc:0.971481
Step: 55710, Val_acc:0.946576
==================>
Step: 55720, Train_acc:0.977388
Step: 55720, Val_acc:0.918673
==================>
Step: 55730, Train_acc:0.976421
Step: 55730, Val_acc:0.92797
==================>
Step: 55740, Train_acc:0.970985
Step: 55740, Val_acc:0.927827
==================>
Step: 55750, Train_acc:0.982104
Step: 55750, Val_acc:0.933263
==================>
Step: 55760, Train_acc:0.978489
Step: 55760, Val_acc:0.929952
==================>
Step: 55770, Train_acc:0.979696
Step: 55770, Val_acc:0.939814
==================>
Step: 55780, Train_acc:0.96829
Step: 55780, Val_acc:0.945862
==================>
Step: 55790, Train_acc:0.97765
Step: 55790, Val_acc:0.901909
==================>
Step: 55800, Train_acc:0.976757
Step: 55800, Val_acc:0.929932
==================>
2017-11-11 17:41:35.658645 ---> Validation_loss: 0.141828
Step: 55810, Train_acc:0.975281
Step: 55810, Val_acc:0.927516
==================>
Step: 55820, Train_acc:0.967338
Step: 55820, Val_acc:0.914995
==================>
Step: 55830, Train_acc:0.976226
Step: 55830, Val_acc:0.936638
==================>
Step: 55840, Train_acc:0.978754
Step: 55840, Val_acc:0.938464
==================>
Step: 55850, Train_acc:0.982286
Step: 55850, Val_acc:0.928123
==================>
Step: 55860, Train_acc:0.966556
Step: 55860, Val_acc:0.92051
==================>
Step: 55870, Train_acc:0.981138
Step: 55870, Val_acc:0.946879
==================>
Step: 55880, Train_acc:0.976709
Step: 55880, Val_acc:0.932902
==================>
Step: 55890, Train_acc:0.978909
Step: 55890, Val_acc:0.901962
==================>
Step: 55900, Train_acc:0.979727
Step: 55900, Val_acc:0.950078
==================>
2017-11-11 17:44:12.550427 ---> Validation_loss: 0.30135
Step: 55910, Train_acc:0.974962
Step: 55910, Val_acc:0.916412
==================>
Step: 55920, Train_acc:0.970234
Step: 55920, Val_acc:0.915746
==================>
Step: 55930, Train_acc:0.978324
Step: 55930, Val_acc:0.950175
==================>
Step: 55940, Train_acc:0.976357
Step: 55940, Val_acc:0.938188
==================>
Step: 55950, Train_acc:0.975103
Step: 55950, Val_acc:0.935714
==================>
Step: 55960, Train_acc:0.972782
Step: 55960, Val_acc:0.908794
==================>
Step: 55970, Train_acc:0.972317
Step: 55970, Val_acc:0.935795
==================>
Step: 55980, Train_acc:0.983247
Step: 55980, Val_acc:0.920059
==================>
Step: 55990, Train_acc:0.974933
Step: 55990, Val_acc:0.935072
==================>
Step: 56000, Train_acc:0.980104
Step: 56000, Val_acc:0.942478
==================>
****************** Epochs completed: 112******************
2017-11-11 17:46:50.080150 ---> Validation_loss: 0.162877
Step: 56010, Train_acc:0.975273
Step: 56010, Val_acc:0.925626
==================>
Step: 56020, Train_acc:0.978812
Step: 56020, Val_acc:0.918329
==================>
Step: 56030, Train_acc:0.973906
Step: 56030, Val_acc:0.920653
==================>
Step: 56040, Train_acc:0.975797
Step: 56040, Val_acc:0.927541
==================>
Step: 56050, Train_acc:0.966077
Step: 56050, Val_acc:0.924015
==================>
Step: 56060, Train_acc:0.973213
Step: 56060, Val_acc:0.920181
==================>
Step: 56070, Train_acc:0.975369
Step: 56070, Val_acc:0.939232
==================>
Step: 56080, Train_acc:0.981617
Step: 56080, Val_acc:0.939833
==================>
Step: 56090, Train_acc:0.979794
Step: 56090, Val_acc:0.942184
==================>
Step: 56100, Train_acc:0.965739
Step: 56100, Val_acc:0.937383
==================>
2017-11-11 17:49:27.298378 ---> Validation_loss: 0.188902
Step: 56110, Train_acc:0.978472
Step: 56110, Val_acc:0.920697
==================>
Step: 56120, Train_acc:0.978308
Step: 56120, Val_acc:0.918485
==================>
Step: 56130, Train_acc:0.981935
Step: 56130, Val_acc:0.938148
==================>
Step: 56140, Train_acc:0.977564
Step: 56140, Val_acc:0.945114
==================>
Step: 56150, Train_acc:0.982026
Step: 56150, Val_acc:0.926458
==================>
Step: 56160, Train_acc:0.982749
Step: 56160, Val_acc:0.927031
==================>
Step: 56170, Train_acc:0.978615
Step: 56170, Val_acc:0.911635
==================>
Step: 56180, Train_acc:0.983107
Step: 56180, Val_acc:0.93166
==================>
Step: 56190, Train_acc:0.980242
Step: 56190, Val_acc:0.92192
==================>
Step: 56200, Train_acc:0.976832
Step: 56200, Val_acc:0.941924
==================>
2017-11-11 17:52:04.726802 ---> Validation_loss: 0.151494
Step: 56210, Train_acc:0.970398
Step: 56210, Val_acc:0.948728
==================>
Step: 56220, Train_acc:0.977761
Step: 56220, Val_acc:0.956792
==================>
Step: 56230, Train_acc:0.971503
Step: 56230, Val_acc:0.94014
==================>
Step: 56240, Train_acc:0.974126
Step: 56240, Val_acc:0.933776
==================>
Step: 56250, Train_acc:0.97733
Step: 56250, Val_acc:0.920874
==================>
Step: 56260, Train_acc:0.972421
Step: 56260, Val_acc:0.93108
==================>
Step: 56270, Train_acc:0.978727
Step: 56270, Val_acc:0.94988
==================>
Step: 56280, Train_acc:0.968335
Step: 56280, Val_acc:0.938007
==================>
Step: 56290, Train_acc:0.975326
Step: 56290, Val_acc:0.936516
==================>
Step: 56300, Train_acc:0.982272
Step: 56300, Val_acc:0.943281
==================>
2017-11-11 17:54:42.833934 ---> Validation_loss: 0.13592
Step: 56310, Train_acc:0.971611
Step: 56310, Val_acc:0.937541
==================>
Step: 56320, Train_acc:0.975721
Step: 56320, Val_acc:0.935286
==================>
Step: 56330, Train_acc:0.975623
Step: 56330, Val_acc:0.945522
==================>
Step: 56340, Train_acc:0.978693
Step: 56340, Val_acc:0.920745
==================>
Step: 56350, Train_acc:0.971906
Step: 56350, Val_acc:0.923138
==================>
Step: 56360, Train_acc:0.979467
Step: 56360, Val_acc:0.931941
==================>
Step: 56370, Train_acc:0.976503
Step: 56370, Val_acc:0.938027
==================>
Step: 56380, Train_acc:0.975686
Step: 56380, Val_acc:0.918005
==================>
Step: 56390, Train_acc:0.975638
Step: 56390, Val_acc:0.937848
==================>
Step: 56400, Train_acc:0.976567
Step: 56400, Val_acc:0.925818
==================>
2017-11-11 17:57:19.626724 ---> Validation_loss: 0.225528
Step: 56410, Train_acc:0.976465
Step: 56410, Val_acc:0.924572
==================>
Step: 56420, Train_acc:0.981259
Step: 56420, Val_acc:0.928531
==================>
Step: 56430, Train_acc:0.975698
Step: 56430, Val_acc:0.904772
==================>
Step: 56440, Train_acc:0.975352
Step: 56440, Val_acc:0.932881
==================>
Step: 56450, Train_acc:0.970104
Step: 56450, Val_acc:0.92772
==================>
Step: 56460, Train_acc:0.973335
Step: 56460, Val_acc:0.928881
==================>
Step: 56470, Train_acc:0.971211
Step: 56470, Val_acc:0.922765
==================>
Step: 56480, Train_acc:0.974922
Step: 56480, Val_acc:0.930322
==================>
Step: 56490, Train_acc:0.973964
Step: 56490, Val_acc:0.929048
==================>
Step: 56500, Train_acc:0.983949
Step: 56500, Val_acc:0.909985
==================>
****************** Epochs completed: 113******************
2017-11-11 17:59:57.149346 ---> Validation_loss: 0.198836
Step: 56510, Train_acc:0.973489
Step: 56510, Val_acc:0.925283
==================>
Step: 56520, Train_acc:0.974696
Step: 56520, Val_acc:0.929821
==================>
Step: 56530, Train_acc:0.962394
Step: 56530, Val_acc:0.941901
==================>
Step: 56540, Train_acc:0.974382
Step: 56540, Val_acc:0.949475
==================>
Step: 56550, Train_acc:0.967095
Step: 56550, Val_acc:0.945433
==================>
Step: 56560, Train_acc:0.975156
Step: 56560, Val_acc:0.954436
==================>
Step: 56570, Train_acc:0.972607
Step: 56570, Val_acc:0.936925
==================>
Step: 56580, Train_acc:0.976077
Step: 56580, Val_acc:0.923971
==================>
Step: 56590, Train_acc:0.974894
Step: 56590, Val_acc:0.93728
==================>
Step: 56600, Train_acc:0.976672
Step: 56600, Val_acc:0.907356
==================>
2017-11-11 18:02:35.504751 ---> Validation_loss: 0.179553
Step: 56610, Train_acc:0.974288
Step: 56610, Val_acc:0.95115
==================>
Step: 56620, Train_acc:0.983674
Step: 56620, Val_acc:0.923702
==================>
Step: 56630, Train_acc:0.974331
Step: 56630, Val_acc:0.960004
==================>
Step: 56640, Train_acc:0.970607
Step: 56640, Val_acc:0.929522
==================>
Step: 56650, Train_acc:0.974313
Step: 56650, Val_acc:0.925883
==================>
Step: 56660, Train_acc:0.977263
Step: 56660, Val_acc:0.950338
==================>
Step: 56670, Train_acc:0.970127
Step: 56670, Val_acc:0.923185
==================>
Step: 56680, Train_acc:0.974965
Step: 56680, Val_acc:0.937201
==================>
Step: 56690, Train_acc:0.980651
Step: 56690, Val_acc:0.914585
==================>
Step: 56700, Train_acc:0.974739
Step: 56700, Val_acc:0.959458
==================>
2017-11-11 18:05:12.779635 ---> Validation_loss: 0.19746
Step: 56710, Train_acc:0.973376
Step: 56710, Val_acc:0.911099
==================>
Step: 56720, Train_acc:0.979225
Step: 56720, Val_acc:0.938569
==================>
Step: 56730, Train_acc:0.974958
Step: 56730, Val_acc:0.918987
==================>
Step: 56740, Train_acc:0.972821
Step: 56740, Val_acc:0.928495
==================>
Step: 56750, Train_acc:0.969507
Step: 56750, Val_acc:0.919664
==================>
Step: 56760, Train_acc:0.97382
Step: 56760, Val_acc:0.94913
==================>
Step: 56770, Train_acc:0.975062
Step: 56770, Val_acc:0.936707
==================>
Step: 56780, Train_acc:0.969121
Step: 56780, Val_acc:0.927144
==================>
Step: 56790, Train_acc:0.977036
Step: 56790, Val_acc:0.922909
==================>
Step: 56800, Train_acc:0.976764
Step: 56800, Val_acc:0.918474
==================>
2017-11-11 18:07:52.325818 ---> Validation_loss: 0.15295
Step: 56810, Train_acc:0.982448
Step: 56810, Val_acc:0.95525
==================>
Step: 56820, Train_acc:0.976191
Step: 56820, Val_acc:0.918861
==================>
Step: 56830, Train_acc:0.973335
Step: 56830, Val_acc:0.941401
==================>
Step: 56840, Train_acc:0.976926
Step: 56840, Val_acc:0.932051
==================>
Step: 56850, Train_acc:0.974464
Step: 56850, Val_acc:0.948398
==================>
Step: 56860, Train_acc:0.969091
Step: 56860, Val_acc:0.940293
==================>
Step: 56870, Train_acc:0.972975
Step: 56870, Val_acc:0.954501
==================>
Step: 56880, Train_acc:0.982058
Step: 56880, Val_acc:0.937069
==================>
Step: 56890, Train_acc:0.972815
Step: 56890, Val_acc:0.922131
==================>
Step: 56900, Train_acc:0.979755
Step: 56900, Val_acc:0.936906
==================>
2017-11-11 18:10:29.476408 ---> Validation_loss: 0.142693
Step: 56910, Train_acc:0.976576
Step: 56910, Val_acc:0.9295
==================>
Step: 56920, Train_acc:0.971677
Step: 56920, Val_acc:0.939767
==================>
Step: 56930, Train_acc:0.97443
Step: 56930, Val_acc:0.908633
==================>
Step: 56940, Train_acc:0.979722
Step: 56940, Val_acc:0.940994
==================>
Step: 56950, Train_acc:0.985469
Step: 56950, Val_acc:0.922015
==================>
Step: 56960, Train_acc:0.982477
Step: 56960, Val_acc:0.94783
==================>
Step: 56970, Train_acc:0.97521
Step: 56970, Val_acc:0.939585
==================>
Step: 56980, Train_acc:0.9772
Step: 56980, Val_acc:0.936421
==================>
Step: 56990, Train_acc:0.982283
Step: 56990, Val_acc:0.933186
==================>
Step: 57000, Train_acc:0.980176
Step: 57000, Val_acc:0.942391
==================>
****************** Epochs completed: 114******************
2017-11-11 18:13:06.063549 ---> Validation_loss: 0.206724
Step: 57010, Train_acc:0.976677
Step: 57010, Val_acc:0.93818
==================>
Step: 57020, Train_acc:0.975077
Step: 57020, Val_acc:0.917611
==================>
Step: 57030, Train_acc:0.970786
Step: 57030, Val_acc:0.94098
==================>
Step: 57040, Train_acc:0.981311
Step: 57040, Val_acc:0.94054
==================>
Step: 57050, Train_acc:0.969403
Step: 57050, Val_acc:0.926975
==================>
Step: 57060, Train_acc:0.974312
Step: 57060, Val_acc:0.923433
==================>
Step: 57070, Train_acc:0.98238
Step: 57070, Val_acc:0.938492
==================>
Step: 57080, Train_acc:0.982129
Step: 57080, Val_acc:0.922402
==================>
Step: 57090, Train_acc:0.987753
Step: 57090, Val_acc:0.955106
==================>
Step: 57100, Train_acc:0.971591
Step: 57100, Val_acc:0.941371
==================>
2017-11-11 18:15:44.568436 ---> Validation_loss: 0.170025
Step: 57110, Train_acc:0.983147
Step: 57110, Val_acc:0.932833
==================>
Step: 57120, Train_acc:0.967845
Step: 57120, Val_acc:0.937814
==================>
Step: 57130, Train_acc:0.97585
Step: 57130, Val_acc:0.949197
==================>
Step: 57140, Train_acc:0.974318
Step: 57140, Val_acc:0.930543
==================>
Step: 57150, Train_acc:0.978757
Step: 57150, Val_acc:0.927686
==================>
Step: 57160, Train_acc:0.978954
Step: 57160, Val_acc:0.940608
==================>
Step: 57170, Train_acc:0.977561
Step: 57170, Val_acc:0.943763
==================>
Step: 57180, Train_acc:0.971971
Step: 57180, Val_acc:0.94213
==================>
****************** Epochs completed: 17******************
Step: 57190, Train_acc:0.976871
Step: 57190, Val_acc:0.92667
==================>
Step: 57200, Train_acc:0.978297
Step: 57200, Val_acc:0.952988
==================>
2017-11-11 18:18:22.383227 ---> Validation_loss: 0.156124
Step: 57210, Train_acc:0.975917
Step: 57210, Val_acc:0.954443
==================>
Step: 57220, Train_acc:0.971818
Step: 57220, Val_acc:0.925906
==================>
Step: 57230, Train_acc:0.977765
Step: 57230, Val_acc:0.946986
==================>
Step: 57240, Train_acc:0.973243
Step: 57240, Val_acc:0.940874
==================>
Step: 57250, Train_acc:0.968159
Step: 57250, Val_acc:0.910225
==================>
Step: 57260, Train_acc:0.981193
Step: 57260, Val_acc:0.92842
==================>
Step: 57270, Train_acc:0.978865
Step: 57270, Val_acc:0.93842
==================>
Step: 57280, Train_acc:0.984558
Step: 57280, Val_acc:0.947183
==================>
Step: 57290, Train_acc:0.969
Step: 57290, Val_acc:0.943538
==================>
Step: 57300, Train_acc:0.984463
Step: 57300, Val_acc:0.953318
==================>
2017-11-11 18:20:58.387789 ---> Validation_loss: 0.137837
Step: 57310, Train_acc:0.971609
Step: 57310, Val_acc:0.92777
==================>
Step: 57320, Train_acc:0.977931
Step: 57320, Val_acc:0.950974
==================>
Step: 57330, Train_acc:0.985963
Step: 57330, Val_acc:0.96109
==================>
Step: 57340, Train_acc:0.979037
Step: 57340, Val_acc:0.938121
==================>
Step: 57350, Train_acc:0.97693
Step: 57350, Val_acc:0.931404
==================>
Step: 57360, Train_acc:0.979586
Step: 57360, Val_acc:0.93813
==================>
Step: 57370, Train_acc:0.966399
Step: 57370, Val_acc:0.933822
==================>
Step: 57380, Train_acc:0.976949
Step: 57380, Val_acc:0.954917
==================>
Step: 57390, Train_acc:0.975668
Step: 57390, Val_acc:0.913357
==================>
Step: 57400, Train_acc:0.984523
Step: 57400, Val_acc:0.937058
==================>
2017-11-11 18:23:34.376560 ---> Validation_loss: 0.18067
Step: 57410, Train_acc:0.974979
Step: 57410, Val_acc:0.951185
==================>
Step: 57420, Train_acc:0.981615
Step: 57420, Val_acc:0.937758
==================>
Step: 57430, Train_acc:0.979948
Step: 57430, Val_acc:0.944874
==================>
Step: 57440, Train_acc:0.974657
Step: 57440, Val_acc:0.954625
==================>
Step: 57450, Train_acc:0.976643
Step: 57450, Val_acc:0.929468
==================>
Step: 57460, Train_acc:0.982136
Step: 57460, Val_acc:0.930945
==================>
Step: 57470, Train_acc:0.978009
Step: 57470, Val_acc:0.934409
==================>
Step: 57480, Train_acc:0.983783
Step: 57480, Val_acc:0.932845
==================>
Step: 57490, Train_acc:0.972552
Step: 57490, Val_acc:0.956855
==================>
Step: 57500, Train_acc:0.977167
Step: 57500, Val_acc:0.953695
==================>
****************** Epochs completed: 115******************
2017-11-11 18:26:13.101215 ---> Validation_loss: 0.109593
Step: 57510, Train_acc:0.973693
Step: 57510, Val_acc:0.941304
==================>
Step: 57520, Train_acc:0.977446
Step: 57520, Val_acc:0.918673
==================>
Step: 57530, Train_acc:0.972072
Step: 57530, Val_acc:0.931884
==================>
Step: 57540, Train_acc:0.974071
Step: 57540, Val_acc:0.93485
==================>
Step: 57550, Train_acc:0.97704
Step: 57550, Val_acc:0.932336
==================>
Step: 57560, Train_acc:0.980703
Step: 57560, Val_acc:0.948632
==================>
Step: 57570, Train_acc:0.969088
Step: 57570, Val_acc:0.930011
==================>
Step: 57580, Train_acc:0.980825
Step: 57580, Val_acc:0.941985
==================>
Step: 57590, Train_acc:0.984026
Step: 57590, Val_acc:0.90309
==================>
Step: 57600, Train_acc:0.984347
Step: 57600, Val_acc:0.93842
==================>
2017-11-11 18:28:50.750407 ---> Validation_loss: 0.180472
Step: 57610, Train_acc:0.979089
Step: 57610, Val_acc:0.931532
==================>
Step: 57620, Train_acc:0.977867
Step: 57620, Val_acc:0.927804
==================>
Step: 57630, Train_acc:0.982056
Step: 57630, Val_acc:0.936077
==================>
Step: 57640, Train_acc:0.978671
Step: 57640, Val_acc:0.952515
==================>
Step: 57650, Train_acc:0.980624
Step: 57650, Val_acc:0.933363
==================>
Step: 57660, Train_acc:0.977512
Step: 57660, Val_acc:0.926194
==================>
Step: 57670, Train_acc:0.974366
Step: 57670, Val_acc:0.917402
==================>
Step: 57680, Train_acc:0.965653
Step: 57680, Val_acc:0.947249
==================>
Step: 57690, Train_acc:0.980029
Step: 57690, Val_acc:0.932688
==================>
Step: 57700, Train_acc:0.986782
Step: 57700, Val_acc:0.946703
==================>
2017-11-11 18:31:28.221505 ---> Validation_loss: 0.176049
Step: 57710, Train_acc:0.980444
Step: 57710, Val_acc:0.900459
==================>
Step: 57720, Train_acc:0.973391
Step: 57720, Val_acc:0.936249
==================>
Step: 57730, Train_acc:0.974395
Step: 57730, Val_acc:0.937339
==================>
Step: 57740, Train_acc:0.970698
Step: 57740, Val_acc:0.921736
==================>
Step: 57750, Train_acc:0.98285
Step: 57750, Val_acc:0.905885
==================>
Step: 57760, Train_acc:0.977345
Step: 57760, Val_acc:0.943556
==================>
Step: 57770, Train_acc:0.972976
Step: 57770, Val_acc:0.931844
==================>
Step: 57780, Train_acc:0.975725
Step: 57780, Val_acc:0.913419
==================>
Step: 57790, Train_acc:0.976206
Step: 57790, Val_acc:0.92927
==================>
Step: 57800, Train_acc:0.971481
Step: 57800, Val_acc:0.934126
==================>
2017-11-11 18:34:06.205033 ---> Validation_loss: 0.163015
Step: 57810, Train_acc:0.977826
Step: 57810, Val_acc:0.936001
==================>
Step: 57820, Train_acc:0.97702
Step: 57820, Val_acc:0.93887
==================>
Step: 57830, Train_acc:0.979519
Step: 57830, Val_acc:0.92436
==================>
Step: 57840, Train_acc:0.980952
Step: 57840, Val_acc:0.915321
==================>
Step: 57850, Train_acc:0.979329
Step: 57850, Val_acc:0.958184
==================>
Step: 57860, Train_acc:0.979661
Step: 57860, Val_acc:0.926925
==================>
Step: 57870, Train_acc:0.975588
Step: 57870, Val_acc:0.922467
==================>
Step: 57880, Train_acc:0.969124
Step: 57880, Val_acc:0.922631
==================>
Step: 57890, Train_acc:0.97708
Step: 57890, Val_acc:0.928633
==================>
Step: 57900, Train_acc:0.98442
Step: 57900, Val_acc:0.937714
==================>
2017-11-11 18:36:43.132689 ---> Validation_loss: 0.2225
Step: 57910, Train_acc:0.978761
Step: 57910, Val_acc:0.931213
==================>
Step: 57920, Train_acc:0.977555
Step: 57920, Val_acc:0.925043
==================>
Step: 57930, Train_acc:0.973087
Step: 57930, Val_acc:0.930133
==================>
Step: 57940, Train_acc:0.979694
Step: 57940, Val_acc:0.925811
==================>
Step: 57950, Train_acc:0.982703
Step: 57950, Val_acc:0.943575
==================>
Step: 57960, Train_acc:0.972584
Step: 57960, Val_acc:0.94743
==================>
Step: 57970, Train_acc:0.973555
Step: 57970, Val_acc:0.940723
==================>
Step: 57980, Train_acc:0.975105
Step: 57980, Val_acc:0.931672
==================>
Step: 57990, Train_acc:0.984387
Step: 57990, Val_acc:0.90364
==================>
Step: 58000, Train_acc:0.98028
Step: 58000, Val_acc:0.923278
==================>
****************** Epochs completed: 116******************
2017-11-11 18:39:20.399630 ---> Validation_loss: 0.147359
Step: 58010, Train_acc:0.975494
Step: 58010, Val_acc:0.939403
==================>
Step: 58020, Train_acc:0.979449
Step: 58020, Val_acc:0.93047
==================>
Step: 58030, Train_acc:0.969532
Step: 58030, Val_acc:0.931156
==================>
Step: 58040, Train_acc:0.97353
Step: 58040, Val_acc:0.917325
==================>
Step: 58050, Train_acc:0.979053
Step: 58050, Val_acc:0.940033
==================>
Step: 58060, Train_acc:0.983805
Step: 58060, Val_acc:0.941686
==================>
Step: 58070, Train_acc:0.96962
Step: 58070, Val_acc:0.937653
==================>
Step: 58080, Train_acc:0.974347
Step: 58080, Val_acc:0.943784
==================>
Step: 58090, Train_acc:0.978771
Step: 58090, Val_acc:0.937533
==================>
Step: 58100, Train_acc:0.970187
Step: 58100, Val_acc:0.955377
==================>
2017-11-11 18:41:57.398543 ---> Validation_loss: 0.147599
Step: 58110, Train_acc:0.975775
Step: 58110, Val_acc:0.943154
==================>
Step: 58120, Train_acc:0.982242
Step: 58120, Val_acc:0.93396
==================>
Step: 58130, Train_acc:0.981644
Step: 58130, Val_acc:0.924719
==================>
Step: 58140, Train_acc:0.98267
Step: 58140, Val_acc:0.928777
==================>
Step: 58150, Train_acc:0.975902
Step: 58150, Val_acc:0.936741
==================>
Step: 58160, Train_acc:0.976584
Step: 58160, Val_acc:0.929321
==================>
Step: 58170, Train_acc:0.98134
Step: 58170, Val_acc:0.938672
==================>
Step: 58180, Train_acc:0.979614
Step: 58180, Val_acc:0.948634
==================>
Step: 58190, Train_acc:0.97097
Step: 58190, Val_acc:0.919829
==================>
Step: 58200, Train_acc:0.976913
Step: 58200, Val_acc:0.930009
==================>
2017-11-11 18:44:34.174278 ---> Validation_loss: 0.232564
Step: 58210, Train_acc:0.980395
Step: 58210, Val_acc:0.917316
==================>
Step: 58220, Train_acc:0.979082
Step: 58220, Val_acc:0.927167
==================>
Step: 58230, Train_acc:0.976027
Step: 58230, Val_acc:0.948096
==================>
Step: 58240, Train_acc:0.97364
Step: 58240, Val_acc:0.937538
==================>
Step: 58250, Train_acc:0.974091
Step: 58250, Val_acc:0.936954
==================>
Step: 58260, Train_acc:0.97186
Step: 58260, Val_acc:0.957087
==================>
Step: 58270, Train_acc:0.973503
Step: 58270, Val_acc:0.947032
==================>
Step: 58280, Train_acc:0.978635
Step: 58280, Val_acc:0.939954
==================>
Step: 58290, Train_acc:0.977716
Step: 58290, Val_acc:0.906204
==================>
Step: 58300, Train_acc:0.967532
Step: 58300, Val_acc:0.909424
==================>
2017-11-11 18:47:10.831056 ---> Validation_loss: 0.131679
Step: 58310, Train_acc:0.980288
Step: 58310, Val_acc:0.938132
==================>
Step: 58320, Train_acc:0.97748
Step: 58320, Val_acc:0.917091
==================>
Step: 58330, Train_acc:0.978982
Step: 58330, Val_acc:0.94241
==================>
Step: 58340, Train_acc:0.966816
Step: 58340, Val_acc:0.939972
==================>
Step: 58350, Train_acc:0.979318
Step: 58350, Val_acc:0.915309
==================>
Step: 58360, Train_acc:0.976012
Step: 58360, Val_acc:0.941998
==================>
Step: 58370, Train_acc:0.969764
Step: 58370, Val_acc:0.933127
==================>
Step: 58380, Train_acc:0.976575
Step: 58380, Val_acc:0.932169
==================>
Step: 58390, Train_acc:0.970697
Step: 58390, Val_acc:0.936265
==================>
Step: 58400, Train_acc:0.977242
Step: 58400, Val_acc:0.951045
==================>
2017-11-11 18:49:47.598805 ---> Validation_loss: 0.178926
Step: 58410, Train_acc:0.976819
Step: 58410, Val_acc:0.938123
==================>
Step: 58420, Train_acc:0.979275
Step: 58420, Val_acc:0.943645
==================>
Step: 58430, Train_acc:0.981543
Step: 58430, Val_acc:0.940321
==================>
Step: 58440, Train_acc:0.9722
Step: 58440, Val_acc:0.949581
==================>
Step: 58450, Train_acc:0.979282
Step: 58450, Val_acc:0.908712
==================>
Step: 58460, Train_acc:0.982109
Step: 58460, Val_acc:0.931173
==================>
Step: 58470, Train_acc:0.966244
Step: 58470, Val_acc:0.947017
==================>
Step: 58480, Train_acc:0.982404
Step: 58480, Val_acc:0.930847
==================>
Step: 58490, Train_acc:0.983197
Step: 58490, Val_acc:0.945663
==================>
Step: 58500, Train_acc:0.985687
Step: 58500, Val_acc:0.9442
==================>
****************** Epochs completed: 117******************
2017-11-11 18:52:24.436118 ---> Validation_loss: 0.170424
Step: 58510, Train_acc:0.980127
Step: 58510, Val_acc:0.922839
==================>
Step: 58520, Train_acc:0.980364
Step: 58520, Val_acc:0.930762
==================>
Step: 58530, Train_acc:0.988478
Step: 58530, Val_acc:0.949563
==================>
Step: 58540, Train_acc:0.972401
Step: 58540, Val_acc:0.932236
==================>
Step: 58550, Train_acc:0.976786
Step: 58550, Val_acc:0.948323
==================>
Step: 58560, Train_acc:0.972122
Step: 58560, Val_acc:0.951055
==================>
Step: 58570, Train_acc:0.978129
Step: 58570, Val_acc:0.921267
==================>
Step: 58580, Train_acc:0.980935
Step: 58580, Val_acc:0.930985
==================>
Step: 58590, Train_acc:0.980956
Step: 58590, Val_acc:0.943982
==================>
Step: 58600, Train_acc:0.983445
Step: 58600, Val_acc:0.924084
==================>
2017-11-11 18:55:01.115082 ---> Validation_loss: 0.213667
Step: 58610, Train_acc:0.980417
Step: 58610, Val_acc:0.931957
==================>
Step: 58620, Train_acc:0.978046
Step: 58620, Val_acc:0.938765
==================>
Step: 58630, Train_acc:0.978995
Step: 58630, Val_acc:0.952472
==================>
Step: 58640, Train_acc:0.974071
Step: 58640, Val_acc:0.940074
==================>
Step: 58650, Train_acc:0.977107
Step: 58650, Val_acc:0.946195
==================>
Step: 58660, Train_acc:0.972911
Step: 58660, Val_acc:0.94074
==================>
Step: 58670, Train_acc:0.979941
Step: 58670, Val_acc:0.913331
==================>
Step: 58680, Train_acc:0.978171
Step: 58680, Val_acc:0.927957
==================>
Step: 58690, Train_acc:0.983151
Step: 58690, Val_acc:0.924358
==================>
Step: 58700, Train_acc:0.983843
Step: 58700, Val_acc:0.943546
==================>
2017-11-11 18:57:36.459829 ---> Validation_loss: 0.174529
Step: 58710, Train_acc:0.97722
Step: 58710, Val_acc:0.925239
==================>
Step: 58720, Train_acc:0.976913
Step: 58720, Val_acc:0.935173
==================>
Step: 58730, Train_acc:0.970458
Step: 58730, Val_acc:0.933275
==================>
Step: 58740, Train_acc:0.976793
Step: 58740, Val_acc:0.943895
==================>
Step: 58750, Train_acc:0.978488
Step: 58750, Val_acc:0.945782
==================>
Step: 58760, Train_acc:0.978123
Step: 58760, Val_acc:0.937058
==================>
Step: 58770, Train_acc:0.981782
Step: 58770, Val_acc:0.940361
==================>
Step: 58780, Train_acc:0.981123
Step: 58780, Val_acc:0.920017
==================>
Step: 58790, Train_acc:0.975339
Step: 58790, Val_acc:0.94296
==================>
Step: 58800, Train_acc:0.982002
Step: 58800, Val_acc:0.92688
==================>
2017-11-11 19:00:11.633154 ---> Validation_loss: 0.156572
Step: 58810, Train_acc:0.974891
Step: 58810, Val_acc:0.945872
==================>
Step: 58820, Train_acc:0.967347
Step: 58820, Val_acc:0.929871
==================>
Step: 58830, Train_acc:0.981306
Step: 58830, Val_acc:0.954843
==================>
Step: 58840, Train_acc:0.972225
Step: 58840, Val_acc:0.925522
==================>
Step: 58850, Train_acc:0.978121
Step: 58850, Val_acc:0.921117
==================>
Step: 58860, Train_acc:0.978231
Step: 58860, Val_acc:0.940147
==================>
Step: 58870, Train_acc:0.971863
Step: 58870, Val_acc:0.932537
==================>
Step: 58880, Train_acc:0.971765
Step: 58880, Val_acc:0.93602
==================>
Step: 58890, Train_acc:0.980059
Step: 58890, Val_acc:0.943997
==================>
Step: 58900, Train_acc:0.974248
Step: 58900, Val_acc:0.950447
==================>
2017-11-11 19:02:46.697405 ---> Validation_loss: 0.142966
Step: 58910, Train_acc:0.975066
Step: 58910, Val_acc:0.928397
==================>
Step: 58920, Train_acc:0.978842
Step: 58920, Val_acc:0.925475
==================>
Step: 58930, Train_acc:0.977833
Step: 58930, Val_acc:0.938166
==================>
Step: 58940, Train_acc:0.97621
Step: 58940, Val_acc:0.938497
==================>
Step: 58950, Train_acc:0.981388
Step: 58950, Val_acc:0.940449
==================>
Step: 58960, Train_acc:0.976761
Step: 58960, Val_acc:0.940088
==================>
Step: 58970, Train_acc:0.978335
Step: 58970, Val_acc:0.930114
==================>
Step: 58980, Train_acc:0.97465
Step: 58980, Val_acc:0.912184
==================>
Step: 58990, Train_acc:0.985441
Step: 58990, Val_acc:0.929219
==================>
Step: 59000, Train_acc:0.979124
Step: 59000, Val_acc:0.917461
==================>
****************** Epochs completed: 118******************
2017-11-11 19:05:21.930948 ---> Validation_loss: 0.218299
Step: 59010, Train_acc:0.983759
Step: 59010, Val_acc:0.942988
==================>
Step: 59020, Train_acc:0.976577
Step: 59020, Val_acc:0.918439
==================>
Step: 59030, Train_acc:0.981797
Step: 59030, Val_acc:0.936804
==================>
Step: 59040, Train_acc:0.975138
Step: 59040, Val_acc:0.957228
==================>
Step: 59050, Train_acc:0.98359
Step: 59050, Val_acc:0.947581
==================>
Step: 59060, Train_acc:0.976416
Step: 59060, Val_acc:0.928435
==================>
Step: 59070, Train_acc:0.980485
Step: 59070, Val_acc:0.935492
==================>
Step: 59080, Train_acc:0.972809
Step: 59080, Val_acc:0.931431
==================>
Step: 59090, Train_acc:0.968231
Step: 59090, Val_acc:0.937623
==================>
Step: 59100, Train_acc:0.978104
Step: 59100, Val_acc:0.923029
==================>
2017-11-11 19:07:56.679372 ---> Validation_loss: 0.123078
Step: 59110, Train_acc:0.982717
Step: 59110, Val_acc:0.968463
==================>
Step: 59120, Train_acc:0.961682
Step: 59120, Val_acc:0.937197
==================>
Step: 59130, Train_acc:0.977372
Step: 59130, Val_acc:0.950083
==================>
Step: 59140, Train_acc:0.974238
Step: 59140, Val_acc:0.943606
==================>
Step: 59150, Train_acc:0.970778
Step: 59150, Val_acc:0.938931
==================>
Step: 59160, Train_acc:0.983867
Step: 59160, Val_acc:0.910612
==================>
Step: 59170, Train_acc:0.977672
Step: 59170, Val_acc:0.939562
==================>
Step: 59180, Train_acc:0.982145
Step: 59180, Val_acc:0.948666
==================>
Step: 59190, Train_acc:0.979635
Step: 59190, Val_acc:0.92491
==================>
Step: 59200, Train_acc:0.981017
Step: 59200, Val_acc:0.938483
==================>
2017-11-11 19:10:31.890067 ---> Validation_loss: 0.103333
Step: 59210, Train_acc:0.974512
Step: 59210, Val_acc:0.929082
==================>
Step: 59220, Train_acc:0.984497
Step: 59220, Val_acc:0.949437
==================>
Step: 59230, Train_acc:0.978547
Step: 59230, Val_acc:0.945778
==================>
Step: 59240, Train_acc:0.979421
Step: 59240, Val_acc:0.940948
==================>
Step: 59250, Train_acc:0.977179
Step: 59250, Val_acc:0.926332
==================>
Step: 59260, Train_acc:0.981949
Step: 59260, Val_acc:0.94635
==================>
Step: 59270, Train_acc:0.982412
Step: 59270, Val_acc:0.929924
==================>
Step: 59280, Train_acc:0.978254
Step: 59280, Val_acc:0.911897
==================>
Step: 59290, Train_acc:0.976794
Step: 59290, Val_acc:0.939741
==================>
Step: 59300, Train_acc:0.980685
Step: 59300, Val_acc:0.946327
==================>
2017-11-11 19:13:06.654725 ---> Validation_loss: 0.229106
Step: 59310, Train_acc:0.981919
Step: 59310, Val_acc:0.955862
==================>
Step: 59320, Train_acc:0.969063
Step: 59320, Val_acc:0.949237
==================>
Step: 59330, Train_acc:0.969312
Step: 59330, Val_acc:0.945341
==================>
Step: 59340, Train_acc:0.976578
Step: 59340, Val_acc:0.937786
==================>
Step: 59350, Train_acc:0.974922
Step: 59350, Val_acc:0.946999
==================>
Step: 59360, Train_acc:0.978776
Step: 59360, Val_acc:0.943195
==================>
Step: 59370, Train_acc:0.981813
Step: 59370, Val_acc:0.939697
==================>
Step: 59380, Train_acc:0.978306
Step: 59380, Val_acc:0.947834
==================>
Step: 59390, Train_acc:0.975245
Step: 59390, Val_acc:0.942979
==================>
Step: 59400, Train_acc:0.980181
Step: 59400, Val_acc:0.949706
==================>
2017-11-11 19:15:41.831062 ---> Validation_loss: 0.192012
Step: 59410, Train_acc:0.97364
Step: 59410, Val_acc:0.950522
==================>
Step: 59420, Train_acc:0.978743
Step: 59420, Val_acc:0.952501
==================>
Step: 59430, Train_acc:0.981599
Step: 59430, Val_acc:0.943506
==================>
Step: 59440, Train_acc:0.973981
Step: 59440, Val_acc:0.913694
==================>
Step: 59450, Train_acc:0.974877
Step: 59450, Val_acc:0.931644
==================>
Step: 59460, Train_acc:0.977378
Step: 59460, Val_acc:0.906997
==================>
Step: 59470, Train_acc:0.980723
Step: 59470, Val_acc:0.954847
==================>
Step: 59480, Train_acc:0.979885
Step: 59480, Val_acc:0.939258
==================>
Step: 59490, Train_acc:0.977094
Step: 59490, Val_acc:0.928722
==================>
Step: 59500, Train_acc:0.966561
Step: 59500, Val_acc:0.927271
==================>
****************** Epochs completed: 119******************
2017-11-11 19:18:16.829647 ---> Validation_loss: 0.194645
Step: 59510, Train_acc:0.980471
Step: 59510, Val_acc:0.950896
==================>
Step: 59520, Train_acc:0.986995
Step: 59520, Val_acc:0.961246
==================>
Step: 59530, Train_acc:0.976426
Step: 59530, Val_acc:0.909281
==================>
Step: 59540, Train_acc:0.978992
Step: 59540, Val_acc:0.936505
==================>
Step: 59550, Train_acc:0.980049
Step: 59550, Val_acc:0.928966
==================>
Step: 59560, Train_acc:0.972948
Step: 59560, Val_acc:0.936228
==================>
Step: 59570, Train_acc:0.977566
Step: 59570, Val_acc:0.906512
==================>
Step: 59580, Train_acc:0.977744
Step: 59580, Val_acc:0.955361
==================>
Step: 59590, Train_acc:0.975123
Step: 59590, Val_acc:0.943544
==================>
Step: 59600, Train_acc:0.978088
Step: 59600, Val_acc:0.93998
==================>
2017-11-11 19:20:51.811409 ---> Validation_loss: 0.131709
Step: 59610, Train_acc:0.977747
Step: 59610, Val_acc:0.934592
==================>
Step: 59620, Train_acc:0.969617
Step: 59620, Val_acc:0.943651
==================>
Step: 59630, Train_acc:0.97746
Step: 59630, Val_acc:0.94673
==================>
Step: 59640, Train_acc:0.975537
Step: 59640, Val_acc:0.928411
==================>
Step: 59650, Train_acc:0.983958
Step: 59650, Val_acc:0.931206
==================>
Step: 59660, Train_acc:0.97072
Step: 59660, Val_acc:0.929513
==================>
Step: 59670, Train_acc:0.970749
Step: 59670, Val_acc:0.943814
==================>
Step: 59680, Train_acc:0.971531
Step: 59680, Val_acc:0.944896
==================>
Step: 59690, Train_acc:0.970815
Step: 59690, Val_acc:0.941965
==================>
Step: 59700, Train_acc:0.981908
Step: 59700, Val_acc:0.933982
==================>
2017-11-11 19:23:27.049422 ---> Validation_loss: 0.167107
Step: 59710, Train_acc:0.980433
Step: 59710, Val_acc:0.939672
==================>
Step: 59720, Train_acc:0.974042
Step: 59720, Val_acc:0.920167
==================>
Step: 59730, Train_acc:0.981936
Step: 59730, Val_acc:0.940273
==================>
Step: 59740, Train_acc:0.980717
Step: 59740, Val_acc:0.917129
==================>
Step: 59750, Train_acc:0.970687
Step: 59750, Val_acc:0.932001
==================>
Step: 59760, Train_acc:0.977712
Step: 59760, Val_acc:0.939308
==================>
Step: 59770, Train_acc:0.980555
Step: 59770, Val_acc:0.948282
==================>
Step: 59780, Train_acc:0.979548
Step: 59780, Val_acc:0.94894
==================>
Step: 59790, Train_acc:0.976862
Step: 59790, Val_acc:0.893367
==================>
Step: 59800, Train_acc:0.979708
Step: 59800, Val_acc:0.924238
==================>
2017-11-11 19:26:02.305187 ---> Validation_loss: 0.200501
Step: 59810, Train_acc:0.969274
Step: 59810, Val_acc:0.946029
==================>
Step: 59820, Train_acc:0.980134
Step: 59820, Val_acc:0.930326
==================>
Step: 59830, Train_acc:0.978331
Step: 59830, Val_acc:0.938859
==================>
Step: 59840, Train_acc:0.975262
Step: 59840, Val_acc:0.932849
==================>
Step: 59850, Train_acc:0.983282
Step: 59850, Val_acc:0.942095
==================>
Step: 59860, Train_acc:0.974594
Step: 59860, Val_acc:0.935778
==================>
Step: 59870, Train_acc:0.978563
Step: 59870, Val_acc:0.925822
==================>
Step: 59880, Train_acc:0.979949
Step: 59880, Val_acc:0.926104
==================>
Step: 59890, Train_acc:0.983682
Step: 59890, Val_acc:0.922521
==================>
Step: 59900, Train_acc:0.97162
Step: 59900, Val_acc:0.938298
==================>
2017-11-11 19:28:37.032993 ---> Validation_loss: 0.156799
Step: 59910, Train_acc:0.963513
Step: 59910, Val_acc:0.930452
==================>
Step: 59920, Train_acc:0.974431
Step: 59920, Val_acc:0.935765
==================>
Step: 59930, Train_acc:0.982588
Step: 59930, Val_acc:0.956736
==================>
Step: 59940, Train_acc:0.982919
Step: 59940, Val_acc:0.923516
==================>
Step: 59950, Train_acc:0.986344
Step: 59950, Val_acc:0.927439
==================>
Step: 59960, Train_acc:0.968439
Step: 59960, Val_acc:0.951053
==================>
Step: 59970, Train_acc:0.976859
Step: 59970, Val_acc:0.925258
==================>
Step: 59980, Train_acc:0.979879
Step: 59980, Val_acc:0.950306
==================>
Step: 59990, Train_acc:0.982123
Step: 59990, Val_acc:0.925741
==================>
Step: 60000, Train_acc:0.975886
Step: 60000, Val_acc:0.941681
==================>
****************** Epochs completed: 120******************
2017-11-11 19:31:12.047774 ---> Validation_loss: 0.171494
Step: 60010, Train_acc:0.977546
Step: 60010, Val_acc:0.934811
==================>
Step: 60020, Train_acc:0.980328
Step: 60020, Val_acc:0.955293
==================>
Step: 60030, Train_acc:0.97624
Step: 60030, Val_acc:0.921351
==================>
Step: 60040, Train_acc:0.969601
Step: 60040, Val_acc:0.916671
==================>
Step: 60050, Train_acc:0.973837
Step: 60050, Val_acc:0.939071
==================>
Step: 60060, Train_acc:0.978951
Step: 60060, Val_acc:0.916063
==================>
Step: 60070, Train_acc:0.979386
Step: 60070, Val_acc:0.916385
==================>
Step: 60080, Train_acc:0.974814
Step: 60080, Val_acc:0.925771
==================>
Step: 60090, Train_acc:0.979149
Step: 60090, Val_acc:0.951934
==================>
Step: 60100, Train_acc:0.980856
Step: 60100, Val_acc:0.940669
==================>
2017-11-11 19:33:47.121466 ---> Validation_loss: 0.172863
Step: 60110, Train_acc:0.981964
Step: 60110, Val_acc:0.946151
==================>
Step: 60120, Train_acc:0.98196
Step: 60120, Val_acc:0.936584
==================>
Step: 60130, Train_acc:0.979269
Step: 60130, Val_acc:0.930134
==================>
Step: 60140, Train_acc:0.975845
Step: 60140, Val_acc:0.935314
==================>
Step: 60150, Train_acc:0.981183
Step: 60150, Val_acc:0.950645
==================>
Step: 60160, Train_acc:0.974807
Step: 60160, Val_acc:0.941851
==================>
Step: 60170, Train_acc:0.978672
Step: 60170, Val_acc:0.944277
==================>
Step: 60180, Train_acc:0.974155
Step: 60180, Val_acc:0.931042
==================>
Step: 60190, Train_acc:0.975808
Step: 60190, Val_acc:0.92179
==================>
Step: 60200, Train_acc:0.978983
Step: 60200, Val_acc:0.912305
==================>
2017-11-11 19:36:22.332745 ---> Validation_loss: 0.126304
Step: 60210, Train_acc:0.977217
Step: 60210, Val_acc:0.939882
==================>
Step: 60220, Train_acc:0.975852
Step: 60220, Val_acc:0.941194
==================>
Step: 60230, Train_acc:0.975536
Step: 60230, Val_acc:0.955824
==================>
Step: 60240, Train_acc:0.966532
Step: 60240, Val_acc:0.930389
==================>
Step: 60250, Train_acc:0.972373
Step: 60250, Val_acc:0.934091
==================>
Step: 60260, Train_acc:0.971921
Step: 60260, Val_acc:0.943347
==================>
Step: 60270, Train_acc:0.982142
Step: 60270, Val_acc:0.951007
==================>
Step: 60280, Train_acc:0.978702
Step: 60280, Val_acc:0.935111
==================>
Step: 60290, Train_acc:0.975299
Step: 60290, Val_acc:0.930311
==================>
Step: 60300, Train_acc:0.980917
Step: 60300, Val_acc:0.904695
==================>
2017-11-11 19:38:57.350874 ---> Validation_loss: 0.159039
Step: 60310, Train_acc:0.977621
Step: 60310, Val_acc:0.932289
==================>
Step: 60320, Train_acc:0.979736
Step: 60320, Val_acc:0.913522
==================>
Step: 60330, Train_acc:0.973875
Step: 60330, Val_acc:0.922895
==================>
Step: 60340, Train_acc:0.977885
Step: 60340, Val_acc:0.930038
==================>
Step: 60350, Train_acc:0.979407
Step: 60350, Val_acc:0.929078
==================>
Step: 60360, Train_acc:0.977217
Step: 60360, Val_acc:0.934349
==================>
Step: 60370, Train_acc:0.982126
Step: 60370, Val_acc:0.933407
==================>
Step: 60380, Train_acc:0.974097
Step: 60380, Val_acc:0.921812
==================>
Step: 60390, Train_acc:0.978741
Step: 60390, Val_acc:0.946652
==================>
Step: 60400, Train_acc:0.979574
Step: 60400, Val_acc:0.925057
==================>
2017-11-11 19:41:32.347516 ---> Validation_loss: 0.145958
Step: 60410, Train_acc:0.982522
Step: 60410, Val_acc:0.937764
==================>
Step: 60420, Train_acc:0.975496
Step: 60420, Val_acc:0.939745
==================>
Step: 60430, Train_acc:0.977028
Step: 60430, Val_acc:0.928911
==================>
Step: 60440, Train_acc:0.979144
Step: 60440, Val_acc:0.927113
==================>
Step: 60450, Train_acc:0.976079
Step: 60450, Val_acc:0.915811
==================>
Step: 60460, Train_acc:0.975376
Step: 60460, Val_acc:0.952883
==================>
Step: 60470, Train_acc:0.980756
Step: 60470, Val_acc:0.939064
==================>
Step: 60480, Train_acc:0.981467
Step: 60480, Val_acc:0.932925
==================>
Step: 60490, Train_acc:0.983605
Step: 60490, Val_acc:0.930044
==================>
Step: 60500, Train_acc:0.983171
Step: 60500, Val_acc:0.940609
==================>
****************** Epochs completed: 121******************
2017-11-11 19:44:07.606558 ---> Validation_loss: 0.133266
Step: 60510, Train_acc:0.975179
Step: 60510, Val_acc:0.944791
==================>
Step: 60520, Train_acc:0.981919
Step: 60520, Val_acc:0.943829
==================>
Step: 60530, Train_acc:0.984108
Step: 60530, Val_acc:0.933721
==================>
Step: 60540, Train_acc:0.977963
Step: 60540, Val_acc:0.926323
==================>
Step: 60550, Train_acc:0.978507
Step: 60550, Val_acc:0.937589
==================>
****************** Epochs completed: 18******************
Step: 60560, Train_acc:0.974277
Step: 60560, Val_acc:0.939143
==================>
Step: 60570, Train_acc:0.979237
Step: 60570, Val_acc:0.918301
==================>
Step: 60580, Train_acc:0.985269
Step: 60580, Val_acc:0.952748
==================>
Step: 60590, Train_acc:0.975712
Step: 60590, Val_acc:0.933976
==================>
Step: 60600, Train_acc:0.985219
Step: 60600, Val_acc:0.943442
==================>
2017-11-11 19:46:42.729179 ---> Validation_loss: 0.134923
Step: 60610, Train_acc:0.978208
Step: 60610, Val_acc:0.927069
==================>
Step: 60620, Train_acc:0.982319
Step: 60620, Val_acc:0.948826
==================>
Step: 60630, Train_acc:0.982238
Step: 60630, Val_acc:0.932643
==================>
Step: 60640, Train_acc:0.978647
Step: 60640, Val_acc:0.946689
==================>
Step: 60650, Train_acc:0.974867
Step: 60650, Val_acc:0.947743
==================>
Step: 60660, Train_acc:0.982103
Step: 60660, Val_acc:0.938154
==================>
Step: 60670, Train_acc:0.976962
Step: 60670, Val_acc:0.946852
==================>
Step: 60680, Train_acc:0.976106
Step: 60680, Val_acc:0.958463
==================>
Step: 60690, Train_acc:0.983661
Step: 60690, Val_acc:0.966451
==================>
Step: 60700, Train_acc:0.979706
Step: 60700, Val_acc:0.937876
==================>
2017-11-11 19:49:17.966976 ---> Validation_loss: 0.164865
Step: 60710, Train_acc:0.980803
Step: 60710, Val_acc:0.929177
==================>
Step: 60720, Train_acc:0.987666
Step: 60720, Val_acc:0.950345
==================>
Step: 60730, Train_acc:0.975217
Step: 60730, Val_acc:0.945135
==================>
Step: 60740, Train_acc:0.984486
Step: 60740, Val_acc:0.939229
==================>
Step: 60750, Train_acc:0.983352
Step: 60750, Val_acc:0.938402
==================>
Step: 60760, Train_acc:0.985507
Step: 60760, Val_acc:0.940586
==================>
Step: 60770, Train_acc:0.976311
Step: 60770, Val_acc:0.931373
==================>
Step: 60780, Train_acc:0.983802
Step: 60780, Val_acc:0.937948
==================>
Step: 60790, Train_acc:0.976796
Step: 60790, Val_acc:0.947776
==================>
Step: 60800, Train_acc:0.980139
Step: 60800, Val_acc:0.931516
==================>
2017-11-11 19:51:53.279719 ---> Validation_loss: 0.208403
Step: 60810, Train_acc:0.978096
Step: 60810, Val_acc:0.925391
==================>
Step: 60820, Train_acc:0.986
Step: 60820, Val_acc:0.940676
==================>
Step: 60830, Train_acc:0.983142
Step: 60830, Val_acc:0.94601
==================>
Step: 60840, Train_acc:0.980631
Step: 60840, Val_acc:0.941232
==================>
Step: 60850, Train_acc:0.975471
Step: 60850, Val_acc:0.943241
==================>
Step: 60860, Train_acc:0.982406
Step: 60860, Val_acc:0.92418
==================>
Step: 60870, Train_acc:0.976853
Step: 60870, Val_acc:0.921012
==================>
Step: 60880, Train_acc:0.975491
Step: 60880, Val_acc:0.941866
==================>
Step: 60890, Train_acc:0.981215
Step: 60890, Val_acc:0.937794
==================>
Step: 60900, Train_acc:0.977142
Step: 60900, Val_acc:0.938104
==================>
2017-11-11 19:54:28.689052 ---> Validation_loss: 0.175896
Step: 60910, Train_acc:0.979561
Step: 60910, Val_acc:0.942645
==================>
Step: 60920, Train_acc:0.979867
Step: 60920, Val_acc:0.93837
==================>
Step: 60930, Train_acc:0.983693
Step: 60930, Val_acc:0.918853
==================>
Step: 60940, Train_acc:0.974314
Step: 60940, Val_acc:0.958911
==================>
Step: 60950, Train_acc:0.979111
Step: 60950, Val_acc:0.937212
==================>
Step: 60960, Train_acc:0.980464
Step: 60960, Val_acc:0.92927
==================>
Step: 60970, Train_acc:0.977926
Step: 60970, Val_acc:0.927371
==================>
Step: 60980, Train_acc:0.975171
Step: 60980, Val_acc:0.938895
==================>
Step: 60990, Train_acc:0.979115
Step: 60990, Val_acc:0.921372
==================>
Step: 61000, Train_acc:0.980229
Step: 61000, Val_acc:0.931835
==================>
****************** Epochs completed: 122******************
2017-11-11 19:57:04.012973 ---> Validation_loss: 0.154925
Step: 61010, Train_acc:0.974974
Step: 61010, Val_acc:0.957673
==================>
Step: 61020, Train_acc:0.973298
Step: 61020, Val_acc:0.922025
==================>
Step: 61030, Train_acc:0.977343
Step: 61030, Val_acc:0.916836
==================>
Step: 61040, Train_acc:0.981342
Step: 61040, Val_acc:0.956736
==================>
Step: 61050, Train_acc:0.976643
Step: 61050, Val_acc:0.932096
==================>
Step: 61060, Train_acc:0.973591
Step: 61060, Val_acc:0.945474
==================>
Step: 61070, Train_acc:0.982637
Step: 61070, Val_acc:0.922656
==================>
Step: 61080, Train_acc:0.979396
Step: 61080, Val_acc:0.933417
==================>
Step: 61090, Train_acc:0.97533
Step: 61090, Val_acc:0.943831
==================>
Step: 61100, Train_acc:0.976592
Step: 61100, Val_acc:0.939792
==================>
2017-11-11 19:59:39.016690 ---> Validation_loss: 0.152766
Step: 61110, Train_acc:0.983838
Step: 61110, Val_acc:0.95486
==================>
Step: 61120, Train_acc:0.979474
Step: 61120, Val_acc:0.921627
==================>
Step: 61130, Train_acc:0.976539
Step: 61130, Val_acc:0.956498
==================>
Step: 61140, Train_acc:0.978718
Step: 61140, Val_acc:0.955584
==================>
Step: 61150, Train_acc:0.97135
Step: 61150, Val_acc:0.952228
==================>
Step: 61160, Train_acc:0.978335
Step: 61160, Val_acc:0.943768
==================>
Step: 61170, Train_acc:0.980284
Step: 61170, Val_acc:0.95265
==================>
Step: 61180, Train_acc:0.980568
Step: 61180, Val_acc:0.941581
==================>
Step: 61190, Train_acc:0.976953
Step: 61190, Val_acc:0.935995
==================>
Step: 61200, Train_acc:0.979214
Step: 61200, Val_acc:0.952856
==================>
2017-11-11 20:02:14.459966 ---> Validation_loss: 0.122164
Step: 61210, Train_acc:0.977889
Step: 61210, Val_acc:0.956086
==================>
Step: 61220, Train_acc:0.97912
Step: 61220, Val_acc:0.952621
==================>
Step: 61230, Train_acc:0.98541
Step: 61230, Val_acc:0.943823
==================>
Step: 61240, Train_acc:0.973434
Step: 61240, Val_acc:0.927312
==================>
Step: 61250, Train_acc:0.97556
Step: 61250, Val_acc:0.947253
==================>
Step: 61260, Train_acc:0.981747
Step: 61260, Val_acc:0.939332
==================>
Step: 61270, Train_acc:0.975636
Step: 61270, Val_acc:0.95134
==================>
Step: 61280, Train_acc:0.985499
Step: 61280, Val_acc:0.92183
==================>
Step: 61290, Train_acc:0.978228
Step: 61290, Val_acc:0.919098
==================>
Step: 61300, Train_acc:0.98061
Step: 61300, Val_acc:0.944552
==================>
2017-11-11 20:04:49.523422 ---> Validation_loss: 0.235817
Step: 61310, Train_acc:0.974926
Step: 61310, Val_acc:0.947037
==================>
Step: 61320, Train_acc:0.981132
Step: 61320, Val_acc:0.941235
==================>
Step: 61330, Train_acc:0.977667
Step: 61330, Val_acc:0.924033
==================>
Step: 61340, Train_acc:0.978262
Step: 61340, Val_acc:0.937822
==================>
Step: 61350, Train_acc:0.972605
Step: 61350, Val_acc:0.931439
==================>
Step: 61360, Train_acc:0.980775
Step: 61360, Val_acc:0.956052
==================>
Step: 61370, Train_acc:0.978293
Step: 61370, Val_acc:0.936093
==================>
Step: 61380, Train_acc:0.982773
Step: 61380, Val_acc:0.937579
==================>
Step: 61390, Train_acc:0.976857
Step: 61390, Val_acc:0.945651
==================>
Step: 61400, Train_acc:0.976504
Step: 61400, Val_acc:0.948
==================>
2017-11-11 20:07:24.940413 ---> Validation_loss: 0.147084
Step: 61410, Train_acc:0.975392
Step: 61410, Val_acc:0.935729
==================>
Step: 61420, Train_acc:0.972559
Step: 61420, Val_acc:0.945355
==================>
Step: 61430, Train_acc:0.971949
Step: 61430, Val_acc:0.93579
==================>
Step: 61440, Train_acc:0.97662
Step: 61440, Val_acc:0.942245
==================>
Step: 61450, Train_acc:0.984435
Step: 61450, Val_acc:0.955155
==================>
Step: 61460, Train_acc:0.984155
Step: 61460, Val_acc:0.932533
==================>
Step: 61470, Train_acc:0.979054
Step: 61470, Val_acc:0.935269
==================>
Step: 61480, Train_acc:0.982266
Step: 61480, Val_acc:0.950585
==================>
Step: 61490, Train_acc:0.979707
Step: 61490, Val_acc:0.927759
==================>
Step: 61500, Train_acc:0.98527
Step: 61500, Val_acc:0.931396
==================>
****************** Epochs completed: 123******************
2017-11-11 20:09:59.892978 ---> Validation_loss: 0.149138
Step: 61510, Train_acc:0.983732
Step: 61510, Val_acc:0.944038
==================>
Step: 61520, Train_acc:0.981655
Step: 61520, Val_acc:0.932017
==================>
Step: 61530, Train_acc:0.973944
Step: 61530, Val_acc:0.949432
==================>
Step: 61540, Train_acc:0.983843
Step: 61540, Val_acc:0.922583
==================>
Step: 61550, Train_acc:0.983047
Step: 61550, Val_acc:0.941306
==================>
Step: 61560, Train_acc:0.975037
Step: 61560, Val_acc:0.915267
==================>
Step: 61570, Train_acc:0.975813
Step: 61570, Val_acc:0.931686
==================>
Step: 61580, Train_acc:0.975405
Step: 61580, Val_acc:0.938822
==================>
Step: 61590, Train_acc:0.983809
Step: 61590, Val_acc:0.943713
==================>
Step: 61600, Train_acc:0.974582
Step: 61600, Val_acc:0.937206
==================>
2017-11-11 20:12:35.497411 ---> Validation_loss: 0.175918
Step: 61610, Train_acc:0.982295
Step: 61610, Val_acc:0.937885
==================>
Step: 61620, Train_acc:0.976744
Step: 61620, Val_acc:0.934325
==================>
Step: 61630, Train_acc:0.976997
Step: 61630, Val_acc:0.941681
==================>
Step: 61640, Train_acc:0.969393
Step: 61640, Val_acc:0.930936
==================>
Step: 61650, Train_acc:0.978586
Step: 61650, Val_acc:0.956084
==================>
Step: 61660, Train_acc:0.978005
Step: 61660, Val_acc:0.934108
==================>
Step: 61670, Train_acc:0.970592
Step: 61670, Val_acc:0.945475
==================>
Step: 61680, Train_acc:0.981941
Step: 61680, Val_acc:0.933179
==================>
Step: 61690, Train_acc:0.976041
Step: 61690, Val_acc:0.943137
==================>
Step: 61700, Train_acc:0.975182
Step: 61700, Val_acc:0.939047
==================>
2017-11-11 20:15:10.675898 ---> Validation_loss: 0.224705
Step: 61710, Train_acc:0.977871
Step: 61710, Val_acc:0.929462
==================>
Step: 61720, Train_acc:0.982048
Step: 61720, Val_acc:0.939402
==================>
Step: 61730, Train_acc:0.978353
Step: 61730, Val_acc:0.940642
==================>
Step: 61740, Train_acc:0.970878
Step: 61740, Val_acc:0.923959
==================>
Step: 61750, Train_acc:0.982571
Step: 61750, Val_acc:0.93275
==================>
Step: 61760, Train_acc:0.980253
Step: 61760, Val_acc:0.948016
==================>
Step: 61770, Train_acc:0.977501
Step: 61770, Val_acc:0.946726
==================>
Step: 61780, Train_acc:0.976469
Step: 61780, Val_acc:0.925713
==================>
Step: 61790, Train_acc:0.981222
Step: 61790, Val_acc:0.941528
==================>
Step: 61800, Train_acc:0.972908
Step: 61800, Val_acc:0.918624
==================>
2017-11-11 20:17:46.093565 ---> Validation_loss: 0.112728
Step: 61810, Train_acc:0.979669
Step: 61810, Val_acc:0.915341
==================>
Step: 61820, Train_acc:0.980685
Step: 61820, Val_acc:0.955603
==================>
Step: 61830, Train_acc:0.982543
Step: 61830, Val_acc:0.937118
==================>
Step: 61840, Train_acc:0.979233
Step: 61840, Val_acc:0.92121
==================>
Step: 61850, Train_acc:0.982307
Step: 61850, Val_acc:0.930463
==================>
Step: 61860, Train_acc:0.982417
Step: 61860, Val_acc:0.951472
==================>
Step: 61870, Train_acc:0.97785
Step: 61870, Val_acc:0.950244
==================>
Step: 61880, Train_acc:0.968058
Step: 61880, Val_acc:0.940642
==================>
Step: 61890, Train_acc:0.974115
Step: 61890, Val_acc:0.936598
==================>
Step: 61900, Train_acc:0.976014
Step: 61900, Val_acc:0.945344
==================>
2017-11-11 20:20:21.079634 ---> Validation_loss: 0.14262
Step: 61910, Train_acc:0.983822
Step: 61910, Val_acc:0.940902
==================>
Step: 61920, Train_acc:0.977889
Step: 61920, Val_acc:0.952614
==================>
Step: 61930, Train_acc:0.97327
Step: 61930, Val_acc:0.960331
==================>
Step: 61940, Train_acc:0.980745
Step: 61940, Val_acc:0.939984
==================>
Step: 61950, Train_acc:0.971536
Step: 61950, Val_acc:0.932792
==================>
Step: 61960, Train_acc:0.976085
Step: 61960, Val_acc:0.930527
==================>
Step: 61970, Train_acc:0.971868
Step: 61970, Val_acc:0.941564
==================>
Step: 61980, Train_acc:0.976644
Step: 61980, Val_acc:0.955955
==================>
Step: 61990, Train_acc:0.980502
Step: 61990, Val_acc:0.935635
==================>
Step: 62000, Train_acc:0.979855
Step: 62000, Val_acc:0.939471
==================>
****************** Epochs completed: 124******************
2017-11-11 20:22:56.270016 ---> Validation_loss: 0.149358
Step: 62010, Train_acc:0.980513
Step: 62010, Val_acc:0.93754
==================>
Step: 62020, Train_acc:0.979342
Step: 62020, Val_acc:0.937452
==================>
Step: 62030, Train_acc:0.975212
Step: 62030, Val_acc:0.927909
==================>
Step: 62040, Train_acc:0.985868
Step: 62040, Val_acc:0.949575
==================>
Step: 62050, Train_acc:0.971888
Step: 62050, Val_acc:0.957262
==================>
Step: 62060, Train_acc:0.982217
Step: 62060, Val_acc:0.946924
==================>
Step: 62070, Train_acc:0.982446
Step: 62070, Val_acc:0.951993
==================>
Step: 62080, Train_acc:0.978093
Step: 62080, Val_acc:0.940219
==================>
Step: 62090, Train_acc:0.985315
Step: 62090, Val_acc:0.943569
==================>
Step: 62100, Train_acc:0.981288
Step: 62100, Val_acc:0.951091
==================>
2017-11-11 20:25:31.259206 ---> Validation_loss: 0.201328
Step: 62110, Train_acc:0.96911
Step: 62110, Val_acc:0.937615
==================>
Step: 62120, Train_acc:0.974886
Step: 62120, Val_acc:0.955645
==================>
Step: 62130, Train_acc:0.977653
Step: 62130, Val_acc:0.933182
==================>
Step: 62140, Train_acc:0.978481
Step: 62140, Val_acc:0.953313
==================>
Step: 62150, Train_acc:0.978146
Step: 62150, Val_acc:0.93613
==================>
Step: 62160, Train_acc:0.979567
Step: 62160, Val_acc:0.933282
==================>
Step: 62170, Train_acc:0.97958
Step: 62170, Val_acc:0.927782
==================>
Step: 62180, Train_acc:0.982222
Step: 62180, Val_acc:0.918213
==================>
Step: 62190, Train_acc:0.982561
Step: 62190, Val_acc:0.944487
==================>
Step: 62200, Train_acc:0.980811
Step: 62200, Val_acc:0.95109
==================>
2017-11-11 20:28:06.293756 ---> Validation_loss: 0.15423
Step: 62210, Train_acc:0.979457
Step: 62210, Val_acc:0.956268
==================>
Step: 62220, Train_acc:0.983274
Step: 62220, Val_acc:0.946754
==================>
Step: 62230, Train_acc:0.975768
Step: 62230, Val_acc:0.928524
==================>
Step: 62240, Train_acc:0.98099
Step: 62240, Val_acc:0.938378
==================>
Step: 62250, Train_acc:0.983694
Step: 62250, Val_acc:0.913997
==================>
Step: 62260, Train_acc:0.98689
Step: 62260, Val_acc:0.942267
==================>
Step: 62270, Train_acc:0.979752
Step: 62270, Val_acc:0.955638
==================>
Step: 62280, Train_acc:0.974414
Step: 62280, Val_acc:0.94605
==================>
Step: 62290, Train_acc:0.975153
Step: 62290, Val_acc:0.93636
==================>
Step: 62300, Train_acc:0.978154
Step: 62300, Val_acc:0.941569
==================>
2017-11-11 20:30:41.442648 ---> Validation_loss: 0.16118
Step: 62310, Train_acc:0.976272
Step: 62310, Val_acc:0.921274
==================>
Step: 62320, Train_acc:0.980225
Step: 62320, Val_acc:0.948806
==================>
Step: 62330, Train_acc:0.979021
Step: 62330, Val_acc:0.925524
==================>
Step: 62340, Train_acc:0.979719
Step: 62340, Val_acc:0.972866
==================>
Step: 62350, Train_acc:0.976998
Step: 62350, Val_acc:0.953798
==================>
Step: 62360, Train_acc:0.975824
Step: 62360, Val_acc:0.920103
==================>
Step: 62370, Train_acc:0.966818
Step: 62370, Val_acc:0.936157
==================>
Step: 62380, Train_acc:0.985735
Step: 62380, Val_acc:0.90682
==================>
Step: 62390, Train_acc:0.976454
Step: 62390, Val_acc:0.928895
==================>
Step: 62400, Train_acc:0.978365
Step: 62400, Val_acc:0.933547
==================>
2017-11-11 20:33:16.777375 ---> Validation_loss: 0.132604
Step: 62410, Train_acc:0.978756
Step: 62410, Val_acc:0.945222
==================>
Step: 62420, Train_acc:0.97843
Step: 62420, Val_acc:0.938094
==================>
Step: 62430, Train_acc:0.977904
Step: 62430, Val_acc:0.92124
==================>
Step: 62440, Train_acc:0.984592
Step: 62440, Val_acc:0.955747
==================>
Step: 62450, Train_acc:0.985045
Step: 62450, Val_acc:0.941156
==================>
Step: 62460, Train_acc:0.983667
Step: 62460, Val_acc:0.943474
==================>
Step: 62470, Train_acc:0.972069
Step: 62470, Val_acc:0.946733
==================>
Step: 62480, Train_acc:0.981825
Step: 62480, Val_acc:0.936792
==================>
Step: 62490, Train_acc:0.977811
Step: 62490, Val_acc:0.93226
==================>
Step: 62500, Train_acc:0.979066
Step: 62500, Val_acc:0.933532
==================>
****************** Epochs completed: 125******************
2017-11-11 20:35:51.925261 ---> Validation_loss: 0.180859
Step: 62510, Train_acc:0.977294
Step: 62510, Val_acc:0.939734
==================>
Step: 62520, Train_acc:0.981443
Step: 62520, Val_acc:0.895009
==================>
Step: 62530, Train_acc:0.972644
Step: 62530, Val_acc:0.926204
==================>
Step: 62540, Train_acc:0.969133
Step: 62540, Val_acc:0.922185
==================>
Step: 62550, Train_acc:0.97973
Step: 62550, Val_acc:0.93288
==================>
Step: 62560, Train_acc:0.982239
Step: 62560, Val_acc:0.927894
==================>
Step: 62570, Train_acc:0.975489
Step: 62570, Val_acc:0.929469
==================>
Step: 62580, Train_acc:0.97924
Step: 62580, Val_acc:0.936991
==================>
Step: 62590, Train_acc:0.964609
Step: 62590, Val_acc:0.943997
==================>
Step: 62600, Train_acc:0.976204
Step: 62600, Val_acc:0.930969
==================>
2017-11-11 20:38:26.643305 ---> Validation_loss: 0.199396
Step: 62610, Train_acc:0.980027
Step: 62610, Val_acc:0.929447
==================>
Step: 62620, Train_acc:0.97139
Step: 62620, Val_acc:0.940066
==================>
Step: 62630, Train_acc:0.978988
Step: 62630, Val_acc:0.942833
==================>
Step: 62640, Train_acc:0.978115
Step: 62640, Val_acc:0.951321
==================>
Step: 62650, Train_acc:0.972874
Step: 62650, Val_acc:0.95739
==================>
Step: 62660, Train_acc:0.985657
Step: 62660, Val_acc:0.928639
==================>
Step: 62670, Train_acc:0.979896
Step: 62670, Val_acc:0.933412
==================>
Step: 62680, Train_acc:0.975536
Step: 62680, Val_acc:0.925967
==================>
Step: 62690, Train_acc:0.977279
Step: 62690, Val_acc:0.937323
==================>
Step: 62700, Train_acc:0.971573
Step: 62700, Val_acc:0.953141
==================>
2017-11-11 20:41:01.848337 ---> Validation_loss: 0.168865
Step: 62710, Train_acc:0.979227
Step: 62710, Val_acc:0.943744
==================>
Step: 62720, Train_acc:0.979308
Step: 62720, Val_acc:0.945092
==================>
Step: 62730, Train_acc:0.98296
Step: 62730, Val_acc:0.932501
==================>
Step: 62740, Train_acc:0.9777
Step: 62740, Val_acc:0.945798
==================>
Step: 62750, Train_acc:0.976816
Step: 62750, Val_acc:0.950074
==================>
Step: 62760, Train_acc:0.974646
Step: 62760, Val_acc:0.928036
==================>
Step: 62770, Train_acc:0.979065
Step: 62770, Val_acc:0.938042
==================>
Step: 62780, Train_acc:0.978407
Step: 62780, Val_acc:0.949679
==================>
Step: 62790, Train_acc:0.975892
Step: 62790, Val_acc:0.932517
==================>
Step: 62800, Train_acc:0.97942
Step: 62800, Val_acc:0.921393
==================>
2017-11-11 20:43:36.893823 ---> Validation_loss: 0.118581
Step: 62810, Train_acc:0.982959
Step: 62810, Val_acc:0.942217
==================>
Step: 62820, Train_acc:0.977401
Step: 62820, Val_acc:0.907008
==================>
Step: 62830, Train_acc:0.978821
Step: 62830, Val_acc:0.922015
==================>
Step: 62840, Train_acc:0.977135
Step: 62840, Val_acc:0.934093
==================>
Step: 62850, Train_acc:0.976766
Step: 62850, Val_acc:0.943872
==================>
Step: 62860, Train_acc:0.969049
Step: 62860, Val_acc:0.929592
==================>
Step: 62870, Train_acc:0.980608
Step: 62870, Val_acc:0.942937
==================>
Step: 62880, Train_acc:0.972827
Step: 62880, Val_acc:0.958414
==================>
Step: 62890, Train_acc:0.976173
Step: 62890, Val_acc:0.955789
==================>
Step: 62900, Train_acc:0.97464
Step: 62900, Val_acc:0.937626
==================>
2017-11-11 20:46:12.309480 ---> Validation_loss: 0.153489
Step: 62910, Train_acc:0.976631
Step: 62910, Val_acc:0.958245
==================>
Step: 62920, Train_acc:0.983002
Step: 62920, Val_acc:0.936029
==================>
Step: 62930, Train_acc:0.977758
Step: 62930, Val_acc:0.951332
==================>
Step: 62940, Train_acc:0.975071
Step: 62940, Val_acc:0.930646
==================>
Step: 62950, Train_acc:0.981288
Step: 62950, Val_acc:0.940371
==================>
Step: 62960, Train_acc:0.977611
Step: 62960, Val_acc:0.935905
==================>
Step: 62970, Train_acc:0.968727
Step: 62970, Val_acc:0.93515
==================>
Step: 62980, Train_acc:0.978812
Step: 62980, Val_acc:0.94386
==================>
Step: 62990, Train_acc:0.979194
Step: 62990, Val_acc:0.931902
==================>
Step: 63000, Train_acc:0.98058
Step: 63000, Val_acc:0.906038
==================>
****************** Epochs completed: 126******************
2017-11-11 20:48:47.450274 ---> Validation_loss: 0.184361
Step: 63010, Train_acc:0.975385
Step: 63010, Val_acc:0.960149
==================>
Step: 63020, Train_acc:0.984248
Step: 63020, Val_acc:0.910178
==================>
Step: 63030, Train_acc:0.983563
Step: 63030, Val_acc:0.928224
==================>
Step: 63040, Train_acc:0.972313
Step: 63040, Val_acc:0.934686
==================>
Step: 63050, Train_acc:0.981237
Step: 63050, Val_acc:0.946321
==================>
Step: 63060, Train_acc:0.974181
Step: 63060, Val_acc:0.946166
==================>
Step: 63070, Train_acc:0.972632
Step: 63070, Val_acc:0.936838
==================>
Step: 63080, Train_acc:0.977278
Step: 63080, Val_acc:0.937543
==================>
Step: 63090, Train_acc:0.974224
Step: 63090, Val_acc:0.923334
==================>
Step: 63100, Train_acc:0.974568
Step: 63100, Val_acc:0.942521
==================>
2017-11-11 20:51:22.569771 ---> Validation_loss: 0.11305
Step: 63110, Train_acc:0.980576
Step: 63110, Val_acc:0.951417
==================>
Step: 63120, Train_acc:0.978754
Step: 63120, Val_acc:0.928293
==================>
Step: 63130, Train_acc:0.97918
Step: 63130, Val_acc:0.949391
==================>
Step: 63140, Train_acc:0.976637
Step: 63140, Val_acc:0.929604
==================>
Step: 63150, Train_acc:0.977384
Step: 63150, Val_acc:0.939175
==================>
Step: 63160, Train_acc:0.983641
Step: 63160, Val_acc:0.928768
==================>
Step: 63170, Train_acc:0.965836
Step: 63170, Val_acc:0.937815
==================>
Step: 63180, Train_acc:0.969063
Step: 63180, Val_acc:0.939781
==================>
Step: 63190, Train_acc:0.979166
Step: 63190, Val_acc:0.95766
==================>
Step: 63200, Train_acc:0.978733
Step: 63200, Val_acc:0.947157
==================>
2017-11-11 20:53:57.755247 ---> Validation_loss: 0.182619
Step: 63210, Train_acc:0.97922
Step: 63210, Val_acc:0.915286
==================>
Step: 63220, Train_acc:0.977815
Step: 63220, Val_acc:0.929066
==================>
Step: 63230, Train_acc:0.973757
Step: 63230, Val_acc:0.957187
==================>
Step: 63240, Train_acc:0.978955
Step: 63240, Val_acc:0.926425
==================>
Step: 63250, Train_acc:0.980509
Step: 63250, Val_acc:0.935293
==================>
Step: 63260, Train_acc:0.975087
Step: 63260, Val_acc:0.934675
==================>
Step: 63270, Train_acc:0.978524
Step: 63270, Val_acc:0.92556
==================>
Step: 63280, Train_acc:0.985769
Step: 63280, Val_acc:0.933645
==================>
Step: 63290, Train_acc:0.975642
Step: 63290, Val_acc:0.947207
==================>
Step: 63300, Train_acc:0.971189
Step: 63300, Val_acc:0.946902
==================>
2017-11-11 20:56:33.259455 ---> Validation_loss: 0.113903
Step: 63310, Train_acc:0.978999
Step: 63310, Val_acc:0.953862
==================>
Step: 63320, Train_acc:0.978563
Step: 63320, Val_acc:0.954661
==================>
Step: 63330, Train_acc:0.980529
Step: 63330, Val_acc:0.927634
==================>
Step: 63340, Train_acc:0.98257
Step: 63340, Val_acc:0.934575
==================>
Step: 63350, Train_acc:0.969344
Step: 63350, Val_acc:0.949545
==================>
Step: 63360, Train_acc:0.98001
Step: 63360, Val_acc:0.922445
==================>
Step: 63370, Train_acc:0.978579
Step: 63370, Val_acc:0.94634
==================>
Step: 63380, Train_acc:0.976472
Step: 63380, Val_acc:0.960786
==================>
Step: 63390, Train_acc:0.981741
Step: 63390, Val_acc:0.947313
==================>
Step: 63400, Train_acc:0.977145
Step: 63400, Val_acc:0.944038
==================>
2017-11-11 20:59:08.758567 ---> Validation_loss: 0.157825
Step: 63410, Train_acc:0.964097
Step: 63410, Val_acc:0.94887
==================>
Step: 63420, Train_acc:0.984374
Step: 63420, Val_acc:0.936217
==================>
Step: 63430, Train_acc:0.976448
Step: 63430, Val_acc:0.947418
==================>
Step: 63440, Train_acc:0.978566
Step: 63440, Val_acc:0.925634
==================>
Step: 63450, Train_acc:0.978643
Step: 63450, Val_acc:0.914514
==================>
Step: 63460, Train_acc:0.981212
Step: 63460, Val_acc:0.936675
==================>
Step: 63470, Train_acc:0.983743
Step: 63470, Val_acc:0.952233
==================>
Step: 63480, Train_acc:0.981396
Step: 63480, Val_acc:0.921714
==================>
Step: 63490, Train_acc:0.968803
Step: 63490, Val_acc:0.955547
==================>
Step: 63500, Train_acc:0.98302
Step: 63500, Val_acc:0.928363
==================>
****************** Epochs completed: 127******************
2017-11-11 21:01:43.675396 ---> Validation_loss: 0.0911573
Step: 63510, Train_acc:0.9823
Step: 63510, Val_acc:0.936678
==================>
Step: 63520, Train_acc:0.976354
Step: 63520, Val_acc:0.954025
==================>
Step: 63530, Train_acc:0.982843
Step: 63530, Val_acc:0.910962
==================>
Step: 63540, Train_acc:0.984851
Step: 63540, Val_acc:0.933357
==================>
Step: 63550, Train_acc:0.975908
Step: 63550, Val_acc:0.954744
==================>
Step: 63560, Train_acc:0.979194
Step: 63560, Val_acc:0.924205
==================>
Step: 63570, Train_acc:0.98094
Step: 63570, Val_acc:0.953956
==================>
Step: 63580, Train_acc:0.983168
Step: 63580, Val_acc:0.951212
==================>
Step: 63590, Train_acc:0.978088
Step: 63590, Val_acc:0.957208
==================>
Step: 63600, Train_acc:0.974578
Step: 63600, Val_acc:0.928286
==================>
2017-11-11 21:04:18.782827 ---> Validation_loss: 0.215506
Step: 63610, Train_acc:0.984233
Step: 63610, Val_acc:0.936854
==================>
Step: 63620, Train_acc:0.987345
Step: 63620, Val_acc:0.941864
==================>
Step: 63630, Train_acc:0.983521
Step: 63630, Val_acc:0.94102
==================>
Step: 63640, Train_acc:0.979269
Step: 63640, Val_acc:0.959
==================>
Step: 63650, Train_acc:0.984204
Step: 63650, Val_acc:0.953418
==================>
Step: 63660, Train_acc:0.976981
Step: 63660, Val_acc:0.921095
==================>
Step: 63670, Train_acc:0.979259
Step: 63670, Val_acc:0.91782
==================>
Step: 63680, Train_acc:0.980748
Step: 63680, Val_acc:0.911359
==================>
Step: 63690, Train_acc:0.981119
Step: 63690, Val_acc:0.922437
==================>
Step: 63700, Train_acc:0.979592
Step: 63700, Val_acc:0.939556
==================>
2017-11-11 21:06:53.740297 ---> Validation_loss: 0.109985
Step: 63710, Train_acc:0.981926
Step: 63710, Val_acc:0.942864
==================>
Step: 63720, Train_acc:0.974221
Step: 63720, Val_acc:0.941737
==================>
Step: 63730, Train_acc:0.978436
Step: 63730, Val_acc:0.954183
==================>
Step: 63740, Train_acc:0.976982
Step: 63740, Val_acc:0.913048
==================>
Step: 63750, Train_acc:0.981953
Step: 63750, Val_acc:0.93077
==================>
Step: 63760, Train_acc:0.986575
Step: 63760, Val_acc:0.944316
==================>
Step: 63770, Train_acc:0.968084
Step: 63770, Val_acc:0.939766
==================>
Step: 63780, Train_acc:0.986849
Step: 63780, Val_acc:0.917338
==================>
Step: 63790, Train_acc:0.980554
Step: 63790, Val_acc:0.939271
==================>
Step: 63800, Train_acc:0.979014
Step: 63800, Val_acc:0.941804
==================>
2017-11-11 21:09:29.030175 ---> Validation_loss: 0.197668
Step: 63810, Train_acc:0.965076
Step: 63810, Val_acc:0.940863
==================>
Step: 63820, Train_acc:0.975536
Step: 63820, Val_acc:0.942252
==================>
Step: 63830, Train_acc:0.976992
Step: 63830, Val_acc:0.941327
==================>
Step: 63840, Train_acc:0.973064
Step: 63840, Val_acc:0.948916
==================>
Step: 63850, Train_acc:0.977957
Step: 63850, Val_acc:0.929142
==================>
Step: 63860, Train_acc:0.985293
Step: 63860, Val_acc:0.939435
==================>
Step: 63870, Train_acc:0.976316
Step: 63870, Val_acc:0.931825
==================>
Step: 63880, Train_acc:0.983303
Step: 63880, Val_acc:0.914811
==================>
Step: 63890, Train_acc:0.97476
Step: 63890, Val_acc:0.92126
==================>
Step: 63900, Train_acc:0.981097
Step: 63900, Val_acc:0.953523
==================>
2017-11-11 21:12:04.171077 ---> Validation_loss: 0.214255
Step: 63910, Train_acc:0.98233
Step: 63910, Val_acc:0.948049
==================>
****************** Epochs completed: 19******************
Step: 63920, Train_acc:0.978723
Step: 63920, Val_acc:0.943146
==================>
Step: 63930, Train_acc:0.9809
Step: 63930, Val_acc:0.953719
==================>
Step: 63940, Train_acc:0.977391
Step: 63940, Val_acc:0.93772
==================>
Step: 63950, Train_acc:0.988333
Step: 63950, Val_acc:0.921581
==================>
Step: 63960, Train_acc:0.980808
Step: 63960, Val_acc:0.946144
==================>
Step: 63970, Train_acc:0.977599
Step: 63970, Val_acc:0.934861
==================>
Step: 63980, Train_acc:0.977649
Step: 63980, Val_acc:0.950116
==================>
Step: 63990, Train_acc:0.978262
Step: 63990, Val_acc:0.955723
==================>
Step: 64000, Train_acc:0.978739
Step: 64000, Val_acc:0.952786
==================>
****************** Epochs completed: 128******************
2017-11-11 21:14:39.216045 ---> Validation_loss: 0.207289
Step: 64010, Train_acc:0.978301
Step: 64010, Val_acc:0.925415
==================>
Step: 64020, Train_acc:0.974437
Step: 64020, Val_acc:0.952144
==================>
Step: 64030, Train_acc:0.974951
Step: 64030, Val_acc:0.93491
==================>
Step: 64040, Train_acc:0.98012
Step: 64040, Val_acc:0.92985
==================>
Step: 64050, Train_acc:0.985363
Step: 64050, Val_acc:0.947462
==================>
Step: 64060, Train_acc:0.973811
Step: 64060, Val_acc:0.934889
==================>
Step: 64070, Train_acc:0.981675
Step: 64070, Val_acc:0.932024
==================>
Step: 64080, Train_acc:0.976449
Step: 64080, Val_acc:0.945992
==================>
Step: 64090, Train_acc:0.984187
Step: 64090, Val_acc:0.957364
==================>
Step: 64100, Train_acc:0.985562
Step: 64100, Val_acc:0.957712
==================>
2017-11-11 21:17:13.878379 ---> Validation_loss: 0.186314
Step: 64110, Train_acc:0.977378
Step: 64110, Val_acc:0.938992
==================>
Step: 64120, Train_acc:0.981465
Step: 64120, Val_acc:0.932209
==================>
Step: 64130, Train_acc:0.982633
Step: 64130, Val_acc:0.928273
==================>
Step: 64140, Train_acc:0.974524
Step: 64140, Val_acc:0.930106
==================>
Step: 64150, Train_acc:0.983517
Step: 64150, Val_acc:0.916271
==================>
Step: 64160, Train_acc:0.978407
Step: 64160, Val_acc:0.941802
==================>
Step: 64170, Train_acc:0.985049
Step: 64170, Val_acc:0.951696
==================>
Step: 64180, Train_acc:0.983625
Step: 64180, Val_acc:0.928765
==================>
Step: 64190, Train_acc:0.986472
Step: 64190, Val_acc:0.941106
==================>
Step: 64200, Train_acc:0.978771
Step: 64200, Val_acc:0.945496
==================>
2017-11-11 21:19:49.476594 ---> Validation_loss: 0.115589
Step: 64210, Train_acc:0.980736
Step: 64210, Val_acc:0.958527
==================>
Step: 64220, Train_acc:0.977236
Step: 64220, Val_acc:0.929227
==================>
Step: 64230, Train_acc:0.977251
Step: 64230, Val_acc:0.942761
==================>
Step: 64240, Train_acc:0.973573
Step: 64240, Val_acc:0.958595
==================>
Step: 64250, Train_acc:0.984685
Step: 64250, Val_acc:0.944031
==================>
Step: 64260, Train_acc:0.979667
Step: 64260, Val_acc:0.932412
==================>
Step: 64270, Train_acc:0.974225
Step: 64270, Val_acc:0.92855
==================>
Step: 64280, Train_acc:0.983555
Step: 64280, Val_acc:0.922804
==================>
Step: 64290, Train_acc:0.97677
Step: 64290, Val_acc:0.933472
==================>
Step: 64300, Train_acc:0.985513
Step: 64300, Val_acc:0.950338
==================>
2017-11-11 21:22:24.706241 ---> Validation_loss: 0.22465
Step: 64310, Train_acc:0.979347
Step: 64310, Val_acc:0.932003
==================>
Step: 64320, Train_acc:0.983932
Step: 64320, Val_acc:0.940049
==================>
Step: 64330, Train_acc:0.975712
Step: 64330, Val_acc:0.938645
==================>
Step: 64340, Train_acc:0.980917
Step: 64340, Val_acc:0.962667
==================>
Step: 64350, Train_acc:0.976763
Step: 64350, Val_acc:0.949967
==================>
Step: 64360, Train_acc:0.982512
Step: 64360, Val_acc:0.937073
==================>
Step: 64370, Train_acc:0.983968
Step: 64370, Val_acc:0.915701
==================>
Step: 64380, Train_acc:0.979319
Step: 64380, Val_acc:0.951664
==================>
Step: 64390, Train_acc:0.982878
Step: 64390, Val_acc:0.943286
==================>
Step: 64400, Train_acc:0.975885
Step: 64400, Val_acc:0.947921
==================>
2017-11-11 21:25:00.104493 ---> Validation_loss: 0.109579
Step: 64410, Train_acc:0.980857
Step: 64410, Val_acc:0.941163
==================>
Step: 64420, Train_acc:0.980953
Step: 64420, Val_acc:0.93213
==================>
Step: 64430, Train_acc:0.982085
Step: 64430, Val_acc:0.938694
==================>
Step: 64440, Train_acc:0.977117
Step: 64440, Val_acc:0.95594
==================>
Step: 64450, Train_acc:0.981351
Step: 64450, Val_acc:0.945071
==================>
Step: 64460, Train_acc:0.985752
Step: 64460, Val_acc:0.946892
==================>
Step: 64470, Train_acc:0.973842
Step: 64470, Val_acc:0.937203
==================>
Step: 64480, Train_acc:0.981024
Step: 64480, Val_acc:0.932506
==================>
Step: 64490, Train_acc:0.982899
Step: 64490, Val_acc:0.958572
==================>
Step: 64500, Train_acc:0.980016
Step: 64500, Val_acc:0.961136
==================>
****************** Epochs completed: 129******************
2017-11-11 21:27:35.094138 ---> Validation_loss: 0.117546
Step: 64510, Train_acc:0.979899
Step: 64510, Val_acc:0.957223
==================>
Step: 64520, Train_acc:0.980996
Step: 64520, Val_acc:0.929806
==================>
Step: 64530, Train_acc:0.978767
Step: 64530, Val_acc:0.93859
==================>
Step: 64540, Train_acc:0.980122
Step: 64540, Val_acc:0.952974
==================>
Step: 64550, Train_acc:0.985206
Step: 64550, Val_acc:0.941331
==================>
Step: 64560, Train_acc:0.973079
Step: 64560, Val_acc:0.940565
==================>
Step: 64570, Train_acc:0.983871
Step: 64570, Val_acc:0.941562
==================>
Step: 64580, Train_acc:0.982539
Step: 64580, Val_acc:0.946108
==================>
Step: 64590, Train_acc:0.974276
Step: 64590, Val_acc:0.927911
==================>
Step: 64600, Train_acc:0.975845
Step: 64600, Val_acc:0.96726
==================>
2017-11-11 21:30:10.467139 ---> Validation_loss: 0.0966349
Step: 64610, Train_acc:0.977786
Step: 64610, Val_acc:0.955448
==================>
Step: 64620, Train_acc:0.978209
Step: 64620, Val_acc:0.928291
==================>
Step: 64630, Train_acc:0.982275
Step: 64630, Val_acc:0.938732
==================>
Step: 64640, Train_acc:0.980059
Step: 64640, Val_acc:0.968269
==================>
Step: 64650, Train_acc:0.978141
Step: 64650, Val_acc:0.947368
==================>
Step: 64660, Train_acc:0.979321
Step: 64660, Val_acc:0.914054
==================>
Step: 64670, Train_acc:0.98606
Step: 64670, Val_acc:0.951335
==================>
Step: 64680, Train_acc:0.976105
Step: 64680, Val_acc:0.939344
==================>
Step: 64690, Train_acc:0.981292
Step: 64690, Val_acc:0.939886
==================>
Step: 64700, Train_acc:0.983882
Step: 64700, Val_acc:0.936345
==================>
2017-11-11 21:32:45.377444 ---> Validation_loss: 0.183709
Step: 64710, Train_acc:0.989569
Step: 64710, Val_acc:0.939869
==================>
Step: 64720, Train_acc:0.982124
Step: 64720, Val_acc:0.921991
==================>
Step: 64730, Train_acc:0.973292
Step: 64730, Val_acc:0.945994
==================>
Step: 64740, Train_acc:0.986634
Step: 64740, Val_acc:0.948865
==================>
Step: 64750, Train_acc:0.979562
Step: 64750, Val_acc:0.916143
==================>
Step: 64760, Train_acc:0.974586
Step: 64760, Val_acc:0.948267
==================>
Step: 64770, Train_acc:0.982024
Step: 64770, Val_acc:0.93801
==================>
Step: 64780, Train_acc:0.982352
Step: 64780, Val_acc:0.937145
==================>
Step: 64790, Train_acc:0.977775
Step: 64790, Val_acc:0.940814
==================>
Step: 64800, Train_acc:0.97946
Step: 64800, Val_acc:0.913379
==================>
2017-11-11 21:35:20.235338 ---> Validation_loss: 0.18325
Step: 64810, Train_acc:0.977349
Step: 64810, Val_acc:0.946506
==================>
Step: 64820, Train_acc:0.978511
Step: 64820, Val_acc:0.931511
==================>
Step: 64830, Train_acc:0.979115
Step: 64830, Val_acc:0.949899
==================>
Step: 64840, Train_acc:0.984629
Step: 64840, Val_acc:0.920239
==================>
Step: 64850, Train_acc:0.980537
Step: 64850, Val_acc:0.950355
==================>
Step: 64860, Train_acc:0.978207
Step: 64860, Val_acc:0.94905
==================>
Step: 64870, Train_acc:0.983333
Step: 64870, Val_acc:0.940615
==================>
Step: 64880, Train_acc:0.977515
Step: 64880, Val_acc:0.934127
==================>
Step: 64890, Train_acc:0.985973
Step: 64890, Val_acc:0.942559
==================>
Step: 64900, Train_acc:0.977712
Step: 64900, Val_acc:0.923826
==================>
2017-11-11 21:37:55.378650 ---> Validation_loss: 0.196045
Step: 64910, Train_acc:0.97722
Step: 64910, Val_acc:0.933665
==================>
Step: 64920, Train_acc:0.978788
Step: 64920, Val_acc:0.949178
==================>
Step: 64930, Train_acc:0.977699
Step: 64930, Val_acc:0.942947
==================>
Step: 64940, Train_acc:0.980522
Step: 64940, Val_acc:0.937671
==================>
Step: 64950, Train_acc:0.97997
Step: 64950, Val_acc:0.942544
==================>
Step: 64960, Train_acc:0.974248
Step: 64960, Val_acc:0.932557
==================>
Step: 64970, Train_acc:0.986047
Step: 64970, Val_acc:0.920123
==================>
Step: 64980, Train_acc:0.977235
Step: 64980, Val_acc:0.925426
==================>
Step: 64990, Train_acc:0.983428
Step: 64990, Val_acc:0.945099
==================>
Step: 65000, Train_acc:0.986493
Step: 65000, Val_acc:0.969718
==================>
****************** Epochs completed: 130******************
2017-11-11 21:40:30.656455 ---> Validation_loss: 0.102398
Step: 65010, Train_acc:0.97913
Step: 65010, Val_acc:0.922053
==================>
Step: 65020, Train_acc:0.976263
Step: 65020, Val_acc:0.935869
==================>
Step: 65030, Train_acc:0.979214
Step: 65030, Val_acc:0.943665
==================>
Step: 65040, Train_acc:0.974717
Step: 65040, Val_acc:0.915142
==================>
Step: 65050, Train_acc:0.980079
Step: 65050, Val_acc:0.929778
==================>
Step: 65060, Train_acc:0.971941
Step: 65060, Val_acc:0.924933
==================>
Step: 65070, Train_acc:0.986439
Step: 65070, Val_acc:0.931521
==================>
Step: 65080, Train_acc:0.982672
Step: 65080, Val_acc:0.940446
==================>
Step: 65090, Train_acc:0.982112
Step: 65090, Val_acc:0.955099
==================>
Step: 65100, Train_acc:0.97896
Step: 65100, Val_acc:0.93041
==================>
2017-11-11 21:43:05.770471 ---> Validation_loss: 0.207992
Step: 65110, Train_acc:0.977538
Step: 65110, Val_acc:0.926117
==================>
Step: 65120, Train_acc:0.978503
Step: 65120, Val_acc:0.94546
==================>
Step: 65130, Train_acc:0.975438
Step: 65130, Val_acc:0.93746
==================>
Step: 65140, Train_acc:0.983881
Step: 65140, Val_acc:0.919327
==================>
Step: 65150, Train_acc:0.983331
Step: 65150, Val_acc:0.927188
==================>
Step: 65160, Train_acc:0.978442
Step: 65160, Val_acc:0.960796
==================>
Step: 65170, Train_acc:0.981443
Step: 65170, Val_acc:0.934384
==================>
Step: 65180, Train_acc:0.984926
Step: 65180, Val_acc:0.918579
==================>
Step: 65190, Train_acc:0.976852
Step: 65190, Val_acc:0.928898
==================>
Step: 65200, Train_acc:0.980531
Step: 65200, Val_acc:0.96241
==================>
2017-11-11 21:45:40.732548 ---> Validation_loss: 0.158162
Step: 65210, Train_acc:0.968114
Step: 65210, Val_acc:0.941399
==================>
Step: 65220, Train_acc:0.98286
Step: 65220, Val_acc:0.956327
==================>
Step: 65230, Train_acc:0.978434
Step: 65230, Val_acc:0.945675
==================>
Step: 65240, Train_acc:0.977675
Step: 65240, Val_acc:0.951068
==================>
Step: 65250, Train_acc:0.977082
Step: 65250, Val_acc:0.945612
==================>
Step: 65260, Train_acc:0.979419
Step: 65260, Val_acc:0.932334
==================>
Step: 65270, Train_acc:0.978263
Step: 65270, Val_acc:0.951482
==================>
Step: 65280, Train_acc:0.975237
Step: 65280, Val_acc:0.940897
==================>
Step: 65290, Train_acc:0.986431
Step: 65290, Val_acc:0.930981
==================>
Step: 65300, Train_acc:0.974459
Step: 65300, Val_acc:0.920074
==================>
2017-11-11 21:48:16.138345 ---> Validation_loss: 0.116321
Step: 65310, Train_acc:0.981068
Step: 65310, Val_acc:0.937833
==================>
Step: 65320, Train_acc:0.978811
Step: 65320, Val_acc:0.928998
==================>
Step: 65330, Train_acc:0.982465
Step: 65330, Val_acc:0.93499
==================>
Step: 65340, Train_acc:0.973939
Step: 65340, Val_acc:0.92906
==================>
Step: 65350, Train_acc:0.978766
Step: 65350, Val_acc:0.94986
==================>
Step: 65360, Train_acc:0.981699
Step: 65360, Val_acc:0.942307
==================>
Step: 65370, Train_acc:0.984592
Step: 65370, Val_acc:0.943834
==================>
Step: 65380, Train_acc:0.980605
Step: 65380, Val_acc:0.924214
==================>
Step: 65390, Train_acc:0.980603
Step: 65390, Val_acc:0.921797
==================>
Step: 65400, Train_acc:0.975006
Step: 65400, Val_acc:0.949036
==================>
2017-11-11 21:50:51.077599 ---> Validation_loss: 0.176419
Step: 65410, Train_acc:0.983044
Step: 65410, Val_acc:0.930448
==================>
Step: 65420, Train_acc:0.98052
Step: 65420, Val_acc:0.938481
==================>
Step: 65430, Train_acc:0.978524
Step: 65430, Val_acc:0.928525
==================>
Step: 65440, Train_acc:0.982194
Step: 65440, Val_acc:0.939091
==================>
Step: 65450, Train_acc:0.976238
Step: 65450, Val_acc:0.939928
==================>
Step: 65460, Train_acc:0.978418
Step: 65460, Val_acc:0.955911
==================>
Step: 65470, Train_acc:0.980757
Step: 65470, Val_acc:0.915923
==================>
Step: 65480, Train_acc:0.979105
Step: 65480, Val_acc:0.912388
==================>
Step: 65490, Train_acc:0.978016
Step: 65490, Val_acc:0.943184
==================>
Step: 65500, Train_acc:0.975348
Step: 65500, Val_acc:0.946902
==================>
****************** Epochs completed: 131******************
2017-11-11 21:53:26.329537 ---> Validation_loss: 0.242528
Step: 65510, Train_acc:0.98108
Step: 65510, Val_acc:0.94887
==================>
Step: 65520, Train_acc:0.977312
Step: 65520, Val_acc:0.949602
==================>
Step: 65530, Train_acc:0.982415
Step: 65530, Val_acc:0.943573
==================>
Step: 65540, Train_acc:0.983011
Step: 65540, Val_acc:0.94842
==================>
Step: 65550, Train_acc:0.979921
Step: 65550, Val_acc:0.945575
==================>
Step: 65560, Train_acc:0.969006
Step: 65560, Val_acc:0.931964
==================>
Step: 65570, Train_acc:0.980026
Step: 65570, Val_acc:0.93222
==================>
Step: 65580, Train_acc:0.979995
Step: 65580, Val_acc:0.935934
==================>
Step: 65590, Train_acc:0.985085
Step: 65590, Val_acc:0.934833
==================>
Step: 65600, Train_acc:0.977303
Step: 65600, Val_acc:0.918624
==================>
2017-11-11 21:56:01.548131 ---> Validation_loss: 0.220144
Step: 65610, Train_acc:0.984674
Step: 65610, Val_acc:0.93984
==================>
Step: 65620, Train_acc:0.983788
Step: 65620, Val_acc:0.946057
==================>
Step: 65630, Train_acc:0.981708
Step: 65630, Val_acc:0.927148
==================>
Step: 65640, Train_acc:0.981963
Step: 65640, Val_acc:0.924875
==================>
Step: 65650, Train_acc:0.981614
Step: 65650, Val_acc:0.954051
==================>
Step: 65660, Train_acc:0.978328
Step: 65660, Val_acc:0.955071
==================>
Step: 65670, Train_acc:0.974541
Step: 65670, Val_acc:0.947145
==================>
Step: 65680, Train_acc:0.981987
Step: 65680, Val_acc:0.956285
==================>
Step: 65690, Train_acc:0.979937
Step: 65690, Val_acc:0.919534
==================>
Step: 65700, Train_acc:0.982745
Step: 65700, Val_acc:0.963831
==================>
2017-11-11 21:58:36.918937 ---> Validation_loss: 0.146571
Step: 65710, Train_acc:0.98416
Step: 65710, Val_acc:0.934683
==================>
Step: 65720, Train_acc:0.978104
Step: 65720, Val_acc:0.931327
==================>
Step: 65730, Train_acc:0.98429
Step: 65730, Val_acc:0.948938
==================>
Step: 65740, Train_acc:0.977048
Step: 65740, Val_acc:0.931041
==================>
Step: 65750, Train_acc:0.976859
Step: 65750, Val_acc:0.933409
==================>
Step: 65760, Train_acc:0.985287
Step: 65760, Val_acc:0.935765
==================>
Step: 65770, Train_acc:0.976765
Step: 65770, Val_acc:0.936669
==================>
Step: 65780, Train_acc:0.980826
Step: 65780, Val_acc:0.929297
==================>
Step: 65790, Train_acc:0.981335
Step: 65790, Val_acc:0.930961
==================>
Step: 65800, Train_acc:0.981677
Step: 65800, Val_acc:0.925552
==================>
2017-11-11 22:01:11.927750 ---> Validation_loss: 0.15233
Step: 65810, Train_acc:0.97881
Step: 65810, Val_acc:0.915148
==================>
Step: 65820, Train_acc:0.97458
Step: 65820, Val_acc:0.968304
==================>
Step: 65830, Train_acc:0.97598
Step: 65830, Val_acc:0.967927
==================>
Step: 65840, Train_acc:0.977368
Step: 65840, Val_acc:0.949139
==================>
Step: 65850, Train_acc:0.983449
Step: 65850, Val_acc:0.934128
==================>
Step: 65860, Train_acc:0.981721
Step: 65860, Val_acc:0.930667
==================>
Step: 65870, Train_acc:0.979419
Step: 65870, Val_acc:0.949941
==================>
Step: 65880, Train_acc:0.978706
Step: 65880, Val_acc:0.94317
==================>
Step: 65890, Train_acc:0.982959
Step: 65890, Val_acc:0.913663
==================>
Step: 65900, Train_acc:0.970392
Step: 65900, Val_acc:0.947153
==================>
2017-11-11 22:03:47.372162 ---> Validation_loss: 0.131359
Step: 65910, Train_acc:0.9745
Step: 65910, Val_acc:0.954828
==================>
Step: 65920, Train_acc:0.980542
Step: 65920, Val_acc:0.948207
==================>
Step: 65930, Train_acc:0.981646
Step: 65930, Val_acc:0.932723
==================>
Step: 65940, Train_acc:0.97306
Step: 65940, Val_acc:0.943674
==================>
Step: 65950, Train_acc:0.976749
Step: 65950, Val_acc:0.937025
==================>
Step: 65960, Train_acc:0.983364
Step: 65960, Val_acc:0.952828
==================>
Step: 65970, Train_acc:0.975492
Step: 65970, Val_acc:0.932135
==================>
Step: 65980, Train_acc:0.984329
Step: 65980, Val_acc:0.944467
==================>
Step: 65990, Train_acc:0.979528
Step: 65990, Val_acc:0.936622
==================>
Step: 66000, Train_acc:0.979412
Step: 66000, Val_acc:0.946118
==================>
****************** Epochs completed: 132******************
2017-11-11 22:06:22.260138 ---> Validation_loss: 0.192299
Step: 66010, Train_acc:0.974237
Step: 66010, Val_acc:0.94069
==================>
Step: 66020, Train_acc:0.980026
Step: 66020, Val_acc:0.930145
==================>
Step: 66030, Train_acc:0.983918
Step: 66030, Val_acc:0.942922
==================>
Step: 66040, Train_acc:0.977023
Step: 66040, Val_acc:0.929578
==================>
Step: 66050, Train_acc:0.975707
Step: 66050, Val_acc:0.94993
==================>
Step: 66060, Train_acc:0.983074
Step: 66060, Val_acc:0.944105
==================>
Step: 66070, Train_acc:0.97656
Step: 66070, Val_acc:0.937075
==================>
Step: 66080, Train_acc:0.980479
Step: 66080, Val_acc:0.951287
==================>
Step: 66090, Train_acc:0.983081
Step: 66090, Val_acc:0.93922
==================>
Step: 66100, Train_acc:0.973405
Step: 66100, Val_acc:0.958887
==================>
2017-11-11 22:08:57.279056 ---> Validation_loss: 0.132585
Step: 66110, Train_acc:0.979878
Step: 66110, Val_acc:0.947869
==================>
Step: 66120, Train_acc:0.980541
Step: 66120, Val_acc:0.947686
==================>
Step: 66130, Train_acc:0.968135
Step: 66130, Val_acc:0.961565
==================>
Step: 66140, Train_acc:0.981815
Step: 66140, Val_acc:0.930801
==================>
Step: 66150, Train_acc:0.980177
Step: 66150, Val_acc:0.943928
==================>
Step: 66160, Train_acc:0.984744
Step: 66160, Val_acc:0.941844
==================>
Step: 66170, Train_acc:0.982694
Step: 66170, Val_acc:0.936525
==================>
Step: 66180, Train_acc:0.974601
Step: 66180, Val_acc:0.931191
==================>
Step: 66190, Train_acc:0.979318
Step: 66190, Val_acc:0.937736
==================>
Step: 66200, Train_acc:0.978151
Step: 66200, Val_acc:0.937424
==================>
2017-11-11 22:11:32.490943 ---> Validation_loss: 0.14269
Step: 66210, Train_acc:0.983862
Step: 66210, Val_acc:0.947722
==================>
Step: 66220, Train_acc:0.97399
Step: 66220, Val_acc:0.926041
==================>
Step: 66230, Train_acc:0.991244
Step: 66230, Val_acc:0.911505
==================>
Step: 66240, Train_acc:0.977816
Step: 66240, Val_acc:0.921522
==================>
Step: 66250, Train_acc:0.981196
Step: 66250, Val_acc:0.95368
==================>
Step: 66260, Train_acc:0.976255
Step: 66260, Val_acc:0.930533
==================>
Step: 66270, Train_acc:0.975458
Step: 66270, Val_acc:0.940525
==================>
Step: 66280, Train_acc:0.980426
Step: 66280, Val_acc:0.937317
==================>
Step: 66290, Train_acc:0.977333
Step: 66290, Val_acc:0.951908
==================>
Step: 66300, Train_acc:0.980592
Step: 66300, Val_acc:0.939366
==================>
2017-11-11 22:14:07.628135 ---> Validation_loss: 0.122512
Step: 66310, Train_acc:0.983966
Step: 66310, Val_acc:0.942347
==================>
Step: 66320, Train_acc:0.981593
Step: 66320, Val_acc:0.939408
==================>
Step: 66330, Train_acc:0.976807
Step: 66330, Val_acc:0.946184
==================>
Step: 66340, Train_acc:0.97809
Step: 66340, Val_acc:0.958677
==================>
Step: 66350, Train_acc:0.983057
Step: 66350, Val_acc:0.942943
==================>
Step: 66360, Train_acc:0.981229
Step: 66360, Val_acc:0.932317
==================>
Step: 66370, Train_acc:0.978901
Step: 66370, Val_acc:0.959961
==================>
Step: 66380, Train_acc:0.983988
Step: 66380, Val_acc:0.903325
==================>
Step: 66390, Train_acc:0.975559
Step: 66390, Val_acc:0.93498
==================>
Step: 66400, Train_acc:0.979518
Step: 66400, Val_acc:0.947135
==================>
2017-11-11 22:16:42.977255 ---> Validation_loss: 0.198504
Step: 66410, Train_acc:0.982577
Step: 66410, Val_acc:0.928199
==================>
Step: 66420, Train_acc:0.974017
Step: 66420, Val_acc:0.938011
==================>
Step: 66430, Train_acc:0.977628
Step: 66430, Val_acc:0.956799
==================>
Step: 66440, Train_acc:0.984822
Step: 66440, Val_acc:0.949019
==================>
Step: 66450, Train_acc:0.978865
Step: 66450, Val_acc:0.953502
==================>
Step: 66460, Train_acc:0.980397
Step: 66460, Val_acc:0.943784
==================>
Step: 66470, Train_acc:0.975699
Step: 66470, Val_acc:0.952297
==================>
Step: 66480, Train_acc:0.977391
Step: 66480, Val_acc:0.929741
==================>
Step: 66490, Train_acc:0.978794
Step: 66490, Val_acc:0.929966
==================>
Step: 66500, Train_acc:0.984843
Step: 66500, Val_acc:0.952884
==================>
****************** Epochs completed: 133******************
2017-11-11 22:19:18.225328 ---> Validation_loss: 0.14499
Step: 66510, Train_acc:0.974888
Step: 66510, Val_acc:0.952004
==================>
Step: 66520, Train_acc:0.981256
Step: 66520, Val_acc:0.957417
==================>
Step: 66530, Train_acc:0.979512
Step: 66530, Val_acc:0.941799
==================>
Step: 66540, Train_acc:0.980286
Step: 66540, Val_acc:0.92819
==================>
Step: 66550, Train_acc:0.983896
Step: 66550, Val_acc:0.922837
==================>
Step: 66560, Train_acc:0.975392
Step: 66560, Val_acc:0.940385
==================>
Step: 66570, Train_acc:0.986855
Step: 66570, Val_acc:0.931412
==================>
Step: 66580, Train_acc:0.975581
Step: 66580, Val_acc:0.948938
==================>
Step: 66590, Train_acc:0.984137
Step: 66590, Val_acc:0.931834
==================>
Step: 66600, Train_acc:0.984592
Step: 66600, Val_acc:0.964586
==================>
2017-11-11 22:21:53.020376 ---> Validation_loss: 0.229677
Step: 66610, Train_acc:0.978467
Step: 66610, Val_acc:0.942976
==================>
Step: 66620, Train_acc:0.98027
Step: 66620, Val_acc:0.918196
==================>
Step: 66630, Train_acc:0.977278
Step: 66630, Val_acc:0.953594
==================>
Step: 66640, Train_acc:0.981786
Step: 66640, Val_acc:0.948026
==================>
Step: 66650, Train_acc:0.985266
Step: 66650, Val_acc:0.911533
==================>
Step: 66660, Train_acc:0.977322
Step: 66660, Val_acc:0.947081
==================>
Step: 66670, Train_acc:0.975855
Step: 66670, Val_acc:0.922378
==================>
Step: 66680, Train_acc:0.979954
Step: 66680, Val_acc:0.926559
==================>
Step: 66690, Train_acc:0.976442
Step: 66690, Val_acc:0.934124
==================>
Step: 66700, Train_acc:0.978027
Step: 66700, Val_acc:0.922263
==================>
2017-11-11 22:24:28.079396 ---> Validation_loss: 0.161191
Step: 66710, Train_acc:0.977991
Step: 66710, Val_acc:0.934916
==================>
Step: 66720, Train_acc:0.98557
Step: 66720, Val_acc:0.94386
==================>
Step: 66730, Train_acc:0.98022
Step: 66730, Val_acc:0.952595
==================>
Step: 66740, Train_acc:0.972148
Step: 66740, Val_acc:0.945143
==================>
Step: 66750, Train_acc:0.982441
Step: 66750, Val_acc:0.927843
==================>
Step: 66760, Train_acc:0.982036
Step: 66760, Val_acc:0.934983
==================>
Step: 66770, Train_acc:0.98092
Step: 66770, Val_acc:0.935709
==================>
Step: 66780, Train_acc:0.980022
Step: 66780, Val_acc:0.929955
==================>
Step: 66790, Train_acc:0.98739
Step: 66790, Val_acc:0.958199
==================>
Step: 66800, Train_acc:0.979219
Step: 66800, Val_acc:0.943114
==================>
2017-11-11 22:27:03.236637 ---> Validation_loss: 0.103725
Step: 66810, Train_acc:0.977374
Step: 66810, Val_acc:0.928971
==================>
Step: 66820, Train_acc:0.985718
Step: 66820, Val_acc:0.952703
==================>
Step: 66830, Train_acc:0.974813
Step: 66830, Val_acc:0.943763
==================>
Step: 66840, Train_acc:0.975338
Step: 66840, Val_acc:0.945793
==================>
Step: 66850, Train_acc:0.977052
Step: 66850, Val_acc:0.933375
==================>
Step: 66860, Train_acc:0.97262
Step: 66860, Val_acc:0.944174
==================>
Step: 66870, Train_acc:0.981868
Step: 66870, Val_acc:0.947343
==================>
Step: 66880, Train_acc:0.977423
Step: 66880, Val_acc:0.944393
==================>
Step: 66890, Train_acc:0.976953
Step: 66890, Val_acc:0.919049
==================>
Step: 66900, Train_acc:0.982979
Step: 66900, Val_acc:0.942866
==================>
2017-11-11 22:29:38.513138 ---> Validation_loss: 0.171308
Step: 66910, Train_acc:0.979873
Step: 66910, Val_acc:0.937755
==================>
Step: 66920, Train_acc:0.973958
Step: 66920, Val_acc:0.933242
==================>
Step: 66930, Train_acc:0.9824
Step: 66930, Val_acc:0.949766
==================>
Step: 66940, Train_acc:0.976531
Step: 66940, Val_acc:0.941945
==================>
Step: 66950, Train_acc:0.978704
Step: 66950, Val_acc:0.945627
==================>
Step: 66960, Train_acc:0.977466
Step: 66960, Val_acc:0.903567
==================>
Step: 66970, Train_acc:0.972136
Step: 66970, Val_acc:0.940043
==================>
Step: 66980, Train_acc:0.974861
Step: 66980, Val_acc:0.915298
==================>
Step: 66990, Train_acc:0.972922
Step: 66990, Val_acc:0.906018
==================>
Step: 67000, Train_acc:0.984209
Step: 67000, Val_acc:0.958286
==================>
****************** Epochs completed: 134******************
2017-11-11 22:32:14.179097 ---> Validation_loss: 0.144485
Step: 67010, Train_acc:0.982551
Step: 67010, Val_acc:0.921431
==================>
Step: 67020, Train_acc:0.978243
Step: 67020, Val_acc:0.929143
==================>
Step: 67030, Train_acc:0.984662
Step: 67030, Val_acc:0.943666
==================>
Step: 67040, Train_acc:0.983517
Step: 67040, Val_acc:0.939564
==================>
Step: 67050, Train_acc:0.975583
Step: 67050, Val_acc:0.915505
==================>
Step: 67060, Train_acc:0.979509
Step: 67060, Val_acc:0.955897
==================>
Step: 67070, Train_acc:0.980867
Step: 67070, Val_acc:0.93509
==================>
Step: 67080, Train_acc:0.977778
Step: 67080, Val_acc:0.953721
==================>
Step: 67090, Train_acc:0.978075
Step: 67090, Val_acc:0.957899
==================>
Step: 67100, Train_acc:0.976893
Step: 67100, Val_acc:0.934097
==================>
2017-11-11 22:34:49.129174 ---> Validation_loss: 0.161587
Step: 67110, Train_acc:0.980498
Step: 67110, Val_acc:0.935421
==================>
Step: 67120, Train_acc:0.982488
Step: 67120, Val_acc:0.91051
==================>
Step: 67130, Train_acc:0.982505
Step: 67130, Val_acc:0.93787
==================>
Step: 67140, Train_acc:0.976466
Step: 67140, Val_acc:0.935112
==================>
Step: 67150, Train_acc:0.976051
Step: 67150, Val_acc:0.920303
==================>
Step: 67160, Train_acc:0.977197
Step: 67160, Val_acc:0.951211
==================>
Step: 67170, Train_acc:0.976093
Step: 67170, Val_acc:0.953438
==================>
Step: 67180, Train_acc:0.975991
Step: 67180, Val_acc:0.925563
==================>
Step: 67190, Train_acc:0.979322
Step: 67190, Val_acc:0.930337
==================>
Step: 67200, Train_acc:0.97795
Step: 67200, Val_acc:0.936748
==================>
2017-11-11 22:37:24.117016 ---> Validation_loss: 0.134873
Step: 67210, Train_acc:0.980227
Step: 67210, Val_acc:0.924021
==================>
Step: 67220, Train_acc:0.977471
Step: 67220, Val_acc:0.953342
==================>
Step: 67230, Train_acc:0.980204
Step: 67230, Val_acc:0.947771
==================>
Step: 67240, Train_acc:0.967552
Step: 67240, Val_acc:0.943649
==================>
Step: 67250, Train_acc:0.982118
Step: 67250, Val_acc:0.948448
==================>
Step: 67260, Train_acc:0.98631
Step: 67260, Val_acc:0.925112
==================>
Step: 67270, Train_acc:0.980364
Step: 67270, Val_acc:0.939111
==================>
****************** Epochs completed: 20******************
Step: 67280, Train_acc:0.985446
Step: 67280, Val_acc:0.941163
==================>
Step: 67290, Train_acc:0.983575
Step: 67290, Val_acc:0.928411
==================>
Step: 67300, Train_acc:0.981899
Step: 67300, Val_acc:0.947175
==================>
2017-11-11 22:39:59.760562 ---> Validation_loss: 0.195509
Step: 67310, Train_acc:0.984747
Step: 67310, Val_acc:0.936578
==================>
Step: 67320, Train_acc:0.978301
Step: 67320, Val_acc:0.951483
==================>
Step: 67330, Train_acc:0.981985
Step: 67330, Val_acc:0.938337
==================>
Step: 67340, Train_acc:0.983682
Step: 67340, Val_acc:0.954216
==================>
Step: 67350, Train_acc:0.979796
Step: 67350, Val_acc:0.951765
==================>
Step: 67360, Train_acc:0.977859
Step: 67360, Val_acc:0.941447
==================>
Step: 67370, Train_acc:0.977874
Step: 67370, Val_acc:0.948262
==================>
Step: 67380, Train_acc:0.98275
Step: 67380, Val_acc:0.939625
==================>
Step: 67390, Train_acc:0.980594
Step: 67390, Val_acc:0.944807
==================>
Step: 67400, Train_acc:0.979774
Step: 67400, Val_acc:0.943197
==================>
2017-11-11 22:42:35.087373 ---> Validation_loss: 0.183696
Step: 67410, Train_acc:0.983827
Step: 67410, Val_acc:0.93913
==================>
Step: 67420, Train_acc:0.976294
Step: 67420, Val_acc:0.933337
==================>
Step: 67430, Train_acc:0.980778
Step: 67430, Val_acc:0.941908
==================>
Step: 67440, Train_acc:0.971862
Step: 67440, Val_acc:0.915886
==================>
Step: 67450, Train_acc:0.983606
Step: 67450, Val_acc:0.933308
==================>
Step: 67460, Train_acc:0.977159
Step: 67460, Val_acc:0.945775
==================>
Step: 67470, Train_acc:0.976421
Step: 67470, Val_acc:0.945295
==================>
Step: 67480, Train_acc:0.981538
Step: 67480, Val_acc:0.940392
==================>
Step: 67490, Train_acc:0.987297
Step: 67490, Val_acc:0.946754
==================>
Step: 67500, Train_acc:0.982411
Step: 67500, Val_acc:0.934659
==================>
****************** Epochs completed: 135******************
2017-11-11 22:45:10.270368 ---> Validation_loss: 0.151922
Step: 67510, Train_acc:0.980756
Step: 67510, Val_acc:0.94026
==================>
Step: 67520, Train_acc:0.983992
Step: 67520, Val_acc:0.928563
==================>
Step: 67530, Train_acc:0.979564
Step: 67530, Val_acc:0.943254
==================>
Step: 67540, Train_acc:0.985608
Step: 67540, Val_acc:0.931831
==================>
Step: 67550, Train_acc:0.977139
Step: 67550, Val_acc:0.944645
==================>
Step: 67560, Train_acc:0.977124
Step: 67560, Val_acc:0.930425
==================>
Step: 67570, Train_acc:0.981741
Step: 67570, Val_acc:0.945312
==================>
Step: 67580, Train_acc:0.973724
Step: 67580, Val_acc:0.925353
==================>
Step: 67590, Train_acc:0.98015
Step: 67590, Val_acc:0.945082
==================>
Step: 67600, Train_acc:0.977358
Step: 67600, Val_acc:0.951423
==================>
2017-11-11 22:47:45.024920 ---> Validation_loss: 0.128531
Step: 67610, Train_acc:0.977074
Step: 67610, Val_acc:0.953308
==================>
Step: 67620, Train_acc:0.977822
Step: 67620, Val_acc:0.96165
==================>
Step: 67630, Train_acc:0.980264
Step: 67630, Val_acc:0.955244
==================>
Step: 67640, Train_acc:0.975176
Step: 67640, Val_acc:0.956229
==================>
Step: 67650, Train_acc:0.976864
Step: 67650, Val_acc:0.945314
==================>
Step: 67660, Train_acc:0.978027
Step: 67660, Val_acc:0.952574
==================>
Step: 67670, Train_acc:0.979404
Step: 67670, Val_acc:0.926414
==================>
Step: 67680, Train_acc:0.981235
Step: 67680, Val_acc:0.950743
==================>
Step: 67690, Train_acc:0.974462
Step: 67690, Val_acc:0.92766
==================>
Step: 67700, Train_acc:0.984578
Step: 67700, Val_acc:0.943752
==================>
2017-11-11 22:50:20.235358 ---> Validation_loss: 0.0909241
Step: 67710, Train_acc:0.979768
Step: 67710, Val_acc:0.930515
==================>
Step: 67720, Train_acc:0.978488
Step: 67720, Val_acc:0.931206
==================>
Step: 67730, Train_acc:0.982557
Step: 67730, Val_acc:0.957964
==================>
Step: 67740, Train_acc:0.975142
Step: 67740, Val_acc:0.90687
==================>
Step: 67750, Train_acc:0.98108
Step: 67750, Val_acc:0.936165
==================>
Step: 67760, Train_acc:0.986001
Step: 67760, Val_acc:0.940957
==================>
Step: 67770, Train_acc:0.981437
Step: 67770, Val_acc:0.955183
==================>
Step: 67780, Train_acc:0.984228
Step: 67780, Val_acc:0.947604
==================>
Step: 67790, Train_acc:0.982621
Step: 67790, Val_acc:0.95355
==================>
Step: 67800, Train_acc:0.982589
Step: 67800, Val_acc:0.948174
==================>
2017-11-11 22:52:54.382183 ---> Validation_loss: 0.248207
Step: 67810, Train_acc:0.97766
Step: 67810, Val_acc:0.948373
==================>
Step: 67820, Train_acc:0.986276
Step: 67820, Val_acc:0.949697
==================>
Step: 67830, Train_acc:0.979855
Step: 67830, Val_acc:0.922039
==================>
Step: 67840, Train_acc:0.980381
Step: 67840, Val_acc:0.944448
==================>
Step: 67850, Train_acc:0.985922
Step: 67850, Val_acc:0.952324
==================>
Step: 67860, Train_acc:0.975781
Step: 67860, Val_acc:0.948508
==================>
Step: 67870, Train_acc:0.977983
Step: 67870, Val_acc:0.948743
==================>
Step: 67880, Train_acc:0.98306
Step: 67880, Val_acc:0.929011
==================>
Step: 67890, Train_acc:0.976605
Step: 67890, Val_acc:0.924485
==================>
Step: 67900, Train_acc:0.982623
Step: 67900, Val_acc:0.936804
==================>
2017-11-11 22:55:29.750065 ---> Validation_loss: 0.183483
Step: 67910, Train_acc:0.983765
Step: 67910, Val_acc:0.946963
==================>
Step: 67920, Train_acc:0.978014
Step: 67920, Val_acc:0.944224
==================>
Step: 67930, Train_acc:0.983011
Step: 67930, Val_acc:0.946769
==================>
Step: 67940, Train_acc:0.984119
Step: 67940, Val_acc:0.940415
==================>
Step: 67950, Train_acc:0.977419
Step: 67950, Val_acc:0.940553
==================>
Step: 67960, Train_acc:0.98043
Step: 67960, Val_acc:0.960312
==================>
Step: 67970, Train_acc:0.976716
Step: 67970, Val_acc:0.9535
==================>
Step: 67980, Train_acc:0.983494
Step: 67980, Val_acc:0.936949
==================>
Step: 67990, Train_acc:0.979702
Step: 67990, Val_acc:0.947698
==================>
Step: 68000, Train_acc:0.979384
Step: 68000, Val_acc:0.929932
==================>
****************** Epochs completed: 136******************
2017-11-11 22:58:04.158118 ---> Validation_loss: 0.115566
Step: 68010, Train_acc:0.986801
Step: 68010, Val_acc:0.930914
==================>
Step: 68020, Train_acc:0.98368
Step: 68020, Val_acc:0.922417
==================>
Step: 68030, Train_acc:0.974987
Step: 68030, Val_acc:0.946025
==================>
Step: 68040, Train_acc:0.978343
Step: 68040, Val_acc:0.954664
==================>
Step: 68050, Train_acc:0.979901
Step: 68050, Val_acc:0.93283
==================>
Step: 68060, Train_acc:0.973691
Step: 68060, Val_acc:0.932225
==================>
Step: 68070, Train_acc:0.979397
Step: 68070, Val_acc:0.934355
==================>
Step: 68080, Train_acc:0.980477
Step: 68080, Val_acc:0.924183
==================>
Step: 68090, Train_acc:0.973602
Step: 68090, Val_acc:0.9397
==================>
Step: 68100, Train_acc:0.981007
Step: 68100, Val_acc:0.962415
==================>
2017-11-11 23:00:39.223675 ---> Validation_loss: 0.172833
Step: 68110, Train_acc:0.97978
Step: 68110, Val_acc:0.947993
==================>
Step: 68120, Train_acc:0.979336
Step: 68120, Val_acc:0.933285
==================>
Step: 68130, Train_acc:0.973971
Step: 68130, Val_acc:0.92995
==================>
Step: 68140, Train_acc:0.985413
Step: 68140, Val_acc:0.950308
==================>
Step: 68150, Train_acc:0.978287
Step: 68150, Val_acc:0.952926
==================>
Step: 68160, Train_acc:0.979252
Step: 68160, Val_acc:0.947643
==================>
Step: 68170, Train_acc:0.979686
Step: 68170, Val_acc:0.930668
==================>
Step: 68180, Train_acc:0.980891
Step: 68180, Val_acc:0.958341
==================>
Step: 68190, Train_acc:0.983617
Step: 68190, Val_acc:0.933116
==================>
Step: 68200, Train_acc:0.980358
Step: 68200, Val_acc:0.946791
==================>
2017-11-11 23:03:13.675873 ---> Validation_loss: 0.185787
Step: 68210, Train_acc:0.980811
Step: 68210, Val_acc:0.932716
==================>
Step: 68220, Train_acc:0.980862
Step: 68220, Val_acc:0.952449
==================>
Step: 68230, Train_acc:0.982634
Step: 68230, Val_acc:0.956971
==================>
Step: 68240, Train_acc:0.980674
Step: 68240, Val_acc:0.905896
==================>
Step: 68250, Train_acc:0.983989
Step: 68250, Val_acc:0.944758
==================>
Step: 68260, Train_acc:0.982183
Step: 68260, Val_acc:0.949145
==================>
Step: 68270, Train_acc:0.975894
Step: 68270, Val_acc:0.933901
==================>
Step: 68280, Train_acc:0.982538
Step: 68280, Val_acc:0.932308
==================>
Step: 68290, Train_acc:0.983171
Step: 68290, Val_acc:0.94147
==================>
Step: 68300, Train_acc:0.979357
Step: 68300, Val_acc:0.934655
==================>
2017-11-11 23:05:49.129636 ---> Validation_loss: 0.157087
Step: 68310, Train_acc:0.977479
Step: 68310, Val_acc:0.93792
==================>
Step: 68320, Train_acc:0.974446
Step: 68320, Val_acc:0.926429
==================>
Step: 68330, Train_acc:0.982282
Step: 68330, Val_acc:0.95918
==================>
Step: 68340, Train_acc:0.976617
Step: 68340, Val_acc:0.929054
==================>
Step: 68350, Train_acc:0.984785
Step: 68350, Val_acc:0.94536
==================>
Step: 68360, Train_acc:0.982457
Step: 68360, Val_acc:0.929965
==================>
Step: 68370, Train_acc:0.980728
Step: 68370, Val_acc:0.950724
==================>
Step: 68380, Train_acc:0.984581
Step: 68380, Val_acc:0.950369
==================>
Step: 68390, Train_acc:0.981576
Step: 68390, Val_acc:0.951393
==================>
Step: 68400, Train_acc:0.979808
Step: 68400, Val_acc:0.949512
==================>
2017-11-11 23:08:23.633125 ---> Validation_loss: 0.134846
Step: 68410, Train_acc:0.981652
Step: 68410, Val_acc:0.927953
==================>
Step: 68420, Train_acc:0.979874
Step: 68420, Val_acc:0.933973
==================>
Step: 68430, Train_acc:0.982163
Step: 68430, Val_acc:0.941448
==================>
Step: 68440, Train_acc:0.981837
Step: 68440, Val_acc:0.948169
==================>
Step: 68450, Train_acc:0.982886
Step: 68450, Val_acc:0.945029
==================>
Step: 68460, Train_acc:0.978108
Step: 68460, Val_acc:0.940005
==================>
Step: 68470, Train_acc:0.985251
Step: 68470, Val_acc:0.949515
==================>
Step: 68480, Train_acc:0.978257
Step: 68480, Val_acc:0.938792
==================>
Step: 68490, Train_acc:0.979386
Step: 68490, Val_acc:0.920542
==================>
Step: 68500, Train_acc:0.978674
Step: 68500, Val_acc:0.947781
==================>
****************** Epochs completed: 137******************
2017-11-11 23:10:58.366790 ---> Validation_loss: 0.130473
Step: 68510, Train_acc:0.98129
Step: 68510, Val_acc:0.948778
==================>
Step: 68520, Train_acc:0.982364
Step: 68520, Val_acc:0.93105
==================>
Step: 68530, Train_acc:0.979161
Step: 68530, Val_acc:0.946023
==================>
Step: 68540, Train_acc:0.98264
Step: 68540, Val_acc:0.938278
==================>
Step: 68550, Train_acc:0.983201
Step: 68550, Val_acc:0.933778
==================>
Step: 68560, Train_acc:0.976896
Step: 68560, Val_acc:0.942874
==================>
Step: 68570, Train_acc:0.978925
Step: 68570, Val_acc:0.93635
==================>
Step: 68580, Train_acc:0.982522
Step: 68580, Val_acc:0.938951
==================>
Step: 68590, Train_acc:0.972023
Step: 68590, Val_acc:0.932263
==================>
Step: 68600, Train_acc:0.976923
Step: 68600, Val_acc:0.929583
==================>
2017-11-11 23:13:32.866583 ---> Validation_loss: 0.186168
Step: 68610, Train_acc:0.97892
Step: 68610, Val_acc:0.964257
==================>
Step: 68620, Train_acc:0.976095
Step: 68620, Val_acc:0.954591
==================>
Step: 68630, Train_acc:0.984165
Step: 68630, Val_acc:0.950262
==================>
Step: 68640, Train_acc:0.98064
Step: 68640, Val_acc:0.932131
==================>
Step: 68650, Train_acc:0.981055
Step: 68650, Val_acc:0.945177
==================>
Step: 68660, Train_acc:0.983328
Step: 68660, Val_acc:0.939066
==================>
Step: 68670, Train_acc:0.980549
Step: 68670, Val_acc:0.935232
==================>
Step: 68680, Train_acc:0.974777
Step: 68680, Val_acc:0.951713
==================>
Step: 68690, Train_acc:0.97848
Step: 68690, Val_acc:0.940883
==================>
Step: 68700, Train_acc:0.982484
Step: 68700, Val_acc:0.936968
==================>
2017-11-11 23:16:07.756589 ---> Validation_loss: 0.144251
Step: 68710, Train_acc:0.971517
Step: 68710, Val_acc:0.935438
==================>
Step: 68720, Train_acc:0.983605
Step: 68720, Val_acc:0.934802
==================>
Step: 68730, Train_acc:0.978562
Step: 68730, Val_acc:0.945719
==================>
Step: 68740, Train_acc:0.985107
Step: 68740, Val_acc:0.933849
==================>
Step: 68750, Train_acc:0.982712
Step: 68750, Val_acc:0.932186
==================>
Step: 68760, Train_acc:0.973158
Step: 68760, Val_acc:0.940388
==================>
Step: 68770, Train_acc:0.975815
Step: 68770, Val_acc:0.931271
==================>
Step: 68780, Train_acc:0.983926
Step: 68780, Val_acc:0.93959
==================>
Step: 68790, Train_acc:0.980797
Step: 68790, Val_acc:0.933636
==================>
Step: 68800, Train_acc:0.978185
Step: 68800, Val_acc:0.939279
==================>
2017-11-11 23:18:42.548585 ---> Validation_loss: 0.182537
Step: 68810, Train_acc:0.981089
Step: 68810, Val_acc:0.946521
==================>
Step: 68820, Train_acc:0.985518
Step: 68820, Val_acc:0.952418
==================>
Step: 68830, Train_acc:0.981001
Step: 68830, Val_acc:0.923496
==================>
Step: 68840, Train_acc:0.981492
Step: 68840, Val_acc:0.941106
==================>
Step: 68850, Train_acc:0.983057
Step: 68850, Val_acc:0.953429
==================>
Step: 68860, Train_acc:0.977653
Step: 68860, Val_acc:0.959332
==================>
Step: 68870, Train_acc:0.979558
Step: 68870, Val_acc:0.953767
==================>
Step: 68880, Train_acc:0.967722
Step: 68880, Val_acc:0.946506
==================>
Step: 68890, Train_acc:0.981748
Step: 68890, Val_acc:0.921062
==================>
Step: 68900, Train_acc:0.976929
Step: 68900, Val_acc:0.941183
==================>
2017-11-11 23:21:17.728129 ---> Validation_loss: 0.108325
Step: 68910, Train_acc:0.978298
Step: 68910, Val_acc:0.941691
==================>
Step: 68920, Train_acc:0.985421
Step: 68920, Val_acc:0.961255
==================>
Step: 68930, Train_acc:0.978151
Step: 68930, Val_acc:0.940745
==================>
Step: 68940, Train_acc:0.981022
Step: 68940, Val_acc:0.940756
==================>
Step: 68950, Train_acc:0.980804
Step: 68950, Val_acc:0.92188
==================>
Step: 68960, Train_acc:0.980763
Step: 68960, Val_acc:0.929758
==================>
Step: 68970, Train_acc:0.980182
Step: 68970, Val_acc:0.947961
==================>
Step: 68980, Train_acc:0.985692
Step: 68980, Val_acc:0.927692
==================>
Step: 68990, Train_acc:0.982305
Step: 68990, Val_acc:0.930393
==================>
Step: 69000, Train_acc:0.98373
Step: 69000, Val_acc:0.927421
==================>
****************** Epochs completed: 138******************
2017-11-11 23:23:52.843016 ---> Validation_loss: 0.191291
Step: 69010, Train_acc:0.982207
Step: 69010, Val_acc:0.940905
==================>
Step: 69020, Train_acc:0.97432
Step: 69020, Val_acc:0.9405
==================>
Step: 69030, Train_acc:0.977886
Step: 69030, Val_acc:0.941558
==================>
Step: 69040, Train_acc:0.976456
Step: 69040, Val_acc:0.963803
==================>
Step: 69050, Train_acc:0.979797
Step: 69050, Val_acc:0.95923
==================>
Step: 69060, Train_acc:0.980933
Step: 69060, Val_acc:0.958954
==================>
Step: 69070, Train_acc:0.981045
Step: 69070, Val_acc:0.940988
==================>
Step: 69080, Train_acc:0.981916
Step: 69080, Val_acc:0.935597
==================>
Step: 69090, Train_acc:0.969294
Step: 69090, Val_acc:0.938345
==================>
Step: 69100, Train_acc:0.98017
Step: 69100, Val_acc:0.924629
==================>
2017-11-11 23:26:27.811303 ---> Validation_loss: 0.136186
Step: 69110, Train_acc:0.976541
Step: 69110, Val_acc:0.946836
==================>
Step: 69120, Train_acc:0.981915
Step: 69120, Val_acc:0.941714
==================>
Step: 69130, Train_acc:0.98129
Step: 69130, Val_acc:0.948257
==================>
Step: 69140, Train_acc:0.974871
Step: 69140, Val_acc:0.934823
==================>
Step: 69150, Train_acc:0.977489
Step: 69150, Val_acc:0.96184
==================>
Step: 69160, Train_acc:0.979515
Step: 69160, Val_acc:0.948674
==================>
Step: 69170, Train_acc:0.982175
Step: 69170, Val_acc:0.938385
==================>
Step: 69180, Train_acc:0.978959
Step: 69180, Val_acc:0.951621
==================>
Step: 69190, Train_acc:0.979326
Step: 69190, Val_acc:0.926787
==================>
Step: 69200, Train_acc:0.97635
Step: 69200, Val_acc:0.92402
==================>
2017-11-11 23:29:02.319080 ---> Validation_loss: 0.162743
Step: 69210, Train_acc:0.974113
Step: 69210, Val_acc:0.949248
==================>
Step: 69220, Train_acc:0.980083
Step: 69220, Val_acc:0.941726
==================>
Step: 69230, Train_acc:0.984153
Step: 69230, Val_acc:0.939974
==================>
Step: 69240, Train_acc:0.984194
Step: 69240, Val_acc:0.95438
==================>
Step: 69250, Train_acc:0.983386
Step: 69250, Val_acc:0.948811
==================>
Step: 69260, Train_acc:0.983005
Step: 69260, Val_acc:0.937267
==================>
Step: 69270, Train_acc:0.98512
Step: 69270, Val_acc:0.9447
==================>
Step: 69280, Train_acc:0.983057
Step: 69280, Val_acc:0.952993
==================>
Step: 69290, Train_acc:0.975439
Step: 69290, Val_acc:0.947382
==================>
Step: 69300, Train_acc:0.975823
Step: 69300, Val_acc:0.959933
==================>
2017-11-11 23:31:37.141842 ---> Validation_loss: 0.137549
Step: 69310, Train_acc:0.981047
Step: 69310, Val_acc:0.970918
==================>
Step: 69320, Train_acc:0.986383
Step: 69320, Val_acc:0.916132
==================>
Step: 69330, Train_acc:0.97136
Step: 69330, Val_acc:0.931722
==================>
Step: 69340, Train_acc:0.984404
Step: 69340, Val_acc:0.939441
==================>
Step: 69350, Train_acc:0.981141
Step: 69350, Val_acc:0.94667
==================>
Step: 69360, Train_acc:0.975133
Step: 69360, Val_acc:0.93865
==================>
Step: 69370, Train_acc:0.97705
Step: 69370, Val_acc:0.93545
==================>
Step: 69380, Train_acc:0.97469
Step: 69380, Val_acc:0.910942
==================>
Step: 69390, Train_acc:0.983109
Step: 69390, Val_acc:0.957395
==================>
Step: 69400, Train_acc:0.977948
Step: 69400, Val_acc:0.928108
==================>
2017-11-11 23:34:12.296621 ---> Validation_loss: 0.182273
Step: 69410, Train_acc:0.981289
Step: 69410, Val_acc:0.934868
==================>
Step: 69420, Train_acc:0.978898
Step: 69420, Val_acc:0.927083
==================>
Step: 69430, Train_acc:0.976801
Step: 69430, Val_acc:0.926224
==================>
Step: 69440, Train_acc:0.981965
Step: 69440, Val_acc:0.937061
==================>
Step: 69450, Train_acc:0.974186
Step: 69450, Val_acc:0.943293
==================>
Step: 69460, Train_acc:0.986154
Step: 69460, Val_acc:0.942059
==================>
Step: 69470, Train_acc:0.979175
Step: 69470, Val_acc:0.953641
==================>
Step: 69480, Train_acc:0.975433
Step: 69480, Val_acc:0.930883
==================>
Step: 69490, Train_acc:0.981594
Step: 69490, Val_acc:0.945707
==================>
Step: 69500, Train_acc:0.976866
Step: 69500, Val_acc:0.897252
==================>
****************** Epochs completed: 139******************
2017-11-11 23:36:47.042356 ---> Validation_loss: 0.139126
Step: 69510, Train_acc:0.985134
Step: 69510, Val_acc:0.932446
==================>
Step: 69520, Train_acc:0.983884
Step: 69520, Val_acc:0.922801
==================>
Step: 69530, Train_acc:0.984199
Step: 69530, Val_acc:0.936481
==================>
Step: 69540, Train_acc:0.982976
Step: 69540, Val_acc:0.948124
==================>
Step: 69550, Train_acc:0.986017
Step: 69550, Val_acc:0.939124
==================>
Step: 69560, Train_acc:0.975258
Step: 69560, Val_acc:0.936374
==================>
Step: 69570, Train_acc:0.985524
Step: 69570, Val_acc:0.945597
==================>
Step: 69580, Train_acc:0.989756
Step: 69580, Val_acc:0.959318
==================>
Step: 69590, Train_acc:0.985944
Step: 69590, Val_acc:0.950995
==================>
Step: 69600, Train_acc:0.978749
Step: 69600, Val_acc:0.954456
==================>
2017-11-11 23:39:22.339476 ---> Validation_loss: 0.151802
Step: 69610, Train_acc:0.97912
Step: 69610, Val_acc:0.944015
==================>
Step: 69620, Train_acc:0.981849
Step: 69620, Val_acc:0.937451
==================>
Step: 69630, Train_acc:0.980216
Step: 69630, Val_acc:0.932971
==================>
Step: 69640, Train_acc:0.97038
Step: 69640, Val_acc:0.944264
==================>
Step: 69650, Train_acc:0.981375
Step: 69650, Val_acc:0.942246
==================>
Step: 69660, Train_acc:0.980238
Step: 69660, Val_acc:0.936562
==================>
Step: 69670, Train_acc:0.985837
Step: 69670, Val_acc:0.960037
==================>
Step: 69680, Train_acc:0.973977
Step: 69680, Val_acc:0.929238
==================>
Step: 69690, Train_acc:0.981686
Step: 69690, Val_acc:0.933373
==================>
Step: 69700, Train_acc:0.983311
Step: 69700, Val_acc:0.938909
==================>
2017-11-11 23:41:56.597801 ---> Validation_loss: 0.214483
Step: 69710, Train_acc:0.982135
Step: 69710, Val_acc:0.944315
==================>
Step: 69720, Train_acc:0.980509
Step: 69720, Val_acc:0.931661
==================>
Step: 69730, Train_acc:0.981399
Step: 69730, Val_acc:0.94418
==================>
Step: 69740, Train_acc:0.982865
Step: 69740, Val_acc:0.939369
==================>
Step: 69750, Train_acc:0.981409
Step: 69750, Val_acc:0.945737
==================>
Step: 69760, Train_acc:0.97196
Step: 69760, Val_acc:0.962032
==================>
Step: 69770, Train_acc:0.977152
Step: 69770, Val_acc:0.939147
==================>
Step: 69780, Train_acc:0.984292
Step: 69780, Val_acc:0.921986
==================>
Step: 69790, Train_acc:0.977191
Step: 69790, Val_acc:0.93114
==================>
Step: 69800, Train_acc:0.977612
Step: 69800, Val_acc:0.946459
==================>
2017-11-11 23:44:32.029517 ---> Validation_loss: 0.154116
Step: 69810, Train_acc:0.980731
Step: 69810, Val_acc:0.960327
==================>
Step: 69820, Train_acc:0.977781
Step: 69820, Val_acc:0.94813
==================>
Step: 69830, Train_acc:0.979932
Step: 69830, Val_acc:0.947074
==================>
Step: 69840, Train_acc:0.983979
Step: 69840, Val_acc:0.944716
==================>
Step: 69850, Train_acc:0.982338
Step: 69850, Val_acc:0.954895
==================>
Step: 69860, Train_acc:0.979546
Step: 69860, Val_acc:0.947877
==================>
Step: 69870, Train_acc:0.983395
Step: 69870, Val_acc:0.939846
==================>
Step: 69880, Train_acc:0.980004
Step: 69880, Val_acc:0.926691
==================>
Step: 69890, Train_acc:0.98797
Step: 69890, Val_acc:0.948517
==================>
Step: 69900, Train_acc:0.9813
Step: 69900, Val_acc:0.920121
==================>
2017-11-11 23:47:07.343901 ---> Validation_loss: 0.142991
Step: 69910, Train_acc:0.983835
Step: 69910, Val_acc:0.939384
==================>
Step: 69920, Train_acc:0.979476
Step: 69920, Val_acc:0.950463
==================>
Step: 69930, Train_acc:0.976418
Step: 69930, Val_acc:0.955381
==================>
Step: 69940, Train_acc:0.978569
Step: 69940, Val_acc:0.929011
==================>
Step: 69950, Train_acc:0.975967
Step: 69950, Val_acc:0.938246
==================>
Step: 69960, Train_acc:0.9773
Step: 69960, Val_acc:0.940214
==================>
Step: 69970, Train_acc:0.978103
Step: 69970, Val_acc:0.939895
==================>
Step: 69980, Train_acc:0.984606
Step: 69980, Val_acc:0.926468
==================>
Step: 69990, Train_acc:0.983948
Step: 69990, Val_acc:0.928562
==================>
Step: 70000, Train_acc:0.977161
Step: 70000, Val_acc:0.94473
==================>
****************** Epochs completed: 140******************
2017-11-11 23:49:43.105072 ---> Validation_loss: 0.150649
Step: 70010, Train_acc:0.986289
Step: 70010, Val_acc:0.934657
==================>
Step: 70020, Train_acc:0.982266
Step: 70020, Val_acc:0.941259
==================>
Step: 70030, Train_acc:0.972891
Step: 70030, Val_acc:0.942136
==================>
Step: 70040, Train_acc:0.982595
Step: 70040, Val_acc:0.939197
==================>
Step: 70050, Train_acc:0.981256
Step: 70050, Val_acc:0.952382
==================>
Step: 70060, Train_acc:0.981301
Step: 70060, Val_acc:0.941571
==================>
Step: 70070, Train_acc:0.985859
Step: 70070, Val_acc:0.93219
==================>
Step: 70080, Train_acc:0.986219
Step: 70080, Val_acc:0.935765
==================>
Step: 70090, Train_acc:0.965833
Step: 70090, Val_acc:0.928912
==================>
Step: 70100, Train_acc:0.980526
Step: 70100, Val_acc:0.94656
==================>
2017-11-11 23:52:18.898293 ---> Validation_loss: 0.12192
Step: 70110, Train_acc:0.974261
Step: 70110, Val_acc:0.934038
==================>
Step: 70120, Train_acc:0.979629
Step: 70120, Val_acc:0.93968
==================>
Step: 70130, Train_acc:0.98043
Step: 70130, Val_acc:0.909993
==================>
Step: 70140, Train_acc:0.983473
Step: 70140, Val_acc:0.952162
==================>
Step: 70150, Train_acc:0.979335
Step: 70150, Val_acc:0.923085
==================>
Step: 70160, Train_acc:0.974114
Step: 70160, Val_acc:0.956202
==================>
Step: 70170, Train_acc:0.974252
Step: 70170, Val_acc:0.937601
==================>
Step: 70180, Train_acc:0.972842
Step: 70180, Val_acc:0.927433
==================>
Step: 70190, Train_acc:0.980404
Step: 70190, Val_acc:0.944757
==================>
Step: 70200, Train_acc:0.980626
Step: 70200, Val_acc:0.947899
==================>
2017-11-11 23:54:55.445975 ---> Validation_loss: 0.155871
Step: 70210, Train_acc:0.979818
Step: 70210, Val_acc:0.941877
==================>
Step: 70220, Train_acc:0.968562
Step: 70220, Val_acc:0.94165
==================>
Step: 70230, Train_acc:0.978958
Step: 70230, Val_acc:0.955988
==================>
Step: 70240, Train_acc:0.975996
Step: 70240, Val_acc:0.934447
==================>
Step: 70250, Train_acc:0.981772
Step: 70250, Val_acc:0.941628
==================>
Step: 70260, Train_acc:0.98033
Step: 70260, Val_acc:0.946382
==================>
Step: 70270, Train_acc:0.984121
Step: 70270, Val_acc:0.919634
==================>
Step: 70280, Train_acc:0.983508
Step: 70280, Val_acc:0.935696
==================>
Step: 70290, Train_acc:0.96538
Step: 70290, Val_acc:0.940945
==================>
Step: 70300, Train_acc:0.982963
Step: 70300, Val_acc:0.954027
==================>
2017-11-11 23:57:30.141125 ---> Validation_loss: 0.169321
Step: 70310, Train_acc:0.981597
Step: 70310, Val_acc:0.937974
==================>
Step: 70320, Train_acc:0.972311
Step: 70320, Val_acc:0.929353
==================>
Step: 70330, Train_acc:0.972288
Step: 70330, Val_acc:0.925354
==================>
Step: 70340, Train_acc:0.979719
Step: 70340, Val_acc:0.943218
==================>
Step: 70350, Train_acc:0.979872
Step: 70350, Val_acc:0.931547
==================>
Step: 70360, Train_acc:0.978407
Step: 70360, Val_acc:0.944968
==================>
Step: 70370, Train_acc:0.981481
Step: 70370, Val_acc:0.946511
==================>
Step: 70380, Train_acc:0.982095
Step: 70380, Val_acc:0.941818
==================>
Step: 70390, Train_acc:0.983284
Step: 70390, Val_acc:0.945765
==================>
Step: 70400, Train_acc:0.980447
Step: 70400, Val_acc:0.922662
==================>
2017-11-12 00:00:05.241157 ---> Validation_loss: 0.161001
Step: 70410, Train_acc:0.97864
Step: 70410, Val_acc:0.953188
==================>
Step: 70420, Train_acc:0.977648
Step: 70420, Val_acc:0.943499
==================>
Step: 70430, Train_acc:0.976433
Step: 70430, Val_acc:0.945305
==================>
Step: 70440, Train_acc:0.977958
Step: 70440, Val_acc:0.938845
==================>
Step: 70450, Train_acc:0.975972
Step: 70450, Val_acc:0.948097
==================>
Step: 70460, Train_acc:0.979491
Step: 70460, Val_acc:0.962734
==================>
Step: 70470, Train_acc:0.978253
Step: 70470, Val_acc:0.941875
==================>
Step: 70480, Train_acc:0.985033
Step: 70480, Val_acc:0.93734
==================>
Step: 70490, Train_acc:0.980194
Step: 70490, Val_acc:0.952561
==================>
Step: 70500, Train_acc:0.979338
Step: 70500, Val_acc:0.936604
==================>
****************** Epochs completed: 141******************
2017-11-12 00:02:40.373761 ---> Validation_loss: 0.144582
Step: 70510, Train_acc:0.975317
Step: 70510, Val_acc:0.945029
==================>
Step: 70520, Train_acc:0.985537
Step: 70520, Val_acc:0.928702
==================>
Step: 70530, Train_acc:0.976986
Step: 70530, Val_acc:0.947921
==================>
Step: 70540, Train_acc:0.979117
Step: 70540, Val_acc:0.953309
==================>
Step: 70550, Train_acc:0.982444
Step: 70550, Val_acc:0.936901
==================>
Step: 70560, Train_acc:0.979088
Step: 70560, Val_acc:0.967946
==================>
Step: 70570, Train_acc:0.98123
Step: 70570, Val_acc:0.950704
==================>
Step: 70580, Train_acc:0.98145
Step: 70580, Val_acc:0.937744
==================>
Step: 70590, Train_acc:0.97747
Step: 70590, Val_acc:0.938656
==================>
Step: 70600, Train_acc:0.978405
Step: 70600, Val_acc:0.936946
==================>
2017-11-12 00:05:15.245667 ---> Validation_loss: 0.138988
Step: 70610, Train_acc:0.982874
Step: 70610, Val_acc:0.940226
==================>
Step: 70620, Train_acc:0.976002
Step: 70620, Val_acc:0.94913
==================>
Step: 70630, Train_acc:0.982269
Step: 70630, Val_acc:0.950087
==================>
Step: 70640, Train_acc:0.980341
Step: 70640, Val_acc:0.942498
==================>
****************** Epochs completed: 21******************
Step: 70650, Train_acc:0.984412
Step: 70650, Val_acc:0.913887
==================>
Step: 70660, Train_acc:0.979481
Step: 70660, Val_acc:0.922377
==================>
Step: 70670, Train_acc:0.978279
Step: 70670, Val_acc:0.919332
==================>
Step: 70680, Train_acc:0.986025
Step: 70680, Val_acc:0.951924
==================>
Step: 70690, Train_acc:0.973525
Step: 70690, Val_acc:0.93239
==================>
Step: 70700, Train_acc:0.9767
Step: 70700, Val_acc:0.959711
==================>
2017-11-12 00:07:50.489643 ---> Validation_loss: 0.0901666
Step: 70710, Train_acc:0.981387
Step: 70710, Val_acc:0.94604
==================>
Step: 70720, Train_acc:0.978574
Step: 70720, Val_acc:0.961169
==================>
Step: 70730, Train_acc:0.980226
Step: 70730, Val_acc:0.932506
==================>
Step: 70740, Train_acc:0.985045
Step: 70740, Val_acc:0.935082
==================>
Step: 70750, Train_acc:0.984241
Step: 70750, Val_acc:0.948673
==================>
Step: 70760, Train_acc:0.987323
Step: 70760, Val_acc:0.951118
==================>
Step: 70770, Train_acc:0.98134
Step: 70770, Val_acc:0.938872
==================>
Step: 70780, Train_acc:0.979027
Step: 70780, Val_acc:0.911633
==================>
Step: 70790, Train_acc:0.98351
Step: 70790, Val_acc:0.954015
==================>
Step: 70800, Train_acc:0.984185
Step: 70800, Val_acc:0.9584
==================>
2017-11-12 00:10:25.435576 ---> Validation_loss: 0.262429
Step: 70810, Train_acc:0.975188
Step: 70810, Val_acc:0.931182
==================>
Step: 70820, Train_acc:0.983235
Step: 70820, Val_acc:0.950436
==================>
Step: 70830, Train_acc:0.981522
Step: 70830, Val_acc:0.942517
==================>
Step: 70840, Train_acc:0.986665
Step: 70840, Val_acc:0.947706
==================>
Step: 70850, Train_acc:0.979515
Step: 70850, Val_acc:0.933132
==================>
Step: 70860, Train_acc:0.982189
Step: 70860, Val_acc:0.967413
==================>
Step: 70870, Train_acc:0.973816
Step: 70870, Val_acc:0.938368
==================>
Step: 70880, Train_acc:0.983463
Step: 70880, Val_acc:0.924207
==================>
Step: 70890, Train_acc:0.9817
Step: 70890, Val_acc:0.939435
==================>
Step: 70900, Train_acc:0.983572
Step: 70900, Val_acc:0.927328
==================>
2017-11-12 00:13:00.478507 ---> Validation_loss: 0.106703
Step: 70910, Train_acc:0.978601
Step: 70910, Val_acc:0.9383
==================>
Step: 70920, Train_acc:0.986279
Step: 70920, Val_acc:0.960096
==================>
Step: 70930, Train_acc:0.976896
Step: 70930, Val_acc:0.943887
==================>
Step: 70940, Train_acc:0.979805
Step: 70940, Val_acc:0.929839
==================>
Step: 70950, Train_acc:0.981121
Step: 70950, Val_acc:0.95111
==================>
Step: 70960, Train_acc:0.983226
Step: 70960, Val_acc:0.94207
==================>
Step: 70970, Train_acc:0.980195
Step: 70970, Val_acc:0.933243
==================>
Step: 70980, Train_acc:0.984916
Step: 70980, Val_acc:0.952058
==================>
Step: 70990, Train_acc:0.986121
Step: 70990, Val_acc:0.958141
==================>
Step: 71000, Train_acc:0.981489
Step: 71000, Val_acc:0.953998
==================>
****************** Epochs completed: 142******************
2017-11-12 00:15:35.712998 ---> Validation_loss: 0.150798
Step: 71010, Train_acc:0.973961
Step: 71010, Val_acc:0.942638
==================>
Step: 71020, Train_acc:0.984114
Step: 71020, Val_acc:0.953337
==================>
Step: 71030, Train_acc:0.981638
Step: 71030, Val_acc:0.950818
==================>
Step: 71040, Train_acc:0.980204
Step: 71040, Val_acc:0.957953
==================>
Step: 71050, Train_acc:0.98803
Step: 71050, Val_acc:0.949812
==================>
Step: 71060, Train_acc:0.982989
Step: 71060, Val_acc:0.944259
==================>
Step: 71070, Train_acc:0.986888
Step: 71070, Val_acc:0.9498
==================>
Step: 71080, Train_acc:0.984309
Step: 71080, Val_acc:0.948259
==================>
Step: 71090, Train_acc:0.978641
Step: 71090, Val_acc:0.954827
==================>
Step: 71100, Train_acc:0.974421
Step: 71100, Val_acc:0.950048
==================>
2017-11-12 00:18:10.857839 ---> Validation_loss: 0.170627
Step: 71110, Train_acc:0.986785
Step: 71110, Val_acc:0.968267
==================>
Step: 71120, Train_acc:0.979926
Step: 71120, Val_acc:0.940248
==================>
Step: 71130, Train_acc:0.984132
Step: 71130, Val_acc:0.949054
==================>
Step: 71140, Train_acc:0.982697
Step: 71140, Val_acc:0.942982
==================>
Step: 71150, Train_acc:0.980399
Step: 71150, Val_acc:0.942671
==================>
Step: 71160, Train_acc:0.981371
Step: 71160, Val_acc:0.93446
==================>
Step: 71170, Train_acc:0.980859
Step: 71170, Val_acc:0.953551
==================>
Step: 71180, Train_acc:0.982275
Step: 71180, Val_acc:0.947491
==================>
Step: 71190, Train_acc:0.983351
Step: 71190, Val_acc:0.954908
==================>
Step: 71200, Train_acc:0.981025
Step: 71200, Val_acc:0.94532
==================>
2017-11-12 00:20:45.983202 ---> Validation_loss: 0.118573
Step: 71210, Train_acc:0.983685
Step: 71210, Val_acc:0.943024
==================>
Step: 71220, Train_acc:0.976893
Step: 71220, Val_acc:0.935906
==================>
Step: 71230, Train_acc:0.981472
Step: 71230, Val_acc:0.953979
==================>
Step: 71240, Train_acc:0.975745
Step: 71240, Val_acc:0.928054
==================>
Step: 71250, Train_acc:0.981207
Step: 71250, Val_acc:0.940491
==================>
Step: 71260, Train_acc:0.9813
Step: 71260, Val_acc:0.936467
==================>
Step: 71270, Train_acc:0.971053
Step: 71270, Val_acc:0.921788
==================>
Step: 71280, Train_acc:0.979305
Step: 71280, Val_acc:0.945559
==================>
Step: 71290, Train_acc:0.983398
Step: 71290, Val_acc:0.944084
==================>
Step: 71300, Train_acc:0.976942
Step: 71300, Val_acc:0.95427
==================>
2017-11-12 00:23:21.183300 ---> Validation_loss: 0.128162
Step: 71310, Train_acc:0.982366
Step: 71310, Val_acc:0.945361
==================>
Step: 71320, Train_acc:0.976735
Step: 71320, Val_acc:0.931688
==================>
Step: 71330, Train_acc:0.98218
Step: 71330, Val_acc:0.949249
==================>
Step: 71340, Train_acc:0.985425
Step: 71340, Val_acc:0.921814
==================>
Step: 71350, Train_acc:0.981984
Step: 71350, Val_acc:0.940703
==================>
Step: 71360, Train_acc:0.980215
Step: 71360, Val_acc:0.942208
==================>
Step: 71370, Train_acc:0.985138
Step: 71370, Val_acc:0.947612
==================>
Step: 71380, Train_acc:0.983657
Step: 71380, Val_acc:0.933396
==================>
Step: 71390, Train_acc:0.985041
Step: 71390, Val_acc:0.946404
==================>
Step: 71400, Train_acc:0.981315
Step: 71400, Val_acc:0.932284
==================>
2017-11-12 00:25:56.441579 ---> Validation_loss: 0.135687
Step: 71410, Train_acc:0.978972
Step: 71410, Val_acc:0.921686
==================>
Step: 71420, Train_acc:0.983159
Step: 71420, Val_acc:0.94363
==================>
Step: 71430, Train_acc:0.977714
Step: 71430, Val_acc:0.948877
==================>
Step: 71440, Train_acc:0.979618
Step: 71440, Val_acc:0.943474
==================>
Step: 71450, Train_acc:0.982076
Step: 71450, Val_acc:0.946063
==================>
Step: 71460, Train_acc:0.97837
Step: 71460, Val_acc:0.962203
==================>
Step: 71470, Train_acc:0.982684
Step: 71470, Val_acc:0.946083
==================>
Step: 71480, Train_acc:0.985209
Step: 71480, Val_acc:0.941437
==================>
Step: 71490, Train_acc:0.979891
Step: 71490, Val_acc:0.933541
==================>
Step: 71500, Train_acc:0.984813
Step: 71500, Val_acc:0.92764
==================>
****************** Epochs completed: 143******************
2017-11-12 00:28:31.159278 ---> Validation_loss: 0.103684
Step: 71510, Train_acc:0.98297
Step: 71510, Val_acc:0.934703
==================>
Step: 71520, Train_acc:0.986191
Step: 71520, Val_acc:0.933729
==================>
Step: 71530, Train_acc:0.973507
Step: 71530, Val_acc:0.946121
==================>
Step: 71540, Train_acc:0.984565
Step: 71540, Val_acc:0.929358
==================>
Step: 71550, Train_acc:0.979481
Step: 71550, Val_acc:0.946113
==================>
Step: 71560, Train_acc:0.986423
Step: 71560, Val_acc:0.940175
==================>
Step: 71570, Train_acc:0.985463
Step: 71570, Val_acc:0.946199
==================>
Step: 71580, Train_acc:0.98431
Step: 71580, Val_acc:0.941006
==================>
Step: 71590, Train_acc:0.985521
Step: 71590, Val_acc:0.949872
==================>
Step: 71600, Train_acc:0.987017
Step: 71600, Val_acc:0.950168
==================>
2017-11-12 00:31:06.147138 ---> Validation_loss: 0.137854
Step: 71610, Train_acc:0.979645
Step: 71610, Val_acc:0.946366
==================>
Step: 71620, Train_acc:0.982588
Step: 71620, Val_acc:0.947859
==================>
Step: 71630, Train_acc:0.982577
Step: 71630, Val_acc:0.931938
==================>
Step: 71640, Train_acc:0.985568
Step: 71640, Val_acc:0.944276
==================>
Step: 71650, Train_acc:0.987058
Step: 71650, Val_acc:0.921548
==================>
Step: 71660, Train_acc:0.984706
Step: 71660, Val_acc:0.942308
==================>
Step: 71670, Train_acc:0.978922
Step: 71670, Val_acc:0.952452
==================>
Step: 71680, Train_acc:0.985333
Step: 71680, Val_acc:0.929232
==================>
Step: 71690, Train_acc:0.976914
Step: 71690, Val_acc:0.934448
==================>
Step: 71700, Train_acc:0.984915
Step: 71700, Val_acc:0.946545
==================>
2017-11-12 00:33:41.313012 ---> Validation_loss: 0.167108
Step: 71710, Train_acc:0.982059
Step: 71710, Val_acc:0.927257
==================>
Step: 71720, Train_acc:0.981567
Step: 71720, Val_acc:0.947109
==================>
Step: 71730, Train_acc:0.986138
Step: 71730, Val_acc:0.93121
==================>
Step: 71740, Train_acc:0.990134
Step: 71740, Val_acc:0.924121
==================>
Step: 71750, Train_acc:0.982196
Step: 71750, Val_acc:0.935179
==================>
Step: 71760, Train_acc:0.983199
Step: 71760, Val_acc:0.92757
==================>
Step: 71770, Train_acc:0.973599
Step: 71770, Val_acc:0.96334
==================>
Step: 71780, Train_acc:0.984078
Step: 71780, Val_acc:0.942563
==================>
Step: 71790, Train_acc:0.984526
Step: 71790, Val_acc:0.951467
==================>
Step: 71800, Train_acc:0.981317
Step: 71800, Val_acc:0.935524
==================>
2017-11-12 00:36:16.413588 ---> Validation_loss: 0.135839
Step: 71810, Train_acc:0.98103
Step: 71810, Val_acc:0.921646
==================>
Step: 71820, Train_acc:0.985034
Step: 71820, Val_acc:0.923585
==================>
Step: 71830, Train_acc:0.985703
Step: 71830, Val_acc:0.957477
==================>
Step: 71840, Train_acc:0.98438
Step: 71840, Val_acc:0.909287
==================>
Step: 71850, Train_acc:0.98729
Step: 71850, Val_acc:0.938961
==================>
Step: 71860, Train_acc:0.978606
Step: 71860, Val_acc:0.943049
==================>
Step: 71870, Train_acc:0.978235
Step: 71870, Val_acc:0.947461
==================>
Step: 71880, Train_acc:0.985146
Step: 71880, Val_acc:0.948752
==================>
Step: 71890, Train_acc:0.983796
Step: 71890, Val_acc:0.97222
==================>
Step: 71900, Train_acc:0.985002
Step: 71900, Val_acc:0.94968
==================>
2017-11-12 00:38:51.374925 ---> Validation_loss: 0.216976
Step: 71910, Train_acc:0.97683
Step: 71910, Val_acc:0.953555
==================>
Step: 71920, Train_acc:0.989572
Step: 71920, Val_acc:0.950294
==================>
Step: 71930, Train_acc:0.986666
Step: 71930, Val_acc:0.941797
==================>
Step: 71940, Train_acc:0.979766
Step: 71940, Val_acc:0.946877
==================>
Step: 71950, Train_acc:0.985542
Step: 71950, Val_acc:0.963866
==================>
Step: 71960, Train_acc:0.985178
Step: 71960, Val_acc:0.944868
==================>
Step: 71970, Train_acc:0.979465
Step: 71970, Val_acc:0.95251
==================>
Step: 71980, Train_acc:0.985354
Step: 71980, Val_acc:0.961519
==================>
Step: 71990, Train_acc:0.98271
Step: 71990, Val_acc:0.939966
==================>
Step: 72000, Train_acc:0.98319
Step: 72000, Val_acc:0.943127
==================>
****************** Epochs completed: 144******************
2017-11-12 00:41:26.669412 ---> Validation_loss: 0.170581
Step: 72010, Train_acc:0.975891
Step: 72010, Val_acc:0.947892
==================>
Step: 72020, Train_acc:0.983036
Step: 72020, Val_acc:0.942275
==================>
Step: 72030, Train_acc:0.980699
Step: 72030, Val_acc:0.950107
==================>
Step: 72040, Train_acc:0.980861
Step: 72040, Val_acc:0.9384
==================>
Step: 72050, Train_acc:0.972097
Step: 72050, Val_acc:0.929191
==================>
Step: 72060, Train_acc:0.987229
Step: 72060, Val_acc:0.962758
==================>
Step: 72070, Train_acc:0.98361
Step: 72070, Val_acc:0.943878
==================>
Step: 72080, Train_acc:0.987273
Step: 72080, Val_acc:0.93978
==================>
Step: 72090, Train_acc:0.978768
Step: 72090, Val_acc:0.941862
==================>
Step: 72100, Train_acc:0.984556
Step: 72100, Val_acc:0.951952
==================>
2017-11-12 00:44:01.460103 ---> Validation_loss: 0.147641
Step: 72110, Train_acc:0.982234
Step: 72110, Val_acc:0.9367
==================>
Step: 72120, Train_acc:0.975861
Step: 72120, Val_acc:0.952563
==================>
Step: 72130, Train_acc:0.98593
Step: 72130, Val_acc:0.948524
==================>
Step: 72140, Train_acc:0.973699
Step: 72140, Val_acc:0.931428
==================>
Step: 72150, Train_acc:0.980316
Step: 72150, Val_acc:0.940504
==================>
Step: 72160, Train_acc:0.983815
Step: 72160, Val_acc:0.92147
==================>
Step: 72170, Train_acc:0.984119
Step: 72170, Val_acc:0.948201
==================>
Step: 72180, Train_acc:0.983927
Step: 72180, Val_acc:0.950342
==================>
Step: 72190, Train_acc:0.983824
Step: 72190, Val_acc:0.933695
==================>
Step: 72200, Train_acc:0.978706
Step: 72200, Val_acc:0.950961
==================>
2017-11-12 00:46:36.465204 ---> Validation_loss: 0.199665
Step: 72210, Train_acc:0.98239
Step: 72210, Val_acc:0.93425
==================>
Step: 72220, Train_acc:0.973184
Step: 72220, Val_acc:0.947377
==================>
Step: 72230, Train_acc:0.981974
Step: 72230, Val_acc:0.9464
==================>
Step: 72240, Train_acc:0.979443
Step: 72240, Val_acc:0.937455
==================>
Step: 72250, Train_acc:0.98464
Step: 72250, Val_acc:0.925127
==================>
Step: 72260, Train_acc:0.977817
Step: 72260, Val_acc:0.958414
==================>
Step: 72270, Train_acc:0.98205
Step: 72270, Val_acc:0.950282
==================>
Step: 72280, Train_acc:0.986436
Step: 72280, Val_acc:0.943102
==================>
Step: 72290, Train_acc:0.980171
Step: 72290, Val_acc:0.946105
==================>
Step: 72300, Train_acc:0.975741
Step: 72300, Val_acc:0.91772
==================>
2017-11-12 00:49:11.315974 ---> Validation_loss: 0.0927572
Step: 72310, Train_acc:0.977811
Step: 72310, Val_acc:0.949659
==================>
Step: 72320, Train_acc:0.975371
Step: 72320, Val_acc:0.95625
==================>
Step: 72330, Train_acc:0.983033
Step: 72330, Val_acc:0.963096
==================>
Step: 72340, Train_acc:0.980359
Step: 72340, Val_acc:0.927494
==================>
Step: 72350, Train_acc:0.983507
Step: 72350, Val_acc:0.942253
==================>
Step: 72360, Train_acc:0.983035
Step: 72360, Val_acc:0.945823
==================>
Step: 72370, Train_acc:0.981353
Step: 72370, Val_acc:0.92877
==================>
Step: 72380, Train_acc:0.979836
Step: 72380, Val_acc:0.96325
==================>
Step: 72390, Train_acc:0.983618
Step: 72390, Val_acc:0.939326
==================>
Step: 72400, Train_acc:0.979393
Step: 72400, Val_acc:0.945885
==================>
2017-11-12 00:51:46.157313 ---> Validation_loss: 0.192368
Step: 72410, Train_acc:0.967969
Step: 72410, Val_acc:0.943059
==================>
Step: 72420, Train_acc:0.984014
Step: 72420, Val_acc:0.937939
==================>
Step: 72430, Train_acc:0.982895
Step: 72430, Val_acc:0.928982
==================>
Step: 72440, Train_acc:0.981708
Step: 72440, Val_acc:0.929468
==================>
Step: 72450, Train_acc:0.984871
Step: 72450, Val_acc:0.95427
==================>
Step: 72460, Train_acc:0.984264
Step: 72460, Val_acc:0.945933
==================>
Step: 72470, Train_acc:0.977301
Step: 72470, Val_acc:0.931925
==================>
Step: 72480, Train_acc:0.982153
Step: 72480, Val_acc:0.922305
==================>
Step: 72490, Train_acc:0.978943
Step: 72490, Val_acc:0.9423
==================>
Step: 72500, Train_acc:0.981886
Step: 72500, Val_acc:0.933533
==================>
****************** Epochs completed: 145******************
2017-11-12 00:54:21.012470 ---> Validation_loss: 0.139822
Step: 72510, Train_acc:0.98749
Step: 72510, Val_acc:0.940088
==================>
Step: 72520, Train_acc:0.982303
Step: 72520, Val_acc:0.929287
==================>
Step: 72530, Train_acc:0.981365
Step: 72530, Val_acc:0.950739
==================>
Step: 72540, Train_acc:0.982003
Step: 72540, Val_acc:0.943928
==================>
Step: 72550, Train_acc:0.979169
Step: 72550, Val_acc:0.95327
==================>
Step: 72560, Train_acc:0.981868
Step: 72560, Val_acc:0.949598
==================>
Step: 72570, Train_acc:0.984506
Step: 72570, Val_acc:0.945565
==================>
Step: 72580, Train_acc:0.979149
Step: 72580, Val_acc:0.93903
==================>
Step: 72590, Train_acc:0.985856
Step: 72590, Val_acc:0.932502
==================>
Step: 72600, Train_acc:0.975978
Step: 72600, Val_acc:0.932305
==================>
2017-11-12 00:56:56.074905 ---> Validation_loss: 0.174739
Step: 72610, Train_acc:0.98101
Step: 72610, Val_acc:0.941688
==================>
Step: 72620, Train_acc:0.981871
Step: 72620, Val_acc:0.954109
==================>
Step: 72630, Train_acc:0.9777
Step: 72630, Val_acc:0.946938
==================>
Step: 72640, Train_acc:0.975833
Step: 72640, Val_acc:0.945498
==================>
Step: 72650, Train_acc:0.986689
Step: 72650, Val_acc:0.948282
==================>
Step: 72660, Train_acc:0.981157
Step: 72660, Val_acc:0.960189
==================>
Step: 72670, Train_acc:0.976565
Step: 72670, Val_acc:0.91988
==================>
Step: 72680, Train_acc:0.978928
Step: 72680, Val_acc:0.936851
==================>
Step: 72690, Train_acc:0.982268
Step: 72690, Val_acc:0.957983
==================>
Step: 72700, Train_acc:0.983754
Step: 72700, Val_acc:0.938604
==================>
2017-11-12 00:59:31.091842 ---> Validation_loss: 0.106744
Step: 72710, Train_acc:0.979089
Step: 72710, Val_acc:0.938608
==================>
Step: 72720, Train_acc:0.968813
Step: 72720, Val_acc:0.947011
==================>
Step: 72730, Train_acc:0.976825
Step: 72730, Val_acc:0.92832
==================>
Step: 72740, Train_acc:0.985369
Step: 72740, Val_acc:0.940095
==================>
Step: 72750, Train_acc:0.978945
Step: 72750, Val_acc:0.932643
==================>
Step: 72760, Train_acc:0.982122
Step: 72760, Val_acc:0.933662
==================>
Step: 72770, Train_acc:0.980898
Step: 72770, Val_acc:0.942512
==================>
Step: 72780, Train_acc:0.980156
Step: 72780, Val_acc:0.936976
==================>
Step: 72790, Train_acc:0.979572
Step: 72790, Val_acc:0.945201
==================>
Step: 72800, Train_acc:0.984103
Step: 72800, Val_acc:0.954829
==================>
2017-11-12 01:02:06.136510 ---> Validation_loss: 0.161303
Step: 72810, Train_acc:0.980925
Step: 72810, Val_acc:0.966243
==================>
Step: 72820, Train_acc:0.983286
Step: 72820, Val_acc:0.951632
==================>
Step: 72830, Train_acc:0.984416
Step: 72830, Val_acc:0.947861
==================>
Step: 72840, Train_acc:0.979989
Step: 72840, Val_acc:0.932982
==================>
Step: 72850, Train_acc:0.982703
Step: 72850, Val_acc:0.948091
==================>
Step: 72860, Train_acc:0.979388
Step: 72860, Val_acc:0.94979
==================>
Step: 72870, Train_acc:0.981604
Step: 72870, Val_acc:0.936814
==================>
Step: 72880, Train_acc:0.980667
Step: 72880, Val_acc:0.967203
==================>
Step: 72890, Train_acc:0.980283
Step: 72890, Val_acc:0.966482
==================>
Step: 72900, Train_acc:0.984954
Step: 72900, Val_acc:0.937174
==================>
2017-11-12 01:04:41.220345 ---> Validation_loss: 0.188602
Step: 72910, Train_acc:0.980273
Step: 72910, Val_acc:0.943407
==================>
Step: 72920, Train_acc:0.977579
Step: 72920, Val_acc:0.954192
==================>
Step: 72930, Train_acc:0.978663
Step: 72930, Val_acc:0.934185
==================>
Step: 72940, Train_acc:0.977148
Step: 72940, Val_acc:0.958745
==================>
Step: 72950, Train_acc:0.982134
Step: 72950, Val_acc:0.940948
==================>
Step: 72960, Train_acc:0.981747
Step: 72960, Val_acc:0.940537
==================>
Step: 72970, Train_acc:0.983372
Step: 72970, Val_acc:0.970398
==================>
Step: 72980, Train_acc:0.982692
Step: 72980, Val_acc:0.95585
==================>
Step: 72990, Train_acc:0.976035
Step: 72990, Val_acc:0.919346
==================>
Step: 73000, Train_acc:0.981521
Step: 73000, Val_acc:0.939276
==================>
****************** Epochs completed: 146******************
2017-11-12 01:07:16.215079 ---> Validation_loss: 0.165621
Step: 73010, Train_acc:0.977162
Step: 73010, Val_acc:0.937322
==================>
Step: 73020, Train_acc:0.981354
Step: 73020, Val_acc:0.958376
==================>
Step: 73030, Train_acc:0.982258
Step: 73030, Val_acc:0.935596
==================>
Step: 73040, Train_acc:0.983137
Step: 73040, Val_acc:0.942761
==================>
Step: 73050, Train_acc:0.973446
Step: 73050, Val_acc:0.922881
==================>
Step: 73060, Train_acc:0.980349
Step: 73060, Val_acc:0.950933
==================>
Step: 73070, Train_acc:0.980272
Step: 73070, Val_acc:0.948438
==================>
Step: 73080, Train_acc:0.983462
Step: 73080, Val_acc:0.940846
==================>
Step: 73090, Train_acc:0.975427
Step: 73090, Val_acc:0.952703
==================>
Step: 73100, Train_acc:0.98051
Step: 73100, Val_acc:0.947488
==================>
2017-11-12 01:09:51.547743 ---> Validation_loss: 0.102027
Step: 73110, Train_acc:0.975878
Step: 73110, Val_acc:0.946815
==================>
Step: 73120, Train_acc:0.983688
Step: 73120, Val_acc:0.933145
==================>
Step: 73130, Train_acc:0.97693
Step: 73130, Val_acc:0.910544
==================>
Step: 73140, Train_acc:0.984556
Step: 73140, Val_acc:0.936763
==================>
Step: 73150, Train_acc:0.978428
Step: 73150, Val_acc:0.930489
==================>
Step: 73160, Train_acc:0.973782
Step: 73160, Val_acc:0.948044
==================>
Step: 73170, Train_acc:0.982979
Step: 73170, Val_acc:0.959036
==================>
Step: 73180, Train_acc:0.978656
Step: 73180, Val_acc:0.966827
==================>
Step: 73190, Train_acc:0.981592
Step: 73190, Val_acc:0.961918
==================>
Step: 73200, Train_acc:0.976239
Step: 73200, Val_acc:0.961455
==================>
2017-11-12 01:12:26.199273 ---> Validation_loss: 0.156206
Step: 73210, Train_acc:0.974027
Step: 73210, Val_acc:0.93748
==================>
Step: 73220, Train_acc:0.971095
Step: 73220, Val_acc:0.941517
==================>
Step: 73230, Train_acc:0.97807
Step: 73230, Val_acc:0.938759
==================>
Step: 73240, Train_acc:0.980461
Step: 73240, Val_acc:0.943085
==================>
Step: 73250, Train_acc:0.979171
Step: 73250, Val_acc:0.95413
==================>
Step: 73260, Train_acc:0.979773
Step: 73260, Val_acc:0.956363
==================>
Step: 73270, Train_acc:0.981013
Step: 73270, Val_acc:0.944699
==================>
Step: 73280, Train_acc:0.97925
Step: 73280, Val_acc:0.882268
==================>
Step: 73290, Train_acc:0.980037
Step: 73290, Val_acc:0.918483
==================>
Step: 73300, Train_acc:0.985972
Step: 73300, Val_acc:0.937714
==================>
2017-11-12 01:15:01.424249 ---> Validation_loss: 0.215838
Step: 73310, Train_acc:0.984174
Step: 73310, Val_acc:0.945298
==================>
Step: 73320, Train_acc:0.978666
Step: 73320, Val_acc:0.947572
==================>
Step: 73330, Train_acc:0.972732
Step: 73330, Val_acc:0.94537
==================>
Step: 73340, Train_acc:0.973959
Step: 73340, Val_acc:0.962048
==================>
Step: 73350, Train_acc:0.984449
Step: 73350, Val_acc:0.935718
==================>
Step: 73360, Train_acc:0.984398
Step: 73360, Val_acc:0.94172
==================>
Step: 73370, Train_acc:0.975707
Step: 73370, Val_acc:0.929197
==================>
Step: 73380, Train_acc:0.981914
Step: 73380, Val_acc:0.964565
==================>
Step: 73390, Train_acc:0.984233
Step: 73390, Val_acc:0.964459
==================>
Step: 73400, Train_acc:0.978339
Step: 73400, Val_acc:0.941498
==================>
2017-11-12 01:17:36.451341 ---> Validation_loss: 0.137775
Step: 73410, Train_acc:0.980031
Step: 73410, Val_acc:0.921074
==================>
Step: 73420, Train_acc:0.974999
Step: 73420, Val_acc:0.948441
==================>
Step: 73430, Train_acc:0.984401
Step: 73430, Val_acc:0.95109
==================>
Step: 73440, Train_acc:0.987667
Step: 73440, Val_acc:0.950572
==================>
Step: 73450, Train_acc:0.979834
Step: 73450, Val_acc:0.935796
==================>
Step: 73460, Train_acc:0.976007
Step: 73460, Val_acc:0.921901
==================>
Step: 73470, Train_acc:0.985424
Step: 73470, Val_acc:0.932825
==================>
Step: 73480, Train_acc:0.980283
Step: 73480, Val_acc:0.93491
==================>
Step: 73490, Train_acc:0.976963
Step: 73490, Val_acc:0.931967
==================>
Step: 73500, Train_acc:0.984542
Step: 73500, Val_acc:0.956643
==================>
****************** Epochs completed: 147******************
2017-11-12 01:20:11.529078 ---> Validation_loss: 0.126325
Step: 73510, Train_acc:0.974552
Step: 73510, Val_acc:0.94641
==================>
Step: 73520, Train_acc:0.98119
Step: 73520, Val_acc:0.938718
==================>
Step: 73530, Train_acc:0.981938
Step: 73530, Val_acc:0.943494
==================>
Step: 73540, Train_acc:0.986761
Step: 73540, Val_acc:0.937847
==================>
Step: 73550, Train_acc:0.982372
Step: 73550, Val_acc:0.948136
==================>
Step: 73560, Train_acc:0.977317
Step: 73560, Val_acc:0.95467
==================>
Step: 73570, Train_acc:0.983263
Step: 73570, Val_acc:0.952279
==================>
Step: 73580, Train_acc:0.984836
Step: 73580, Val_acc:0.958198
==================>
Step: 73590, Train_acc:0.978346
Step: 73590, Val_acc:0.949623
==================>
Step: 73600, Train_acc:0.973856
Step: 73600, Val_acc:0.94264
==================>
2017-11-12 01:22:46.673209 ---> Validation_loss: 0.114465
Step: 73610, Train_acc:0.980348
Step: 73610, Val_acc:0.956539
==================>
Step: 73620, Train_acc:0.984346
Step: 73620, Val_acc:0.953438
==================>
Step: 73630, Train_acc:0.98547
Step: 73630, Val_acc:0.939736
==================>
Step: 73640, Train_acc:0.980675
Step: 73640, Val_acc:0.942051
==================>
Step: 73650, Train_acc:0.980342
Step: 73650, Val_acc:0.932061
==================>
Step: 73660, Train_acc:0.980814
Step: 73660, Val_acc:0.947395
==================>
Step: 73670, Train_acc:0.978298
Step: 73670, Val_acc:0.928766
==================>
Step: 73680, Train_acc:0.977883
Step: 73680, Val_acc:0.94285
==================>
Step: 73690, Train_acc:0.98604
Step: 73690, Val_acc:0.949091
==================>
Step: 73700, Train_acc:0.98553
Step: 73700, Val_acc:0.941705
==================>
2017-11-12 01:25:21.681458 ---> Validation_loss: 0.204795
Step: 73710, Train_acc:0.97912
Step: 73710, Val_acc:0.912201
==================>
Step: 73720, Train_acc:0.972415
Step: 73720, Val_acc:0.938933
==================>
Step: 73730, Train_acc:0.979197
Step: 73730, Val_acc:0.933163
==================>
Step: 73740, Train_acc:0.983837
Step: 73740, Val_acc:0.946811
==================>
Step: 73750, Train_acc:0.984883
Step: 73750, Val_acc:0.907894
==================>
Step: 73760, Train_acc:0.976362
Step: 73760, Val_acc:0.938724
==================>
Step: 73770, Train_acc:0.980746
Step: 73770, Val_acc:0.964634
==================>
Step: 73780, Train_acc:0.976119
Step: 73780, Val_acc:0.941326
==================>
Step: 73790, Train_acc:0.984716
Step: 73790, Val_acc:0.956929
==================>
Step: 73800, Train_acc:0.976091
Step: 73800, Val_acc:0.938439
==================>
2017-11-12 01:27:56.373384 ---> Validation_loss: 0.129642
Step: 73810, Train_acc:0.977767
Step: 73810, Val_acc:0.93983
==================>
Step: 73820, Train_acc:0.97488
Step: 73820, Val_acc:0.914148
==================>
Step: 73830, Train_acc:0.985566
Step: 73830, Val_acc:0.95464
==================>
Step: 73840, Train_acc:0.982263
Step: 73840, Val_acc:0.933328
==================>
Step: 73850, Train_acc:0.9816
Step: 73850, Val_acc:0.932771
==================>
Step: 73860, Train_acc:0.975732
Step: 73860, Val_acc:0.933274
==================>
Step: 73870, Train_acc:0.986617
Step: 73870, Val_acc:0.922278
==================>
Step: 73880, Train_acc:0.984525
Step: 73880, Val_acc:0.946555
==================>
Step: 73890, Train_acc:0.978582
Step: 73890, Val_acc:0.930978
==================>
Step: 73900, Train_acc:0.983707
Step: 73900, Val_acc:0.940299
==================>
2017-11-12 01:30:30.918916 ---> Validation_loss: 0.252703
Step: 73910, Train_acc:0.978071
Step: 73910, Val_acc:0.964304
==================>
Step: 73920, Train_acc:0.981128
Step: 73920, Val_acc:0.962721
==================>
Step: 73930, Train_acc:0.978073
Step: 73930, Val_acc:0.932557
==================>
Step: 73940, Train_acc:0.976622
Step: 73940, Val_acc:0.942495
==================>
Step: 73950, Train_acc:0.982463
Step: 73950, Val_acc:0.953617
==================>
Step: 73960, Train_acc:0.97911
Step: 73960, Val_acc:0.917051
==================>
Step: 73970, Train_acc:0.98278
Step: 73970, Val_acc:0.9251
==================>
Step: 73980, Train_acc:0.980225
Step: 73980, Val_acc:0.935261
==================>
Step: 73990, Train_acc:0.972992
Step: 73990, Val_acc:0.917977
==================>
Step: 74000, Train_acc:0.981763
Step: 74000, Val_acc:0.930143
==================>
****************** Epochs completed: 148******************
2017-11-12 01:33:05.841408 ---> Validation_loss: 0.139522
****************** Epochs completed: 22******************
Step: 74010, Train_acc:0.977693
Step: 74010, Val_acc:0.949102
==================>
Step: 74020, Train_acc:0.984602
Step: 74020, Val_acc:0.933661
==================>
Step: 74030, Train_acc:0.980803
Step: 74030, Val_acc:0.947947
==================>
Step: 74040, Train_acc:0.983615
Step: 74040, Val_acc:0.959958
==================>
Step: 74050, Train_acc:0.986205
Step: 74050, Val_acc:0.947454
==================>
Step: 74060, Train_acc:0.984228
Step: 74060, Val_acc:0.916663
==================>
Step: 74070, Train_acc:0.980385
Step: 74070, Val_acc:0.92592
==================>
Step: 74080, Train_acc:0.980598
Step: 74080, Val_acc:0.947234
==================>
Step: 74090, Train_acc:0.97973
Step: 74090, Val_acc:0.952325
==================>
Step: 74100, Train_acc:0.981653
Step: 74100, Val_acc:0.941896
==================>
2017-11-12 01:35:40.355132 ---> Validation_loss: 0.14546
Step: 74110, Train_acc:0.981975
Step: 74110, Val_acc:0.946144
==================>
Step: 74120, Train_acc:0.983956
Step: 74120, Val_acc:0.943105
==================>
Step: 74130, Train_acc:0.983342
Step: 74130, Val_acc:0.935106
==================>
Step: 74140, Train_acc:0.981256
Step: 74140, Val_acc:0.922136
==================>
Step: 74150, Train_acc:0.976244
Step: 74150, Val_acc:0.933097
==================>
Step: 74160, Train_acc:0.979286
Step: 74160, Val_acc:0.927388
==================>
Step: 74170, Train_acc:0.980062
Step: 74170, Val_acc:0.944167
==================>
Step: 74180, Train_acc:0.984017
Step: 74180, Val_acc:0.94478
==================>
Step: 74190, Train_acc:0.976389
Step: 74190, Val_acc:0.93856
==================>
Step: 74200, Train_acc:0.986749
Step: 74200, Val_acc:0.948889
==================>
2017-11-12 01:38:14.943284 ---> Validation_loss: 0.146809
Step: 74210, Train_acc:0.984567
Step: 74210, Val_acc:0.947777
==================>
Step: 74220, Train_acc:0.985184
Step: 74220, Val_acc:0.939589
==================>
Step: 74230, Train_acc:0.985175
Step: 74230, Val_acc:0.948541
==================>
Step: 74240, Train_acc:0.981141
Step: 74240, Val_acc:0.962711
==================>
Step: 74250, Train_acc:0.983192
Step: 74250, Val_acc:0.960986
==================>
Step: 74260, Train_acc:0.981211
Step: 74260, Val_acc:0.941261
==================>
Step: 74270, Train_acc:0.978442
Step: 74270, Val_acc:0.94387
==================>
Step: 74280, Train_acc:0.980933
Step: 74280, Val_acc:0.929651
==================>
Step: 74290, Train_acc:0.984202
Step: 74290, Val_acc:0.960439
==================>
Step: 74300, Train_acc:0.979045
Step: 74300, Val_acc:0.926952
==================>
2017-11-12 01:40:49.360603 ---> Validation_loss: 0.203212
Step: 74310, Train_acc:0.982056
Step: 74310, Val_acc:0.949204
==================>
Step: 74320, Train_acc:0.974908
Step: 74320, Val_acc:0.920824
==================>
Step: 74330, Train_acc:0.984431
Step: 74330, Val_acc:0.951361
==================>
Step: 74340, Train_acc:0.984418
Step: 74340, Val_acc:0.929781
==================>
Step: 74350, Train_acc:0.974612
Step: 74350, Val_acc:0.946799
==================>
Step: 74360, Train_acc:0.979542
Step: 74360, Val_acc:0.953474
==================>
Step: 74370, Train_acc:0.981626
Step: 74370, Val_acc:0.923044
==================>
Step: 74380, Train_acc:0.982848
Step: 74380, Val_acc:0.96457
==================>
Step: 74390, Train_acc:0.985909
Step: 74390, Val_acc:0.952229
==================>
Step: 74400, Train_acc:0.986157
Step: 74400, Val_acc:0.950037
==================>
2017-11-12 01:43:24.480074 ---> Validation_loss: 0.140227
Step: 74410, Train_acc:0.981301
Step: 74410, Val_acc:0.942072
==================>
Step: 74420, Train_acc:0.979252
Step: 74420, Val_acc:0.94119
==================>
Step: 74430, Train_acc:0.983314
Step: 74430, Val_acc:0.960124
==================>
Step: 74440, Train_acc:0.977522
Step: 74440, Val_acc:0.934208
==================>
Step: 74450, Train_acc:0.979604
Step: 74450, Val_acc:0.931312
==================>
Step: 74460, Train_acc:0.984863
Step: 74460, Val_acc:0.933141
==================>
Step: 74470, Train_acc:0.973207
Step: 74470, Val_acc:0.924851
==================>
Step: 74480, Train_acc:0.981106
Step: 74480, Val_acc:0.935515
==================>
Step: 74490, Train_acc:0.981016
Step: 74490, Val_acc:0.937971
==================>
Step: 74500, Train_acc:0.985407
Step: 74500, Val_acc:0.919102
==================>
****************** Epochs completed: 149******************
2017-11-12 01:45:59.193106 ---> Validation_loss: 0.180201
Step: 74510, Train_acc:0.97769
Step: 74510, Val_acc:0.956508
==================>
Step: 74520, Train_acc:0.981112
Step: 74520, Val_acc:0.937432
==================>
Step: 74530, Train_acc:0.983962
Step: 74530, Val_acc:0.951786
==================>
Step: 74540, Train_acc:0.981569
Step: 74540, Val_acc:0.951813
==================>
Step: 74550, Train_acc:0.978951
Step: 74550, Val_acc:0.923518
==================>
Step: 74560, Train_acc:0.988107
Step: 74560, Val_acc:0.945233
==================>
Step: 74570, Train_acc:0.972915
Step: 74570, Val_acc:0.931832
==================>
Step: 74580, Train_acc:0.982051
Step: 74580, Val_acc:0.9413
==================>
Step: 74590, Train_acc:0.980448
Step: 74590, Val_acc:0.941962
==================>
Step: 74600, Train_acc:0.985751
Step: 74600, Val_acc:0.944362
==================>
2017-11-12 01:48:34.161931 ---> Validation_loss: 0.163921
Step: 74610, Train_acc:0.981515
Step: 74610, Val_acc:0.954512
==================>
Step: 74620, Train_acc:0.982911
Step: 74620, Val_acc:0.937535
==================>
Step: 74630, Train_acc:0.982821
Step: 74630, Val_acc:0.933529
==================>
Step: 74640, Train_acc:0.984023
Step: 74640, Val_acc:0.944058
==================>
Step: 74650, Train_acc:0.979575
Step: 74650, Val_acc:0.932086
==================>
Step: 74660, Train_acc:0.987384
Step: 74660, Val_acc:0.949192
==================>
Step: 74670, Train_acc:0.981919
Step: 74670, Val_acc:0.958871
==================>
Step: 74680, Train_acc:0.986597
Step: 74680, Val_acc:0.93936
==================>
Step: 74690, Train_acc:0.984194
Step: 74690, Val_acc:0.950384
==================>
Step: 74700, Train_acc:0.977445
Step: 74700, Val_acc:0.937717
==================>
2017-11-12 01:51:08.882559 ---> Validation_loss: 0.153898
Step: 74710, Train_acc:0.98795
Step: 74710, Val_acc:0.930973
==================>
Step: 74720, Train_acc:0.988933
Step: 74720, Val_acc:0.937838
==================>
Step: 74730, Train_acc:0.983184
Step: 74730, Val_acc:0.94402
==================>
Step: 74740, Train_acc:0.984279
Step: 74740, Val_acc:0.944065
==================>
Step: 74750, Train_acc:0.981969
Step: 74750, Val_acc:0.948867
==================>
Step: 74760, Train_acc:0.974634
Step: 74760, Val_acc:0.936528
==================>
Step: 74770, Train_acc:0.982953
Step: 74770, Val_acc:0.953584
==================>
Step: 74780, Train_acc:0.98098
Step: 74780, Val_acc:0.953163
==================>
Step: 74790, Train_acc:0.980553
Step: 74790, Val_acc:0.954054
==================>
Step: 74800, Train_acc:0.983261
Step: 74800, Val_acc:0.943063
==================>
2017-11-12 01:53:43.799400 ---> Validation_loss: 0.15821
Step: 74810, Train_acc:0.989574
Step: 74810, Val_acc:0.946567
==================>
Step: 74820, Train_acc:0.974281
Step: 74820, Val_acc:0.940598
==================>
Step: 74830, Train_acc:0.980077
Step: 74830, Val_acc:0.953142
==================>
Step: 74840, Train_acc:0.987532
Step: 74840, Val_acc:0.96329
==================>
Step: 74850, Train_acc:0.982794
Step: 74850, Val_acc:0.938125
==================>
Step: 74860, Train_acc:0.985595
Step: 74860, Val_acc:0.922061
==================>
Step: 74870, Train_acc:0.984242
Step: 74870, Val_acc:0.938921
==================>
Step: 74880, Train_acc:0.985313
Step: 74880, Val_acc:0.953658
==================>
Step: 74890, Train_acc:0.98038
Step: 74890, Val_acc:0.954083
==================>
Step: 74900, Train_acc:0.98266
Step: 74900, Val_acc:0.954631
==================>
2017-11-12 01:56:18.700286 ---> Validation_loss: 0.129357
Step: 74910, Train_acc:0.980834
Step: 74910, Val_acc:0.957334
==================>
Step: 74920, Train_acc:0.980613
Step: 74920, Val_acc:0.90376
==================>
Step: 74930, Train_acc:0.981761
Step: 74930, Val_acc:0.949988
==================>
Step: 74940, Train_acc:0.981472
Step: 74940, Val_acc:0.950942
==================>
Step: 74950, Train_acc:0.980768
Step: 74950, Val_acc:0.92459
==================>
Step: 74960, Train_acc:0.984757
Step: 74960, Val_acc:0.931503
==================>
Step: 74970, Train_acc:0.979161
Step: 74970, Val_acc:0.943907
==================>
Step: 74980, Train_acc:0.983057
Step: 74980, Val_acc:0.937515
==================>
Step: 74990, Train_acc:0.98681
Step: 74990, Val_acc:0.926283
==================>
Step: 75000, Train_acc:0.978861
Step: 75000, Val_acc:0.95205
==================>
****************** Epochs completed: 150******************
2017-11-12 01:58:54.333699 ---> Validation_loss: 0.137182
Step: 75010, Train_acc:0.985552
Step: 75010, Val_acc:0.952017
==================>
Step: 75020, Train_acc:0.977682
Step: 75020, Val_acc:0.955101
==================>
Step: 75030, Train_acc:0.980193
Step: 75030, Val_acc:0.934033
==================>
Step: 75040, Train_acc:0.978374
Step: 75040, Val_acc:0.946611
==================>
Step: 75050, Train_acc:0.985966
Step: 75050, Val_acc:0.935609
==================>
Step: 75060, Train_acc:0.983126
Step: 75060, Val_acc:0.95452
==================>
Step: 75070, Train_acc:0.98141
Step: 75070, Val_acc:0.952263
==================>
Step: 75080, Train_acc:0.979144
Step: 75080, Val_acc:0.948787
==================>
Step: 75090, Train_acc:0.987249
Step: 75090, Val_acc:0.943557
==================>
Step: 75100, Train_acc:0.98014
Step: 75100, Val_acc:0.931869
==================>
2017-11-12 02:01:28.964831 ---> Validation_loss: 0.209229
Step: 75110, Train_acc:0.983716
Step: 75110, Val_acc:0.949728
==================>
Step: 75120, Train_acc:0.981306
Step: 75120, Val_acc:0.943717
==================>
Step: 75130, Train_acc:0.975292
Step: 75130, Val_acc:0.92907
==================>
Step: 75140, Train_acc:0.977501
Step: 75140, Val_acc:0.96291
==================>
Step: 75150, Train_acc:0.971477
Step: 75150, Val_acc:0.935635
==================>
Step: 75160, Train_acc:0.979681
Step: 75160, Val_acc:0.939562
==================>
Step: 75170, Train_acc:0.980176
Step: 75170, Val_acc:0.954077
==================>
Step: 75180, Train_acc:0.983802
Step: 75180, Val_acc:0.928025
==================>
Step: 75190, Train_acc:0.9863
Step: 75190, Val_acc:0.952048
==================>
Step: 75200, Train_acc:0.975493
Step: 75200, Val_acc:0.946044
==================>
2017-11-12 02:04:04.114148 ---> Validation_loss: 0.147217
Step: 75210, Train_acc:0.980199
Step: 75210, Val_acc:0.965432
==================>
Step: 75220, Train_acc:0.981031
Step: 75220, Val_acc:0.961243
==================>
Step: 75230, Train_acc:0.977999
Step: 75230, Val_acc:0.948921
==================>
Step: 75240, Train_acc:0.978921
Step: 75240, Val_acc:0.948057
==================>
Step: 75250, Train_acc:0.979152
Step: 75250, Val_acc:0.943967
==================>
Step: 75260, Train_acc:0.977256
Step: 75260, Val_acc:0.954633
==================>
Step: 75270, Train_acc:0.988826
Step: 75270, Val_acc:0.924454
==================>
Step: 75280, Train_acc:0.97941
Step: 75280, Val_acc:0.9323
==================>
Step: 75290, Train_acc:0.979633
Step: 75290, Val_acc:0.940675
==================>
Step: 75300, Train_acc:0.984228
Step: 75300, Val_acc:0.938208
==================>
2017-11-12 02:06:39.372533 ---> Validation_loss: 0.177706
Step: 75310, Train_acc:0.984731
Step: 75310, Val_acc:0.956176
==================>
Step: 75320, Train_acc:0.982262
Step: 75320, Val_acc:0.956545
==================>
Step: 75330, Train_acc:0.981931
Step: 75330, Val_acc:0.932705
==================>
Step: 75340, Train_acc:0.983187
Step: 75340, Val_acc:0.9289
==================>
Step: 75350, Train_acc:0.977844
Step: 75350, Val_acc:0.941344
==================>
Step: 75360, Train_acc:0.982733
Step: 75360, Val_acc:0.957107
==================>
Step: 75370, Train_acc:0.984056
Step: 75370, Val_acc:0.946952
==================>
Step: 75380, Train_acc:0.981732
Step: 75380, Val_acc:0.94129
==================>
Step: 75390, Train_acc:0.980775
Step: 75390, Val_acc:0.941699
==================>
Step: 75400, Train_acc:0.984801
Step: 75400, Val_acc:0.933075
==================>
2017-11-12 02:09:14.437058 ---> Validation_loss: 0.112588
Step: 75410, Train_acc:0.982834
Step: 75410, Val_acc:0.920855
==================>
Step: 75420, Train_acc:0.981865
Step: 75420, Val_acc:0.944254
==================>
Step: 75430, Train_acc:0.982821
Step: 75430, Val_acc:0.947427
==================>
Step: 75440, Train_acc:0.977451
Step: 75440, Val_acc:0.962307
==================>
Step: 75450, Train_acc:0.985439
Step: 75450, Val_acc:0.934264
==================>
Step: 75460, Train_acc:0.981697
Step: 75460, Val_acc:0.929197
==================>
Step: 75470, Train_acc:0.983792
Step: 75470, Val_acc:0.956761
==================>
Step: 75480, Train_acc:0.976885
Step: 75480, Val_acc:0.928495
==================>
Step: 75490, Train_acc:0.981571
Step: 75490, Val_acc:0.956548
==================>
Step: 75500, Train_acc:0.983235
Step: 75500, Val_acc:0.922495
==================>
****************** Epochs completed: 151******************
2017-11-12 02:11:49.605441 ---> Validation_loss: 0.19651
Step: 75510, Train_acc:0.987761
Step: 75510, Val_acc:0.94406
==================>
Step: 75520, Train_acc:0.978981
Step: 75520, Val_acc:0.932068
==================>
Step: 75530, Train_acc:0.980669
Step: 75530, Val_acc:0.933169
==================>
Step: 75540, Train_acc:0.978249
Step: 75540, Val_acc:0.928656
==================>
Step: 75550, Train_acc:0.981697
Step: 75550, Val_acc:0.955153
==================>
Step: 75560, Train_acc:0.976207
Step: 75560, Val_acc:0.934913
==================>
Step: 75570, Train_acc:0.982786
Step: 75570, Val_acc:0.956376
==================>
Step: 75580, Train_acc:0.98191
Step: 75580, Val_acc:0.954069
==================>
Step: 75590, Train_acc:0.977229
Step: 75590, Val_acc:0.942516
==================>
Step: 75600, Train_acc:0.986798
Step: 75600, Val_acc:0.953282
==================>
2017-11-12 02:14:24.785085 ---> Validation_loss: 0.164597
Step: 75610, Train_acc:0.98187
Step: 75610, Val_acc:0.924761
==================>
Step: 75620, Train_acc:0.98317
Step: 75620, Val_acc:0.936239
==================>
Step: 75630, Train_acc:0.983352
Step: 75630, Val_acc:0.938082
==================>
Step: 75640, Train_acc:0.985684
Step: 75640, Val_acc:0.949485
==================>
Step: 75650, Train_acc:0.986176
Step: 75650, Val_acc:0.923693
==================>
Step: 75660, Train_acc:0.981799
Step: 75660, Val_acc:0.953743
==================>
Step: 75670, Train_acc:0.985232
Step: 75670, Val_acc:0.953209
==================>
Step: 75680, Train_acc:0.987527
Step: 75680, Val_acc:0.940596
==================>
Step: 75690, Train_acc:0.978439
Step: 75690, Val_acc:0.955796
==================>
Step: 75700, Train_acc:0.982301
Step: 75700, Val_acc:0.941073
==================>
2017-11-12 02:17:00.052708 ---> Validation_loss: 0.133191
Step: 75710, Train_acc:0.970127
Step: 75710, Val_acc:0.944749
==================>
Step: 75720, Train_acc:0.980996
Step: 75720, Val_acc:0.925416
==================>
Step: 75730, Train_acc:0.976661
Step: 75730, Val_acc:0.953055
==================>
Step: 75740, Train_acc:0.981357
Step: 75740, Val_acc:0.947607
==================>
Step: 75750, Train_acc:0.984009
Step: 75750, Val_acc:0.950258
==================>
Step: 75760, Train_acc:0.980514
Step: 75760, Val_acc:0.93265
==================>
Step: 75770, Train_acc:0.974829
Step: 75770, Val_acc:0.922085
==================>
Step: 75780, Train_acc:0.987761
Step: 75780, Val_acc:0.945348
==================>
Step: 75790, Train_acc:0.982874
Step: 75790, Val_acc:0.925768
==================>
Step: 75800, Train_acc:0.982998
Step: 75800, Val_acc:0.948072
==================>
2017-11-12 02:19:34.877306 ---> Validation_loss: 0.155477
Step: 75810, Train_acc:0.981232
Step: 75810, Val_acc:0.949122
==================>
Step: 75820, Train_acc:0.983333
Step: 75820, Val_acc:0.941353
==================>
Step: 75830, Train_acc:0.980835
Step: 75830, Val_acc:0.932083
==================>
Step: 75840, Train_acc:0.982488
Step: 75840, Val_acc:0.930461
==================>
Step: 75850, Train_acc:0.980748
Step: 75850, Val_acc:0.935745
==================>
Step: 75860, Train_acc:0.985422
Step: 75860, Val_acc:0.942219
==================>
Step: 75870, Train_acc:0.985323
Step: 75870, Val_acc:0.938717
==================>
Step: 75880, Train_acc:0.978041
Step: 75880, Val_acc:0.938644
==================>
Step: 75890, Train_acc:0.983214
Step: 75890, Val_acc:0.936464
==================>
Step: 75900, Train_acc:0.986089
Step: 75900, Val_acc:0.932405
==================>
2017-11-12 02:22:09.711998 ---> Validation_loss: 0.152433
Step: 75910, Train_acc:0.979895
Step: 75910, Val_acc:0.922864
==================>
Step: 75920, Train_acc:0.985763
Step: 75920, Val_acc:0.950607
==================>
Step: 75930, Train_acc:0.977012
Step: 75930, Val_acc:0.924606
==================>
Step: 75940, Train_acc:0.984319
Step: 75940, Val_acc:0.948225
==================>
Step: 75950, Train_acc:0.975706
Step: 75950, Val_acc:0.919338
==================>
Step: 75960, Train_acc:0.982985
Step: 75960, Val_acc:0.937163
==================>
Step: 75970, Train_acc:0.984922
Step: 75970, Val_acc:0.939618
==================>
Step: 75980, Train_acc:0.980631
Step: 75980, Val_acc:0.962004
==================>
Step: 75990, Train_acc:0.981519
Step: 75990, Val_acc:0.946456
==================>
Step: 76000, Train_acc:0.980193
Step: 76000, Val_acc:0.930923
==================>
****************** Epochs completed: 152******************
2017-11-12 02:24:44.993738 ---> Validation_loss: 0.103559
Step: 76010, Train_acc:0.984437
Step: 76010, Val_acc:0.946781
==================>
Step: 76020, Train_acc:0.984221
Step: 76020, Val_acc:0.952195
==================>
Step: 76030, Train_acc:0.969469
Step: 76030, Val_acc:0.947239
==================>
Step: 76040, Train_acc:0.981448
Step: 76040, Val_acc:0.948395
==================>
Step: 76050, Train_acc:0.978353
Step: 76050, Val_acc:0.962554
==================>
Step: 76060, Train_acc:0.979519
Step: 76060, Val_acc:0.964457
==================>
Step: 76070, Train_acc:0.984904
Step: 76070, Val_acc:0.942902
==================>
Step: 76080, Train_acc:0.97401
Step: 76080, Val_acc:0.944926
==================>
Step: 76090, Train_acc:0.976256
Step: 76090, Val_acc:0.929695
==================>
Step: 76100, Train_acc:0.985458
Step: 76100, Val_acc:0.923232
==================>
2017-11-12 02:27:20.217422 ---> Validation_loss: 0.171787
Step: 76110, Train_acc:0.980323
Step: 76110, Val_acc:0.928209
==================>
Step: 76120, Train_acc:0.985391
Step: 76120, Val_acc:0.951495
==================>
Step: 76130, Train_acc:0.981694
Step: 76130, Val_acc:0.947142
==================>
Step: 76140, Train_acc:0.978079
Step: 76140, Val_acc:0.947084
==================>
Step: 76150, Train_acc:0.985009
Step: 76150, Val_acc:0.960865
==================>
Step: 76160, Train_acc:0.985966
Step: 76160, Val_acc:0.952733
==================>
Step: 76170, Train_acc:0.983185
Step: 76170, Val_acc:0.961318
==================>
Step: 76180, Train_acc:0.980275
Step: 76180, Val_acc:0.964879
==================>
Step: 76190, Train_acc:0.985038
Step: 76190, Val_acc:0.961301
==================>
Step: 76200, Train_acc:0.985183
Step: 76200, Val_acc:0.935017
==================>
2017-11-12 02:29:55.349576 ---> Validation_loss: 0.153171
Step: 76210, Train_acc:0.977209
Step: 76210, Val_acc:0.938287
==================>
Step: 76220, Train_acc:0.980316
Step: 76220, Val_acc:0.935367
==================>
Step: 76230, Train_acc:0.984004
Step: 76230, Val_acc:0.949082
==================>
Step: 76240, Train_acc:0.97839
Step: 76240, Val_acc:0.948242
==================>
Step: 76250, Train_acc:0.983221
Step: 76250, Val_acc:0.949845
==================>
Step: 76260, Train_acc:0.987484
Step: 76260, Val_acc:0.940596
==================>
Step: 76270, Train_acc:0.977183
Step: 76270, Val_acc:0.940497
==================>
Step: 76280, Train_acc:0.986208
Step: 76280, Val_acc:0.936672
==================>
Step: 76290, Train_acc:0.983992
Step: 76290, Val_acc:0.952609
==================>
Step: 76300, Train_acc:0.982948
Step: 76300, Val_acc:0.955862
==================>
2017-11-12 02:32:30.950328 ---> Validation_loss: 0.132629
Step: 76310, Train_acc:0.981415
Step: 76310, Val_acc:0.946278
==================>
Step: 76320, Train_acc:0.977733
Step: 76320, Val_acc:0.953131
==================>
Step: 76330, Train_acc:0.985604
Step: 76330, Val_acc:0.938927
==================>
Step: 76340, Train_acc:0.977621
Step: 76340, Val_acc:0.945461
==================>
Step: 76350, Train_acc:0.983293
Step: 76350, Val_acc:0.959345
==================>
Step: 76360, Train_acc:0.980166
Step: 76360, Val_acc:0.945676
==================>
Step: 76370, Train_acc:0.985841
Step: 76370, Val_acc:0.95495
==================>
Step: 76380, Train_acc:0.978763
Step: 76380, Val_acc:0.937595
==================>
Step: 76390, Train_acc:0.981477
Step: 76390, Val_acc:0.948411
==================>
Step: 76400, Train_acc:0.981827
Step: 76400, Val_acc:0.946905
==================>
2017-11-12 02:35:06.603979 ---> Validation_loss: 0.176371
Step: 76410, Train_acc:0.987671
Step: 76410, Val_acc:0.93615
==================>
Step: 76420, Train_acc:0.983063
Step: 76420, Val_acc:0.936531
==================>
Step: 76430, Train_acc:0.974874
Step: 76430, Val_acc:0.934908
==================>
Step: 76440, Train_acc:0.978155
Step: 76440, Val_acc:0.948477
==================>
Step: 76450, Train_acc:0.98228
Step: 76450, Val_acc:0.943387
==================>
Step: 76460, Train_acc:0.981401
Step: 76460, Val_acc:0.950247
==================>
Step: 76470, Train_acc:0.972228
Step: 76470, Val_acc:0.935812
==================>
Step: 76480, Train_acc:0.979929
Step: 76480, Val_acc:0.948242
==================>
Step: 76490, Train_acc:0.981049
Step: 76490, Val_acc:0.947229
==================>
Step: 76500, Train_acc:0.979922
Step: 76500, Val_acc:0.919131
==================>
****************** Epochs completed: 153******************
2017-11-12 02:37:41.678764 ---> Validation_loss: 0.171239
Step: 76510, Train_acc:0.984528
Step: 76510, Val_acc:0.952437
==================>
Step: 76520, Train_acc:0.982155
Step: 76520, Val_acc:0.940605
==================>
Step: 76530, Train_acc:0.978739
Step: 76530, Val_acc:0.960106
==================>
Step: 76540, Train_acc:0.98163
Step: 76540, Val_acc:0.923053
==================>
Step: 76550, Train_acc:0.979722
Step: 76550, Val_acc:0.968319
==================>
Step: 76560, Train_acc:0.983818
Step: 76560, Val_acc:0.936547
==================>
Step: 76570, Train_acc:0.986172
Step: 76570, Val_acc:0.948793
==================>
Step: 76580, Train_acc:0.982981
Step: 76580, Val_acc:0.953209
==================>
Step: 76590, Train_acc:0.982277
Step: 76590, Val_acc:0.936091
==================>
Step: 76600, Train_acc:0.975524
Step: 76600, Val_acc:0.924995
==================>
2017-11-12 02:40:17.051861 ---> Validation_loss: 0.176614
Step: 76610, Train_acc:0.985581
Step: 76610, Val_acc:0.938665
==================>
Step: 76620, Train_acc:0.983301
Step: 76620, Val_acc:0.942289
==================>
Step: 76630, Train_acc:0.982345
Step: 76630, Val_acc:0.938674
==================>
Step: 76640, Train_acc:0.980763
Step: 76640, Val_acc:0.956256
==================>
Step: 76650, Train_acc:0.983966
Step: 76650, Val_acc:0.937427
==================>
Step: 76660, Train_acc:0.981965
Step: 76660, Val_acc:0.947524
==================>
Step: 76670, Train_acc:0.982925
Step: 76670, Val_acc:0.942134
==================>
Step: 76680, Train_acc:0.981288
Step: 76680, Val_acc:0.939326
==================>
Step: 76690, Train_acc:0.980812
Step: 76690, Val_acc:0.948147
==================>
Step: 76700, Train_acc:0.980665
Step: 76700, Val_acc:0.943346
==================>
2017-11-12 02:42:52.101653 ---> Validation_loss: 0.140139
Step: 76710, Train_acc:0.977952
Step: 76710, Val_acc:0.91915
==================>
Step: 76720, Train_acc:0.984873
Step: 76720, Val_acc:0.94602
==================>
Step: 76730, Train_acc:0.980925
Step: 76730, Val_acc:0.951672
==================>
Step: 76740, Train_acc:0.977235
Step: 76740, Val_acc:0.938925
==================>
Step: 76750, Train_acc:0.978829
Step: 76750, Val_acc:0.946377
==================>
Step: 76760, Train_acc:0.980933
Step: 76760, Val_acc:0.950542
==================>
Step: 76770, Train_acc:0.983649
Step: 76770, Val_acc:0.936117
==================>
Step: 76780, Train_acc:0.978455
Step: 76780, Val_acc:0.959712
==================>
Step: 76790, Train_acc:0.988048
Step: 76790, Val_acc:0.911149
==================>
Step: 76800, Train_acc:0.984617
Step: 76800, Val_acc:0.944807
==================>
2017-11-12 02:45:26.915264 ---> Validation_loss: 0.126064
Step: 76810, Train_acc:0.976371
Step: 76810, Val_acc:0.934679
==================>
Step: 76820, Train_acc:0.986267
Step: 76820, Val_acc:0.929917
==================>
Step: 76830, Train_acc:0.9812
Step: 76830, Val_acc:0.943556
==================>
Step: 76840, Train_acc:0.981819
Step: 76840, Val_acc:0.946409
==================>
Step: 76850, Train_acc:0.983226
Step: 76850, Val_acc:0.946473
==================>
Step: 76860, Train_acc:0.981991
Step: 76860, Val_acc:0.932079
==================>
Step: 76870, Train_acc:0.983904
Step: 76870, Val_acc:0.944076
==================>
Step: 76880, Train_acc:0.985729
Step: 76880, Val_acc:0.953542
==================>
Step: 76890, Train_acc:0.983978
Step: 76890, Val_acc:0.919531
==================>
Step: 76900, Train_acc:0.979305
Step: 76900, Val_acc:0.964373
==================>
2017-11-12 02:48:02.171523 ---> Validation_loss: 0.165674
Step: 76910, Train_acc:0.983267
Step: 76910, Val_acc:0.943989
==================>
Step: 76920, Train_acc:0.981249
Step: 76920, Val_acc:0.945065
==================>
Step: 76930, Train_acc:0.983785
Step: 76930, Val_acc:0.929243
==================>
Step: 76940, Train_acc:0.982039
Step: 76940, Val_acc:0.929553
==================>
Step: 76950, Train_acc:0.979304
Step: 76950, Val_acc:0.949725
==================>
Step: 76960, Train_acc:0.989
Step: 76960, Val_acc:0.949976
==================>
Step: 76970, Train_acc:0.981157
Step: 76970, Val_acc:0.92585
==================>
Step: 76980, Train_acc:0.983606
Step: 76980, Val_acc:0.952496
==================>
Step: 76990, Train_acc:0.982919
Step: 76990, Val_acc:0.94272
==================>
Step: 77000, Train_acc:0.975223
Step: 77000, Val_acc:0.946656
==================>
****************** Epochs completed: 154******************
2017-11-12 02:50:37.427211 ---> Validation_loss: 0.160372
Step: 77010, Train_acc:0.985748
Step: 77010, Val_acc:0.956714
==================>
Step: 77020, Train_acc:0.98137
Step: 77020, Val_acc:0.93103
==================>
Step: 77030, Train_acc:0.977816
Step: 77030, Val_acc:0.918197
==================>
Step: 77040, Train_acc:0.981818
Step: 77040, Val_acc:0.932484
==================>
Step: 77050, Train_acc:0.978815
Step: 77050, Val_acc:0.930999
==================>
Step: 77060, Train_acc:0.975107
Step: 77060, Val_acc:0.945063
==================>
Step: 77070, Train_acc:0.98546
Step: 77070, Val_acc:0.942749
==================>
Step: 77080, Train_acc:0.982587
Step: 77080, Val_acc:0.934965
==================>
Step: 77090, Train_acc:0.982118
Step: 77090, Val_acc:0.958315
==================>
Step: 77100, Train_acc:0.983748
Step: 77100, Val_acc:0.927683
==================>
2017-11-12 02:53:13.808629 ---> Validation_loss: 0.131271
Step: 77110, Train_acc:0.97788
Step: 77110, Val_acc:0.958751
==================>
Step: 77120, Train_acc:0.979724
Step: 77120, Val_acc:0.939963
==================>
Step: 77130, Train_acc:0.990549
Step: 77130, Val_acc:0.951531
==================>
Step: 77140, Train_acc:0.980278
Step: 77140, Val_acc:0.942343
==================>
Step: 77150, Train_acc:0.986088
Step: 77150, Val_acc:0.930212
==================>
Step: 77160, Train_acc:0.973763
Step: 77160, Val_acc:0.934856
==================>
Step: 77170, Train_acc:0.980986
Step: 77170, Val_acc:0.934749
==================>
Step: 77180, Train_acc:0.985907
Step: 77180, Val_acc:0.961234
==================>
Step: 77190, Train_acc:0.979648
Step: 77190, Val_acc:0.945808
==================>
Step: 77200, Train_acc:0.979257
Step: 77200, Val_acc:0.938278
==================>
2017-11-12 02:55:50.363304 ---> Validation_loss: 0.13493
Step: 77210, Train_acc:0.983669
Step: 77210, Val_acc:0.951831
==================>
Step: 77220, Train_acc:0.985211
Step: 77220, Val_acc:0.949919
==================>
Step: 77230, Train_acc:0.979423
Step: 77230, Val_acc:0.928308
==================>
Step: 77240, Train_acc:0.980056
Step: 77240, Val_acc:0.924399
==================>
Step: 77250, Train_acc:0.981122
Step: 77250, Val_acc:0.950243
==================>
Step: 77260, Train_acc:0.985852
Step: 77260, Val_acc:0.925721
==================>
Step: 77270, Train_acc:0.978409
Step: 77270, Val_acc:0.958004
==================>
Step: 77280, Train_acc:0.977712
Step: 77280, Val_acc:0.951643
==================>
Step: 77290, Train_acc:0.986702
Step: 77290, Val_acc:0.951454
==================>
Step: 77300, Train_acc:0.987286
Step: 77300, Val_acc:0.966853
==================>
2017-11-12 02:58:27.028150 ---> Validation_loss: 0.175
Step: 77310, Train_acc:0.982543
Step: 77310, Val_acc:0.943638
==================>
Step: 77320, Train_acc:0.969187
Step: 77320, Val_acc:0.946559
==================>
Step: 77330, Train_acc:0.975807
Step: 77330, Val_acc:0.961105
==================>
Step: 77340, Train_acc:0.976415
Step: 77340, Val_acc:0.941205
==================>
Step: 77350, Train_acc:0.985946
Step: 77350, Val_acc:0.929407
==================>
Step: 77360, Train_acc:0.983182
Step: 77360, Val_acc:0.955072
==================>
Step: 77370, Train_acc:0.986509
Step: 77370, Val_acc:0.933184
==================>
****************** Epochs completed: 23******************
Step: 77380, Train_acc:0.977836
Step: 77380, Val_acc:0.935928
==================>
Step: 77390, Train_acc:0.986681
Step: 77390, Val_acc:0.947263
==================>
Step: 77400, Train_acc:0.982953
Step: 77400, Val_acc:0.893489
==================>
2017-11-12 03:01:03.607797 ---> Validation_loss: 0.150519
Step: 77410, Train_acc:0.984442
Step: 77410, Val_acc:0.950504
==================>
Step: 77420, Train_acc:0.985405
Step: 77420, Val_acc:0.938439
==================>
Step: 77430, Train_acc:0.983038
Step: 77430, Val_acc:0.924084
==================>
Step: 77440, Train_acc:0.984961
Step: 77440, Val_acc:0.953679
==================>
Step: 77450, Train_acc:0.984415
Step: 77450, Val_acc:0.937745
==================>
Step: 77460, Train_acc:0.984604
Step: 77460, Val_acc:0.958728
==================>
Step: 77470, Train_acc:0.988813
Step: 77470, Val_acc:0.931731
==================>
Step: 77480, Train_acc:0.983685
Step: 77480, Val_acc:0.940337
==================>
Step: 77490, Train_acc:0.97829
Step: 77490, Val_acc:0.958817
==================>
Step: 77500, Train_acc:0.980931
Step: 77500, Val_acc:0.94973
==================>
****************** Epochs completed: 155******************
2017-11-12 03:03:40.317913 ---> Validation_loss: 0.162718
Step: 77510, Train_acc:0.981689
Step: 77510, Val_acc:0.947604
==================>
Step: 77520, Train_acc:0.980363
Step: 77520, Val_acc:0.962412
==================>
Step: 77530, Train_acc:0.978914
Step: 77530, Val_acc:0.927692
==================>
Step: 77540, Train_acc:0.987801
Step: 77540, Val_acc:0.942303
==================>
Step: 77550, Train_acc:0.980485
Step: 77550, Val_acc:0.950334
==================>
Step: 77560, Train_acc:0.983903
Step: 77560, Val_acc:0.949829
==================>
Step: 77570, Train_acc:0.980477
Step: 77570, Val_acc:0.955466
==================>
Step: 77580, Train_acc:0.980664
Step: 77580, Val_acc:0.95552
==================>
Step: 77590, Train_acc:0.980599
Step: 77590, Val_acc:0.947135
==================>
Step: 77600, Train_acc:0.980988
Step: 77600, Val_acc:0.938127
==================>
2017-11-12 03:06:16.858011 ---> Validation_loss: 0.142617
Step: 77610, Train_acc:0.984799
Step: 77610, Val_acc:0.950637
==================>
Step: 77620, Train_acc:0.980516
Step: 77620, Val_acc:0.958065
==================>
Step: 77630, Train_acc:0.979667
Step: 77630, Val_acc:0.924769
==================>
Step: 77640, Train_acc:0.981461
Step: 77640, Val_acc:0.932306
==================>
Step: 77650, Train_acc:0.983352
Step: 77650, Val_acc:0.951526
==================>
Step: 77660, Train_acc:0.979238
Step: 77660, Val_acc:0.946901
==================>
Step: 77670, Train_acc:0.979622
Step: 77670, Val_acc:0.963867
==================>
Step: 77680, Train_acc:0.980404
Step: 77680, Val_acc:0.959934
==================>
Step: 77690, Train_acc:0.980399
Step: 77690, Val_acc:0.938325
==================>
Step: 77700, Train_acc:0.985411
Step: 77700, Val_acc:0.938773
==================>
2017-11-12 03:08:53.505105 ---> Validation_loss: 0.170786
Step: 77710, Train_acc:0.983556
Step: 77710, Val_acc:0.941672
==================>
Step: 77720, Train_acc:0.984264
Step: 77720, Val_acc:0.950636
==================>
Step: 77730, Train_acc:0.978092
Step: 77730, Val_acc:0.941298
==================>
Step: 77740, Train_acc:0.989606
Step: 77740, Val_acc:0.962686
==================>
Step: 77750, Train_acc:0.985565
Step: 77750, Val_acc:0.944971
==================>
Step: 77760, Train_acc:0.978707
Step: 77760, Val_acc:0.942589
==================>
Step: 77770, Train_acc:0.982728
Step: 77770, Val_acc:0.937124
==================>
Step: 77780, Train_acc:0.979633
Step: 77780, Val_acc:0.944728
==================>
Step: 77790, Train_acc:0.98566
Step: 77790, Val_acc:0.929869
==================>
Step: 77800, Train_acc:0.986003
Step: 77800, Val_acc:0.933053
==================>
2017-11-12 03:11:30.266524 ---> Validation_loss: 0.121351
Step: 77810, Train_acc:0.983131
Step: 77810, Val_acc:0.957491
==================>
Step: 77820, Train_acc:0.982777
Step: 77820, Val_acc:0.958307
==================>
Step: 77830, Train_acc:0.98652
Step: 77830, Val_acc:0.945543
==================>
Step: 77840, Train_acc:0.97949
Step: 77840, Val_acc:0.963031
==================>
Step: 77850, Train_acc:0.987876
Step: 77850, Val_acc:0.94757
==================>
Step: 77860, Train_acc:0.980566
Step: 77860, Val_acc:0.94671
==================>
Step: 77870, Train_acc:0.98345
Step: 77870, Val_acc:0.94856
==================>
Step: 77880, Train_acc:0.9824
Step: 77880, Val_acc:0.934764
==================>
Step: 77890, Train_acc:0.987817
Step: 77890, Val_acc:0.93519
==================>
Step: 77900, Train_acc:0.982474
Step: 77900, Val_acc:0.946254
==================>
2017-11-12 03:14:07.132184 ---> Validation_loss: 0.148875
Step: 77910, Train_acc:0.978114
Step: 77910, Val_acc:0.963829
==================>
Step: 77920, Train_acc:0.986876
Step: 77920, Val_acc:0.939104
==================>
Step: 77930, Train_acc:0.982178
Step: 77930, Val_acc:0.947152
==================>
Step: 77940, Train_acc:0.982621
Step: 77940, Val_acc:0.964189
==================>
Step: 77950, Train_acc:0.980049
Step: 77950, Val_acc:0.944282
==================>
Step: 77960, Train_acc:0.983551
Step: 77960, Val_acc:0.948905
==================>
Step: 77970, Train_acc:0.985991
Step: 77970, Val_acc:0.94882
==================>
Step: 77980, Train_acc:0.98467
Step: 77980, Val_acc:0.937506
==================>
Step: 77990, Train_acc:0.986302
Step: 77990, Val_acc:0.94325
==================>
Step: 78000, Train_acc:0.985653
Step: 78000, Val_acc:0.942545
==================>
****************** Epochs completed: 156******************
2017-11-12 03:16:43.663991 ---> Validation_loss: 0.131055
Step: 78010, Train_acc:0.983513
Step: 78010, Val_acc:0.9452
==================>
Step: 78020, Train_acc:0.981976
Step: 78020, Val_acc:0.958037
==================>
Step: 78030, Train_acc:0.986395
Step: 78030, Val_acc:0.944768
==================>
Step: 78040, Train_acc:0.982251
Step: 78040, Val_acc:0.934325
==================>
Step: 78050, Train_acc:0.983206
Step: 78050, Val_acc:0.915739
==================>
Step: 78060, Train_acc:0.985787
Step: 78060, Val_acc:0.950156
==================>
Step: 78070, Train_acc:0.986696
Step: 78070, Val_acc:0.956093
==================>
Step: 78080, Train_acc:0.974359
Step: 78080, Val_acc:0.942384
==================>
Step: 78090, Train_acc:0.979373
Step: 78090, Val_acc:0.948724
==================>
Step: 78100, Train_acc:0.985914
Step: 78100, Val_acc:0.954114
==================>
2017-11-12 03:19:19.965535 ---> Validation_loss: 0.108563
Step: 78110, Train_acc:0.981367
Step: 78110, Val_acc:0.948319
==================>
Step: 78120, Train_acc:0.981205
Step: 78120, Val_acc:0.918588
==================>
Step: 78130, Train_acc:0.980928
Step: 78130, Val_acc:0.938767
==================>
Step: 78140, Train_acc:0.981831
Step: 78140, Val_acc:0.948945
==================>
Step: 78150, Train_acc:0.980869
Step: 78150, Val_acc:0.949734
==================>
Step: 78160, Train_acc:0.976691
Step: 78160, Val_acc:0.94854
==================>
Step: 78170, Train_acc:0.982052
Step: 78170, Val_acc:0.950681
==================>
Step: 78180, Train_acc:0.97916
Step: 78180, Val_acc:0.935485
==================>
Step: 78190, Train_acc:0.978462
Step: 78190, Val_acc:0.939712
==================>
Step: 78200, Train_acc:0.981288
Step: 78200, Val_acc:0.93116
==================>
2017-11-12 03:21:56.342647 ---> Validation_loss: 0.175604
Step: 78210, Train_acc:0.985817
Step: 78210, Val_acc:0.94103
==================>
Step: 78220, Train_acc:0.9767
Step: 78220, Val_acc:0.936067
==================>
Step: 78230, Train_acc:0.978137
Step: 78230, Val_acc:0.93519
==================>
Step: 78240, Train_acc:0.981387
Step: 78240, Val_acc:0.947115
==================>
Step: 78250, Train_acc:0.985116
Step: 78250, Val_acc:0.953429
==================>
Step: 78260, Train_acc:0.982971
Step: 78260, Val_acc:0.950011
==================>
Step: 78270, Train_acc:0.98776
Step: 78270, Val_acc:0.940685
==================>
Step: 78280, Train_acc:0.985593
Step: 78280, Val_acc:0.94144
==================>
Step: 78290, Train_acc:0.984334
Step: 78290, Val_acc:0.922428
==================>
Step: 78300, Train_acc:0.979176
Step: 78300, Val_acc:0.956086
==================>
2017-11-12 03:24:32.702387 ---> Validation_loss: 0.152283
Step: 78310, Train_acc:0.985752
Step: 78310, Val_acc:0.950208
==================>
Step: 78320, Train_acc:0.984497
Step: 78320, Val_acc:0.937175
==================>
Step: 78330, Train_acc:0.982284
Step: 78330, Val_acc:0.941386
==================>
Step: 78340, Train_acc:0.982339
Step: 78340, Val_acc:0.947002
==================>
Step: 78350, Train_acc:0.985383
Step: 78350, Val_acc:0.933636
==================>
Step: 78360, Train_acc:0.980944
Step: 78360, Val_acc:0.955607
==================>
Step: 78370, Train_acc:0.986034
Step: 78370, Val_acc:0.947429
==================>
Step: 78380, Train_acc:0.983208
Step: 78380, Val_acc:0.948511
==================>
Step: 78390, Train_acc:0.977282
Step: 78390, Val_acc:0.950289
==================>
Step: 78400, Train_acc:0.985531
Step: 78400, Val_acc:0.945233
==================>
2017-11-12 03:27:09.299570 ---> Validation_loss: 0.132967
Step: 78410, Train_acc:0.979595
Step: 78410, Val_acc:0.942609
==================>
Step: 78420, Train_acc:0.982529
Step: 78420, Val_acc:0.937076
==================>
Step: 78430, Train_acc:0.980243
Step: 78430, Val_acc:0.954181
==================>
Step: 78440, Train_acc:0.978466
Step: 78440, Val_acc:0.935409
==================>
Step: 78450, Train_acc:0.981423
Step: 78450, Val_acc:0.950797
==================>
Step: 78460, Train_acc:0.982576
Step: 78460, Val_acc:0.959973
==================>
Step: 78470, Train_acc:0.980018
Step: 78470, Val_acc:0.941326
==================>
Step: 78480, Train_acc:0.979496
Step: 78480, Val_acc:0.938756
==================>
Step: 78490, Train_acc:0.981071
Step: 78490, Val_acc:0.952649
==================>
Step: 78500, Train_acc:0.980103
Step: 78500, Val_acc:0.918968
==================>
****************** Epochs completed: 157******************
2017-11-12 03:29:45.827904 ---> Validation_loss: 0.190468
Step: 78510, Train_acc:0.981953
Step: 78510, Val_acc:0.943723
==================>
Step: 78520, Train_acc:0.980033
Step: 78520, Val_acc:0.931774
==================>
Step: 78530, Train_acc:0.981775
Step: 78530, Val_acc:0.946948
==================>
Step: 78540, Train_acc:0.985469
Step: 78540, Val_acc:0.969753
==================>
Step: 78550, Train_acc:0.978544
Step: 78550, Val_acc:0.938802
==================>
Step: 78560, Train_acc:0.981708
Step: 78560, Val_acc:0.942675
==================>
Step: 78570, Train_acc:0.98745
Step: 78570, Val_acc:0.949175
==================>
Step: 78580, Train_acc:0.980643
Step: 78580, Val_acc:0.918645
==================>
Step: 78590, Train_acc:0.97811
Step: 78590, Val_acc:0.941768
==================>
Step: 78600, Train_acc:0.982711
Step: 78600, Val_acc:0.894675
==================>
2017-11-12 03:32:22.251561 ---> Validation_loss: 0.145159
Step: 78610, Train_acc:0.98535
Step: 78610, Val_acc:0.95876
==================>
Step: 78620, Train_acc:0.979686
Step: 78620, Val_acc:0.958453
==================>
Step: 78630, Train_acc:0.98621
Step: 78630, Val_acc:0.953738
==================>
Step: 78640, Train_acc:0.983584
Step: 78640, Val_acc:0.940342
==================>
Step: 78650, Train_acc:0.980803
Step: 78650, Val_acc:0.951362
==================>
Step: 78660, Train_acc:0.978237
Step: 78660, Val_acc:0.951752
==================>
Step: 78670, Train_acc:0.985189
Step: 78670, Val_acc:0.94121
==================>
Step: 78680, Train_acc:0.985115
Step: 78680, Val_acc:0.95194
==================>
Step: 78690, Train_acc:0.977692
Step: 78690, Val_acc:0.965459
==================>
Step: 78700, Train_acc:0.985641
Step: 78700, Val_acc:0.938105
==================>
2017-11-12 03:34:58.909429 ---> Validation_loss: 0.139786
Step: 78710, Train_acc:0.982974
Step: 78710, Val_acc:0.928959
==================>
Step: 78720, Train_acc:0.978169
Step: 78720, Val_acc:0.93004
==================>
Step: 78730, Train_acc:0.985726
Step: 78730, Val_acc:0.941851
==================>
Step: 78740, Train_acc:0.979308
Step: 78740, Val_acc:0.932623
==================>
Step: 78750, Train_acc:0.983334
Step: 78750, Val_acc:0.936024
==================>
Step: 78760, Train_acc:0.977556
Step: 78760, Val_acc:0.971437
==================>
Step: 78770, Train_acc:0.986129
Step: 78770, Val_acc:0.928519
==================>
Step: 78780, Train_acc:0.979291
Step: 78780, Val_acc:0.951338
==================>
Step: 78790, Train_acc:0.980421
Step: 78790, Val_acc:0.939022
==================>
Step: 78800, Train_acc:0.988865
Step: 78800, Val_acc:0.950758
==================>
2017-11-12 03:37:35.600301 ---> Validation_loss: 0.148989
Step: 78810, Train_acc:0.984399
Step: 78810, Val_acc:0.933936
==================>
Step: 78820, Train_acc:0.982092
Step: 78820, Val_acc:0.950062
==================>
Step: 78830, Train_acc:0.985259
Step: 78830, Val_acc:0.942223
==================>
Step: 78840, Train_acc:0.979287
Step: 78840, Val_acc:0.956967
==================>
Step: 78850, Train_acc:0.987128
Step: 78850, Val_acc:0.938459
==================>
Step: 78860, Train_acc:0.983695
Step: 78860, Val_acc:0.942751
==================>
Step: 78870, Train_acc:0.984391
Step: 78870, Val_acc:0.937693
==================>
Step: 78880, Train_acc:0.983218
Step: 78880, Val_acc:0.91375
==================>
Step: 78890, Train_acc:0.978326
Step: 78890, Val_acc:0.944386
==================>
Step: 78900, Train_acc:0.974707
Step: 78900, Val_acc:0.966112
==================>
2017-11-12 03:40:11.579744 ---> Validation_loss: 0.10659
Step: 78910, Train_acc:0.987733
Step: 78910, Val_acc:0.959388
==================>
Step: 78920, Train_acc:0.9804
Step: 78920, Val_acc:0.955432
==================>
Step: 78930, Train_acc:0.986732
Step: 78930, Val_acc:0.939249
==================>
Step: 78940, Train_acc:0.98265
Step: 78940, Val_acc:0.934789
==================>
Step: 78950, Train_acc:0.981047
Step: 78950, Val_acc:0.942559
==================>
Step: 78960, Train_acc:0.983884
Step: 78960, Val_acc:0.945961
==================>
Step: 78970, Train_acc:0.983759
Step: 78970, Val_acc:0.951167
==================>
Step: 78980, Train_acc:0.984668
Step: 78980, Val_acc:0.973995
==================>
Step: 78990, Train_acc:0.981396
Step: 78990, Val_acc:0.936967
==================>
Step: 79000, Train_acc:0.984133
Step: 79000, Val_acc:0.914517
==================>
****************** Epochs completed: 158******************
2017-11-12 03:42:47.923503 ---> Validation_loss: 0.125102
Step: 79010, Train_acc:0.983234
Step: 79010, Val_acc:0.939613
==================>
Step: 79020, Train_acc:0.983203
Step: 79020, Val_acc:0.938232
==================>
Step: 79030, Train_acc:0.982864
Step: 79030, Val_acc:0.952523
==================>
Step: 79040, Train_acc:0.987377
Step: 79040, Val_acc:0.947646
==================>
Step: 79050, Train_acc:0.982919
Step: 79050, Val_acc:0.94481
==================>
Step: 79060, Train_acc:0.986832
Step: 79060, Val_acc:0.951427
==================>
Step: 79070, Train_acc:0.985482
Step: 79070, Val_acc:0.961303
==================>
Step: 79080, Train_acc:0.9802
Step: 79080, Val_acc:0.938173
==================>
Step: 79090, Train_acc:0.972629
Step: 79090, Val_acc:0.939004
==================>
Step: 79100, Train_acc:0.982111
Step: 79100, Val_acc:0.912269
==================>
2017-11-12 03:45:24.385504 ---> Validation_loss: 0.14271
Step: 79110, Train_acc:0.981176
Step: 79110, Val_acc:0.951312
==================>
Step: 79120, Train_acc:0.979553
Step: 79120, Val_acc:0.9577
==================>
Step: 79130, Train_acc:0.9853
Step: 79130, Val_acc:0.950713
==================>
Step: 79140, Train_acc:0.981188
Step: 79140, Val_acc:0.933593
==================>
Step: 79150, Train_acc:0.983871
Step: 79150, Val_acc:0.932079
==================>
Step: 79160, Train_acc:0.986226
Step: 79160, Val_acc:0.940392
==================>
Step: 79170, Train_acc:0.977324
Step: 79170, Val_acc:0.942683
==================>
Step: 79180, Train_acc:0.982098
Step: 79180, Val_acc:0.941228
==================>
Step: 79190, Train_acc:0.982916
Step: 79190, Val_acc:0.936349
==================>
Step: 79200, Train_acc:0.982211
Step: 79200, Val_acc:0.937136
==================>
2017-11-12 03:48:00.877130 ---> Validation_loss: 0.155978
Step: 79210, Train_acc:0.980937
Step: 79210, Val_acc:0.947213
==================>
Step: 79220, Train_acc:0.979502
Step: 79220, Val_acc:0.955897
==================>
Step: 79230, Train_acc:0.977097
Step: 79230, Val_acc:0.946469
==================>
Step: 79240, Train_acc:0.976189
Step: 79240, Val_acc:0.941515
==================>
Step: 79250, Train_acc:0.986213
Step: 79250, Val_acc:0.948571
==================>
Step: 79260, Train_acc:0.983514
Step: 79260, Val_acc:0.952666
==================>
Step: 79270, Train_acc:0.977217
Step: 79270, Val_acc:0.936215
==================>
Step: 79280, Train_acc:0.983026
Step: 79280, Val_acc:0.924416
==================>
Step: 79290, Train_acc:0.984872
Step: 79290, Val_acc:0.922272
==================>
Step: 79300, Train_acc:0.98266
Step: 79300, Val_acc:0.958677
==================>
2017-11-12 03:50:37.871792 ---> Validation_loss: 0.139461
Step: 79310, Train_acc:0.974761
Step: 79310, Val_acc:0.940177
==================>
Step: 79320, Train_acc:0.981285
Step: 79320, Val_acc:0.931704
==================>
Step: 79330, Train_acc:0.985536
Step: 79330, Val_acc:0.932661
==================>
Step: 79340, Train_acc:0.983203
Step: 79340, Val_acc:0.926874
==================>
Step: 79350, Train_acc:0.982048
Step: 79350, Val_acc:0.944523
==================>
Step: 79360, Train_acc:0.983146
Step: 79360, Val_acc:0.953756
==================>
Step: 79370, Train_acc:0.978704
Step: 79370, Val_acc:0.935898
==================>
Step: 79380, Train_acc:0.985027
Step: 79380, Val_acc:0.952057
==================>
Step: 79390, Train_acc:0.981043
Step: 79390, Val_acc:0.930299
==================>
Step: 79400, Train_acc:0.979226
Step: 79400, Val_acc:0.953204
==================>
2017-11-12 03:53:14.496748 ---> Validation_loss: 0.159283
Step: 79410, Train_acc:0.985463
Step: 79410, Val_acc:0.938265
==================>
Step: 79420, Train_acc:0.982003
Step: 79420, Val_acc:0.968218
==================>
Step: 79430, Train_acc:0.984098
Step: 79430, Val_acc:0.957472
==================>
Step: 79440, Train_acc:0.984965
Step: 79440, Val_acc:0.952636
==================>
Step: 79450, Train_acc:0.980576
Step: 79450, Val_acc:0.944277
==================>
Step: 79460, Train_acc:0.978059
Step: 79460, Val_acc:0.942034
==================>
Step: 79470, Train_acc:0.984794
Step: 79470, Val_acc:0.90496
==================>
Step: 79480, Train_acc:0.985511
Step: 79480, Val_acc:0.948009
==================>
Step: 79490, Train_acc:0.983593
Step: 79490, Val_acc:0.943297
==================>
Step: 79500, Train_acc:0.979214
Step: 79500, Val_acc:0.95401
==================>
****************** Epochs completed: 159******************
2017-11-12 03:55:50.936973 ---> Validation_loss: 0.148585
Step: 79510, Train_acc:0.98063
Step: 79510, Val_acc:0.949388
==================>
Step: 79520, Train_acc:0.986062
Step: 79520, Val_acc:0.951835
==================>
Step: 79530, Train_acc:0.984572
Step: 79530, Val_acc:0.941057
==================>
Step: 79540, Train_acc:0.977961
Step: 79540, Val_acc:0.943651
==================>
Step: 79550, Train_acc:0.978616
Step: 79550, Val_acc:0.962194
==================>
Step: 79560, Train_acc:0.97666
Step: 79560, Val_acc:0.942107
==================>
Step: 79570, Train_acc:0.981747
Step: 79570, Val_acc:0.946489
==================>
Step: 79580, Train_acc:0.986963
Step: 79580, Val_acc:0.933297
==================>
Step: 79590, Train_acc:0.981869
Step: 79590, Val_acc:0.916572
==================>
Step: 79600, Train_acc:0.985852
Step: 79600, Val_acc:0.903854
==================>
2017-11-12 03:58:27.787444 ---> Validation_loss: 0.132376
Step: 79610, Train_acc:0.985109
Step: 79610, Val_acc:0.942976
==================>
Step: 79620, Train_acc:0.981184
Step: 79620, Val_acc:0.959762
==================>
Step: 79630, Train_acc:0.985161
Step: 79630, Val_acc:0.94849
==================>
Step: 79640, Train_acc:0.979717
Step: 79640, Val_acc:0.922031
==================>
Step: 79650, Train_acc:0.983621
Step: 79650, Val_acc:0.926768
==================>
Step: 79660, Train_acc:0.984492
Step: 79660, Val_acc:0.955387
==================>
Step: 79670, Train_acc:0.984601
Step: 79670, Val_acc:0.933024
==================>
Step: 79680, Train_acc:0.979806
Step: 79680, Val_acc:0.9586
==================>
Step: 79690, Train_acc:0.978668
Step: 79690, Val_acc:0.928071
==================>
Step: 79700, Train_acc:0.982303
Step: 79700, Val_acc:0.937741
==================>
2017-11-12 04:01:04.160682 ---> Validation_loss: 0.175635
Step: 79710, Train_acc:0.987152
Step: 79710, Val_acc:0.952242
==================>
Step: 79720, Train_acc:0.984608
Step: 79720, Val_acc:0.957355
==================>
Step: 79730, Train_acc:0.984612
Step: 79730, Val_acc:0.918436
==================>
Step: 79740, Train_acc:0.98214
Step: 79740, Val_acc:0.939825
==================>
Step: 79750, Train_acc:0.982404
Step: 79750, Val_acc:0.95897
==================>
Step: 79760, Train_acc:0.978795
Step: 79760, Val_acc:0.959086
==================>
Step: 79770, Train_acc:0.989604
Step: 79770, Val_acc:0.936515
==================>
Step: 79780, Train_acc:0.977247
Step: 79780, Val_acc:0.949713
==================>
Step: 79790, Train_acc:0.986634
Step: 79790, Val_acc:0.96099
==================>
Step: 79800, Train_acc:0.977456
Step: 79800, Val_acc:0.94589
==================>
2017-11-12 04:03:41.173178 ---> Validation_loss: 0.160966
Step: 79810, Train_acc:0.986998
Step: 79810, Val_acc:0.948477
==================>
Step: 79820, Train_acc:0.980797
Step: 79820, Val_acc:0.951433
==================>
Step: 79830, Train_acc:0.984738
Step: 79830, Val_acc:0.9475
==================>
Step: 79840, Train_acc:0.979523
Step: 79840, Val_acc:0.953147
==================>
Step: 79850, Train_acc:0.977562
Step: 79850, Val_acc:0.946342
==================>
Step: 79860, Train_acc:0.97911
Step: 79860, Val_acc:0.947256
==================>
Step: 79870, Train_acc:0.980657
Step: 79870, Val_acc:0.939133
==================>
Step: 79880, Train_acc:0.980708
Step: 79880, Val_acc:0.933535
==================>
Step: 79890, Train_acc:0.980936
Step: 79890, Val_acc:0.942756
==================>
Step: 79900, Train_acc:0.976554
Step: 79900, Val_acc:0.947478
==================>
2017-11-12 04:06:18.258929 ---> Validation_loss: 0.167559
Step: 79910, Train_acc:0.981993
Step: 79910, Val_acc:0.94572
==================>
Step: 79920, Train_acc:0.984868
Step: 79920, Val_acc:0.94639
==================>
Step: 79930, Train_acc:0.979103
Step: 79930, Val_acc:0.959194
==================>
Step: 79940, Train_acc:0.983645
Step: 79940, Val_acc:0.937948
==================>
Step: 79950, Train_acc:0.983975
Step: 79950, Val_acc:0.917659
==================>
Step: 79960, Train_acc:0.970569
Step: 79960, Val_acc:0.939033
==================>
Step: 79970, Train_acc:0.974437
Step: 79970, Val_acc:0.917117
==================>
Step: 79980, Train_acc:0.981412
Step: 79980, Val_acc:0.930398
==================>
Step: 79990, Train_acc:0.987191
Step: 79990, Val_acc:0.962058
==================>
Step: 80000, Train_acc:0.968492
Step: 80000, Val_acc:0.943218
==================>
****************** Epochs completed: 160******************
2017-11-12 04:08:54.877951 ---> Validation_loss: 0.128217
Step: 80010, Train_acc:0.980985
Step: 80010, Val_acc:0.947656
==================>
Step: 80020, Train_acc:0.977041
Step: 80020, Val_acc:0.922729
==================>
Step: 80030, Train_acc:0.981462
Step: 80030, Val_acc:0.948333
==================>
Step: 80040, Train_acc:0.984769
Step: 80040, Val_acc:0.925153
==================>
Step: 80050, Train_acc:0.98245
Step: 80050, Val_acc:0.962025
==================>
Step: 80060, Train_acc:0.978834
Step: 80060, Val_acc:0.954099
==================>
Step: 80070, Train_acc:0.983945
Step: 80070, Val_acc:0.952933
==================>
Step: 80080, Train_acc:0.983789
Step: 80080, Val_acc:0.939607
==================>
Step: 80090, Train_acc:0.985234
Step: 80090, Val_acc:0.929705
==================>
Step: 80100, Train_acc:0.98804
Step: 80100, Val_acc:0.959335
==================>
2017-11-12 04:11:31.407748 ---> Validation_loss: 0.321504
Step: 80110, Train_acc:0.982745
Step: 80110, Val_acc:0.967209
==================>
Step: 80120, Train_acc:0.984376
Step: 80120, Val_acc:0.965418
==================>
Step: 80130, Train_acc:0.983191
Step: 80130, Val_acc:0.950543
==================>
Step: 80140, Train_acc:0.981234
Step: 80140, Val_acc:0.943221
==================>
Step: 80150, Train_acc:0.987198
Step: 80150, Val_acc:0.936554
==================>
Step: 80160, Train_acc:0.976515
Step: 80160, Val_acc:0.927401
==================>
Step: 80170, Train_acc:0.985203
Step: 80170, Val_acc:0.955017
==================>
Step: 80180, Train_acc:0.971461
Step: 80180, Val_acc:0.923527
==================>
Step: 80190, Train_acc:0.980916
Step: 80190, Val_acc:0.938975
==================>
Step: 80200, Train_acc:0.982839
Step: 80200, Val_acc:0.936666
==================>
2017-11-12 04:14:07.765754 ---> Validation_loss: 0.105275
Step: 80210, Train_acc:0.980446
Step: 80210, Val_acc:0.95246
==================>
Step: 80220, Train_acc:0.980615
Step: 80220, Val_acc:0.954213
==================>
Step: 80230, Train_acc:0.962892
Step: 80230, Val_acc:0.931478
==================>
Step: 80240, Train_acc:0.980442
Step: 80240, Val_acc:0.957756
==================>
Step: 80250, Train_acc:0.976796
Step: 80250, Val_acc:0.943539
==================>
Step: 80260, Train_acc:0.973303
Step: 80260, Val_acc:0.929141
==================>
Step: 80270, Train_acc:0.987488
Step: 80270, Val_acc:0.941114
==================>
Step: 80280, Train_acc:0.977933
Step: 80280, Val_acc:0.94552
==================>
Step: 80290, Train_acc:0.983649
Step: 80290, Val_acc:0.92333
==================>
Step: 80300, Train_acc:0.983973
Step: 80300, Val_acc:0.955884
==================>
2017-11-12 04:16:44.169260 ---> Validation_loss: 0.181004
Step: 80310, Train_acc:0.98264
Step: 80310, Val_acc:0.954456
==================>
Step: 80320, Train_acc:0.983698
Step: 80320, Val_acc:0.921702
==================>
Step: 80330, Train_acc:0.98441
Step: 80330, Val_acc:0.951029
==================>
Step: 80340, Train_acc:0.984952
Step: 80340, Val_acc:0.95095
==================>
Step: 80350, Train_acc:0.985526
Step: 80350, Val_acc:0.969174
==================>
Step: 80360, Train_acc:0.981061
Step: 80360, Val_acc:0.961667
==================>
Step: 80370, Train_acc:0.978076
Step: 80370, Val_acc:0.941747
==================>
Step: 80380, Train_acc:0.985013
Step: 80380, Val_acc:0.944092
==================>
Step: 80390, Train_acc:0.978917
Step: 80390, Val_acc:0.929175
==================>
Step: 80400, Train_acc:0.976656
Step: 80400, Val_acc:0.954961
==================>
2017-11-12 04:19:20.643555 ---> Validation_loss: 0.115811
Step: 80410, Train_acc:0.980377
Step: 80410, Val_acc:0.943097
==================>
Step: 80420, Train_acc:0.981746
Step: 80420, Val_acc:0.944803
==================>
Step: 80430, Train_acc:0.9815
Step: 80430, Val_acc:0.942505
==================>
Step: 80440, Train_acc:0.982822
Step: 80440, Val_acc:0.944521
==================>
Step: 80450, Train_acc:0.982012
Step: 80450, Val_acc:0.951718
==================>
Step: 80460, Train_acc:0.985228
Step: 80460, Val_acc:0.950089
==================>
Step: 80470, Train_acc:0.982926
Step: 80470, Val_acc:0.957927
==================>
Step: 80480, Train_acc:0.984584
Step: 80480, Val_acc:0.947515
==================>
Step: 80490, Train_acc:0.976957
Step: 80490, Val_acc:0.950105
==================>
Step: 80500, Train_acc:0.979392
Step: 80500, Val_acc:0.947704
==================>
****************** Epochs completed: 161******************
2017-11-12 04:21:56.870446 ---> Validation_loss: 0.157506
Step: 80510, Train_acc:0.976145
Step: 80510, Val_acc:0.945035
==================>
Step: 80520, Train_acc:0.983954
Step: 80520, Val_acc:0.95176
==================>
Step: 80530, Train_acc:0.983907
Step: 80530, Val_acc:0.956792
==================>
Step: 80540, Train_acc:0.981245
Step: 80540, Val_acc:0.939705
==================>
Step: 80550, Train_acc:0.98379
Step: 80550, Val_acc:0.9555
==================>
Step: 80560, Train_acc:0.988066
Step: 80560, Val_acc:0.957689
==================>
Step: 80570, Train_acc:0.973405
Step: 80570, Val_acc:0.934763
==================>
Step: 80580, Train_acc:0.981924
Step: 80580, Val_acc:0.941046
==================>
Step: 80590, Train_acc:0.974731
Step: 80590, Val_acc:0.955114
==================>
Step: 80600, Train_acc:0.981715
Step: 80600, Val_acc:0.935079
==================>
2017-11-12 04:24:33.539053 ---> Validation_loss: 0.199273
Step: 80610, Train_acc:0.984991
Step: 80610, Val_acc:0.946168
==================>
Step: 80620, Train_acc:0.979446
Step: 80620, Val_acc:0.966945
==================>
Step: 80630, Train_acc:0.98028
Step: 80630, Val_acc:0.950793
==================>
Step: 80640, Train_acc:0.98319
Step: 80640, Val_acc:0.962203
==================>
Step: 80650, Train_acc:0.985029
Step: 80650, Val_acc:0.970355
==================>
Step: 80660, Train_acc:0.983147
Step: 80660, Val_acc:0.944911
==================>
Step: 80670, Train_acc:0.980972
Step: 80670, Val_acc:0.942332
==================>
Step: 80680, Train_acc:0.978754
Step: 80680, Val_acc:0.937175
==================>
Step: 80690, Train_acc:0.985291
Step: 80690, Val_acc:0.946957
==================>
Step: 80700, Train_acc:0.982991
Step: 80700, Val_acc:0.92718
==================>
2017-11-12 04:27:10.339586 ---> Validation_loss: 0.120675
Step: 80710, Train_acc:0.980361
Step: 80710, Val_acc:0.948768
==================>
Step: 80720, Train_acc:0.982854
Step: 80720, Val_acc:0.93738
==================>
Step: 80730, Train_acc:0.981547
Step: 80730, Val_acc:0.934834
==================>
****************** Epochs completed: 24******************
Step: 80740, Train_acc:0.985623
Step: 80740, Val_acc:0.961078
==================>
Step: 80750, Train_acc:0.984134
Step: 80750, Val_acc:0.95114
==================>
Step: 80760, Train_acc:0.985062
Step: 80760, Val_acc:0.953842
==================>
Step: 80770, Train_acc:0.981074
Step: 80770, Val_acc:0.941251
==================>
Step: 80780, Train_acc:0.985284
Step: 80780, Val_acc:0.964791
==================>
Step: 80790, Train_acc:0.985499
Step: 80790, Val_acc:0.958013
==================>
Step: 80800, Train_acc:0.981589
Step: 80800, Val_acc:0.96455
==================>
2017-11-12 04:29:46.453366 ---> Validation_loss: 0.141747
Step: 80810, Train_acc:0.980969
Step: 80810, Val_acc:0.955121
==================>
Step: 80820, Train_acc:0.986099
Step: 80820, Val_acc:0.951997
==================>
Step: 80830, Train_acc:0.982362
Step: 80830, Val_acc:0.962151
==================>
Step: 80840, Train_acc:0.982356
Step: 80840, Val_acc:0.935714
==================>
Step: 80850, Train_acc:0.981935
Step: 80850, Val_acc:0.937917
==================>
Step: 80860, Train_acc:0.987123
Step: 80860, Val_acc:0.957258
==================>
Step: 80870, Train_acc:0.989056
Step: 80870, Val_acc:0.949445
==================>
Step: 80880, Train_acc:0.985861
Step: 80880, Val_acc:0.946029
==================>
Step: 80890, Train_acc:0.980343
Step: 80890, Val_acc:0.935442
==================>
Step: 80900, Train_acc:0.983229
Step: 80900, Val_acc:0.938561
==================>
2017-11-12 04:32:22.589090 ---> Validation_loss: 0.0930364
Step: 80910, Train_acc:0.981855
Step: 80910, Val_acc:0.904668
==================>
Step: 80920, Train_acc:0.977245
Step: 80920, Val_acc:0.958798
==================>
Step: 80930, Train_acc:0.984847
Step: 80930, Val_acc:0.920155
==================>
Step: 80940, Train_acc:0.978483
Step: 80940, Val_acc:0.958575
==================>
Step: 80950, Train_acc:0.981758
Step: 80950, Val_acc:0.938596
==================>
Step: 80960, Train_acc:0.980439
Step: 80960, Val_acc:0.947246
==================>
Step: 80970, Train_acc:0.983719
Step: 80970, Val_acc:0.932703
==================>
Step: 80980, Train_acc:0.982588
Step: 80980, Val_acc:0.953353
==================>
Step: 80990, Train_acc:0.977208
Step: 80990, Val_acc:0.945466
==================>
Step: 81000, Train_acc:0.98338
Step: 81000, Val_acc:0.965512
==================>
****************** Epochs completed: 162******************
2017-11-12 04:34:58.310762 ---> Validation_loss: 0.19137
Step: 81010, Train_acc:0.977457
Step: 81010, Val_acc:0.956643
==================>
Step: 81020, Train_acc:0.982821
Step: 81020, Val_acc:0.970673
==================>
Step: 81030, Train_acc:0.98496
Step: 81030, Val_acc:0.944379
==================>
Step: 81040, Train_acc:0.987581
Step: 81040, Val_acc:0.933604
==================>
Step: 81050, Train_acc:0.986901
Step: 81050, Val_acc:0.940524
==================>
Step: 81060, Train_acc:0.978817
Step: 81060, Val_acc:0.950614
==================>
Step: 81070, Train_acc:0.981969
Step: 81070, Val_acc:0.936615
==================>
Step: 81080, Train_acc:0.984799
Step: 81080, Val_acc:0.946248
==================>
Step: 81090, Train_acc:0.9801
Step: 81090, Val_acc:0.945666
==================>
Step: 81100, Train_acc:0.97866
Step: 81100, Val_acc:0.932396
==================>
2017-11-12 04:37:35.163008 ---> Validation_loss: 0.209789
Step: 81110, Train_acc:0.982213
Step: 81110, Val_acc:0.94296
==================>
Step: 81120, Train_acc:0.980796
Step: 81120, Val_acc:0.957656
==================>
Step: 81130, Train_acc:0.982698
Step: 81130, Val_acc:0.950906
==================>
Step: 81140, Train_acc:0.983304
Step: 81140, Val_acc:0.960652
==================>
Step: 81150, Train_acc:0.980951
Step: 81150, Val_acc:0.956291
==================>
Step: 81160, Train_acc:0.984961
Step: 81160, Val_acc:0.955123
==================>
Step: 81170, Train_acc:0.988315
Step: 81170, Val_acc:0.945057
==================>
Step: 81180, Train_acc:0.983549
Step: 81180, Val_acc:0.946139
==================>
Step: 81190, Train_acc:0.98676
Step: 81190, Val_acc:0.938955
==================>
Step: 81200, Train_acc:0.979906
Step: 81200, Val_acc:0.936418
==================>
2017-11-12 04:40:11.603272 ---> Validation_loss: 0.135909
Step: 81210, Train_acc:0.987723
Step: 81210, Val_acc:0.939664
==================>
Step: 81220, Train_acc:0.979695
Step: 81220, Val_acc:0.935508
==================>
Step: 81230, Train_acc:0.985409
Step: 81230, Val_acc:0.93644
==================>
Step: 81240, Train_acc:0.981149
Step: 81240, Val_acc:0.933127
==================>
Step: 81250, Train_acc:0.982445
Step: 81250, Val_acc:0.941333
==================>
Step: 81260, Train_acc:0.979279
Step: 81260, Val_acc:0.952035
==================>
Step: 81270, Train_acc:0.987707
Step: 81270, Val_acc:0.949793
==================>
Step: 81280, Train_acc:0.987169
Step: 81280, Val_acc:0.955858
==================>
Step: 81290, Train_acc:0.983282
Step: 81290, Val_acc:0.963544
==================>
Step: 81300, Train_acc:0.980642
Step: 81300, Val_acc:0.955007
==================>
2017-11-12 04:42:47.980363 ---> Validation_loss: 0.0965526
Step: 81310, Train_acc:0.982907
Step: 81310, Val_acc:0.920493
==================>
Step: 81320, Train_acc:0.984729
Step: 81320, Val_acc:0.950588
==================>
Step: 81330, Train_acc:0.988092
Step: 81330, Val_acc:0.951764
==================>
Step: 81340, Train_acc:0.98385
Step: 81340, Val_acc:0.95426
==================>
Step: 81350, Train_acc:0.980631
Step: 81350, Val_acc:0.945983
==================>
Step: 81360, Train_acc:0.986825
Step: 81360, Val_acc:0.938644
==================>
Step: 81370, Train_acc:0.980059
Step: 81370, Val_acc:0.931387
==================>
Step: 81380, Train_acc:0.981455
Step: 81380, Val_acc:0.95772
==================>
Step: 81390, Train_acc:0.980194
Step: 81390, Val_acc:0.944347
==================>
Step: 81400, Train_acc:0.983174
Step: 81400, Val_acc:0.952111
==================>
2017-11-12 04:45:24.342281 ---> Validation_loss: 0.115885
Step: 81410, Train_acc:0.988865
Step: 81410, Val_acc:0.943054
==================>
Step: 81420, Train_acc:0.984301
Step: 81420, Val_acc:0.931324
==================>
Step: 81430, Train_acc:0.985996
Step: 81430, Val_acc:0.945743
==================>
Step: 81440, Train_acc:0.986566
Step: 81440, Val_acc:0.945966
==================>
Step: 81450, Train_acc:0.981151
Step: 81450, Val_acc:0.949585
==================>
Step: 81460, Train_acc:0.975162
Step: 81460, Val_acc:0.941553
==================>
Step: 81470, Train_acc:0.986213
Step: 81470, Val_acc:0.952133
==================>
Step: 81480, Train_acc:0.978768
Step: 81480, Val_acc:0.953368
==================>
Step: 81490, Train_acc:0.982328
Step: 81490, Val_acc:0.938418
==================>
Step: 81500, Train_acc:0.987107
Step: 81500, Val_acc:0.952883
==================>
****************** Epochs completed: 163******************
2017-11-12 04:48:00.775932 ---> Validation_loss: 0.134632
Step: 81510, Train_acc:0.991724
Step: 81510, Val_acc:0.940278
==================>
Step: 81520, Train_acc:0.985114
Step: 81520, Val_acc:0.933715
==================>
Step: 81530, Train_acc:0.984282
Step: 81530, Val_acc:0.957709
==================>
Step: 81540, Train_acc:0.984952
Step: 81540, Val_acc:0.943035
==================>
Step: 81550, Train_acc:0.988218
Step: 81550, Val_acc:0.952552
==================>
Step: 81560, Train_acc:0.981548
Step: 81560, Val_acc:0.953071
==================>
Step: 81570, Train_acc:0.98574
Step: 81570, Val_acc:0.952853
==================>
Step: 81580, Train_acc:0.985081
Step: 81580, Val_acc:0.951801
==================>
Step: 81590, Train_acc:0.985288
Step: 81590, Val_acc:0.933142
==================>
Step: 81600, Train_acc:0.985576
Step: 81600, Val_acc:0.93941
==================>
2017-11-12 04:50:37.034536 ---> Validation_loss: 0.115774
Step: 81610, Train_acc:0.981697
Step: 81610, Val_acc:0.958794
==================>
Step: 81620, Train_acc:0.985673
Step: 81620, Val_acc:0.932948
==================>
Step: 81630, Train_acc:0.986063
Step: 81630, Val_acc:0.943925
==================>
Step: 81640, Train_acc:0.983069
Step: 81640, Val_acc:0.947811
==================>
Step: 81650, Train_acc:0.983519
Step: 81650, Val_acc:0.958402
==================>
Step: 81660, Train_acc:0.985956
Step: 81660, Val_acc:0.951938
==================>
Step: 81670, Train_acc:0.987267
Step: 81670, Val_acc:0.959972
==================>
Step: 81680, Train_acc:0.986863
Step: 81680, Val_acc:0.93498
==================>
Step: 81690, Train_acc:0.980664
Step: 81690, Val_acc:0.946389
==================>
Step: 81700, Train_acc:0.981102
Step: 81700, Val_acc:0.944146
==================>
2017-11-12 04:53:13.855047 ---> Validation_loss: 0.265192
Step: 81710, Train_acc:0.980543
Step: 81710, Val_acc:0.949482
==================>
Step: 81720, Train_acc:0.981858
Step: 81720, Val_acc:0.933274
==================>
Step: 81730, Train_acc:0.980551
Step: 81730, Val_acc:0.972408
==================>
Step: 81740, Train_acc:0.986544
Step: 81740, Val_acc:0.942643
==================>
Step: 81750, Train_acc:0.983385
Step: 81750, Val_acc:0.938022
==================>
Step: 81760, Train_acc:0.983549
Step: 81760, Val_acc:0.954026
==================>
Step: 81770, Train_acc:0.983901
Step: 81770, Val_acc:0.947611
==================>
Step: 81780, Train_acc:0.983938
Step: 81780, Val_acc:0.943478
==================>
Step: 81790, Train_acc:0.983717
Step: 81790, Val_acc:0.940928
==================>
Step: 81800, Train_acc:0.981233
Step: 81800, Val_acc:0.938818
==================>
2017-11-12 04:55:50.437298 ---> Validation_loss: 0.217673
Step: 81810, Train_acc:0.98376
Step: 81810, Val_acc:0.943472
==================>
Step: 81820, Train_acc:0.982594
Step: 81820, Val_acc:0.943517
==================>
Step: 81830, Train_acc:0.984065
Step: 81830, Val_acc:0.945809
==================>
Step: 81840, Train_acc:0.986693
Step: 81840, Val_acc:0.955478
==================>
Step: 81850, Train_acc:0.979242
Step: 81850, Val_acc:0.956753
==================>
Step: 81860, Train_acc:0.98083
Step: 81860, Val_acc:0.953712
==================>
Step: 81870, Train_acc:0.9864
Step: 81870, Val_acc:0.941725
==================>
Step: 81880, Train_acc:0.98191
Step: 81880, Val_acc:0.969292
==================>
Step: 81890, Train_acc:0.983474
Step: 81890, Val_acc:0.946047
==================>
Step: 81900, Train_acc:0.987064
Step: 81900, Val_acc:0.954597
==================>
2017-11-12 04:58:26.765609 ---> Validation_loss: 0.170132
Step: 81910, Train_acc:0.983801
Step: 81910, Val_acc:0.9377
==================>
Step: 81920, Train_acc:0.976428
Step: 81920, Val_acc:0.955363
==================>
Step: 81930, Train_acc:0.983894
Step: 81930, Val_acc:0.937039
==================>
Step: 81940, Train_acc:0.989075
Step: 81940, Val_acc:0.948475
==================>
Step: 81950, Train_acc:0.98108
Step: 81950, Val_acc:0.932792
==================>
Step: 81960, Train_acc:0.983936
Step: 81960, Val_acc:0.939441
==================>
Step: 81970, Train_acc:0.984069
Step: 81970, Val_acc:0.962462
==================>
Step: 81980, Train_acc:0.988125
Step: 81980, Val_acc:0.939722
==================>
Step: 81990, Train_acc:0.985223
Step: 81990, Val_acc:0.940253
==================>
Step: 82000, Train_acc:0.986692
Step: 82000, Val_acc:0.957023
==================>
****************** Epochs completed: 164******************
2017-11-12 05:01:03.190650 ---> Validation_loss: 0.137865
Step: 82010, Train_acc:0.983296
Step: 82010, Val_acc:0.91725
==================>
Step: 82020, Train_acc:0.98661
Step: 82020, Val_acc:0.952047
==================>
Step: 82030, Train_acc:0.986378
Step: 82030, Val_acc:0.954518
==================>
Step: 82040, Train_acc:0.978032
Step: 82040, Val_acc:0.953922
==================>
Step: 82050, Train_acc:0.984857
Step: 82050, Val_acc:0.940432
==================>
Step: 82060, Train_acc:0.983437
Step: 82060, Val_acc:0.947189
==================>
Step: 82070, Train_acc:0.984078
Step: 82070, Val_acc:0.961857
==================>
Step: 82080, Train_acc:0.97955
Step: 82080, Val_acc:0.961033
==================>
Step: 82090, Train_acc:0.979344
Step: 82090, Val_acc:0.951044
==================>
Step: 82100, Train_acc:0.980342
Step: 82100, Val_acc:0.940344
==================>
2017-11-12 05:03:39.562570 ---> Validation_loss: 0.152899
Step: 82110, Train_acc:0.984864
Step: 82110, Val_acc:0.954862
==================>
Step: 82120, Train_acc:0.982606
Step: 82120, Val_acc:0.952773
==================>
Step: 82130, Train_acc:0.977589
Step: 82130, Val_acc:0.933335
==================>
Step: 82140, Train_acc:0.982535
Step: 82140, Val_acc:0.945577
==================>
Step: 82150, Train_acc:0.985551
Step: 82150, Val_acc:0.946106
==================>
Step: 82160, Train_acc:0.982067
Step: 82160, Val_acc:0.941959
==================>
Step: 82170, Train_acc:0.981843
Step: 82170, Val_acc:0.943361
==================>
Step: 82180, Train_acc:0.982327
Step: 82180, Val_acc:0.907495
==================>
Step: 82190, Train_acc:0.979276
Step: 82190, Val_acc:0.945162
==================>
Step: 82200, Train_acc:0.988451
Step: 82200, Val_acc:0.938307
==================>
2017-11-12 05:06:16.262659 ---> Validation_loss: 0.14031
Step: 82210, Train_acc:0.978083
Step: 82210, Val_acc:0.933921
==================>
Step: 82220, Train_acc:0.980908
Step: 82220, Val_acc:0.940734
==================>
Step: 82230, Train_acc:0.984785
Step: 82230, Val_acc:0.964949
==================>
Step: 82240, Train_acc:0.984164
Step: 82240, Val_acc:0.967421
==================>
Step: 82250, Train_acc:0.984796
Step: 82250, Val_acc:0.960319
==================>
Step: 82260, Train_acc:0.985342
Step: 82260, Val_acc:0.95634
==================>
Step: 82270, Train_acc:0.987168
Step: 82270, Val_acc:0.944268
==================>
Step: 82280, Train_acc:0.987925
Step: 82280, Val_acc:0.928971
==================>
Step: 82290, Train_acc:0.983925
Step: 82290, Val_acc:0.950809
==================>
Step: 82300, Train_acc:0.977219
Step: 82300, Val_acc:0.952397
==================>
2017-11-12 05:08:52.571497 ---> Validation_loss: 0.139654
Step: 82310, Train_acc:0.983947
Step: 82310, Val_acc:0.96572
==================>
Step: 82320, Train_acc:0.981605
Step: 82320, Val_acc:0.939442
==================>
Step: 82330, Train_acc:0.98135
Step: 82330, Val_acc:0.948541
==================>
Step: 82340, Train_acc:0.982793
Step: 82340, Val_acc:0.95009
==================>
Step: 82350, Train_acc:0.988199
Step: 82350, Val_acc:0.948176
==================>
Step: 82360, Train_acc:0.984279
Step: 82360, Val_acc:0.955312
==================>
Step: 82370, Train_acc:0.985157
Step: 82370, Val_acc:0.962988
==================>
Step: 82380, Train_acc:0.986495
Step: 82380, Val_acc:0.95692
==================>
Step: 82390, Train_acc:0.987711
Step: 82390, Val_acc:0.939965
==================>
Step: 82400, Train_acc:0.981022
Step: 82400, Val_acc:0.931206
==================>
2017-11-12 05:11:28.982533 ---> Validation_loss: 0.161379
Step: 82410, Train_acc:0.982124
Step: 82410, Val_acc:0.947279
==================>
Step: 82420, Train_acc:0.98037
Step: 82420, Val_acc:0.939697
==================>
Step: 82430, Train_acc:0.982787
Step: 82430, Val_acc:0.927543
==================>
Step: 82440, Train_acc:0.983658
Step: 82440, Val_acc:0.93781
==================>
Step: 82450, Train_acc:0.978706
Step: 82450, Val_acc:0.943196
==================>
Step: 82460, Train_acc:0.985426
Step: 82460, Val_acc:0.947213
==================>
Step: 82470, Train_acc:0.979707
Step: 82470, Val_acc:0.94172
==================>
Step: 82480, Train_acc:0.981613
Step: 82480, Val_acc:0.930476
==================>
Step: 82490, Train_acc:0.980283
Step: 82490, Val_acc:0.958331
==================>
Step: 82500, Train_acc:0.986328
Step: 82500, Val_acc:0.923157
==================>
****************** Epochs completed: 165******************
2017-11-12 05:14:05.381430 ---> Validation_loss: 0.0960431
Step: 82510, Train_acc:0.985585
Step: 82510, Val_acc:0.961791
==================>
Step: 82520, Train_acc:0.985403
Step: 82520, Val_acc:0.945989
==================>
Step: 82530, Train_acc:0.980485
Step: 82530, Val_acc:0.943187
==================>
Step: 82540, Train_acc:0.983599
Step: 82540, Val_acc:0.947589
==================>
Step: 82550, Train_acc:0.985027
Step: 82550, Val_acc:0.926967
==================>
Step: 82560, Train_acc:0.985466
Step: 82560, Val_acc:0.958657
==================>
Step: 82570, Train_acc:0.981266
Step: 82570, Val_acc:0.952715
==================>
Step: 82580, Train_acc:0.987822
Step: 82580, Val_acc:0.954656
==================>
Step: 82590, Train_acc:0.984564
Step: 82590, Val_acc:0.953998
==================>
Step: 82600, Train_acc:0.989
Step: 82600, Val_acc:0.926366
==================>
2017-11-12 05:16:41.901763 ---> Validation_loss: 0.185608
Step: 82610, Train_acc:0.983452
Step: 82610, Val_acc:0.935742
==================>
Step: 82620, Train_acc:0.979954
Step: 82620, Val_acc:0.95714
==================>
Step: 82630, Train_acc:0.983589
Step: 82630, Val_acc:0.942831
==================>
Step: 82640, Train_acc:0.985288
Step: 82640, Val_acc:0.954108
==================>
Step: 82650, Train_acc:0.980475
Step: 82650, Val_acc:0.93792
==================>
Step: 82660, Train_acc:0.985865
Step: 82660, Val_acc:0.955028
==================>
Step: 82670, Train_acc:0.986638
Step: 82670, Val_acc:0.934353
==================>
Step: 82680, Train_acc:0.978855
Step: 82680, Val_acc:0.948995
==================>
Step: 82690, Train_acc:0.982346
Step: 82690, Val_acc:0.961713
==================>
Step: 82700, Train_acc:0.981113
Step: 82700, Val_acc:0.941371
==================>
2017-11-12 05:19:18.274907 ---> Validation_loss: 0.159336
Step: 82710, Train_acc:0.978464
Step: 82710, Val_acc:0.944359
==================>
Step: 82720, Train_acc:0.984912
Step: 82720, Val_acc:0.945497
==================>
Step: 82730, Train_acc:0.98488
Step: 82730, Val_acc:0.931523
==================>
Step: 82740, Train_acc:0.984819
Step: 82740, Val_acc:0.967235
==================>
Step: 82750, Train_acc:0.981533
Step: 82750, Val_acc:0.945928
==================>
Step: 82760, Train_acc:0.976316
Step: 82760, Val_acc:0.962426
==================>
Step: 82770, Train_acc:0.979087
Step: 82770, Val_acc:0.962994
==================>
Step: 82780, Train_acc:0.979735
Step: 82780, Val_acc:0.958623
==================>
Step: 82790, Train_acc:0.967888
Step: 82790, Val_acc:0.942648
==================>
Step: 82800, Train_acc:0.983187
Step: 82800, Val_acc:0.954534
==================>
2017-11-12 05:21:55.108331 ---> Validation_loss: 0.139781
Step: 82810, Train_acc:0.983411
Step: 82810, Val_acc:0.969825
==================>
Step: 82820, Train_acc:0.984843
Step: 82820, Val_acc:0.959169
==================>
Step: 82830, Train_acc:0.983909
Step: 82830, Val_acc:0.9439
==================>
Step: 82840, Train_acc:0.981176
Step: 82840, Val_acc:0.943723
==================>
Step: 82850, Train_acc:0.984915
Step: 82850, Val_acc:0.959797
==================>
Step: 82860, Train_acc:0.983444
Step: 82860, Val_acc:0.947271
==================>
Step: 82870, Train_acc:0.98696
Step: 82870, Val_acc:0.940621
==================>
Step: 82880, Train_acc:0.979945
Step: 82880, Val_acc:0.951382
==================>
Step: 82890, Train_acc:0.986168
Step: 82890, Val_acc:0.958683
==================>
Step: 82900, Train_acc:0.984612
Step: 82900, Val_acc:0.953306
==================>
2017-11-12 05:24:31.799746 ---> Validation_loss: 0.184305
Step: 82910, Train_acc:0.989087
Step: 82910, Val_acc:0.938192
==================>
Step: 82920, Train_acc:0.980962
Step: 82920, Val_acc:0.954159
==================>
Step: 82930, Train_acc:0.98552
Step: 82930, Val_acc:0.959553
==================>
Step: 82940, Train_acc:0.983223
Step: 82940, Val_acc:0.953263
==================>
Step: 82950, Train_acc:0.981593
Step: 82950, Val_acc:0.94343
==================>
Step: 82960, Train_acc:0.973955
Step: 82960, Val_acc:0.939973
==================>
Step: 82970, Train_acc:0.982333
Step: 82970, Val_acc:0.947745
==================>
Step: 82980, Train_acc:0.983926
Step: 82980, Val_acc:0.951047
==================>
Step: 82990, Train_acc:0.988563
Step: 82990, Val_acc:0.943899
==================>
Step: 83000, Train_acc:0.984994
Step: 83000, Val_acc:0.944385
==================>
****************** Epochs completed: 166******************
2017-11-12 05:27:08.326556 ---> Validation_loss: 0.0972131
Step: 83010, Train_acc:0.984784
Step: 83010, Val_acc:0.943341
==================>
Step: 83020, Train_acc:0.981667
Step: 83020, Val_acc:0.961904
==================>
Step: 83030, Train_acc:0.980864
Step: 83030, Val_acc:0.935057
==================>
Step: 83040, Train_acc:0.986516
Step: 83040, Val_acc:0.933473
==================>
Step: 83050, Train_acc:0.977373
Step: 83050, Val_acc:0.936495
==================>
Step: 83060, Train_acc:0.987448
Step: 83060, Val_acc:0.937261
==================>
Step: 83070, Train_acc:0.986492
Step: 83070, Val_acc:0.948149
==================>
Step: 83080, Train_acc:0.981448
Step: 83080, Val_acc:0.922153
==================>
Step: 83090, Train_acc:0.980431
Step: 83090, Val_acc:0.949945
==================>
Step: 83100, Train_acc:0.978516
Step: 83100, Val_acc:0.943793
==================>
2017-11-12 05:29:44.927638 ---> Validation_loss: 0.142303
Step: 83110, Train_acc:0.980007
Step: 83110, Val_acc:0.93376
==================>
Step: 83120, Train_acc:0.983545
Step: 83120, Val_acc:0.96062
==================>
Step: 83130, Train_acc:0.984025
Step: 83130, Val_acc:0.93319
==================>
Step: 83140, Train_acc:0.983474
Step: 83140, Val_acc:0.934901
==================>
Step: 83150, Train_acc:0.986339
Step: 83150, Val_acc:0.953148
==================>
Step: 83160, Train_acc:0.98391
Step: 83160, Val_acc:0.95437
==================>
Step: 83170, Train_acc:0.977935
Step: 83170, Val_acc:0.923657
==================>
Step: 83180, Train_acc:0.981825
Step: 83180, Val_acc:0.955585
==================>
Step: 83190, Train_acc:0.978733
Step: 83190, Val_acc:0.930095
==================>
Step: 83200, Train_acc:0.983419
Step: 83200, Val_acc:0.949414
==================>
2017-11-12 05:32:21.444103 ---> Validation_loss: 0.152676
Step: 83210, Train_acc:0.979232
Step: 83210, Val_acc:0.94771
==================>
Step: 83220, Train_acc:0.983793
Step: 83220, Val_acc:0.955957
==================>
Step: 83230, Train_acc:0.984534
Step: 83230, Val_acc:0.934789
==================>
Step: 83240, Train_acc:0.983687
Step: 83240, Val_acc:0.965049
==================>
Step: 83250, Train_acc:0.98855
Step: 83250, Val_acc:0.952194
==================>
Step: 83260, Train_acc:0.977726
Step: 83260, Val_acc:0.947356
==================>
Step: 83270, Train_acc:0.989308
Step: 83270, Val_acc:0.945963
==================>
Step: 83280, Train_acc:0.977939
Step: 83280, Val_acc:0.921505
==================>
Step: 83290, Train_acc:0.984286
Step: 83290, Val_acc:0.931781
==================>
Step: 83300, Train_acc:0.985961
Step: 83300, Val_acc:0.954331
==================>
2017-11-12 05:34:57.689961 ---> Validation_loss: 0.187019
Step: 83310, Train_acc:0.977545
Step: 83310, Val_acc:0.932142
==================>
Step: 83320, Train_acc:0.983422
Step: 83320, Val_acc:0.943236
==================>
Step: 83330, Train_acc:0.980204
Step: 83330, Val_acc:0.952706
==================>
Step: 83340, Train_acc:0.980345
Step: 83340, Val_acc:0.947218
==================>
Step: 83350, Train_acc:0.98562
Step: 83350, Val_acc:0.948434
==================>
Step: 83360, Train_acc:0.986416
Step: 83360, Val_acc:0.941198
==================>
Step: 83370, Train_acc:0.978827
Step: 83370, Val_acc:0.962312
==================>
Step: 83380, Train_acc:0.983528
Step: 83380, Val_acc:0.960593
==================>
Step: 83390, Train_acc:0.982584
Step: 83390, Val_acc:0.943386
==================>
Step: 83400, Train_acc:0.979786
Step: 83400, Val_acc:0.957129
==================>
2017-11-12 05:37:34.070619 ---> Validation_loss: 0.13101
Step: 83410, Train_acc:0.978779
Step: 83410, Val_acc:0.951575
==================>
Step: 83420, Train_acc:0.987317
Step: 83420, Val_acc:0.941338
==================>
Step: 83430, Train_acc:0.984055
Step: 83430, Val_acc:0.927769
==================>
Step: 83440, Train_acc:0.983837
Step: 83440, Val_acc:0.95129
==================>
Step: 83450, Train_acc:0.983497
Step: 83450, Val_acc:0.958807
==================>
Step: 83460, Train_acc:0.983237
Step: 83460, Val_acc:0.94574
==================>
Step: 83470, Train_acc:0.982159
Step: 83470, Val_acc:0.963897
==================>
Step: 83480, Train_acc:0.988149
Step: 83480, Val_acc:0.950265
==================>
Step: 83490, Train_acc:0.988065
Step: 83490, Val_acc:0.94902
==================>
Step: 83500, Train_acc:0.988986
Step: 83500, Val_acc:0.956449
==================>
****************** Epochs completed: 167******************
2017-11-12 05:40:10.950601 ---> Validation_loss: 0.150424
Step: 83510, Train_acc:0.979777
Step: 83510, Val_acc:0.935327
==================>
Step: 83520, Train_acc:0.983319
Step: 83520, Val_acc:0.94608
==================>
Step: 83530, Train_acc:0.984592
Step: 83530, Val_acc:0.951218
==================>
Step: 83540, Train_acc:0.985172
Step: 83540, Val_acc:0.967866
==================>
Step: 83550, Train_acc:0.981605
Step: 83550, Val_acc:0.967277
==================>
Step: 83560, Train_acc:0.976285
Step: 83560, Val_acc:0.953967
==================>
Step: 83570, Train_acc:0.983649
Step: 83570, Val_acc:0.932314
==================>
Step: 83580, Train_acc:0.981509
Step: 83580, Val_acc:0.945122
==================>
Step: 83590, Train_acc:0.982014
Step: 83590, Val_acc:0.94801
==================>
Step: 83600, Train_acc:0.984547
Step: 83600, Val_acc:0.963191
==================>
2017-11-12 05:42:47.152073 ---> Validation_loss: 0.137998
Step: 83610, Train_acc:0.988805
Step: 83610, Val_acc:0.943053
==================>
Step: 83620, Train_acc:0.981249
Step: 83620, Val_acc:0.945575
==================>
Step: 83630, Train_acc:0.981626
Step: 83630, Val_acc:0.940265
==================>
Step: 83640, Train_acc:0.980524
Step: 83640, Val_acc:0.946202
==================>
Step: 83650, Train_acc:0.983684
Step: 83650, Val_acc:0.919296
==================>
Step: 83660, Train_acc:0.976671
Step: 83660, Val_acc:0.953291
==================>
Step: 83670, Train_acc:0.97656
Step: 83670, Val_acc:0.937145
==================>
Step: 83680, Train_acc:0.986394
Step: 83680, Val_acc:0.961425
==================>
Step: 83690, Train_acc:0.984309
Step: 83690, Val_acc:0.943989
==================>
Step: 83700, Train_acc:0.985339
Step: 83700, Val_acc:0.954493
==================>
2017-11-12 05:45:23.499674 ---> Validation_loss: 0.148958
Step: 83710, Train_acc:0.978999
Step: 83710, Val_acc:0.945951
==================>
Step: 83720, Train_acc:0.981069
Step: 83720, Val_acc:0.955409
==================>
Step: 83730, Train_acc:0.979287
Step: 83730, Val_acc:0.935258
==================>
Step: 83740, Train_acc:0.988512
Step: 83740, Val_acc:0.936398
==================>
Step: 83750, Train_acc:0.986248
Step: 83750, Val_acc:0.931727
==================>
Step: 83760, Train_acc:0.984164
Step: 83760, Val_acc:0.934867
==================>
Step: 83770, Train_acc:0.978134
Step: 83770, Val_acc:0.96062
==================>
Step: 83780, Train_acc:0.984316
Step: 83780, Val_acc:0.949863
==================>
Step: 83790, Train_acc:0.981875
Step: 83790, Val_acc:0.935795
==================>
Step: 83800, Train_acc:0.980018
Step: 83800, Val_acc:0.946571
==================>
2017-11-12 05:47:59.938867 ---> Validation_loss: 0.182359
Step: 83810, Train_acc:0.984237
Step: 83810, Val_acc:0.948248
==================>
Step: 83820, Train_acc:0.979937
Step: 83820, Val_acc:0.945154
==================>
Step: 83830, Train_acc:0.980825
Step: 83830, Val_acc:0.943102
==================>
Step: 83840, Train_acc:0.984927
Step: 83840, Val_acc:0.942025
==================>
Step: 83850, Train_acc:0.987798
Step: 83850, Val_acc:0.952092
==================>
Step: 83860, Train_acc:0.985895
Step: 83860, Val_acc:0.927537
==================>
Step: 83870, Train_acc:0.982131
Step: 83870, Val_acc:0.928926
==================>
Step: 83880, Train_acc:0.983923
Step: 83880, Val_acc:0.962683
==================>
Step: 83890, Train_acc:0.982635
Step: 83890, Val_acc:0.94136
==================>
Step: 83900, Train_acc:0.982274
Step: 83900, Val_acc:0.946999
==================>
2017-11-12 05:50:36.287270 ---> Validation_loss: 0.0922733
Step: 83910, Train_acc:0.985105
Step: 83910, Val_acc:0.944059
==================>
Step: 83920, Train_acc:0.982263
Step: 83920, Val_acc:0.94873
==================>
Step: 83930, Train_acc:0.985068
Step: 83930, Val_acc:0.968794
==================>
Step: 83940, Train_acc:0.987291
Step: 83940, Val_acc:0.944669
==================>
Step: 83950, Train_acc:0.984429
Step: 83950, Val_acc:0.966062
==================>
Step: 83960, Train_acc:0.987412
Step: 83960, Val_acc:0.955906
==================>
Step: 83970, Train_acc:0.988196
Step: 83970, Val_acc:0.948524
==================>
Step: 83980, Train_acc:0.985826
Step: 83980, Val_acc:0.957904
==================>
Step: 83990, Train_acc:0.980319
Step: 83990, Val_acc:0.958522
==================>
Step: 84000, Train_acc:0.981968
Step: 84000, Val_acc:0.945852
==================>
****************** Epochs completed: 168******************
2017-11-12 05:53:12.875430 ---> Validation_loss: 0.11471
Step: 84010, Train_acc:0.984736
Step: 84010, Val_acc:0.944534
==================>
Step: 84020, Train_acc:0.975858
Step: 84020, Val_acc:0.956304
==================>
Step: 84030, Train_acc:0.976449
Step: 84030, Val_acc:0.947293
==================>
Step: 84040, Train_acc:0.983484
Step: 84040, Val_acc:0.942737
==================>
Step: 84050, Train_acc:0.980649
Step: 84050, Val_acc:0.939714
==================>
Step: 84060, Train_acc:0.980359
Step: 84060, Val_acc:0.927432
==================>
Step: 84070, Train_acc:0.982853
Step: 84070, Val_acc:0.941345
==================>
Step: 84080, Train_acc:0.977982
Step: 84080, Val_acc:0.938813
==================>
Step: 84090, Train_acc:0.985358
Step: 84090, Val_acc:0.944014
==================>
****************** Epochs completed: 25******************
Step: 84100, Train_acc:0.982997
Step: 84100, Val_acc:0.944385
==================>
2017-11-12 05:55:49.516531 ---> Validation_loss: 0.16063
Step: 84110, Train_acc:0.987523
Step: 84110, Val_acc:0.958536
==================>
Step: 84120, Train_acc:0.987311
Step: 84120, Val_acc:0.943367
==================>
Step: 84130, Train_acc:0.982116
Step: 84130, Val_acc:0.953214
==================>
Step: 84140, Train_acc:0.986855
Step: 84140, Val_acc:0.944633
==================>
Step: 84150, Train_acc:0.982158
Step: 84150, Val_acc:0.944429
==================>
Step: 84160, Train_acc:0.981272
Step: 84160, Val_acc:0.936617
==================>
Step: 84170, Train_acc:0.986309
Step: 84170, Val_acc:0.94733
==================>
Step: 84180, Train_acc:0.987345
Step: 84180, Val_acc:0.956685
==================>
Step: 84190, Train_acc:0.984658
Step: 84190, Val_acc:0.969688
==================>
Step: 84200, Train_acc:0.985571
Step: 84200, Val_acc:0.941003
==================>
2017-11-12 05:58:26.248538 ---> Validation_loss: 0.128804
Step: 84210, Train_acc:0.984163
Step: 84210, Val_acc:0.950044
==================>
Step: 84220, Train_acc:0.982828
Step: 84220, Val_acc:0.95444
==================>
Step: 84230, Train_acc:0.988355
Step: 84230, Val_acc:0.953037
==================>
Step: 84240, Train_acc:0.978971
Step: 84240, Val_acc:0.924331
==================>
Step: 84250, Train_acc:0.980941
Step: 84250, Val_acc:0.949723
==================>
Step: 84260, Train_acc:0.986652
Step: 84260, Val_acc:0.941361
==================>
Step: 84270, Train_acc:0.986851
Step: 84270, Val_acc:0.933745
==================>
Step: 84280, Train_acc:0.986919
Step: 84280, Val_acc:0.943733
==================>
Step: 84290, Train_acc:0.980367
Step: 84290, Val_acc:0.949269
==================>
Step: 84300, Train_acc:0.981677
Step: 84300, Val_acc:0.961432
==================>
2017-11-12 06:01:02.743731 ---> Validation_loss: 0.173471
Step: 84310, Train_acc:0.981427
Step: 84310, Val_acc:0.960685
==================>
Step: 84320, Train_acc:0.981907
Step: 84320, Val_acc:0.950952
==================>
Step: 84330, Train_acc:0.986451
Step: 84330, Val_acc:0.930226
==================>
Step: 84340, Train_acc:0.97785
Step: 84340, Val_acc:0.956801
==================>
Step: 84350, Train_acc:0.984221
Step: 84350, Val_acc:0.945431
==================>
Step: 84360, Train_acc:0.987131
Step: 84360, Val_acc:0.965272
==================>
Step: 84370, Train_acc:0.986468
Step: 84370, Val_acc:0.956288
==================>
Step: 84380, Train_acc:0.98402
Step: 84380, Val_acc:0.939
==================>
Step: 84390, Train_acc:0.986274
Step: 84390, Val_acc:0.952081
==================>
Step: 84400, Train_acc:0.980527
Step: 84400, Val_acc:0.965436
==================>
2017-11-12 06:03:39.419089 ---> Validation_loss: 0.119413
Step: 84410, Train_acc:0.984408
Step: 84410, Val_acc:0.945707
==================>
Step: 84420, Train_acc:0.984908
Step: 84420, Val_acc:0.95172
==================>
Step: 84430, Train_acc:0.986678
Step: 84430, Val_acc:0.943766
==================>
Step: 84440, Train_acc:0.983618
Step: 84440, Val_acc:0.932045
==================>
Step: 84450, Train_acc:0.979838
Step: 84450, Val_acc:0.959994
==================>
Step: 84460, Train_acc:0.980309
Step: 84460, Val_acc:0.933759
==================>
Step: 84470, Train_acc:0.985751
Step: 84470, Val_acc:0.959326
==================>
Step: 84480, Train_acc:0.982147
Step: 84480, Val_acc:0.949458
==================>
Step: 84490, Train_acc:0.986006
Step: 84490, Val_acc:0.941407
==================>
Step: 84500, Train_acc:0.985438
Step: 84500, Val_acc:0.934927
==================>
****************** Epochs completed: 169******************
2017-11-12 06:06:15.880982 ---> Validation_loss: 0.105192
Step: 84510, Train_acc:0.985653
Step: 84510, Val_acc:0.941375
==================>
Step: 84520, Train_acc:0.982377
Step: 84520, Val_acc:0.945316
==================>
Step: 84530, Train_acc:0.984415
Step: 84530, Val_acc:0.956418
==================>
Step: 84540, Train_acc:0.982491
Step: 84540, Val_acc:0.951959
==================>
Step: 84550, Train_acc:0.985301
Step: 84550, Val_acc:0.953084
==================>
Step: 84560, Train_acc:0.985917
Step: 84560, Val_acc:0.948036
==================>
Step: 84570, Train_acc:0.983949
Step: 84570, Val_acc:0.967291
==================>
Step: 84580, Train_acc:0.98504
Step: 84580, Val_acc:0.93942
==================>
Step: 84590, Train_acc:0.984672
Step: 84590, Val_acc:0.951851
==================>
Step: 84600, Train_acc:0.986824
Step: 84600, Val_acc:0.945981
==================>
2017-11-12 06:08:51.839837 ---> Validation_loss: 0.129861
Step: 84610, Train_acc:0.98303
Step: 84610, Val_acc:0.950703
==================>
Step: 84620, Train_acc:0.978588
Step: 84620, Val_acc:0.920779
==================>
Step: 84630, Train_acc:0.978563
Step: 84630, Val_acc:0.950779
==================>
Step: 84640, Train_acc:0.979545
Step: 84640, Val_acc:0.920511
==================>
Step: 84650, Train_acc:0.984705
Step: 84650, Val_acc:0.963281
==================>
Step: 84660, Train_acc:0.983605
Step: 84660, Val_acc:0.954255
==================>
Step: 84670, Train_acc:0.985847
Step: 84670, Val_acc:0.951564
==================>
Step: 84680, Train_acc:0.973098
Step: 84680, Val_acc:0.954786
==================>
Step: 84690, Train_acc:0.980483
Step: 84690, Val_acc:0.958483
==================>
Step: 84700, Train_acc:0.984971
Step: 84700, Val_acc:0.956288
==================>
2017-11-12 06:11:28.417912 ---> Validation_loss: 0.20124
Step: 84710, Train_acc:0.97899
Step: 84710, Val_acc:0.953646
==================>
Step: 84720, Train_acc:0.982468
Step: 84720, Val_acc:0.961035
==================>
Step: 84730, Train_acc:0.983041
Step: 84730, Val_acc:0.955787
==================>
Step: 84740, Train_acc:0.986223
Step: 84740, Val_acc:0.957814
==================>
Step: 84750, Train_acc:0.983134
Step: 84750, Val_acc:0.933718
==================>
Step: 84760, Train_acc:0.981461
Step: 84760, Val_acc:0.951018
==================>
Step: 84770, Train_acc:0.979265
Step: 84770, Val_acc:0.964901
==================>
Step: 84780, Train_acc:0.985806
Step: 84780, Val_acc:0.958452
==================>
Step: 84790, Train_acc:0.986846
Step: 84790, Val_acc:0.938601
==================>
Step: 84800, Train_acc:0.981932
Step: 84800, Val_acc:0.960221
==================>
2017-11-12 06:14:05.242470 ---> Validation_loss: 0.12885
Step: 84810, Train_acc:0.982789
Step: 84810, Val_acc:0.949492
==================>
Step: 84820, Train_acc:0.981519
Step: 84820, Val_acc:0.921036
==================>
Step: 84830, Train_acc:0.980992
Step: 84830, Val_acc:0.93983
==================>
Step: 84840, Train_acc:0.982722
Step: 84840, Val_acc:0.942417
==================>
Step: 84850, Train_acc:0.986212
Step: 84850, Val_acc:0.928721
==================>
Step: 84860, Train_acc:0.988962
Step: 84860, Val_acc:0.929785
==================>
Step: 84870, Train_acc:0.987321
Step: 84870, Val_acc:0.945562
==================>
Step: 84880, Train_acc:0.988189
Step: 84880, Val_acc:0.951379
==================>
Step: 84890, Train_acc:0.982037
Step: 84890, Val_acc:0.945066
==================>
Step: 84900, Train_acc:0.987617
Step: 84900, Val_acc:0.942916
==================>
2017-11-12 06:16:41.620699 ---> Validation_loss: 0.136886
Step: 84910, Train_acc:0.982134
Step: 84910, Val_acc:0.962677
==================>
Step: 84920, Train_acc:0.987438
Step: 84920, Val_acc:0.954846
==================>
Step: 84930, Train_acc:0.984319
Step: 84930, Val_acc:0.961796
==================>
Step: 84940, Train_acc:0.977269
Step: 84940, Val_acc:0.956135
==================>
Step: 84950, Train_acc:0.985264
Step: 84950, Val_acc:0.959117
==================>
Step: 84960, Train_acc:0.988779
Step: 84960, Val_acc:0.946573
==================>
Step: 84970, Train_acc:0.982499
Step: 84970, Val_acc:0.94078
==================>
Step: 84980, Train_acc:0.981636
Step: 84980, Val_acc:0.956405
==================>
Step: 84990, Train_acc:0.987161
Step: 84990, Val_acc:0.956296
==================>
Step: 85000, Train_acc:0.98139
Step: 85000, Val_acc:0.953796
==================>
****************** Epochs completed: 170******************
2017-11-12 06:19:18.479632 ---> Validation_loss: 0.117324
Step: 85010, Train_acc:0.984669
Step: 85010, Val_acc:0.929327
==================>
Step: 85020, Train_acc:0.981013
Step: 85020, Val_acc:0.92941
==================>
Step: 85030, Train_acc:0.984591
Step: 85030, Val_acc:0.941956
==================>
Step: 85040, Train_acc:0.982306
Step: 85040, Val_acc:0.951023
==================>
Step: 85050, Train_acc:0.978746
Step: 85050, Val_acc:0.939139
==================>
Step: 85060, Train_acc:0.985605
Step: 85060, Val_acc:0.952293
==================>
Step: 85070, Train_acc:0.980616
Step: 85070, Val_acc:0.935394
==================>
Step: 85080, Train_acc:0.988478
Step: 85080, Val_acc:0.93626
==================>
Step: 85090, Train_acc:0.984554
Step: 85090, Val_acc:0.941584
==================>
Step: 85100, Train_acc:0.977244
Step: 85100, Val_acc:0.961388
==================>
2017-11-12 06:21:54.238868 ---> Validation_loss: 0.202284
Step: 85110, Train_acc:0.984838
Step: 85110, Val_acc:0.97609
==================>
Step: 85120, Train_acc:0.976987
Step: 85120, Val_acc:0.956459
==================>
Step: 85130, Train_acc:0.986095
Step: 85130, Val_acc:0.950981
==================>
Step: 85140, Train_acc:0.97905
Step: 85140, Val_acc:0.947966
==================>
Step: 85150, Train_acc:0.98672
Step: 85150, Val_acc:0.942819
==================>
Step: 85160, Train_acc:0.980972
Step: 85160, Val_acc:0.955316
==================>
Step: 85170, Train_acc:0.984939
Step: 85170, Val_acc:0.95062
==================>
Step: 85180, Train_acc:0.987172
Step: 85180, Val_acc:0.962847
==================>
Step: 85190, Train_acc:0.988893
Step: 85190, Val_acc:0.936401
==================>
Step: 85200, Train_acc:0.98463
Step: 85200, Val_acc:0.944949
==================>
2017-11-12 06:24:31.238354 ---> Validation_loss: 0.129456
Step: 85210, Train_acc:0.985361
Step: 85210, Val_acc:0.930483
==================>
Step: 85220, Train_acc:0.982379
Step: 85220, Val_acc:0.960177
==================>
Step: 85230, Train_acc:0.981509
Step: 85230, Val_acc:0.947218
==================>
Step: 85240, Train_acc:0.98866
Step: 85240, Val_acc:0.949592
==================>
Step: 85250, Train_acc:0.986129
Step: 85250, Val_acc:0.919828
==================>
Step: 85260, Train_acc:0.983718
Step: 85260, Val_acc:0.959336
==================>
Step: 85270, Train_acc:0.984364
Step: 85270, Val_acc:0.947583
==================>
Step: 85280, Train_acc:0.986634
Step: 85280, Val_acc:0.965728
==================>
Step: 85290, Train_acc:0.985369
Step: 85290, Val_acc:0.960872
==================>
Step: 85300, Train_acc:0.980349
Step: 85300, Val_acc:0.960358
==================>
2017-11-12 06:27:07.619420 ---> Validation_loss: 0.0988597
Step: 85310, Train_acc:0.98287
Step: 85310, Val_acc:0.946416
==================>
Step: 85320, Train_acc:0.983669
Step: 85320, Val_acc:0.933317
==================>
Step: 85330, Train_acc:0.985068
Step: 85330, Val_acc:0.903073
==================>
Step: 85340, Train_acc:0.98606
Step: 85340, Val_acc:0.967556
==================>
Step: 85350, Train_acc:0.98759
Step: 85350, Val_acc:0.938965
==================>
Step: 85360, Train_acc:0.980951
Step: 85360, Val_acc:0.956012
==================>
Step: 85370, Train_acc:0.987795
Step: 85370, Val_acc:0.953402
==================>
Step: 85380, Train_acc:0.984481
Step: 85380, Val_acc:0.952199
==================>
Step: 85390, Train_acc:0.981086
Step: 85390, Val_acc:0.959719
==================>
Step: 85400, Train_acc:0.980931
Step: 85400, Val_acc:0.944672
==================>
2017-11-12 06:29:44.240493 ---> Validation_loss: 0.136247
Step: 85410, Train_acc:0.978423
Step: 85410, Val_acc:0.946719
==================>
Step: 85420, Train_acc:0.986715
Step: 85420, Val_acc:0.943217
==================>
Step: 85430, Train_acc:0.98723
Step: 85430, Val_acc:0.938781
==================>
Step: 85440, Train_acc:0.987415
Step: 85440, Val_acc:0.958828
==================>
Step: 85450, Train_acc:0.988322
Step: 85450, Val_acc:0.905468
==================>
Step: 85460, Train_acc:0.981956
Step: 85460, Val_acc:0.95248
==================>
Step: 85470, Train_acc:0.987898
Step: 85470, Val_acc:0.942225
==================>
Step: 85480, Train_acc:0.987665
Step: 85480, Val_acc:0.95746
==================>
Step: 85490, Train_acc:0.984817
Step: 85490, Val_acc:0.954797
==================>
Step: 85500, Train_acc:0.984376
Step: 85500, Val_acc:0.926505
==================>
****************** Epochs completed: 171******************
2017-11-12 06:32:20.559292 ---> Validation_loss: 0.170915
Step: 85510, Train_acc:0.98072
Step: 85510, Val_acc:0.964799
==================>
Step: 85520, Train_acc:0.98545
Step: 85520, Val_acc:0.963673
==================>
Step: 85530, Train_acc:0.981261
Step: 85530, Val_acc:0.947274
==================>
Step: 85540, Train_acc:0.984806
Step: 85540, Val_acc:0.937178
==================>
Step: 85550, Train_acc:0.980765
Step: 85550, Val_acc:0.935515
==================>
Step: 85560, Train_acc:0.978512
Step: 85560, Val_acc:0.940171
==================>
Step: 85570, Train_acc:0.986975
Step: 85570, Val_acc:0.940809
==================>
Step: 85580, Train_acc:0.986748
Step: 85580, Val_acc:0.949735
==================>
Step: 85590, Train_acc:0.980668
Step: 85590, Val_acc:0.937202
==================>
Step: 85600, Train_acc:0.98141
Step: 85600, Val_acc:0.942317
==================>
2017-11-12 06:34:57.208776 ---> Validation_loss: 0.188281
Step: 85610, Train_acc:0.982659
Step: 85610, Val_acc:0.951971
==================>
Step: 85620, Train_acc:0.984786
Step: 85620, Val_acc:0.951506
==================>
Step: 85630, Train_acc:0.984161
Step: 85630, Val_acc:0.958041
==================>
Step: 85640, Train_acc:0.983975
Step: 85640, Val_acc:0.938048
==================>
Step: 85650, Train_acc:0.985518
Step: 85650, Val_acc:0.939845
==================>
Step: 85660, Train_acc:0.980426
Step: 85660, Val_acc:0.964425
==================>
Step: 85670, Train_acc:0.981676
Step: 85670, Val_acc:0.969155
==================>
Step: 85680, Train_acc:0.981986
Step: 85680, Val_acc:0.938643
==================>
Step: 85690, Train_acc:0.987616
Step: 85690, Val_acc:0.938932
==================>
Step: 85700, Train_acc:0.980526
Step: 85700, Val_acc:0.960087
==================>
2017-11-12 06:37:33.848625 ---> Validation_loss: 0.138619
Step: 85710, Train_acc:0.981379
Step: 85710, Val_acc:0.943084
==================>
Step: 85720, Train_acc:0.982521
Step: 85720, Val_acc:0.964191
==================>
Step: 85730, Train_acc:0.980282
Step: 85730, Val_acc:0.959456
==================>
Step: 85740, Train_acc:0.983724
Step: 85740, Val_acc:0.957437
==================>
Step: 85750, Train_acc:0.984719
Step: 85750, Val_acc:0.961907
==================>
Step: 85760, Train_acc:0.988451
Step: 85760, Val_acc:0.952378
==================>
Step: 85770, Train_acc:0.977278
Step: 85770, Val_acc:0.95088
==================>
Step: 85780, Train_acc:0.984119
Step: 85780, Val_acc:0.952511
==================>
Step: 85790, Train_acc:0.981838
Step: 85790, Val_acc:0.946058
==================>
Step: 85800, Train_acc:0.986454
Step: 85800, Val_acc:0.938882
==================>
2017-11-12 06:40:10.481207 ---> Validation_loss: 0.123153
Step: 85810, Train_acc:0.986512
Step: 85810, Val_acc:0.949928
==================>
Step: 85820, Train_acc:0.984374
Step: 85820, Val_acc:0.933689
==================>
Step: 85830, Train_acc:0.981864
Step: 85830, Val_acc:0.961472
==================>
Step: 85840, Train_acc:0.980966
Step: 85840, Val_acc:0.955706
==================>
Step: 85850, Train_acc:0.984683
Step: 85850, Val_acc:0.949088
==================>
Step: 85860, Train_acc:0.984795
Step: 85860, Val_acc:0.931174
==================>
Step: 85870, Train_acc:0.983481
Step: 85870, Val_acc:0.958784
==================>
Step: 85880, Train_acc:0.982717
Step: 85880, Val_acc:0.939668
==================>
Step: 85890, Train_acc:0.986998
Step: 85890, Val_acc:0.950293
==================>
Step: 85900, Train_acc:0.981827
Step: 85900, Val_acc:0.94541
==================>
2017-11-12 06:42:46.942380 ---> Validation_loss: 0.140853
Step: 85910, Train_acc:0.992706
Step: 85910, Val_acc:0.95786
==================>
Step: 85920, Train_acc:0.977386
Step: 85920, Val_acc:0.944714
==================>
Step: 85930, Train_acc:0.983955
Step: 85930, Val_acc:0.954504
==================>
Step: 85940, Train_acc:0.982501
Step: 85940, Val_acc:0.954259
==================>
Step: 85950, Train_acc:0.983721
Step: 85950, Val_acc:0.937698
==================>
Step: 85960, Train_acc:0.983052
Step: 85960, Val_acc:0.952454
==================>
Step: 85970, Train_acc:0.987074
Step: 85970, Val_acc:0.957223
==================>
Step: 85980, Train_acc:0.990148
Step: 85980, Val_acc:0.956462
==================>
Step: 85990, Train_acc:0.986163
Step: 85990, Val_acc:0.959368
==================>
Step: 86000, Train_acc:0.988105
Step: 86000, Val_acc:0.945359
==================>
****************** Epochs completed: 172******************
2017-11-12 06:45:23.603820 ---> Validation_loss: 0.145652
Step: 86010, Train_acc:0.978534
Step: 86010, Val_acc:0.960804
==================>
Step: 86020, Train_acc:0.986478
Step: 86020, Val_acc:0.94326
==================>
Step: 86030, Train_acc:0.983204
Step: 86030, Val_acc:0.937983
==================>
Step: 86040, Train_acc:0.988212
Step: 86040, Val_acc:0.948875
==================>
Step: 86050, Train_acc:0.984802
Step: 86050, Val_acc:0.94597
==================>
Step: 86060, Train_acc:0.978543
Step: 86060, Val_acc:0.936813
==================>
Step: 86070, Train_acc:0.98699
Step: 86070, Val_acc:0.93859
==================>
Step: 86080, Train_acc:0.985691
Step: 86080, Val_acc:0.958779
==================>
Step: 86090, Train_acc:0.984092
Step: 86090, Val_acc:0.957863
==================>
Step: 86100, Train_acc:0.980972
Step: 86100, Val_acc:0.965512
==================>
2017-11-12 06:48:00.375594 ---> Validation_loss: 0.0831436
Step: 86110, Train_acc:0.984064
Step: 86110, Val_acc:0.959231
==================>
Step: 86120, Train_acc:0.983302
Step: 86120, Val_acc:0.948993
==================>
Step: 86130, Train_acc:0.98066
Step: 86130, Val_acc:0.953805
==================>
Step: 86140, Train_acc:0.981074
Step: 86140, Val_acc:0.930519
==================>
Step: 86150, Train_acc:0.975947
Step: 86150, Val_acc:0.952552
==================>
Step: 86160, Train_acc:0.986348
Step: 86160, Val_acc:0.953533
==================>
Step: 86170, Train_acc:0.981256
Step: 86170, Val_acc:0.937314
==================>
Step: 86180, Train_acc:0.983154
Step: 86180, Val_acc:0.946329
==================>
Step: 86190, Train_acc:0.978678
Step: 86190, Val_acc:0.948654
==================>
Step: 86200, Train_acc:0.983928
Step: 86200, Val_acc:0.927444
==================>
2017-11-12 06:50:36.934855 ---> Validation_loss: 0.104963
Step: 86210, Train_acc:0.984252
Step: 86210, Val_acc:0.940178
==================>
Step: 86220, Train_acc:0.986484
Step: 86220, Val_acc:0.935392
==================>
Step: 86230, Train_acc:0.984938
Step: 86230, Val_acc:0.947638
==================>
Step: 86240, Train_acc:0.97848
Step: 86240, Val_acc:0.909843
==================>
Step: 86250, Train_acc:0.983135
Step: 86250, Val_acc:0.944438
==================>
Step: 86260, Train_acc:0.985731
Step: 86260, Val_acc:0.955098
==================>
Step: 86270, Train_acc:0.980222
Step: 86270, Val_acc:0.94998
==================>
Step: 86280, Train_acc:0.988717
Step: 86280, Val_acc:0.961665
==================>
Step: 86290, Train_acc:0.989369
Step: 86290, Val_acc:0.95839
==================>
Step: 86300, Train_acc:0.986432
Step: 86300, Val_acc:0.95131
==================>
2017-11-12 06:53:13.696420 ---> Validation_loss: 0.189549
Step: 86310, Train_acc:0.984623
Step: 86310, Val_acc:0.946569
==================>
Step: 86320, Train_acc:0.980809
Step: 86320, Val_acc:0.955522
==================>
Step: 86330, Train_acc:0.979996
Step: 86330, Val_acc:0.939835
==================>
Step: 86340, Train_acc:0.986547
Step: 86340, Val_acc:0.959806
==================>
Step: 86350, Train_acc:0.984423
Step: 86350, Val_acc:0.945105
==================>
Step: 86360, Train_acc:0.976694
Step: 86360, Val_acc:0.953423
==================>
Step: 86370, Train_acc:0.987615
Step: 86370, Val_acc:0.941393
==================>
Step: 86380, Train_acc:0.980365
Step: 86380, Val_acc:0.950554
==================>
Step: 86390, Train_acc:0.979391
Step: 86390, Val_acc:0.940955
==================>
Step: 86400, Train_acc:0.979246
Step: 86400, Val_acc:0.945143
==================>
2017-11-12 06:55:50.237614 ---> Validation_loss: 0.209545
Step: 86410, Train_acc:0.98006
Step: 86410, Val_acc:0.943622
==================>
Step: 86420, Train_acc:0.984199
Step: 86420, Val_acc:0.957766
==================>
Step: 86430, Train_acc:0.985531
Step: 86430, Val_acc:0.938237
==================>
Step: 86440, Train_acc:0.976688
Step: 86440, Val_acc:0.960232
==================>
Step: 86450, Train_acc:0.985001
Step: 86450, Val_acc:0.959161
==================>
Step: 86460, Train_acc:0.983138
Step: 86460, Val_acc:0.934044
==================>
Step: 86470, Train_acc:0.98246
Step: 86470, Val_acc:0.954838
==================>
Step: 86480, Train_acc:0.988597
Step: 86480, Val_acc:0.948359
==================>
Step: 86490, Train_acc:0.976117
Step: 86490, Val_acc:0.942046
==================>
Step: 86500, Train_acc:0.983208
Step: 86500, Val_acc:0.963074
==================>
****************** Epochs completed: 173******************
2017-11-12 06:58:26.244370 ---> Validation_loss: 0.183445
Step: 86510, Train_acc:0.977953
Step: 86510, Val_acc:0.957994
==================>
Step: 86520, Train_acc:0.979246
Step: 86520, Val_acc:0.95753
==================>
Step: 86530, Train_acc:0.989696
Step: 86530, Val_acc:0.948308
==================>
Step: 86540, Train_acc:0.983562
Step: 86540, Val_acc:0.95151
==================>
Step: 86550, Train_acc:0.982444
Step: 86550, Val_acc:0.956014
==================>
Step: 86560, Train_acc:0.982395
Step: 86560, Val_acc:0.951274
==================>
Step: 86570, Train_acc:0.983258
Step: 86570, Val_acc:0.954669
==================>
Step: 86580, Train_acc:0.977515
Step: 86580, Val_acc:0.964263
==================>
Step: 86590, Train_acc:0.984558
Step: 86590, Val_acc:0.958224
==================>
Step: 86600, Train_acc:0.984971
Step: 86600, Val_acc:0.941855
==================>
2017-11-12 07:01:02.528576 ---> Validation_loss: 0.155761
Step: 86610, Train_acc:0.983284
Step: 86610, Val_acc:0.94313
==================>
Step: 86620, Train_acc:0.978115
Step: 86620, Val_acc:0.949952
==================>
Step: 86630, Train_acc:0.985795
Step: 86630, Val_acc:0.93463
==================>
Step: 86640, Train_acc:0.980629
Step: 86640, Val_acc:0.938674
==================>
Step: 86650, Train_acc:0.985573
Step: 86650, Val_acc:0.955608
==================>
Step: 86660, Train_acc:0.986298
Step: 86660, Val_acc:0.959845
==================>
Step: 86670, Train_acc:0.978209
Step: 86670, Val_acc:0.920878
==================>
Step: 86680, Train_acc:0.984868
Step: 86680, Val_acc:0.943903
==================>
Step: 86690, Train_acc:0.978706
Step: 86690, Val_acc:0.945844
==================>
Step: 86700, Train_acc:0.983674
Step: 86700, Val_acc:0.961577
==================>
2017-11-12 07:03:39.052927 ---> Validation_loss: 0.147051
Step: 86710, Train_acc:0.97873
Step: 86710, Val_acc:0.942399
==================>
Step: 86720, Train_acc:0.983146
Step: 86720, Val_acc:0.946342
==================>
Step: 86730, Train_acc:0.983369
Step: 86730, Val_acc:0.951178
==================>
Step: 86740, Train_acc:0.980425
Step: 86740, Val_acc:0.940153
==================>
Step: 86750, Train_acc:0.98525
Step: 86750, Val_acc:0.937994
==================>
Step: 86760, Train_acc:0.98304
Step: 86760, Val_acc:0.942958
==================>
Step: 86770, Train_acc:0.982625
Step: 86770, Val_acc:0.955336
==================>
Step: 86780, Train_acc:0.983804
Step: 86780, Val_acc:0.96038
==================>
Step: 86790, Train_acc:0.9811
Step: 86790, Val_acc:0.957361
==================>
Step: 86800, Train_acc:0.981111
Step: 86800, Val_acc:0.933997
==================>
2017-11-12 07:06:15.589758 ---> Validation_loss: 0.122696
Step: 86810, Train_acc:0.983658
Step: 86810, Val_acc:0.945171
==================>
Step: 86820, Train_acc:0.979939
Step: 86820, Val_acc:0.946691
==================>
Step: 86830, Train_acc:0.9796
Step: 86830, Val_acc:0.939491
==================>
Step: 86840, Train_acc:0.982479
Step: 86840, Val_acc:0.960593
==================>
Step: 86850, Train_acc:0.980016
Step: 86850, Val_acc:0.941458
==================>
Step: 86860, Train_acc:0.982715
Step: 86860, Val_acc:0.958281
==================>
Step: 86870, Train_acc:0.984249
Step: 86870, Val_acc:0.954011
==================>
Step: 86880, Train_acc:0.978682
Step: 86880, Val_acc:0.934496
==================>
Step: 86890, Train_acc:0.977124
Step: 86890, Val_acc:0.941791
==================>
Step: 86900, Train_acc:0.982462
Step: 86900, Val_acc:0.957687
==================>
2017-11-12 07:08:52.216694 ---> Validation_loss: 0.15622
Step: 86910, Train_acc:0.980756
Step: 86910, Val_acc:0.934755
==================>
Step: 86920, Train_acc:0.987996
Step: 86920, Val_acc:0.955828
==================>
Step: 86930, Train_acc:0.985395
Step: 86930, Val_acc:0.938674
==================>
Step: 86940, Train_acc:0.987233
Step: 86940, Val_acc:0.962649
==================>
Step: 86950, Train_acc:0.985704
Step: 86950, Val_acc:0.962389
==================>
Step: 86960, Train_acc:0.976708
Step: 86960, Val_acc:0.926338
==================>
Step: 86970, Train_acc:0.981392
Step: 86970, Val_acc:0.948174
==================>
Step: 86980, Train_acc:0.980045
Step: 86980, Val_acc:0.949423
==================>
Step: 86990, Train_acc:0.979763
Step: 86990, Val_acc:0.964956
==================>
Step: 87000, Train_acc:0.987228
Step: 87000, Val_acc:0.947994
==================>
****************** Epochs completed: 174******************
2017-11-12 07:11:28.766654 ---> Validation_loss: 0.154422
Step: 87010, Train_acc:0.980372
Step: 87010, Val_acc:0.955062
==================>
Step: 87020, Train_acc:0.978615
Step: 87020, Val_acc:0.95118
==================>
Step: 87030, Train_acc:0.984922
Step: 87030, Val_acc:0.930487
==================>
Step: 87040, Train_acc:0.980428
Step: 87040, Val_acc:0.955552
==================>
Step: 87050, Train_acc:0.98241
Step: 87050, Val_acc:0.962667
==================>
Step: 87060, Train_acc:0.987274
Step: 87060, Val_acc:0.910536
==================>
Step: 87070, Train_acc:0.986117
Step: 87070, Val_acc:0.954392
==================>
Step: 87080, Train_acc:0.985674
Step: 87080, Val_acc:0.945798
==================>
Step: 87090, Train_acc:0.980659
Step: 87090, Val_acc:0.923193
==================>
Step: 87100, Train_acc:0.982996
Step: 87100, Val_acc:0.955642
==================>
2017-11-12 07:14:05.225803 ---> Validation_loss: 0.122323
Step: 87110, Train_acc:0.985582
Step: 87110, Val_acc:0.957166
==================>
Step: 87120, Train_acc:0.985637
Step: 87120, Val_acc:0.951118
==================>
Step: 87130, Train_acc:0.983903
Step: 87130, Val_acc:0.947869
==================>
Step: 87140, Train_acc:0.979446
Step: 87140, Val_acc:0.939128
==================>
Step: 87150, Train_acc:0.986572
Step: 87150, Val_acc:0.935946
==================>
Step: 87160, Train_acc:0.984509
Step: 87160, Val_acc:0.962383
==================>
Step: 87170, Train_acc:0.980737
Step: 87170, Val_acc:0.960234
==================>
Step: 87180, Train_acc:0.98552
Step: 87180, Val_acc:0.941318
==================>
Step: 87190, Train_acc:0.980122
Step: 87190, Val_acc:0.931895
==================>
Step: 87200, Train_acc:0.984891
Step: 87200, Val_acc:0.927063
==================>
2017-11-12 07:16:41.697792 ---> Validation_loss: 0.122209
Step: 87210, Train_acc:0.982974
Step: 87210, Val_acc:0.947471
==================>
Step: 87220, Train_acc:0.983739
Step: 87220, Val_acc:0.946892
==================>
Step: 87230, Train_acc:0.986094
Step: 87230, Val_acc:0.912888
==================>
Step: 87240, Train_acc:0.980248
Step: 87240, Val_acc:0.935592
==================>
Step: 87250, Train_acc:0.982861
Step: 87250, Val_acc:0.95075
==================>
Step: 87260, Train_acc:0.983824
Step: 87260, Val_acc:0.952583
==================>
Step: 87270, Train_acc:0.980228
Step: 87270, Val_acc:0.952953
==================>
Step: 87280, Train_acc:0.981205
Step: 87280, Val_acc:0.966329
==================>
Step: 87290, Train_acc:0.981417
Step: 87290, Val_acc:0.94246
==================>
Step: 87300, Train_acc:0.979653
Step: 87300, Val_acc:0.954043
==================>
2017-11-12 07:19:18.097988 ---> Validation_loss: 0.188871
Step: 87310, Train_acc:0.980521
Step: 87310, Val_acc:0.917867
==================>
Step: 87320, Train_acc:0.98201
Step: 87320, Val_acc:0.949
==================>
Step: 87330, Train_acc:0.984094
Step: 87330, Val_acc:0.956481
==================>
Step: 87340, Train_acc:0.98421
Step: 87340, Val_acc:0.955605
==================>
Step: 87350, Train_acc:0.980605
Step: 87350, Val_acc:0.957775
==================>
Step: 87360, Train_acc:0.983997
Step: 87360, Val_acc:0.951927
==================>
Step: 87370, Train_acc:0.986377
Step: 87370, Val_acc:0.95541
==================>
Step: 87380, Train_acc:0.976595
Step: 87380, Val_acc:0.974807
==================>
Step: 87390, Train_acc:0.974138
Step: 87390, Val_acc:0.960197
==================>
Step: 87400, Train_acc:0.982013
Step: 87400, Val_acc:0.95421
==================>
2017-11-12 07:21:54.691812 ---> Validation_loss: 0.123053
Step: 87410, Train_acc:0.978604
Step: 87410, Val_acc:0.959978
==================>
Step: 87420, Train_acc:0.978059
Step: 87420, Val_acc:0.962256
==================>
Step: 87430, Train_acc:0.987758
Step: 87430, Val_acc:0.954662
==================>
Step: 87440, Train_acc:0.98318
Step: 87440, Val_acc:0.955134
==================>
Step: 87450, Train_acc:0.979688
Step: 87450, Val_acc:0.962738
==================>
Step: 87460, Train_acc:0.979878
Step: 87460, Val_acc:0.940946
==================>
****************** Epochs completed: 26******************
Step: 87470, Train_acc:0.979539
Step: 87470, Val_acc:0.948186
==================>
Step: 87480, Train_acc:0.984271
Step: 87480, Val_acc:0.95125
==================>
Step: 87490, Train_acc:0.98217
Step: 87490, Val_acc:0.930735
==================>
Step: 87500, Train_acc:0.983208
Step: 87500, Val_acc:0.953435
==================>
****************** Epochs completed: 175******************
2017-11-12 07:24:30.974759 ---> Validation_loss: 0.144538
Step: 87510, Train_acc:0.984895
Step: 87510, Val_acc:0.940603
==================>
Step: 87520, Train_acc:0.982605
Step: 87520, Val_acc:0.940072
==================>
Step: 87530, Train_acc:0.988035
Step: 87530, Val_acc:0.952085
==================>
Step: 87540, Train_acc:0.989464
Step: 87540, Val_acc:0.94478
==================>
Step: 87550, Train_acc:0.982465
Step: 87550, Val_acc:0.956353
==================>
Step: 87560, Train_acc:0.975322
Step: 87560, Val_acc:0.944525
==================>
Step: 87570, Train_acc:0.988365
Step: 87570, Val_acc:0.938621
==================>
Step: 87580, Train_acc:0.983615
Step: 87580, Val_acc:0.95303
==================>
Step: 87590, Train_acc:0.989888
Step: 87590, Val_acc:0.950538
==================>
Step: 87600, Train_acc:0.977869
Step: 87600, Val_acc:0.961285
==================>
2017-11-12 07:27:06.893804 ---> Validation_loss: 0.118465
Step: 87610, Train_acc:0.983704
Step: 87610, Val_acc:0.956974
==================>
Step: 87620, Train_acc:0.979302
Step: 87620, Val_acc:0.944624
==================>
Step: 87630, Train_acc:0.983536
Step: 87630, Val_acc:0.962875
==================>
Step: 87640, Train_acc:0.983649
Step: 87640, Val_acc:0.941779
==================>
Step: 87650, Train_acc:0.982452
Step: 87650, Val_acc:0.952681
==================>
Step: 87660, Train_acc:0.984459
Step: 87660, Val_acc:0.942899
==================>
Step: 87670, Train_acc:0.984205
Step: 87670, Val_acc:0.965305
==================>
Step: 87680, Train_acc:0.984395
Step: 87680, Val_acc:0.935892
==================>
Step: 87690, Train_acc:0.983593
Step: 87690, Val_acc:0.940892
==================>
Step: 87700, Train_acc:0.98337
Step: 87700, Val_acc:0.950452
==================>
2017-11-12 07:29:43.064822 ---> Validation_loss: 0.16384
Step: 87710, Train_acc:0.978387
Step: 87710, Val_acc:0.953439
==================>
Step: 87720, Train_acc:0.986663
Step: 87720, Val_acc:0.961068
==================>
Step: 87730, Train_acc:0.985717
Step: 87730, Val_acc:0.957812
==================>
Step: 87740, Train_acc:0.986844
Step: 87740, Val_acc:0.950167
==================>
Step: 87750, Train_acc:0.979585
Step: 87750, Val_acc:0.954598
==================>
Step: 87760, Train_acc:0.991453
Step: 87760, Val_acc:0.945308
==================>
Step: 87770, Train_acc:0.984247
Step: 87770, Val_acc:0.968165
==================>
Step: 87780, Train_acc:0.988861
Step: 87780, Val_acc:0.942666
==================>
Step: 87790, Train_acc:0.975337
Step: 87790, Val_acc:0.964713
==================>
Step: 87800, Train_acc:0.982241
Step: 87800, Val_acc:0.951542
==================>
2017-11-12 07:32:19.489454 ---> Validation_loss: 0.146133
Step: 87810, Train_acc:0.976119
Step: 87810, Val_acc:0.948937
==================>
Step: 87820, Train_acc:0.980474
Step: 87820, Val_acc:0.942455
==================>
Step: 87830, Train_acc:0.984937
Step: 87830, Val_acc:0.950447
==================>
Step: 87840, Train_acc:0.985535
Step: 87840, Val_acc:0.951692
==================>
Step: 87850, Train_acc:0.987521
Step: 87850, Val_acc:0.958275
==================>
Step: 87860, Train_acc:0.98079
Step: 87860, Val_acc:0.933326
==================>
Step: 87870, Train_acc:0.983449
Step: 87870, Val_acc:0.946322
==================>
Step: 87880, Train_acc:0.980967
Step: 87880, Val_acc:0.945013
==================>
Step: 87890, Train_acc:0.984827
Step: 87890, Val_acc:0.947281
==================>
Step: 87900, Train_acc:0.978866
Step: 87900, Val_acc:0.948524
==================>
2017-11-12 07:34:55.888527 ---> Validation_loss: 0.147374
Step: 87910, Train_acc:0.981272
Step: 87910, Val_acc:0.954051
==================>
Step: 87920, Train_acc:0.984956
Step: 87920, Val_acc:0.936644
==================>
Step: 87930, Train_acc:0.982634
Step: 87930, Val_acc:0.944828
==================>
Step: 87940, Train_acc:0.987673
Step: 87940, Val_acc:0.967217
==================>
Step: 87950, Train_acc:0.986812
Step: 87950, Val_acc:0.951814
==================>
Step: 87960, Train_acc:0.984252
Step: 87960, Val_acc:0.951816
==================>
Step: 87970, Train_acc:0.98161
Step: 87970, Val_acc:0.940426
==================>
Step: 87980, Train_acc:0.983887
Step: 87980, Val_acc:0.93819
==================>
Step: 87990, Train_acc:0.982283
Step: 87990, Val_acc:0.958108
==================>
Step: 88000, Train_acc:0.986106
Step: 88000, Val_acc:0.953442
==================>
****************** Epochs completed: 176******************
2017-11-12 07:37:31.983403 ---> Validation_loss: 0.150905
Step: 88010, Train_acc:0.983485
Step: 88010, Val_acc:0.955521
==================>
Step: 88020, Train_acc:0.984103
Step: 88020, Val_acc:0.9349
==================>
Step: 88030, Train_acc:0.978353
Step: 88030, Val_acc:0.942117
==================>
Step: 88040, Train_acc:0.9901
Step: 88040, Val_acc:0.927563
==================>
Step: 88050, Train_acc:0.983881
Step: 88050, Val_acc:0.933053
==================>
Step: 88060, Train_acc:0.97708
Step: 88060, Val_acc:0.94599
==================>
Step: 88070, Train_acc:0.98307
Step: 88070, Val_acc:0.950229
==================>
Step: 88080, Train_acc:0.988058
Step: 88080, Val_acc:0.936073
==================>
Step: 88090, Train_acc:0.985988
Step: 88090, Val_acc:0.930236
==================>
Step: 88100, Train_acc:0.980326
Step: 88100, Val_acc:0.92999
==================>
2017-11-12 07:40:08.182244 ---> Validation_loss: 0.127242
Step: 88110, Train_acc:0.984851
Step: 88110, Val_acc:0.952673
==================>
Step: 88120, Train_acc:0.980647
Step: 88120, Val_acc:0.931011
==================>
Step: 88130, Train_acc:0.98797
Step: 88130, Val_acc:0.954341
==================>
Step: 88140, Train_acc:0.98444
Step: 88140, Val_acc:0.966106
==================>
Step: 88150, Train_acc:0.98531
Step: 88150, Val_acc:0.926765
==================>
Step: 88160, Train_acc:0.981996
Step: 88160, Val_acc:0.931665
==================>
Step: 88170, Train_acc:0.976514
Step: 88170, Val_acc:0.920735
==================>
Step: 88180, Train_acc:0.985684
Step: 88180, Val_acc:0.961953
==================>
Step: 88190, Train_acc:0.974366
Step: 88190, Val_acc:0.954242
==================>
Step: 88200, Train_acc:0.981792
Step: 88200, Val_acc:0.958547
==================>
2017-11-12 07:42:44.273580 ---> Validation_loss: 0.104855
Step: 88210, Train_acc:0.979078
Step: 88210, Val_acc:0.927898
==================>
Step: 88220, Train_acc:0.986985
Step: 88220, Val_acc:0.942629
==================>
Step: 88230, Train_acc:0.982871
Step: 88230, Val_acc:0.93832
==================>
Step: 88240, Train_acc:0.982836
Step: 88240, Val_acc:0.933473
==================>
Step: 88250, Train_acc:0.983804
Step: 88250, Val_acc:0.928463
==================>
Step: 88260, Train_acc:0.987434
Step: 88260, Val_acc:0.944283
==================>
Step: 88270, Train_acc:0.987379
Step: 88270, Val_acc:0.942394
==================>
Step: 88280, Train_acc:0.985533
Step: 88280, Val_acc:0.960441
==================>
Step: 88290, Train_acc:0.98803
Step: 88290, Val_acc:0.953079
==================>
Step: 88300, Train_acc:0.980981
Step: 88300, Val_acc:0.928057
==================>
2017-11-12 07:45:20.782993 ---> Validation_loss: 0.138948
Step: 88310, Train_acc:0.984519
Step: 88310, Val_acc:0.933929
==================>
Step: 88320, Train_acc:0.983433
Step: 88320, Val_acc:0.963455
==================>
Step: 88330, Train_acc:0.980917
Step: 88330, Val_acc:0.947325
==================>
Step: 88340, Train_acc:0.984999
Step: 88340, Val_acc:0.944905
==================>
Step: 88350, Train_acc:0.976786
Step: 88350, Val_acc:0.939684
==================>
Step: 88360, Train_acc:0.985992
Step: 88360, Val_acc:0.949231
==================>
Step: 88370, Train_acc:0.981204
Step: 88370, Val_acc:0.954623
==================>
Step: 88380, Train_acc:0.980635
Step: 88380, Val_acc:0.959358
==================>
Step: 88390, Train_acc:0.982318
Step: 88390, Val_acc:0.960149
==================>
Step: 88400, Train_acc:0.98896
Step: 88400, Val_acc:0.943518
==================>
2017-11-12 07:47:57.379610 ---> Validation_loss: 0.150992
Step: 88410, Train_acc:0.986364
Step: 88410, Val_acc:0.963958
==================>
Step: 88420, Train_acc:0.980051
Step: 88420, Val_acc:0.950908
==================>
Step: 88430, Train_acc:0.981394
Step: 88430, Val_acc:0.930514
==================>
Step: 88440, Train_acc:0.985504
Step: 88440, Val_acc:0.953381
==================>
Step: 88450, Train_acc:0.984956
Step: 88450, Val_acc:0.943658
==================>
Step: 88460, Train_acc:0.983744
Step: 88460, Val_acc:0.960546
==================>
Step: 88470, Train_acc:0.979255
Step: 88470, Val_acc:0.940782
==================>
Step: 88480, Train_acc:0.987266
Step: 88480, Val_acc:0.955492
==================>
Step: 88490, Train_acc:0.981014
Step: 88490, Val_acc:0.953573
==================>
Step: 88500, Train_acc:0.977789
Step: 88500, Val_acc:0.939877
==================>
****************** Epochs completed: 177******************
2017-11-12 07:50:33.693327 ---> Validation_loss: 0.0997831
Step: 88510, Train_acc:0.987116
Step: 88510, Val_acc:0.966671
==================>
Step: 88520, Train_acc:0.983221
Step: 88520, Val_acc:0.944042
==================>
Step: 88530, Train_acc:0.986814
Step: 88530, Val_acc:0.959921
==================>
Step: 88540, Train_acc:0.992553
Step: 88540, Val_acc:0.948228
==================>
Step: 88550, Train_acc:0.98746
Step: 88550, Val_acc:0.9558
==================>
Step: 88560, Train_acc:0.987351
Step: 88560, Val_acc:0.950443
==================>
Step: 88570, Train_acc:0.988052
Step: 88570, Val_acc:0.942439
==================>
Step: 88580, Train_acc:0.980634
Step: 88580, Val_acc:0.962969
==================>
Step: 88590, Train_acc:0.98314
Step: 88590, Val_acc:0.947657
==================>
Step: 88600, Train_acc:0.983473
Step: 88600, Val_acc:0.922834
==================>
2017-11-12 07:53:10.077468 ---> Validation_loss: 0.12717
Step: 88610, Train_acc:0.983744
Step: 88610, Val_acc:0.951571
==================>
Step: 88620, Train_acc:0.979213
Step: 88620, Val_acc:0.948881
==================>
Step: 88630, Train_acc:0.977657
Step: 88630, Val_acc:0.964504
==================>
Step: 88640, Train_acc:0.980969
Step: 88640, Val_acc:0.948553
==================>
Step: 88650, Train_acc:0.984565
Step: 88650, Val_acc:0.942074
==================>
Step: 88660, Train_acc:0.98691
Step: 88660, Val_acc:0.963807
==================>
Step: 88670, Train_acc:0.985425
Step: 88670, Val_acc:0.931133
==================>
Step: 88680, Train_acc:0.983462
Step: 88680, Val_acc:0.94793
==================>
Step: 88690, Train_acc:0.983209
Step: 88690, Val_acc:0.94483
==================>
Step: 88700, Train_acc:0.988218
Step: 88700, Val_acc:0.960892
==================>
2017-11-12 07:55:46.438528 ---> Validation_loss: 0.207085
Step: 88710, Train_acc:0.98002
Step: 88710, Val_acc:0.954628
==================>
Step: 88720, Train_acc:0.983738
Step: 88720, Val_acc:0.960265
==================>
Step: 88730, Train_acc:0.983874
Step: 88730, Val_acc:0.93082
==================>
Step: 88740, Train_acc:0.986895
Step: 88740, Val_acc:0.966951
==================>
Step: 88750, Train_acc:0.98077
Step: 88750, Val_acc:0.949178
==================>
Step: 88760, Train_acc:0.985737
Step: 88760, Val_acc:0.941709
==================>
Step: 88770, Train_acc:0.98524
Step: 88770, Val_acc:0.958296
==================>
Step: 88780, Train_acc:0.981855
Step: 88780, Val_acc:0.952463
==================>
Step: 88790, Train_acc:0.980038
Step: 88790, Val_acc:0.944735
==================>
Step: 88800, Train_acc:0.985908
Step: 88800, Val_acc:0.920552
==================>
2017-11-12 07:58:23.025253 ---> Validation_loss: 0.136515
Step: 88810, Train_acc:0.976274
Step: 88810, Val_acc:0.966713
==================>
Step: 88820, Train_acc:0.987361
Step: 88820, Val_acc:0.960736
==================>
Step: 88830, Train_acc:0.983958
Step: 88830, Val_acc:0.927338
==================>
Step: 88840, Train_acc:0.980876
Step: 88840, Val_acc:0.961011
==================>
Step: 88850, Train_acc:0.984003
Step: 88850, Val_acc:0.941738
==================>
Step: 88860, Train_acc:0.98499
Step: 88860, Val_acc:0.94278
==================>
Step: 88870, Train_acc:0.987501
Step: 88870, Val_acc:0.922541
==================>
Step: 88880, Train_acc:0.986895
Step: 88880, Val_acc:0.944834
==================>
Step: 88890, Train_acc:0.977457
Step: 88890, Val_acc:0.943209
==================>
Step: 88900, Train_acc:0.986465
Step: 88900, Val_acc:0.945632
==================>
2017-11-12 08:00:59.357240 ---> Validation_loss: 0.147275
Step: 88910, Train_acc:0.986311
Step: 88910, Val_acc:0.937815
==================>
Step: 88920, Train_acc:0.983261
Step: 88920, Val_acc:0.952025
==================>
Step: 88930, Train_acc:0.984672
Step: 88930, Val_acc:0.93399
==================>
Step: 88940, Train_acc:0.98292
Step: 88940, Val_acc:0.949458
==================>
Step: 88950, Train_acc:0.984585
Step: 88950, Val_acc:0.953661
==================>
Step: 88960, Train_acc:0.982159
Step: 88960, Val_acc:0.946067
==================>
Step: 88970, Train_acc:0.983507
Step: 88970, Val_acc:0.946139
==================>
Step: 88980, Train_acc:0.978976
Step: 88980, Val_acc:0.959047
==================>
Step: 88990, Train_acc:0.977252
Step: 88990, Val_acc:0.953201
==================>
Step: 89000, Train_acc:0.989154
Step: 89000, Val_acc:0.961923
==================>
****************** Epochs completed: 178******************
2017-11-12 08:03:35.991704 ---> Validation_loss: 0.172409
Step: 89010, Train_acc:0.98788
Step: 89010, Val_acc:0.96183
==================>
Step: 89020, Train_acc:0.986166
Step: 89020, Val_acc:0.961317
==================>
Step: 89030, Train_acc:0.979062
Step: 89030, Val_acc:0.937989
==================>
Step: 89040, Train_acc:0.984595
Step: 89040, Val_acc:0.942543
==================>
Step: 89050, Train_acc:0.983784
Step: 89050, Val_acc:0.950496
==================>
Step: 89060, Train_acc:0.985416
Step: 89060, Val_acc:0.964772
==================>
Step: 89070, Train_acc:0.984878
Step: 89070, Val_acc:0.961377
==================>
Step: 89080, Train_acc:0.984463
Step: 89080, Val_acc:0.957466
==================>
Step: 89090, Train_acc:0.983479
Step: 89090, Val_acc:0.948444
==================>
Step: 89100, Train_acc:0.988779
Step: 89100, Val_acc:0.9547
==================>
2017-11-12 08:06:12.421595 ---> Validation_loss: 0.15153
Step: 89110, Train_acc:0.977572
Step: 89110, Val_acc:0.933422
==================>
Step: 89120, Train_acc:0.985156
Step: 89120, Val_acc:0.955143
==================>
Step: 89130, Train_acc:0.97807
Step: 89130, Val_acc:0.945778
==================>
Step: 89140, Train_acc:0.984548
Step: 89140, Val_acc:0.954475
==================>
Step: 89150, Train_acc:0.987639
Step: 89150, Val_acc:0.95145
==================>
Step: 89160, Train_acc:0.979376
Step: 89160, Val_acc:0.946813
==================>
Step: 89170, Train_acc:0.987211
Step: 89170, Val_acc:0.957417
==================>
Step: 89180, Train_acc:0.983459
Step: 89180, Val_acc:0.946003
==================>
Step: 89190, Train_acc:0.976737
Step: 89190, Val_acc:0.953116
==================>
Step: 89200, Train_acc:0.9776
Step: 89200, Val_acc:0.933307
==================>
2017-11-12 08:08:49.208482 ---> Validation_loss: 0.0947583
Step: 89210, Train_acc:0.986921
Step: 89210, Val_acc:0.946011
==================>
Step: 89220, Train_acc:0.982152
Step: 89220, Val_acc:0.952721
==================>
Step: 89230, Train_acc:0.983547
Step: 89230, Val_acc:0.961779
==================>
Step: 89240, Train_acc:0.979076
Step: 89240, Val_acc:0.961725
==================>
Step: 89250, Train_acc:0.988662
Step: 89250, Val_acc:0.954489
==================>
Step: 89260, Train_acc:0.981968
Step: 89260, Val_acc:0.958185
==================>
Step: 89270, Train_acc:0.986561
Step: 89270, Val_acc:0.962504
==================>
Step: 89280, Train_acc:0.98486
Step: 89280, Val_acc:0.955182
==================>
Step: 89290, Train_acc:0.985946
Step: 89290, Val_acc:0.957773
==================>
Step: 89300, Train_acc:0.984226
Step: 89300, Val_acc:0.949626
==================>
2017-11-12 08:11:25.730236 ---> Validation_loss: 0.0981005
Step: 89310, Train_acc:0.986873
Step: 89310, Val_acc:0.965983
==================>
Step: 89320, Train_acc:0.980028
Step: 89320, Val_acc:0.962876
==================>
Step: 89330, Train_acc:0.989044
Step: 89330, Val_acc:0.932701
==================>
Step: 89340, Train_acc:0.978828
Step: 89340, Val_acc:0.958774
==================>
Step: 89350, Train_acc:0.987206
Step: 89350, Val_acc:0.93938
==================>
Step: 89360, Train_acc:0.987352
Step: 89360, Val_acc:0.941897
==================>
Step: 89370, Train_acc:0.99097
Step: 89370, Val_acc:0.957267
==================>
Step: 89380, Train_acc:0.977704
Step: 89380, Val_acc:0.931161
==================>
Step: 89390, Train_acc:0.98682
Step: 89390, Val_acc:0.948479
==================>
Step: 89400, Train_acc:0.977908
Step: 89400, Val_acc:0.951748
==================>
2017-11-12 08:14:02.276374 ---> Validation_loss: 0.159827
Step: 89410, Train_acc:0.989052
Step: 89410, Val_acc:0.92588
==================>
Step: 89420, Train_acc:0.978556
Step: 89420, Val_acc:0.956392
==================>
Step: 89430, Train_acc:0.985723
Step: 89430, Val_acc:0.954235
==================>
Step: 89440, Train_acc:0.981152
Step: 89440, Val_acc:0.92877
==================>
Step: 89450, Train_acc:0.986049
Step: 89450, Val_acc:0.937601
==================>
Step: 89460, Train_acc:0.986763
Step: 89460, Val_acc:0.953685
==================>
Step: 89470, Train_acc:0.980853
Step: 89470, Val_acc:0.952105
==================>
Step: 89480, Train_acc:0.985372
Step: 89480, Val_acc:0.95354
==================>
Step: 89490, Train_acc:0.981744
Step: 89490, Val_acc:0.940587
==================>
Step: 89500, Train_acc:0.984908
Step: 89500, Val_acc:0.947678
==================>
****************** Epochs completed: 179******************
2017-11-12 08:16:38.722129 ---> Validation_loss: 0.12562
Step: 89510, Train_acc:0.988496
Step: 89510, Val_acc:0.951332
==================>
Step: 89520, Train_acc:0.980959
Step: 89520, Val_acc:0.968065
==================>
Step: 89530, Train_acc:0.983705
Step: 89530, Val_acc:0.954019
==================>
Step: 89540, Train_acc:0.982198
Step: 89540, Val_acc:0.945946
==================>
Step: 89550, Train_acc:0.979684
Step: 89550, Val_acc:0.91759
==================>
Step: 89560, Train_acc:0.98813
Step: 89560, Val_acc:0.947412
==================>
Step: 89570, Train_acc:0.98481
Step: 89570, Val_acc:0.964589
==================>
Step: 89580, Train_acc:0.983071
Step: 89580, Val_acc:0.969281
==================>
Step: 89590, Train_acc:0.982535
Step: 89590, Val_acc:0.921921
==================>
Step: 89600, Train_acc:0.980526
Step: 89600, Val_acc:0.948988
==================>
2017-11-12 08:19:15.492749 ---> Validation_loss: 0.241574
Step: 89610, Train_acc:0.984305
Step: 89610, Val_acc:0.95345
==================>
Step: 89620, Train_acc:0.986897
Step: 89620, Val_acc:0.961182
==================>
Step: 89630, Train_acc:0.985543
Step: 89630, Val_acc:0.927909
==================>
Step: 89640, Train_acc:0.981445
Step: 89640, Val_acc:0.9604
==================>
Step: 89650, Train_acc:0.979199
Step: 89650, Val_acc:0.926912
==================>
Step: 89660, Train_acc:0.987925
Step: 89660, Val_acc:0.937587
==================>
Step: 89670, Train_acc:0.984274
Step: 89670, Val_acc:0.931355
==================>
Step: 89680, Train_acc:0.986011
Step: 89680, Val_acc:0.945233
==================>
Step: 89690, Train_acc:0.985951
Step: 89690, Val_acc:0.955356
==================>
Step: 89700, Train_acc:0.986665
Step: 89700, Val_acc:0.938626
==================>
2017-11-12 08:21:51.997953 ---> Validation_loss: 0.118512
Step: 89710, Train_acc:0.982465
Step: 89710, Val_acc:0.953245
==================>
Step: 89720, Train_acc:0.985006
Step: 89720, Val_acc:0.935791
==================>
Step: 89730, Train_acc:0.985687
Step: 89730, Val_acc:0.942605
==================>
Step: 89740, Train_acc:0.985886
Step: 89740, Val_acc:0.927112
==================>
Step: 89750, Train_acc:0.980828
Step: 89750, Val_acc:0.931865
==================>
Step: 89760, Train_acc:0.985668
Step: 89760, Val_acc:0.955704
==================>
Step: 89770, Train_acc:0.982526
Step: 89770, Val_acc:0.940884
==================>
Step: 89780, Train_acc:0.984158
Step: 89780, Val_acc:0.966757
==================>
Step: 89790, Train_acc:0.983146
Step: 89790, Val_acc:0.95519
==================>
Step: 89800, Train_acc:0.983248
Step: 89800, Val_acc:0.95249
==================>
2017-11-12 08:24:28.808250 ---> Validation_loss: 0.13731
Step: 89810, Train_acc:0.988361
Step: 89810, Val_acc:0.949674
==================>
Step: 89820, Train_acc:0.9853
Step: 89820, Val_acc:0.95411
==================>
Step: 89830, Train_acc:0.982844
Step: 89830, Val_acc:0.945278
==================>
Step: 89840, Train_acc:0.983904
Step: 89840, Val_acc:0.964117
==================>
Step: 89850, Train_acc:0.985441
Step: 89850, Val_acc:0.953827
==================>
Step: 89860, Train_acc:0.98134
Step: 89860, Val_acc:0.930988
==================>
Step: 89870, Train_acc:0.984098
Step: 89870, Val_acc:0.956465
==================>
Step: 89880, Train_acc:0.986157
Step: 89880, Val_acc:0.949839
==================>
Step: 89890, Train_acc:0.989048
Step: 89890, Val_acc:0.953015
==================>
Step: 89900, Train_acc:0.982852
Step: 89900, Val_acc:0.959996
==================>
2017-11-12 08:27:05.039636 ---> Validation_loss: 0.106314
Step: 89910, Train_acc:0.981571
Step: 89910, Val_acc:0.953851
==================>
Step: 89920, Train_acc:0.98223
Step: 89920, Val_acc:0.940151
==================>
Step: 89930, Train_acc:0.98584
Step: 89930, Val_acc:0.926021
==================>
Step: 89940, Train_acc:0.98406
Step: 89940, Val_acc:0.944252
==================>
Step: 89950, Train_acc:0.987772
Step: 89950, Val_acc:0.963088
==================>
Step: 89960, Train_acc:0.986012
Step: 89960, Val_acc:0.951156
==================>
Step: 89970, Train_acc:0.981137
Step: 89970, Val_acc:0.937111
==================>
Step: 89980, Train_acc:0.981644
Step: 89980, Val_acc:0.93155
==================>
Step: 89990, Train_acc:0.983094
Step: 89990, Val_acc:0.954028
==================>
Step: 90000, Train_acc:0.982998
Step: 90000, Val_acc:0.95631
==================>
****************** Epochs completed: 180******************
2017-11-12 08:29:41.660574 ---> Validation_loss: 0.124822
Step: 90010, Train_acc:0.984751
Step: 90010, Val_acc:0.965822
==================>
Step: 90020, Train_acc:0.984457
Step: 90020, Val_acc:0.959612
==================>
Step: 90030, Train_acc:0.986564
Step: 90030, Val_acc:0.94062
==================>
Step: 90040, Train_acc:0.985135
Step: 90040, Val_acc:0.957957
==================>
Step: 90050, Train_acc:0.983594
Step: 90050, Val_acc:0.944087
==================>
Step: 90060, Train_acc:0.981746
Step: 90060, Val_acc:0.941093
==================>
Step: 90070, Train_acc:0.981323
Step: 90070, Val_acc:0.964797
==================>
Step: 90080, Train_acc:0.980653
Step: 90080, Val_acc:0.951713
==================>
Step: 90090, Train_acc:0.981063
Step: 90090, Val_acc:0.940736
==================>
Step: 90100, Train_acc:0.984406
Step: 90100, Val_acc:0.961322
==================>
2017-11-12 08:32:18.100907 ---> Validation_loss: 0.172933
Step: 90110, Train_acc:0.982539
Step: 90110, Val_acc:0.961886
==================>
Step: 90120, Train_acc:0.984982
Step: 90120, Val_acc:0.94926
==================>
Step: 90130, Train_acc:0.986779
Step: 90130, Val_acc:0.951714
==================>
Step: 90140, Train_acc:0.980785
Step: 90140, Val_acc:0.961838
==================>
Step: 90150, Train_acc:0.978589
Step: 90150, Val_acc:0.951891
==================>
Step: 90160, Train_acc:0.978165
Step: 90160, Val_acc:0.952753
==================>
Step: 90170, Train_acc:0.978605
Step: 90170, Val_acc:0.958876
==================>
Step: 90180, Train_acc:0.986825
Step: 90180, Val_acc:0.944067
==================>
Step: 90190, Train_acc:0.985219
Step: 90190, Val_acc:0.965554
==================>
Step: 90200, Train_acc:0.98514
Step: 90200, Val_acc:0.951467
==================>
2017-11-12 08:34:54.841697 ---> Validation_loss: 0.139395
Step: 90210, Train_acc:0.986967
Step: 90210, Val_acc:0.945789
==================>
Step: 90220, Train_acc:0.989651
Step: 90220, Val_acc:0.962231
==================>
Step: 90230, Train_acc:0.983306
Step: 90230, Val_acc:0.961597
==================>
Step: 90240, Train_acc:0.984641
Step: 90240, Val_acc:0.947966
==================>
Step: 90250, Train_acc:0.98428
Step: 90250, Val_acc:0.918822
==================>
Step: 90260, Train_acc:0.984216
Step: 90260, Val_acc:0.958259
==================>
Step: 90270, Train_acc:0.985537
Step: 90270, Val_acc:0.94316
==================>
Step: 90280, Train_acc:0.977518
Step: 90280, Val_acc:0.959985
==================>
Step: 90290, Train_acc:0.984312
Step: 90290, Val_acc:0.954157
==================>
Step: 90300, Train_acc:0.982448
Step: 90300, Val_acc:0.960068
==================>
2017-11-12 08:37:31.078436 ---> Validation_loss: 0.129478
Step: 90310, Train_acc:0.985588
Step: 90310, Val_acc:0.964307
==================>
Step: 90320, Train_acc:0.980839
Step: 90320, Val_acc:0.950663
==================>
Step: 90330, Train_acc:0.987089
Step: 90330, Val_acc:0.920945
==================>
Step: 90340, Train_acc:0.983948
Step: 90340, Val_acc:0.96038
==================>
Step: 90350, Train_acc:0.977957
Step: 90350, Val_acc:0.933307
==================>
Step: 90360, Train_acc:0.98673
Step: 90360, Val_acc:0.948367
==================>
Step: 90370, Train_acc:0.974976
Step: 90370, Val_acc:0.938073
==================>
Step: 90380, Train_acc:0.989896
Step: 90380, Val_acc:0.952511
==================>
Step: 90390, Train_acc:0.987823
Step: 90390, Val_acc:0.947362
==================>
Step: 90400, Train_acc:0.97955
Step: 90400, Val_acc:0.945234
==================>
2017-11-12 08:40:07.501986 ---> Validation_loss: 0.122843
Step: 90410, Train_acc:0.984893
Step: 90410, Val_acc:0.933861
==================>
Step: 90420, Train_acc:0.98187
Step: 90420, Val_acc:0.948862
==================>
Step: 90430, Train_acc:0.988508
Step: 90430, Val_acc:0.944009
==================>
Step: 90440, Train_acc:0.98395
Step: 90440, Val_acc:0.942137
==================>
Step: 90450, Train_acc:0.984524
Step: 90450, Val_acc:0.950928
==================>
Step: 90460, Train_acc:0.983145
Step: 90460, Val_acc:0.911389
==================>
Step: 90470, Train_acc:0.984506
Step: 90470, Val_acc:0.956799
==================>
Step: 90480, Train_acc:0.983201
Step: 90480, Val_acc:0.954059
==================>
Step: 90490, Train_acc:0.982501
Step: 90490, Val_acc:0.949866
==================>
Step: 90500, Train_acc:0.984078
Step: 90500, Val_acc:0.948585
==================>
****************** Epochs completed: 181******************
2017-11-12 08:42:43.809906 ---> Validation_loss: 0.138513
Step: 90510, Train_acc:0.981028
Step: 90510, Val_acc:0.934789
==================>
Step: 90520, Train_acc:0.979874
Step: 90520, Val_acc:0.963722
==================>
Step: 90530, Train_acc:0.984752
Step: 90530, Val_acc:0.929647
==================>
Step: 90540, Train_acc:0.984766
Step: 90540, Val_acc:0.958359
==================>
Step: 90550, Train_acc:0.980165
Step: 90550, Val_acc:0.944612
==================>
Step: 90560, Train_acc:0.981901
Step: 90560, Val_acc:0.955433
==================>
Step: 90570, Train_acc:0.983264
Step: 90570, Val_acc:0.949542
==================>
Step: 90580, Train_acc:0.984576
Step: 90580, Val_acc:0.951283
==================>
Step: 90590, Train_acc:0.98209
Step: 90590, Val_acc:0.954822
==================>
Step: 90600, Train_acc:0.983757
Step: 90600, Val_acc:0.918627
==================>
2017-11-12 08:45:20.475856 ---> Validation_loss: 0.191105
Step: 90610, Train_acc:0.986785
Step: 90610, Val_acc:0.926617
==================>
Step: 90620, Train_acc:0.981071
Step: 90620, Val_acc:0.942482
==================>
Step: 90630, Train_acc:0.981458
Step: 90630, Val_acc:0.951493
==================>
Step: 90640, Train_acc:0.983584
Step: 90640, Val_acc:0.94519
==================>
Step: 90650, Train_acc:0.979458
Step: 90650, Val_acc:0.961654
==================>
Step: 90660, Train_acc:0.982289
Step: 90660, Val_acc:0.925988
==================>
Step: 90670, Train_acc:0.97333
Step: 90670, Val_acc:0.955929
==================>
Step: 90680, Train_acc:0.982312
Step: 90680, Val_acc:0.938707
==================>
Step: 90690, Train_acc:0.983546
Step: 90690, Val_acc:0.948352
==================>
Step: 90700, Train_acc:0.9872
Step: 90700, Val_acc:0.955431
==================>
2017-11-12 08:47:56.714219 ---> Validation_loss: 0.124709
Step: 90710, Train_acc:0.98321
Step: 90710, Val_acc:0.959738
==================>
Step: 90720, Train_acc:0.985407
Step: 90720, Val_acc:0.962686
==================>
Step: 90730, Train_acc:0.981616
Step: 90730, Val_acc:0.970582
==================>
Step: 90740, Train_acc:0.97921
Step: 90740, Val_acc:0.944508
==================>
Step: 90750, Train_acc:0.986416
Step: 90750, Val_acc:0.951267
==================>
Step: 90760, Train_acc:0.979167
Step: 90760, Val_acc:0.962305
==================>
Step: 90770, Train_acc:0.980876
Step: 90770, Val_acc:0.959642
==================>
Step: 90780, Train_acc:0.981173
Step: 90780, Val_acc:0.935427
==================>
Step: 90790, Train_acc:0.984052
Step: 90790, Val_acc:0.93895
==================>
Step: 90800, Train_acc:0.988894
Step: 90800, Val_acc:0.943032
==================>
2017-11-12 08:50:32.881777 ---> Validation_loss: 0.154764
Step: 90810, Train_acc:0.98579
Step: 90810, Val_acc:0.947532
==================>
Step: 90820, Train_acc:0.984576
Step: 90820, Val_acc:0.957163
==================>
****************** Epochs completed: 27******************
Step: 90830, Train_acc:0.987705
Step: 90830, Val_acc:0.952649
==================>
Step: 90840, Train_acc:0.987432
Step: 90840, Val_acc:0.955425
==================>
Step: 90850, Train_acc:0.988734
Step: 90850, Val_acc:0.962396
==================>
Step: 90860, Train_acc:0.982749
Step: 90860, Val_acc:0.946302
==================>
Step: 90870, Train_acc:0.981467
Step: 90870, Val_acc:0.933933
==================>
Step: 90880, Train_acc:0.98376
Step: 90880, Val_acc:0.938479
==================>
Step: 90890, Train_acc:0.984611
Step: 90890, Val_acc:0.943943
==================>
Step: 90900, Train_acc:0.980667
Step: 90900, Val_acc:0.95163
==================>
2017-11-12 08:53:09.006607 ---> Validation_loss: 0.118932
Step: 90910, Train_acc:0.978809
Step: 90910, Val_acc:0.950983
==================>
Step: 90920, Train_acc:0.986051
Step: 90920, Val_acc:0.96389
==================>
Step: 90930, Train_acc:0.983497
Step: 90930, Val_acc:0.950983
==================>
Step: 90940, Train_acc:0.990914
Step: 90940, Val_acc:0.934672
==================>
Step: 90950, Train_acc:0.982646
Step: 90950, Val_acc:0.956641
==================>
Step: 90960, Train_acc:0.978746
Step: 90960, Val_acc:0.934805
==================>
Step: 90970, Train_acc:0.990675
Step: 90970, Val_acc:0.959363
==================>
Step: 90980, Train_acc:0.982108
Step: 90980, Val_acc:0.952018
==================>
Step: 90990, Train_acc:0.985016
Step: 90990, Val_acc:0.940945
==================>
Step: 91000, Train_acc:0.981951
Step: 91000, Val_acc:0.955538
==================>
****************** Epochs completed: 182******************
2017-11-12 08:55:45.167481 ---> Validation_loss: 0.179417
Step: 91010, Train_acc:0.988881
Step: 91010, Val_acc:0.951126
==================>
Step: 91020, Train_acc:0.989288
Step: 91020, Val_acc:0.954048
==================>
Step: 91030, Train_acc:0.983523
Step: 91030, Val_acc:0.961538
==================>
Step: 91040, Train_acc:0.985433
Step: 91040, Val_acc:0.957546
==================>
Step: 91050, Train_acc:0.981678
Step: 91050, Val_acc:0.944764
==================>
Step: 91060, Train_acc:0.980751
Step: 91060, Val_acc:0.939666
==================>
Step: 91070, Train_acc:0.98125
Step: 91070, Val_acc:0.95182
==================>
Step: 91080, Train_acc:0.990752
Step: 91080, Val_acc:0.945665
==================>
Step: 91090, Train_acc:0.981575
Step: 91090, Val_acc:0.951809
==================>
Step: 91100, Train_acc:0.982709
Step: 91100, Val_acc:0.94792
==================>
2017-11-12 08:58:20.858750 ---> Validation_loss: 0.141948
Step: 91110, Train_acc:0.987615
Step: 91110, Val_acc:0.939781
==================>
Step: 91120, Train_acc:0.984592
Step: 91120, Val_acc:0.942878
==================>
Step: 91130, Train_acc:0.987761
Step: 91130, Val_acc:0.960367
==================>
Step: 91140, Train_acc:0.986038
Step: 91140, Val_acc:0.945063
==================>
Step: 91150, Train_acc:0.987562
Step: 91150, Val_acc:0.943451
==================>
Step: 91160, Train_acc:0.974816
Step: 91160, Val_acc:0.964606
==================>
Step: 91170, Train_acc:0.984506
Step: 91170, Val_acc:0.957834
==================>
Step: 91180, Train_acc:0.981228
Step: 91180, Val_acc:0.961307
==================>
Step: 91190, Train_acc:0.980997
Step: 91190, Val_acc:0.940806
==================>
Step: 91200, Train_acc:0.986592
Step: 91200, Val_acc:0.959757
==================>
2017-11-12 09:00:56.731864 ---> Validation_loss: 0.109538
Step: 91210, Train_acc:0.986338
Step: 91210, Val_acc:0.941824
==================>
Step: 91220, Train_acc:0.985106
Step: 91220, Val_acc:0.959558
==================>
Step: 91230, Train_acc:0.988423
Step: 91230, Val_acc:0.954104
==================>
Step: 91240, Train_acc:0.986991
Step: 91240, Val_acc:0.936896
==================>
Step: 91250, Train_acc:0.98624
Step: 91250, Val_acc:0.954766
==================>
Step: 91260, Train_acc:0.986239
Step: 91260, Val_acc:0.954196
==================>
Step: 91270, Train_acc:0.991412
Step: 91270, Val_acc:0.93963
==================>
Step: 91280, Train_acc:0.97991
Step: 91280, Val_acc:0.965652
==================>
Step: 91290, Train_acc:0.986548
Step: 91290, Val_acc:0.951788
==================>
Step: 91300, Train_acc:0.981835
Step: 91300, Val_acc:0.95666
==================>
2017-11-12 09:03:32.423324 ---> Validation_loss: 0.110875
Step: 91310, Train_acc:0.983427
Step: 91310, Val_acc:0.945469
==================>
Step: 91320, Train_acc:0.981553
Step: 91320, Val_acc:0.948284
==================>
Step: 91330, Train_acc:0.984921
Step: 91330, Val_acc:0.930544
==================>
Step: 91340, Train_acc:0.984724
Step: 91340, Val_acc:0.951161
==================>
Step: 91350, Train_acc:0.986761
Step: 91350, Val_acc:0.957249
==================>
Step: 91360, Train_acc:0.987429
Step: 91360, Val_acc:0.954251
==================>
Step: 91370, Train_acc:0.987756
Step: 91370, Val_acc:0.945393
==================>
Step: 91380, Train_acc:0.98707
Step: 91380, Val_acc:0.953922
==================>
Step: 91390, Train_acc:0.982391
Step: 91390, Val_acc:0.948374
==================>
Step: 91400, Train_acc:0.988086
Step: 91400, Val_acc:0.953123
==================>
2017-11-12 09:06:08.399708 ---> Validation_loss: 0.153714
Step: 91410, Train_acc:0.984102
Step: 91410, Val_acc:0.958922
==================>
Step: 91420, Train_acc:0.986007
Step: 91420, Val_acc:0.95219
==================>
Step: 91430, Train_acc:0.986587
Step: 91430, Val_acc:0.952747
==================>
Step: 91440, Train_acc:0.99002
Step: 91440, Val_acc:0.938193
==================>
Step: 91450, Train_acc:0.981243
Step: 91450, Val_acc:0.936586
==================>
Step: 91460, Train_acc:0.978551
Step: 91460, Val_acc:0.944154
==================>
Step: 91470, Train_acc:0.985725
Step: 91470, Val_acc:0.952456
==================>
Step: 91480, Train_acc:0.985809
Step: 91480, Val_acc:0.943737
==================>
Step: 91490, Train_acc:0.977566
Step: 91490, Val_acc:0.950397
==================>
Step: 91500, Train_acc:0.982394
Step: 91500, Val_acc:0.939182
==================>
****************** Epochs completed: 183******************
2017-11-12 09:08:44.620883 ---> Validation_loss: 0.117909
Step: 91510, Train_acc:0.97929
Step: 91510, Val_acc:0.956302
==================>
Step: 91520, Train_acc:0.982886
Step: 91520, Val_acc:0.951848
==================>
Step: 91530, Train_acc:0.984536
Step: 91530, Val_acc:0.945565
==================>
Step: 91540, Train_acc:0.98444
Step: 91540, Val_acc:0.946332
==================>
Step: 91550, Train_acc:0.987422
Step: 91550, Val_acc:0.961274
==================>
Step: 91560, Train_acc:0.987469
Step: 91560, Val_acc:0.954545
==================>
Step: 91570, Train_acc:0.986777
Step: 91570, Val_acc:0.948162
==================>
Step: 91580, Train_acc:0.982191
Step: 91580, Val_acc:0.941843
==================>
Step: 91590, Train_acc:0.990212
Step: 91590, Val_acc:0.922907
==================>
Step: 91600, Train_acc:0.985984
Step: 91600, Val_acc:0.941178
==================>
2017-11-12 09:11:20.790553 ---> Validation_loss: 0.102814
Step: 91610, Train_acc:0.984727
Step: 91610, Val_acc:0.963953
==================>
Step: 91620, Train_acc:0.98537
Step: 91620, Val_acc:0.957407
==================>
Step: 91630, Train_acc:0.986243
Step: 91630, Val_acc:0.965519
==================>
Step: 91640, Train_acc:0.983068
Step: 91640, Val_acc:0.961102
==================>
Step: 91650, Train_acc:0.983378
Step: 91650, Val_acc:0.952653
==================>
Step: 91660, Train_acc:0.984637
Step: 91660, Val_acc:0.933457
==================>
Step: 91670, Train_acc:0.989875
Step: 91670, Val_acc:0.945065
==================>
Step: 91680, Train_acc:0.983218
Step: 91680, Val_acc:0.937493
==================>
Step: 91690, Train_acc:0.988494
Step: 91690, Val_acc:0.966009
==================>
Step: 91700, Train_acc:0.990032
Step: 91700, Val_acc:0.958351
==================>
2017-11-12 09:13:56.709913 ---> Validation_loss: 0.128685
Step: 91710, Train_acc:0.986718
Step: 91710, Val_acc:0.9342
==================>
Step: 91720, Train_acc:0.984301
Step: 91720, Val_acc:0.945112
==================>
Step: 91730, Train_acc:0.982875
Step: 91730, Val_acc:0.942253
==================>
Step: 91740, Train_acc:0.980599
Step: 91740, Val_acc:0.94991
==================>
Step: 91750, Train_acc:0.984327
Step: 91750, Val_acc:0.95205
==================>
Step: 91760, Train_acc:0.978282
Step: 91760, Val_acc:0.937806
==================>
Step: 91770, Train_acc:0.987743
Step: 91770, Val_acc:0.945406
==================>
Step: 91780, Train_acc:0.984132
Step: 91780, Val_acc:0.964458
==================>
Step: 91790, Train_acc:0.992238
Step: 91790, Val_acc:0.927653
==================>
Step: 91800, Train_acc:0.985927
Step: 91800, Val_acc:0.962524
==================>
2017-11-12 09:16:32.319009 ---> Validation_loss: 0.124832
Step: 91810, Train_acc:0.985317
Step: 91810, Val_acc:0.923677
==================>
Step: 91820, Train_acc:0.986864
Step: 91820, Val_acc:0.953997
==================>
Step: 91830, Train_acc:0.984833
Step: 91830, Val_acc:0.944333
==================>
Step: 91840, Train_acc:0.985901
Step: 91840, Val_acc:0.937482
==================>
Step: 91850, Train_acc:0.981831
Step: 91850, Val_acc:0.942709
==================>
Step: 91860, Train_acc:0.985878
Step: 91860, Val_acc:0.944825
==================>
Step: 91870, Train_acc:0.983121
Step: 91870, Val_acc:0.941682
==================>
Step: 91880, Train_acc:0.986158
Step: 91880, Val_acc:0.955124
==================>
Step: 91890, Train_acc:0.980636
Step: 91890, Val_acc:0.931121
==================>
Step: 91900, Train_acc:0.983732
Step: 91900, Val_acc:0.943606
==================>
2017-11-12 09:19:08.655447 ---> Validation_loss: 0.234124
Step: 91910, Train_acc:0.989028
Step: 91910, Val_acc:0.952129
==================>
Step: 91920, Train_acc:0.980631
Step: 91920, Val_acc:0.946161
==================>
Step: 91930, Train_acc:0.983109
Step: 91930, Val_acc:0.932035
==================>
Step: 91940, Train_acc:0.98283
Step: 91940, Val_acc:0.954801
==================>
Step: 91950, Train_acc:0.98465
Step: 91950, Val_acc:0.948899
==================>
Step: 91960, Train_acc:0.980422
Step: 91960, Val_acc:0.950315
==================>
Step: 91970, Train_acc:0.98689
Step: 91970, Val_acc:0.948475
==================>
Step: 91980, Train_acc:0.985789
Step: 91980, Val_acc:0.959025
==================>
Step: 91990, Train_acc:0.983817
Step: 91990, Val_acc:0.932762
==================>
Step: 92000, Train_acc:0.989108
Step: 92000, Val_acc:0.939202
==================>
****************** Epochs completed: 184******************
2017-11-12 09:21:44.622304 ---> Validation_loss: 0.125641
Step: 92010, Train_acc:0.989385
Step: 92010, Val_acc:0.967627
==================>
Step: 92020, Train_acc:0.985256
Step: 92020, Val_acc:0.950959
==================>
Step: 92030, Train_acc:0.981543
Step: 92030, Val_acc:0.930029
==================>
Step: 92040, Train_acc:0.986633
Step: 92040, Val_acc:0.935649
==================>
Step: 92050, Train_acc:0.983981
Step: 92050, Val_acc:0.946166
==================>
Step: 92060, Train_acc:0.989308
Step: 92060, Val_acc:0.943488
==================>
Step: 92070, Train_acc:0.98061
Step: 92070, Val_acc:0.943474
==================>
Step: 92080, Train_acc:0.988485
Step: 92080, Val_acc:0.942893
==================>
Step: 92090, Train_acc:0.987988
Step: 92090, Val_acc:0.948577
==================>
Step: 92100, Train_acc:0.98733
Step: 92100, Val_acc:0.930437
==================>
2017-11-12 09:24:20.525399 ---> Validation_loss: 0.143255
Step: 92110, Train_acc:0.986223
Step: 92110, Val_acc:0.955372
==================>
Step: 92120, Train_acc:0.984032
Step: 92120, Val_acc:0.954435
==================>
Step: 92130, Train_acc:0.985992
Step: 92130, Val_acc:0.950947
==================>
Step: 92140, Train_acc:0.986332
Step: 92140, Val_acc:0.9504
==================>
Step: 92150, Train_acc:0.978379
Step: 92150, Val_acc:0.947784
==================>
Step: 92160, Train_acc:0.98356
Step: 92160, Val_acc:0.927672
==================>
Step: 92170, Train_acc:0.983169
Step: 92170, Val_acc:0.959508
==================>
Step: 92180, Train_acc:0.983984
Step: 92180, Val_acc:0.954894
==================>
Step: 92190, Train_acc:0.982999
Step: 92190, Val_acc:0.952666
==================>
Step: 92200, Train_acc:0.982119
Step: 92200, Val_acc:0.950759
==================>
2017-11-12 09:26:56.720796 ---> Validation_loss: 0.103186
Step: 92210, Train_acc:0.985094
Step: 92210, Val_acc:0.950043
==================>
Step: 92220, Train_acc:0.985568
Step: 92220, Val_acc:0.955372
==================>
Step: 92230, Train_acc:0.986021
Step: 92230, Val_acc:0.962156
==================>
Step: 92240, Train_acc:0.985112
Step: 92240, Val_acc:0.952036
==================>
Step: 92250, Train_acc:0.986591
Step: 92250, Val_acc:0.946683
==================>
Step: 92260, Train_acc:0.97647
Step: 92260, Val_acc:0.93852
==================>
Step: 92270, Train_acc:0.982424
Step: 92270, Val_acc:0.968282
==================>
Step: 92280, Train_acc:0.986937
Step: 92280, Val_acc:0.948792
==================>
Step: 92290, Train_acc:0.978031
Step: 92290, Val_acc:0.947479
==================>
Step: 92300, Train_acc:0.983591
Step: 92300, Val_acc:0.941575
==================>
2017-11-12 09:29:32.616527 ---> Validation_loss: 0.151359
Step: 92310, Train_acc:0.983163
Step: 92310, Val_acc:0.962233
==================>
Step: 92320, Train_acc:0.98853
Step: 92320, Val_acc:0.947434
==================>
Step: 92330, Train_acc:0.98666
Step: 92330, Val_acc:0.93913
==================>
Step: 92340, Train_acc:0.987367
Step: 92340, Val_acc:0.947932
==================>
Step: 92350, Train_acc:0.976613
Step: 92350, Val_acc:0.968849
==================>
Step: 92360, Train_acc:0.985931
Step: 92360, Val_acc:0.948695
==================>
Step: 92370, Train_acc:0.982893
Step: 92370, Val_acc:0.943955
==================>
Step: 92380, Train_acc:0.981466
Step: 92380, Val_acc:0.964747
==================>
Step: 92390, Train_acc:0.986742
Step: 92390, Val_acc:0.96188
==================>
Step: 92400, Train_acc:0.987712
Step: 92400, Val_acc:0.954355
==================>
2017-11-12 09:32:08.368672 ---> Validation_loss: 0.130781
Step: 92410, Train_acc:0.983929
Step: 92410, Val_acc:0.951818
==================>
Step: 92420, Train_acc:0.98572
Step: 92420, Val_acc:0.955717
==================>
Step: 92430, Train_acc:0.988092
Step: 92430, Val_acc:0.936062
==================>
Step: 92440, Train_acc:0.980331
Step: 92440, Val_acc:0.956272
==================>
Step: 92450, Train_acc:0.97985
Step: 92450, Val_acc:0.955167
==================>
Step: 92460, Train_acc:0.988265
Step: 92460, Val_acc:0.954846
==================>
Step: 92470, Train_acc:0.989448
Step: 92470, Val_acc:0.958391
==================>
Step: 92480, Train_acc:0.982261
Step: 92480, Val_acc:0.955238
==================>
Step: 92490, Train_acc:0.982676
Step: 92490, Val_acc:0.931151
==================>
Step: 92500, Train_acc:0.981715
Step: 92500, Val_acc:0.963131
==================>
****************** Epochs completed: 185******************
2017-11-12 09:34:44.345738 ---> Validation_loss: 0.137897
Step: 92510, Train_acc:0.97901
Step: 92510, Val_acc:0.948308
==================>
Step: 92520, Train_acc:0.980713
Step: 92520, Val_acc:0.935848
==================>
Step: 92530, Train_acc:0.971864
Step: 92530, Val_acc:0.963119
==================>
Step: 92540, Train_acc:0.989403
Step: 92540, Val_acc:0.939919
==================>
Step: 92550, Train_acc:0.983579
Step: 92550, Val_acc:0.945752
==================>
Step: 92560, Train_acc:0.982452
Step: 92560, Val_acc:0.945233
==================>
Step: 92570, Train_acc:0.984656
Step: 92570, Val_acc:0.961759
==================>
Step: 92580, Train_acc:0.986956
Step: 92580, Val_acc:0.957468
==================>
Step: 92590, Train_acc:0.986396
Step: 92590, Val_acc:0.950443
==================>
Step: 92600, Train_acc:0.982895
Step: 92600, Val_acc:0.93698
==================>
2017-11-12 09:37:20.711595 ---> Validation_loss: 0.186294
Step: 92610, Train_acc:0.986515
Step: 92610, Val_acc:0.948882
==================>
Step: 92620, Train_acc:0.987844
Step: 92620, Val_acc:0.946495
==================>
Step: 92630, Train_acc:0.986497
Step: 92630, Val_acc:0.960963
==================>
Step: 92640, Train_acc:0.98524
Step: 92640, Val_acc:0.958027
==================>
Step: 92650, Train_acc:0.9804
Step: 92650, Val_acc:0.945264
==================>
Step: 92660, Train_acc:0.978702
Step: 92660, Val_acc:0.939875
==================>
Step: 92670, Train_acc:0.986309
Step: 92670, Val_acc:0.941366
==================>
Step: 92680, Train_acc:0.985676
Step: 92680, Val_acc:0.953687
==================>
Step: 92690, Train_acc:0.981465
Step: 92690, Val_acc:0.951116
==================>
Step: 92700, Train_acc:0.985004
Step: 92700, Val_acc:0.949402
==================>
2017-11-12 09:39:56.701165 ---> Validation_loss: 0.103893
Step: 92710, Train_acc:0.985104
Step: 92710, Val_acc:0.951467
==================>
Step: 92720, Train_acc:0.985857
Step: 92720, Val_acc:0.944703
==================>
Step: 92730, Train_acc:0.986443
Step: 92730, Val_acc:0.930315
==================>
Step: 92740, Train_acc:0.985804
Step: 92740, Val_acc:0.945525
==================>
Step: 92750, Train_acc:0.982053
Step: 92750, Val_acc:0.943475
==================>
Step: 92760, Train_acc:0.987966
Step: 92760, Val_acc:0.952048
==================>
Step: 92770, Train_acc:0.984695
Step: 92770, Val_acc:0.948573
==================>
Step: 92780, Train_acc:0.986899
Step: 92780, Val_acc:0.931771
==================>
Step: 92790, Train_acc:0.989406
Step: 92790, Val_acc:0.939011
==================>
Step: 92800, Train_acc:0.989998
Step: 92800, Val_acc:0.948854
==================>
2017-11-12 09:42:32.504022 ---> Validation_loss: 0.110568
Step: 92810, Train_acc:0.990753
Step: 92810, Val_acc:0.920205
==================>
Step: 92820, Train_acc:0.987194
Step: 92820, Val_acc:0.942541
==================>
Step: 92830, Train_acc:0.986862
Step: 92830, Val_acc:0.945566
==================>
Step: 92840, Train_acc:0.982332
Step: 92840, Val_acc:0.946702
==================>
Step: 92850, Train_acc:0.977832
Step: 92850, Val_acc:0.934
==================>
Step: 92860, Train_acc:0.986726
Step: 92860, Val_acc:0.946038
==================>
Step: 92870, Train_acc:0.982981
Step: 92870, Val_acc:0.935062
==================>
Step: 92880, Train_acc:0.982598
Step: 92880, Val_acc:0.930735
==================>
Step: 92890, Train_acc:0.985
Step: 92890, Val_acc:0.956072
==================>
Step: 92900, Train_acc:0.984092
Step: 92900, Val_acc:0.936721
==================>
2017-11-12 09:45:08.548457 ---> Validation_loss: 0.205211
Step: 92910, Train_acc:0.988326
Step: 92910, Val_acc:0.947764
==================>
Step: 92920, Train_acc:0.987406
Step: 92920, Val_acc:0.916834
==================>
Step: 92930, Train_acc:0.9821
Step: 92930, Val_acc:0.951848
==================>
Step: 92940, Train_acc:0.984572
Step: 92940, Val_acc:0.951941
==================>
Step: 92950, Train_acc:0.987213
Step: 92950, Val_acc:0.968082
==================>
Step: 92960, Train_acc:0.985614
Step: 92960, Val_acc:0.949756
==================>
Step: 92970, Train_acc:0.983942
Step: 92970, Val_acc:0.951183
==================>
Step: 92980, Train_acc:0.982596
Step: 92980, Val_acc:0.963962
==================>
Step: 92990, Train_acc:0.982441
Step: 92990, Val_acc:0.94688
==================>
Step: 93000, Train_acc:0.975914
Step: 93000, Val_acc:0.956414
==================>
****************** Epochs completed: 186******************
2017-11-12 09:47:44.505034 ---> Validation_loss: 0.102204
Step: 93010, Train_acc:0.986959
Step: 93010, Val_acc:0.939303
==================>
Step: 93020, Train_acc:0.979713
Step: 93020, Val_acc:0.943564
==================>
Step: 93030, Train_acc:0.984454
Step: 93030, Val_acc:0.952174
==================>
Step: 93040, Train_acc:0.989552
Step: 93040, Val_acc:0.963079
==================>
Step: 93050, Train_acc:0.986406
Step: 93050, Val_acc:0.92304
==================>
Step: 93060, Train_acc:0.982773
Step: 93060, Val_acc:0.949276
==================>
Step: 93070, Train_acc:0.986288
Step: 93070, Val_acc:0.939456
==================>
Step: 93080, Train_acc:0.981752
Step: 93080, Val_acc:0.964866
==================>
Step: 93090, Train_acc:0.975872
Step: 93090, Val_acc:0.937123
==================>
Step: 93100, Train_acc:0.988584
Step: 93100, Val_acc:0.962367
==================>
2017-11-12 09:50:20.324654 ---> Validation_loss: 0.164453
Step: 93110, Train_acc:0.988809
Step: 93110, Val_acc:0.951094
==================>
Step: 93120, Train_acc:0.980675
Step: 93120, Val_acc:0.946038
==================>
Step: 93130, Train_acc:0.984247
Step: 93130, Val_acc:0.956752
==================>
Step: 93140, Train_acc:0.983621
Step: 93140, Val_acc:0.962043
==================>
Step: 93150, Train_acc:0.98364
Step: 93150, Val_acc:0.952968
==================>
Step: 93160, Train_acc:0.982731
Step: 93160, Val_acc:0.943726
==================>
Step: 93170, Train_acc:0.988372
Step: 93170, Val_acc:0.922653
==================>
Step: 93180, Train_acc:0.987985
Step: 93180, Val_acc:0.965183
==================>
Step: 93190, Train_acc:0.987498
Step: 93190, Val_acc:0.954224
==================>
Step: 93200, Train_acc:0.9801
Step: 93200, Val_acc:0.946602
==================>
2017-11-12 09:52:56.371947 ---> Validation_loss: 0.142134
Step: 93210, Train_acc:0.97969
Step: 93210, Val_acc:0.946849
==================>
Step: 93220, Train_acc:0.988667
Step: 93220, Val_acc:0.930131
==================>
Step: 93230, Train_acc:0.985767
Step: 93230, Val_acc:0.955155
==================>
Step: 93240, Train_acc:0.980148
Step: 93240, Val_acc:0.961136
==================>
Step: 93250, Train_acc:0.985579
Step: 93250, Val_acc:0.933964
==================>
Step: 93260, Train_acc:0.990216
Step: 93260, Val_acc:0.926096
==================>
Step: 93270, Train_acc:0.987856
Step: 93270, Val_acc:0.94988
==================>
Step: 93280, Train_acc:0.986504
Step: 93280, Val_acc:0.922184
==================>
Step: 93290, Train_acc:0.980315
Step: 93290, Val_acc:0.939393
==================>
Step: 93300, Train_acc:0.983682
Step: 93300, Val_acc:0.932502
==================>
2017-11-12 09:55:32.279311 ---> Validation_loss: 0.169707
Step: 93310, Train_acc:0.979528
Step: 93310, Val_acc:0.950795
==================>
Step: 93320, Train_acc:0.987208
Step: 93320, Val_acc:0.962306
==================>
Step: 93330, Train_acc:0.978506
Step: 93330, Val_acc:0.942144
==================>
Step: 93340, Train_acc:0.981904
Step: 93340, Val_acc:0.950662
==================>
Step: 93350, Train_acc:0.978591
Step: 93350, Val_acc:0.942329
==================>
Step: 93360, Train_acc:0.988815
Step: 93360, Val_acc:0.954252
==================>
Step: 93370, Train_acc:0.990417
Step: 93370, Val_acc:0.948844
==================>
Step: 93380, Train_acc:0.983059
Step: 93380, Val_acc:0.939268
==================>
Step: 93390, Train_acc:0.984056
Step: 93390, Val_acc:0.949342
==================>
Step: 93400, Train_acc:0.982109
Step: 93400, Val_acc:0.970402
==================>
2017-11-12 09:58:08.064675 ---> Validation_loss: 0.13263
Step: 93410, Train_acc:0.984047
Step: 93410, Val_acc:0.964158
==================>
Step: 93420, Train_acc:0.986991
Step: 93420, Val_acc:0.945859
==================>
Step: 93430, Train_acc:0.98813
Step: 93430, Val_acc:0.965272
==================>
Step: 93440, Train_acc:0.976521
Step: 93440, Val_acc:0.931992
==================>
Step: 93450, Train_acc:0.986399
Step: 93450, Val_acc:0.955524
==================>
Step: 93460, Train_acc:0.98459
Step: 93460, Val_acc:0.944542
==================>
Step: 93470, Train_acc:0.982573
Step: 93470, Val_acc:0.951107
==================>
Step: 93480, Train_acc:0.984713
Step: 93480, Val_acc:0.926598
==================>
Step: 93490, Train_acc:0.987834
Step: 93490, Val_acc:0.950006
==================>
Step: 93500, Train_acc:0.987871
Step: 93500, Val_acc:0.948398
==================>
****************** Epochs completed: 187******************
2017-11-12 10:00:43.921534 ---> Validation_loss: 0.137966
Step: 93510, Train_acc:0.986234
Step: 93510, Val_acc:0.952594
==================>
Step: 93520, Train_acc:0.985142
Step: 93520, Val_acc:0.925916
==================>
Step: 93530, Train_acc:0.983738
Step: 93530, Val_acc:0.963915
==================>
Step: 93540, Train_acc:0.983142
Step: 93540, Val_acc:0.948383
==================>
Step: 93550, Train_acc:0.981309
Step: 93550, Val_acc:0.951624
==================>
Step: 93560, Train_acc:0.988051
Step: 93560, Val_acc:0.943896
==================>
Step: 93570, Train_acc:0.987235
Step: 93570, Val_acc:0.947245
==================>
Step: 93580, Train_acc:0.990476
Step: 93580, Val_acc:0.877849
==================>
Step: 93590, Train_acc:0.986027
Step: 93590, Val_acc:0.937423
==================>
Step: 93600, Train_acc:0.990165
Step: 93600, Val_acc:0.94673
==================>
2017-11-12 10:03:19.874118 ---> Validation_loss: 0.103429
Step: 93610, Train_acc:0.983054
Step: 93610, Val_acc:0.952899
==================>
Step: 93620, Train_acc:0.981058
Step: 93620, Val_acc:0.954236
==================>
Step: 93630, Train_acc:0.984442
Step: 93630, Val_acc:0.95266
==================>
Step: 93640, Train_acc:0.986998
Step: 93640, Val_acc:0.938567
==================>
Step: 93650, Train_acc:0.983381
Step: 93650, Val_acc:0.936443
==================>
Step: 93660, Train_acc:0.979535
Step: 93660, Val_acc:0.911946
==================>
Step: 93670, Train_acc:0.98413
Step: 93670, Val_acc:0.930053
==================>
Step: 93680, Train_acc:0.98871
Step: 93680, Val_acc:0.9324
==================>
Step: 93690, Train_acc:0.985022
Step: 93690, Val_acc:0.929949
==================>
Step: 93700, Train_acc:0.985511
Step: 93700, Val_acc:0.926819
==================>
2017-11-12 10:05:55.888968 ---> Validation_loss: 0.182938
Step: 93710, Train_acc:0.984894
Step: 93710, Val_acc:0.928083
==================>
Step: 93720, Train_acc:0.979834
Step: 93720, Val_acc:0.946116
==================>
Step: 93730, Train_acc:0.979425
Step: 93730, Val_acc:0.953776
==================>
Step: 93740, Train_acc:0.976433
Step: 93740, Val_acc:0.949078
==================>
Step: 93750, Train_acc:0.980055
Step: 93750, Val_acc:0.930459
==================>
Step: 93760, Train_acc:0.988191
Step: 93760, Val_acc:0.944139
==================>
Step: 93770, Train_acc:0.984747
Step: 93770, Val_acc:0.946683
==================>
Step: 93780, Train_acc:0.986932
Step: 93780, Val_acc:0.965054
==================>
Step: 93790, Train_acc:0.981471
Step: 93790, Val_acc:0.946367
==================>
Step: 93800, Train_acc:0.985981
Step: 93800, Val_acc:0.968611
==================>
2017-11-12 10:08:31.576998 ---> Validation_loss: 0.147379
Step: 93810, Train_acc:0.979384
Step: 93810, Val_acc:0.958267
==================>
Step: 93820, Train_acc:0.984103
Step: 93820, Val_acc:0.952423
==================>
Step: 93830, Train_acc:0.981261
Step: 93830, Val_acc:0.948242
==================>
Step: 93840, Train_acc:0.983846
Step: 93840, Val_acc:0.934618
==================>
Step: 93850, Train_acc:0.986534
Step: 93850, Val_acc:0.941836
==================>
Step: 93860, Train_acc:0.983562
Step: 93860, Val_acc:0.927567
==================>
Step: 93870, Train_acc:0.983048
Step: 93870, Val_acc:0.94632
==================>
Step: 93880, Train_acc:0.985033
Step: 93880, Val_acc:0.943339
==================>
Step: 93890, Train_acc:0.980038
Step: 93890, Val_acc:0.944479
==================>
Step: 93900, Train_acc:0.977966
Step: 93900, Val_acc:0.944387
==================>
2017-11-12 10:11:07.257403 ---> Validation_loss: 0.143709
Step: 93910, Train_acc:0.986348
Step: 93910, Val_acc:0.940355
==================>
Step: 93920, Train_acc:0.981179
Step: 93920, Val_acc:0.967555
==================>
Step: 93930, Train_acc:0.988876
Step: 93930, Val_acc:0.939323
==================>
Step: 93940, Train_acc:0.97329
Step: 93940, Val_acc:0.950028
==================>
Step: 93950, Train_acc:0.987102
Step: 93950, Val_acc:0.946411
==================>
Step: 93960, Train_acc:0.983499
Step: 93960, Val_acc:0.947228
==================>
Step: 93970, Train_acc:0.987096
Step: 93970, Val_acc:0.958029
==================>
Step: 93980, Train_acc:0.986293
Step: 93980, Val_acc:0.966508
==================>
Step: 93990, Train_acc:0.982722
Step: 93990, Val_acc:0.943481
==================>
Step: 94000, Train_acc:0.978824
Step: 94000, Val_acc:0.948854
==================>
****************** Epochs completed: 188******************
2017-11-12 10:13:43.052773 ---> Validation_loss: 0.153244
Step: 94010, Train_acc:0.983242
Step: 94010, Val_acc:0.939559
==================>
Step: 94020, Train_acc:0.9803
Step: 94020, Val_acc:0.950389
==================>
Step: 94030, Train_acc:0.988505
Step: 94030, Val_acc:0.96266
==================>
Step: 94040, Train_acc:0.985024
Step: 94040, Val_acc:0.940524
==================>
Step: 94050, Train_acc:0.987126
Step: 94050, Val_acc:0.945356
==================>
Step: 94060, Train_acc:0.978525
Step: 94060, Val_acc:0.950627
==================>
Step: 94070, Train_acc:0.982108
Step: 94070, Val_acc:0.946396
==================>
Step: 94080, Train_acc:0.985513
Step: 94080, Val_acc:0.957513
==================>
Step: 94090, Train_acc:0.983917
Step: 94090, Val_acc:0.936039
==================>
Step: 94100, Train_acc:0.980801
Step: 94100, Val_acc:0.953362
==================>
2017-11-12 10:16:19.338936 ---> Validation_loss: 0.144803
Step: 94110, Train_acc:0.985033
Step: 94110, Val_acc:0.953826
==================>
Step: 94120, Train_acc:0.985153
Step: 94120, Val_acc:0.932484
==================>
Step: 94130, Train_acc:0.98899
Step: 94130, Val_acc:0.951077
==================>
Step: 94140, Train_acc:0.984667
Step: 94140, Val_acc:0.926483
==================>
Step: 94150, Train_acc:0.983787
Step: 94150, Val_acc:0.945524
==================>
Step: 94160, Train_acc:0.979623
Step: 94160, Val_acc:0.941289
==================>
Step: 94170, Train_acc:0.980148
Step: 94170, Val_acc:0.945205
==================>
Step: 94180, Train_acc:0.983047
Step: 94180, Val_acc:0.959988
==================>
Step: 94190, Train_acc:0.981919
Step: 94190, Val_acc:0.95385
==================>
****************** Epochs completed: 28******************
Step: 94200, Train_acc:0.978955
Step: 94200, Val_acc:0.949283
==================>
2017-11-12 10:18:55.370053 ---> Validation_loss: 0.0971723
Step: 94210, Train_acc:0.986196
Step: 94210, Val_acc:0.953113
==================>
Step: 94220, Train_acc:0.984806
Step: 94220, Val_acc:0.95265
==================>
Step: 94230, Train_acc:0.986353
Step: 94230, Val_acc:0.948124
==================>
Step: 94240, Train_acc:0.987816
Step: 94240, Val_acc:0.956772
==================>
Step: 94250, Train_acc:0.987633
Step: 94250, Val_acc:0.960388
==================>
Step: 94260, Train_acc:0.988546
Step: 94260, Val_acc:0.958881
==================>
Step: 94270, Train_acc:0.984424
Step: 94270, Val_acc:0.951184
==================>
Step: 94280, Train_acc:0.988024
Step: 94280, Val_acc:0.960333
==================>
Step: 94290, Train_acc:0.982836
Step: 94290, Val_acc:0.930079
==================>
Step: 94300, Train_acc:0.984885
Step: 94300, Val_acc:0.950138
==================>
2017-11-12 10:21:32.192335 ---> Validation_loss: 0.149751
Step: 94310, Train_acc:0.985582
Step: 94310, Val_acc:0.938114
==================>
Step: 94320, Train_acc:0.985175
Step: 94320, Val_acc:0.945361
==================>
Step: 94330, Train_acc:0.98913
Step: 94330, Val_acc:0.946746
==================>
Step: 94340, Train_acc:0.987434
Step: 94340, Val_acc:0.96897
==================>
Step: 94350, Train_acc:0.986486
Step: 94350, Val_acc:0.93066
==================>
Step: 94360, Train_acc:0.983511
Step: 94360, Val_acc:0.946736
==================>
Step: 94370, Train_acc:0.985723
Step: 94370, Val_acc:0.924303
==================>
Step: 94380, Train_acc:0.979292
Step: 94380, Val_acc:0.962975
==================>
Step: 94390, Train_acc:0.982452
Step: 94390, Val_acc:0.933508
==================>
Step: 94400, Train_acc:0.986897
Step: 94400, Val_acc:0.961202
==================>
2017-11-12 10:24:08.600396 ---> Validation_loss: 0.130005
Step: 94410, Train_acc:0.980835
Step: 94410, Val_acc:0.935614
==================>
Step: 94420, Train_acc:0.98671
Step: 94420, Val_acc:0.946925
==================>
Step: 94430, Train_acc:0.987546
Step: 94430, Val_acc:0.934481
==================>
Step: 94440, Train_acc:0.986913
Step: 94440, Val_acc:0.943956
==================>
Step: 94450, Train_acc:0.987256
Step: 94450, Val_acc:0.947606
==================>
Step: 94460, Train_acc:0.983445
Step: 94460, Val_acc:0.954211
==================>
Step: 94470, Train_acc:0.982754
Step: 94470, Val_acc:0.967959
==================>
Step: 94480, Train_acc:0.986381
Step: 94480, Val_acc:0.957629
==================>
Step: 94490, Train_acc:0.987218
Step: 94490, Val_acc:0.970099
==================>
Step: 94500, Train_acc:0.98797
Step: 94500, Val_acc:0.965297
==================>
****************** Epochs completed: 189******************
2017-11-12 10:26:45.328096 ---> Validation_loss: 0.150201
Step: 94510, Train_acc:0.984871
Step: 94510, Val_acc:0.947523
==================>
Step: 94520, Train_acc:0.986097
Step: 94520, Val_acc:0.952678
==================>
Step: 94530, Train_acc:0.986117
Step: 94530, Val_acc:0.948993
==================>
Step: 94540, Train_acc:0.979604
Step: 94540, Val_acc:0.953722
==================>
Step: 94550, Train_acc:0.985088
Step: 94550, Val_acc:0.962439
==================>
Step: 94560, Train_acc:0.985874
Step: 94560, Val_acc:0.956069
==================>
Step: 94570, Train_acc:0.984362
Step: 94570, Val_acc:0.936702
==================>
Step: 94580, Train_acc:0.980903
Step: 94580, Val_acc:0.959647
==================>
Step: 94590, Train_acc:0.981416
Step: 94590, Val_acc:0.959645
==================>
Step: 94600, Train_acc:0.984962
Step: 94600, Val_acc:0.954519
==================>
2017-11-12 10:29:21.950759 ---> Validation_loss: 0.156097
Step: 94610, Train_acc:0.985934
Step: 94610, Val_acc:0.957168
==================>
Step: 94620, Train_acc:0.986575
Step: 94620, Val_acc:0.956648
==================>
Step: 94630, Train_acc:0.983783
Step: 94630, Val_acc:0.942223
==================>
Step: 94640, Train_acc:0.986046
Step: 94640, Val_acc:0.942021
==================>
Step: 94650, Train_acc:0.977236
Step: 94650, Val_acc:0.929867
==================>
Step: 94660, Train_acc:0.984301
Step: 94660, Val_acc:0.922545
==================>
Step: 94670, Train_acc:0.988271
Step: 94670, Val_acc:0.951414
==================>
Step: 94680, Train_acc:0.983422
Step: 94680, Val_acc:0.959279
==================>
Step: 94690, Train_acc:0.98194
Step: 94690, Val_acc:0.952246
==================>
Step: 94700, Train_acc:0.983531
Step: 94700, Val_acc:0.954503
==================>
2017-11-12 10:31:58.408348 ---> Validation_loss: 0.0925997
Step: 94710, Train_acc:0.987116
Step: 94710, Val_acc:0.944373
==================>
Step: 94720, Train_acc:0.987324
Step: 94720, Val_acc:0.938344
==================>
Step: 94730, Train_acc:0.979019
Step: 94730, Val_acc:0.950772
==================>
Step: 94740, Train_acc:0.988759
Step: 94740, Val_acc:0.939331
==================>
Step: 94750, Train_acc:0.984142
Step: 94750, Val_acc:0.956645
==================>
Step: 94760, Train_acc:0.992532
Step: 94760, Val_acc:0.951449
==================>
Step: 94770, Train_acc:0.985568
Step: 94770, Val_acc:0.949564
==================>
Step: 94780, Train_acc:0.990499
Step: 94780, Val_acc:0.952965
==================>
Step: 94790, Train_acc:0.981941
Step: 94790, Val_acc:0.937419
==================>
Step: 94800, Train_acc:0.987419
Step: 94800, Val_acc:0.955879
==================>
2017-11-12 10:34:34.900882 ---> Validation_loss: 0.115158
Step: 94810, Train_acc:0.987872
Step: 94810, Val_acc:0.949464
==================>
Step: 94820, Train_acc:0.977704
Step: 94820, Val_acc:0.962399
==================>
Step: 94830, Train_acc:0.98783
Step: 94830, Val_acc:0.954478
==================>
Step: 94840, Train_acc:0.990367
Step: 94840, Val_acc:0.969071
==================>
Step: 94850, Train_acc:0.976608
Step: 94850, Val_acc:0.94891
==================>
Step: 94860, Train_acc:0.988374
Step: 94860, Val_acc:0.961637
==================>
Step: 94870, Train_acc:0.982661
Step: 94870, Val_acc:0.957596
==================>
Step: 94880, Train_acc:0.984585
Step: 94880, Val_acc:0.943668
==================>
Step: 94890, Train_acc:0.985551
Step: 94890, Val_acc:0.947374
==================>
Step: 94900, Train_acc:0.988522
Step: 94900, Val_acc:0.940022
==================>
2017-11-12 10:37:11.388377 ---> Validation_loss: 0.155656
Step: 94910, Train_acc:0.985442
Step: 94910, Val_acc:0.969716
==================>
Step: 94920, Train_acc:0.98254
Step: 94920, Val_acc:0.951774
==================>
Step: 94930, Train_acc:0.987932
Step: 94930, Val_acc:0.94536
==================>
Step: 94940, Train_acc:0.983687
Step: 94940, Val_acc:0.964631
==================>
Step: 94950, Train_acc:0.978755
Step: 94950, Val_acc:0.966829
==================>
Step: 94960, Train_acc:0.986713
Step: 94960, Val_acc:0.942272
==================>
Step: 94970, Train_acc:0.984052
Step: 94970, Val_acc:0.941121
==================>
Step: 94980, Train_acc:0.981135
Step: 94980, Val_acc:0.952089
==================>
Step: 94990, Train_acc:0.982241
Step: 94990, Val_acc:0.953469
==================>
Step: 95000, Train_acc:0.986732
Step: 95000, Val_acc:0.930085
==================>
****************** Epochs completed: 190******************
2017-11-12 10:39:48.943811 ---> Validation_loss: 0.184289
Step: 95010, Train_acc:0.983391
Step: 95010, Val_acc:0.95786
==================>
Step: 95020, Train_acc:0.984701
Step: 95020, Val_acc:0.949144
==================>
Step: 95030, Train_acc:0.984221
Step: 95030, Val_acc:0.952209
==================>
Step: 95040, Train_acc:0.986556
Step: 95040, Val_acc:0.946362
==================>
Step: 95050, Train_acc:0.988768
Step: 95050, Val_acc:0.960454
==================>
Step: 95060, Train_acc:0.985498
Step: 95060, Val_acc:0.941913
==================>
Step: 95070, Train_acc:0.986062
Step: 95070, Val_acc:0.965806
==================>
Step: 95080, Train_acc:0.983501
Step: 95080, Val_acc:0.957997
==================>
Step: 95090, Train_acc:0.985178
Step: 95090, Val_acc:0.95381
==================>
Step: 95100, Train_acc:0.978987
Step: 95100, Val_acc:0.945587
==================>
2017-11-12 10:42:25.709031 ---> Validation_loss: 0.169418
Step: 95110, Train_acc:0.990494
Step: 95110, Val_acc:0.950797
==================>
Step: 95120, Train_acc:0.989086
Step: 95120, Val_acc:0.959661
==================>
Step: 95130, Train_acc:0.986754
Step: 95130, Val_acc:0.958542
==================>
Step: 95140, Train_acc:0.983059
Step: 95140, Val_acc:0.945416
==================>
Step: 95150, Train_acc:0.987764
Step: 95150, Val_acc:0.934825
==================>
Step: 95160, Train_acc:0.980424
Step: 95160, Val_acc:0.954139
==================>
Step: 95170, Train_acc:0.984375
Step: 95170, Val_acc:0.955052
==================>
Step: 95180, Train_acc:0.987979
Step: 95180, Val_acc:0.953848
==================>
Step: 95190, Train_acc:0.985756
Step: 95190, Val_acc:0.950764
==================>
Step: 95200, Train_acc:0.983618
Step: 95200, Val_acc:0.950134
==================>
2017-11-12 10:45:02.338967 ---> Validation_loss: 0.144006
Step: 95210, Train_acc:0.98278
Step: 95210, Val_acc:0.951815
==================>
Step: 95220, Train_acc:0.987987
Step: 95220, Val_acc:0.959751
==================>
Step: 95230, Train_acc:0.984728
Step: 95230, Val_acc:0.949586
==================>
Step: 95240, Train_acc:0.988206
Step: 95240, Val_acc:0.961804
==================>
Step: 95250, Train_acc:0.985657
Step: 95250, Val_acc:0.94725
==================>
Step: 95260, Train_acc:0.985181
Step: 95260, Val_acc:0.950017
==================>
Step: 95270, Train_acc:0.986038
Step: 95270, Val_acc:0.948732
==================>
Step: 95280, Train_acc:0.986244
Step: 95280, Val_acc:0.939862
==================>
Step: 95290, Train_acc:0.984698
Step: 95290, Val_acc:0.951837
==================>
Step: 95300, Train_acc:0.985171
Step: 95300, Val_acc:0.949922
==================>
2017-11-12 10:47:38.986793 ---> Validation_loss: 0.137247
Step: 95310, Train_acc:0.989539
Step: 95310, Val_acc:0.966615
==================>
Step: 95320, Train_acc:0.983103
Step: 95320, Val_acc:0.959818
==================>
Step: 95330, Train_acc:0.981822
Step: 95330, Val_acc:0.955371
==================>
Step: 95340, Train_acc:0.988001
Step: 95340, Val_acc:0.961738
==================>
Step: 95350, Train_acc:0.987271
Step: 95350, Val_acc:0.937993
==================>
Step: 95360, Train_acc:0.984612
Step: 95360, Val_acc:0.960612
==================>
Step: 95370, Train_acc:0.981276
Step: 95370, Val_acc:0.956329
==================>
Step: 95380, Train_acc:0.987936
Step: 95380, Val_acc:0.948475
==================>
Step: 95390, Train_acc:0.984301
Step: 95390, Val_acc:0.955867
==================>
Step: 95400, Train_acc:0.982297
Step: 95400, Val_acc:0.940869
==================>
2017-11-12 10:50:15.768681 ---> Validation_loss: 0.0869125
Step: 95410, Train_acc:0.984613
Step: 95410, Val_acc:0.952985
==================>
Step: 95420, Train_acc:0.977369
Step: 95420, Val_acc:0.958218
==================>
Step: 95430, Train_acc:0.984264
Step: 95430, Val_acc:0.951366
==================>
Step: 95440, Train_acc:0.986987
Step: 95440, Val_acc:0.951344
==================>
Step: 95450, Train_acc:0.987382
Step: 95450, Val_acc:0.953917
==================>
Step: 95460, Train_acc:0.976643
Step: 95460, Val_acc:0.953838
==================>
Step: 95470, Train_acc:0.987855
Step: 95470, Val_acc:0.935415
==================>
Step: 95480, Train_acc:0.985983
Step: 95480, Val_acc:0.950035
==================>
Step: 95490, Train_acc:0.983152
Step: 95490, Val_acc:0.949878
==================>
Step: 95500, Train_acc:0.984078
Step: 95500, Val_acc:0.96004
==================>
****************** Epochs completed: 191******************
2017-11-12 10:52:52.088292 ---> Validation_loss: 0.159782
Step: 95510, Train_acc:0.987324
Step: 95510, Val_acc:0.953427
==================>
Step: 95520, Train_acc:0.982282
Step: 95520, Val_acc:0.953037
==================>
Step: 95530, Train_acc:0.981025
Step: 95530, Val_acc:0.955983
==================>
Step: 95540, Train_acc:0.981061
Step: 95540, Val_acc:0.960759
==================>
Step: 95550, Train_acc:0.987097
Step: 95550, Val_acc:0.954651
==================>
Step: 95560, Train_acc:0.983894
Step: 95560, Val_acc:0.95295
==================>
Step: 95570, Train_acc:0.984701
Step: 95570, Val_acc:0.950974
==================>
Step: 95580, Train_acc:0.988082
Step: 95580, Val_acc:0.95197
==================>
Step: 95590, Train_acc:0.984102
Step: 95590, Val_acc:0.967046
==================>
Step: 95600, Train_acc:0.987621
Step: 95600, Val_acc:0.930544
==================>
2017-11-12 10:55:28.973659 ---> Validation_loss: 0.0863476
Step: 95610, Train_acc:0.98259
Step: 95610, Val_acc:0.954485
==================>
Step: 95620, Train_acc:0.983058
Step: 95620, Val_acc:0.956245
==================>
Step: 95630, Train_acc:0.979176
Step: 95630, Val_acc:0.962089
==================>
Step: 95640, Train_acc:0.986888
Step: 95640, Val_acc:0.957521
==================>
Step: 95650, Train_acc:0.983826
Step: 95650, Val_acc:0.95733
==================>
Step: 95660, Train_acc:0.981317
Step: 95660, Val_acc:0.940677
==================>
Step: 95670, Train_acc:0.984852
Step: 95670, Val_acc:0.959984
==================>
Step: 95680, Train_acc:0.988312
Step: 95680, Val_acc:0.966021
==================>
Step: 95690, Train_acc:0.97726
Step: 95690, Val_acc:0.948647
==================>
Step: 95700, Train_acc:0.981857
Step: 95700, Val_acc:0.944657
==================>
2017-11-12 10:58:05.676699 ---> Validation_loss: 0.190924
Step: 95710, Train_acc:0.990371
Step: 95710, Val_acc:0.95624
==================>
Step: 95720, Train_acc:0.985096
Step: 95720, Val_acc:0.947916
==================>
Step: 95730, Train_acc:0.982833
Step: 95730, Val_acc:0.946111
==================>
Step: 95740, Train_acc:0.9866
Step: 95740, Val_acc:0.958734
==================>
Step: 95750, Train_acc:0.989636
Step: 95750, Val_acc:0.941379
==================>
Step: 95760, Train_acc:0.987366
Step: 95760, Val_acc:0.947002
==================>
Step: 95770, Train_acc:0.985704
Step: 95770, Val_acc:0.939282
==================>
Step: 95780, Train_acc:0.987356
Step: 95780, Val_acc:0.940079
==================>
Step: 95790, Train_acc:0.984958
Step: 95790, Val_acc:0.945125
==================>
Step: 95800, Train_acc:0.983198
Step: 95800, Val_acc:0.930437
==================>
2017-11-12 11:00:42.447137 ---> Validation_loss: 0.172469
Step: 95810, Train_acc:0.98502
Step: 95810, Val_acc:0.940498
==================>
Step: 95820, Train_acc:0.98725
Step: 95820, Val_acc:0.958072
==================>
Step: 95830, Train_acc:0.985514
Step: 95830, Val_acc:0.956752
==================>
Step: 95840, Train_acc:0.989683
Step: 95840, Val_acc:0.954846
==================>
Step: 95850, Train_acc:0.979933
Step: 95850, Val_acc:0.947021
==================>
Step: 95860, Train_acc:0.982773
Step: 95860, Val_acc:0.953138
==================>
Step: 95870, Train_acc:0.980662
Step: 95870, Val_acc:0.930558
==================>
Step: 95880, Train_acc:0.981517
Step: 95880, Val_acc:0.954293
==================>
Step: 95890, Train_acc:0.989248
Step: 95890, Val_acc:0.939327
==================>
Step: 95900, Train_acc:0.981165
Step: 95900, Val_acc:0.929049
==================>
2017-11-12 11:03:19.184149 ---> Validation_loss: 0.151978
Step: 95910, Train_acc:0.985704
Step: 95910, Val_acc:0.956051
==================>
Step: 95920, Train_acc:0.98665
Step: 95920, Val_acc:0.943179
==================>
Step: 95930, Train_acc:0.982518
Step: 95930, Val_acc:0.943477
==================>
Step: 95940, Train_acc:0.987714
Step: 95940, Val_acc:0.936002
==================>
Step: 95950, Train_acc:0.979463
Step: 95950, Val_acc:0.94527
==================>
Step: 95960, Train_acc:0.983983
Step: 95960, Val_acc:0.951141
==================>
Step: 95970, Train_acc:0.989553
Step: 95970, Val_acc:0.960347
==================>
Step: 95980, Train_acc:0.984983
Step: 95980, Val_acc:0.93396
==================>
Step: 95990, Train_acc:0.984008
Step: 95990, Val_acc:0.952072
==================>
Step: 96000, Train_acc:0.980078
Step: 96000, Val_acc:0.9473
==================>
****************** Epochs completed: 192******************
2017-11-12 11:05:55.814019 ---> Validation_loss: 0.0932337
Step: 96010, Train_acc:0.984982
Step: 96010, Val_acc:0.941982
==================>
Step: 96020, Train_acc:0.980881
Step: 96020, Val_acc:0.946395
==================>
Step: 96030, Train_acc:0.982201
Step: 96030, Val_acc:0.946958
==================>
Step: 96040, Train_acc:0.985879
Step: 96040, Val_acc:0.956101
==================>
Step: 96050, Train_acc:0.987511
Step: 96050, Val_acc:0.954744
==================>
Step: 96060, Train_acc:0.982382
Step: 96060, Val_acc:0.959692
==================>
Step: 96070, Train_acc:0.984353
Step: 96070, Val_acc:0.957419
==================>
Step: 96080, Train_acc:0.987673
Step: 96080, Val_acc:0.94851
==================>
Step: 96090, Train_acc:0.989025
Step: 96090, Val_acc:0.95136
==================>
Step: 96100, Train_acc:0.984761
Step: 96100, Val_acc:0.956266
==================>
2017-11-12 11:08:32.434769 ---> Validation_loss: 0.172355
Step: 96110, Train_acc:0.982383
Step: 96110, Val_acc:0.926436
==================>
Step: 96120, Train_acc:0.984313
Step: 96120, Val_acc:0.959391
==================>
Step: 96130, Train_acc:0.981562
Step: 96130, Val_acc:0.958448
==================>
Step: 96140, Train_acc:0.981542
Step: 96140, Val_acc:0.941957
==================>
Step: 96150, Train_acc:0.981128
Step: 96150, Val_acc:0.941569
==================>
Step: 96160, Train_acc:0.987887
Step: 96160, Val_acc:0.970641
==================>
Step: 96170, Train_acc:0.983762
Step: 96170, Val_acc:0.955632
==================>
Step: 96180, Train_acc:0.985896
Step: 96180, Val_acc:0.95443
==================>
Step: 96190, Train_acc:0.985471
Step: 96190, Val_acc:0.964423
==================>
Step: 96200, Train_acc:0.986085
Step: 96200, Val_acc:0.954551
==================>
2017-11-12 11:11:09.147868 ---> Validation_loss: 0.153814
Step: 96210, Train_acc:0.983334
Step: 96210, Val_acc:0.936331
==================>
Step: 96220, Train_acc:0.985438
Step: 96220, Val_acc:0.941948
==================>
Step: 96230, Train_acc:0.987051
Step: 96230, Val_acc:0.941096
==================>
Step: 96240, Train_acc:0.98821
Step: 96240, Val_acc:0.969631
==================>
Step: 96250, Train_acc:0.980311
Step: 96250, Val_acc:0.946244
==================>
Step: 96260, Train_acc:0.983258
Step: 96260, Val_acc:0.958867
==================>
Step: 96270, Train_acc:0.982408
Step: 96270, Val_acc:0.956251
==================>
Step: 96280, Train_acc:0.984919
Step: 96280, Val_acc:0.954229
==================>
Step: 96290, Train_acc:0.987881
Step: 96290, Val_acc:0.962638
==================>
Step: 96300, Train_acc:0.980197
Step: 96300, Val_acc:0.95879
==================>
2017-11-12 11:13:45.495063 ---> Validation_loss: 0.108651
Step: 96310, Train_acc:0.98532
Step: 96310, Val_acc:0.947046
==================>
Step: 96320, Train_acc:0.986758
Step: 96320, Val_acc:0.964567
==================>
Step: 96330, Train_acc:0.988474
Step: 96330, Val_acc:0.924562
==================>
Step: 96340, Train_acc:0.982341
Step: 96340, Val_acc:0.953855
==================>
Step: 96350, Train_acc:0.985972
Step: 96350, Val_acc:0.966898
==================>
Step: 96360, Train_acc:0.983832
Step: 96360, Val_acc:0.942629
==================>
Step: 96370, Train_acc:0.983739
Step: 96370, Val_acc:0.946855
==================>
Step: 96380, Train_acc:0.982936
Step: 96380, Val_acc:0.958394
==================>
Step: 96390, Train_acc:0.989067
Step: 96390, Val_acc:0.949161
==================>
Step: 96400, Train_acc:0.980101
Step: 96400, Val_acc:0.941366
==================>
2017-11-12 11:16:22.088839 ---> Validation_loss: 0.184819
Step: 96410, Train_acc:0.983507
Step: 96410, Val_acc:0.956195
==================>
Step: 96420, Train_acc:0.985458
Step: 96420, Val_acc:0.970873
==================>
Step: 96430, Train_acc:0.98291
Step: 96430, Val_acc:0.942223
==================>
Step: 96440, Train_acc:0.98647
Step: 96440, Val_acc:0.951267
==================>
Step: 96450, Train_acc:0.990309
Step: 96450, Val_acc:0.956643
==================>
Step: 96460, Train_acc:0.984564
Step: 96460, Val_acc:0.905996
==================>
Step: 96470, Train_acc:0.984022
Step: 96470, Val_acc:0.956361
==================>
Step: 96480, Train_acc:0.988879
Step: 96480, Val_acc:0.957325
==================>
Step: 96490, Train_acc:0.981736
Step: 96490, Val_acc:0.962971
==================>
Step: 96500, Train_acc:0.987219
Step: 96500, Val_acc:0.967186
==================>
****************** Epochs completed: 193******************
2017-11-12 11:18:58.740575 ---> Validation_loss: 0.103899
Step: 96510, Train_acc:0.979327
Step: 96510, Val_acc:0.938848
==================>
Step: 96520, Train_acc:0.98797
Step: 96520, Val_acc:0.948832
==================>
Step: 96530, Train_acc:0.984841
Step: 96530, Val_acc:0.965547
==================>
Step: 96540, Train_acc:0.983004
Step: 96540, Val_acc:0.948915
==================>
Step: 96550, Train_acc:0.985515
Step: 96550, Val_acc:0.956638
==================>
Step: 96560, Train_acc:0.987654
Step: 96560, Val_acc:0.902847
==================>
Step: 96570, Train_acc:0.980966
Step: 96570, Val_acc:0.943921
==================>
Step: 96580, Train_acc:0.985298
Step: 96580, Val_acc:0.952294
==================>
Step: 96590, Train_acc:0.987577
Step: 96590, Val_acc:0.944605
==================>
Step: 96600, Train_acc:0.983654
Step: 96600, Val_acc:0.94412
==================>
2017-11-12 11:21:35.461863 ---> Validation_loss: 0.0871153
Step: 96610, Train_acc:0.982805
Step: 96610, Val_acc:0.948267
==================>
Step: 96620, Train_acc:0.985306
Step: 96620, Val_acc:0.951344
==================>
Step: 96630, Train_acc:0.987095
Step: 96630, Val_acc:0.920405
==================>
Step: 96640, Train_acc:0.985386
Step: 96640, Val_acc:0.955123
==================>
Step: 96650, Train_acc:0.98979
Step: 96650, Val_acc:0.96743
==================>
Step: 96660, Train_acc:0.990145
Step: 96660, Val_acc:0.945499
==================>
Step: 96670, Train_acc:0.988889
Step: 96670, Val_acc:0.960256
==================>
Step: 96680, Train_acc:0.986628
Step: 96680, Val_acc:0.954536
==================>
Step: 96690, Train_acc:0.986151
Step: 96690, Val_acc:0.954299
==================>
Step: 96700, Train_acc:0.98625
Step: 96700, Val_acc:0.94895
==================>
2017-11-12 11:24:11.941077 ---> Validation_loss: 0.165329
Step: 96710, Train_acc:0.986539
Step: 96710, Val_acc:0.931013
==================>
Step: 96720, Train_acc:0.983225
Step: 96720, Val_acc:0.946398
==================>
Step: 96730, Train_acc:0.985172
Step: 96730, Val_acc:0.960079
==================>
Step: 96740, Train_acc:0.987814
Step: 96740, Val_acc:0.95097
==================>
Step: 96750, Train_acc:0.978749
Step: 96750, Val_acc:0.954288
==================>
Step: 96760, Train_acc:0.981383
Step: 96760, Val_acc:0.938058
==================>
Step: 96770, Train_acc:0.988167
Step: 96770, Val_acc:0.940053
==================>
Step: 96780, Train_acc:0.981687
Step: 96780, Val_acc:0.941813
==================>
Step: 96790, Train_acc:0.982086
Step: 96790, Val_acc:0.960221
==================>
Step: 96800, Train_acc:0.984205
Step: 96800, Val_acc:0.94618
==================>
2017-11-12 11:26:48.774984 ---> Validation_loss: 0.136744
Step: 96810, Train_acc:0.982628
Step: 96810, Val_acc:0.934557
==================>
Step: 96820, Train_acc:0.984261
Step: 96820, Val_acc:0.942582
==================>
Step: 96830, Train_acc:0.988766
Step: 96830, Val_acc:0.962627
==================>
Step: 96840, Train_acc:0.989104
Step: 96840, Val_acc:0.95179
==================>
Step: 96850, Train_acc:0.987831
Step: 96850, Val_acc:0.959839
==================>
Step: 96860, Train_acc:0.986038
Step: 96860, Val_acc:0.95624
==================>
Step: 96870, Train_acc:0.990914
Step: 96870, Val_acc:0.968435
==================>
Step: 96880, Train_acc:0.987211
Step: 96880, Val_acc:0.958475
==================>
Step: 96890, Train_acc:0.989595
Step: 96890, Val_acc:0.962623
==================>
Step: 96900, Train_acc:0.98703
Step: 96900, Val_acc:0.932971
==================>
2017-11-12 11:29:25.512762 ---> Validation_loss: 0.141067
Step: 96910, Train_acc:0.986824
Step: 96910, Val_acc:0.959128
==================>
Step: 96920, Train_acc:0.98843
Step: 96920, Val_acc:0.946716
==================>
Step: 96930, Train_acc:0.986135
Step: 96930, Val_acc:0.938151
==================>
Step: 96940, Train_acc:0.979227
Step: 96940, Val_acc:0.95428
==================>
Step: 96950, Train_acc:0.981583
Step: 96950, Val_acc:0.948636
==================>
Step: 96960, Train_acc:0.983436
Step: 96960, Val_acc:0.96561
==================>
Step: 96970, Train_acc:0.985225
Step: 96970, Val_acc:0.948058
==================>
Step: 96980, Train_acc:0.988932
Step: 96980, Val_acc:0.945751
==================>
Step: 96990, Train_acc:0.977998
Step: 96990, Val_acc:0.958123
==================>
Step: 97000, Train_acc:0.987863
Step: 97000, Val_acc:0.939636
==================>
****************** Epochs completed: 194******************
2017-11-12 11:32:02.010078 ---> Validation_loss: 0.144954
Step: 97010, Train_acc:0.984943
Step: 97010, Val_acc:0.946493
==================>
Step: 97020, Train_acc:0.984817
Step: 97020, Val_acc:0.956012
==================>
Step: 97030, Train_acc:0.987136
Step: 97030, Val_acc:0.960732
==================>
Step: 97040, Train_acc:0.978966
Step: 97040, Val_acc:0.960107
==================>
Step: 97050, Train_acc:0.983929
Step: 97050, Val_acc:0.952446
==================>
Step: 97060, Train_acc:0.984402
Step: 97060, Val_acc:0.926008
==================>
Step: 97070, Train_acc:0.983888
Step: 97070, Val_acc:0.932205
==================>
Step: 97080, Train_acc:0.983978
Step: 97080, Val_acc:0.941254
==================>
Step: 97090, Train_acc:0.987035
Step: 97090, Val_acc:0.947534
==================>
Step: 97100, Train_acc:0.987009
Step: 97100, Val_acc:0.950024
==================>
2017-11-12 11:34:38.716113 ---> Validation_loss: 0.123659
Step: 97110, Train_acc:0.987194
Step: 97110, Val_acc:0.944529
==================>
Step: 97120, Train_acc:0.986206
Step: 97120, Val_acc:0.956243
==================>
Step: 97130, Train_acc:0.985444
Step: 97130, Val_acc:0.947004
==================>
Step: 97140, Train_acc:0.982915
Step: 97140, Val_acc:0.947003
==================>
Step: 97150, Train_acc:0.986891
Step: 97150, Val_acc:0.958899
==================>
Step: 97160, Train_acc:0.989794
Step: 97160, Val_acc:0.965127
==================>
Step: 97170, Train_acc:0.985573
Step: 97170, Val_acc:0.941305
==================>
Step: 97180, Train_acc:0.976135
Step: 97180, Val_acc:0.922111
==================>
Step: 97190, Train_acc:0.988317
Step: 97190, Val_acc:0.959214
==================>
Step: 97200, Train_acc:0.984387
Step: 97200, Val_acc:0.951431
==================>
2017-11-12 11:37:15.424056 ---> Validation_loss: 0.138454
Step: 97210, Train_acc:0.982787
Step: 97210, Val_acc:0.958615
==================>
Step: 97220, Train_acc:0.983234
Step: 97220, Val_acc:0.953906
==================>
Step: 97230, Train_acc:0.98412
Step: 97230, Val_acc:0.961428
==================>
Step: 97240, Train_acc:0.98101
Step: 97240, Val_acc:0.958721
==================>
Step: 97250, Train_acc:0.988315
Step: 97250, Val_acc:0.951396
==================>
Step: 97260, Train_acc:0.981824
Step: 97260, Val_acc:0.94963
==================>
Step: 97270, Train_acc:0.984393
Step: 97270, Val_acc:0.951346
==================>
Step: 97280, Train_acc:0.984327
Step: 97280, Val_acc:0.954148
==================>
Step: 97290, Train_acc:0.983905
Step: 97290, Val_acc:0.939788
==================>
Step: 97300, Train_acc:0.983319
Step: 97300, Val_acc:0.950493
==================>
2017-11-12 11:39:51.724165 ---> Validation_loss: 0.122293
Step: 97310, Train_acc:0.985387
Step: 97310, Val_acc:0.937079
==================>
Step: 97320, Train_acc:0.98553
Step: 97320, Val_acc:0.949177
==================>
Step: 97330, Train_acc:0.985051
Step: 97330, Val_acc:0.946821
==================>
Step: 97340, Train_acc:0.983412
Step: 97340, Val_acc:0.952373
==================>
Step: 97350, Train_acc:0.986893
Step: 97350, Val_acc:0.949872
==================>
Step: 97360, Train_acc:0.98365
Step: 97360, Val_acc:0.965863
==================>
Step: 97370, Train_acc:0.984717
Step: 97370, Val_acc:0.93866
==================>
Step: 97380, Train_acc:0.985161
Step: 97380, Val_acc:0.950555
==================>
Step: 97390, Train_acc:0.984917
Step: 97390, Val_acc:0.959744
==================>
Step: 97400, Train_acc:0.982843
Step: 97400, Val_acc:0.951755
==================>
2017-11-12 11:42:28.458832 ---> Validation_loss: 0.17241
Step: 97410, Train_acc:0.981771
Step: 97410, Val_acc:0.949712
==================>
Step: 97420, Train_acc:0.983068
Step: 97420, Val_acc:0.951992
==================>
Step: 97430, Train_acc:0.990105
Step: 97430, Val_acc:0.950494
==================>
Step: 97440, Train_acc:0.986749
Step: 97440, Val_acc:0.923042
==================>
Step: 97450, Train_acc:0.986003
Step: 97450, Val_acc:0.946794
==================>
Step: 97460, Train_acc:0.984502
Step: 97460, Val_acc:0.948136
==================>
Step: 97470, Train_acc:0.979541
Step: 97470, Val_acc:0.96652
==================>
Step: 97480, Train_acc:0.977567
Step: 97480, Val_acc:0.961024
==================>
Step: 97490, Train_acc:0.98639
Step: 97490, Val_acc:0.947153
==================>
Step: 97500, Train_acc:0.983988
Step: 97500, Val_acc:0.941371
==================>
****************** Epochs completed: 195******************
2017-11-12 11:45:05.245392 ---> Validation_loss: 0.130601
Step: 97510, Train_acc:0.987968
Step: 97510, Val_acc:0.932412
==================>
Step: 97520, Train_acc:0.987053
Step: 97520, Val_acc:0.955453
==================>
Step: 97530, Train_acc:0.983547
Step: 97530, Val_acc:0.949454
==================>
Step: 97540, Train_acc:0.983368
Step: 97540, Val_acc:0.960449
==================>
Step: 97550, Train_acc:0.981746
Step: 97550, Val_acc:0.943035
==================>
****************** Epochs completed: 29******************
Step: 97560, Train_acc:0.987278
Step: 97560, Val_acc:0.931986
==================>
Step: 97570, Train_acc:0.982789
Step: 97570, Val_acc:0.954879
==================>
Step: 97580, Train_acc:0.980856
Step: 97580, Val_acc:0.946965
==================>
Step: 97590, Train_acc:0.985962
Step: 97590, Val_acc:0.944618
==================>
Step: 97600, Train_acc:0.987427
Step: 97600, Val_acc:0.944504
==================>
2017-11-12 11:47:41.603187 ---> Validation_loss: 0.134395
Step: 97610, Train_acc:0.987407
Step: 97610, Val_acc:0.935272
==================>
Step: 97620, Train_acc:0.979999
Step: 97620, Val_acc:0.958862
==================>
Step: 97630, Train_acc:0.989836
Step: 97630, Val_acc:0.95209
==================>
Step: 97640, Train_acc:0.986067
Step: 97640, Val_acc:0.953279
==================>
Step: 97650, Train_acc:0.983082
Step: 97650, Val_acc:0.945078
==================>
Step: 97660, Train_acc:0.984601
Step: 97660, Val_acc:0.94759
==================>
Step: 97670, Train_acc:0.983204
Step: 97670, Val_acc:0.958066
==================>
Step: 97680, Train_acc:0.984136
Step: 97680, Val_acc:0.947817
==================>
Step: 97690, Train_acc:0.982882
Step: 97690, Val_acc:0.948103
==================>
Step: 97700, Train_acc:0.989098
Step: 97700, Val_acc:0.951461
==================>
2017-11-12 11:50:17.692872 ---> Validation_loss: 0.220596
Step: 97710, Train_acc:0.983651
Step: 97710, Val_acc:0.938666
==================>
Step: 97720, Train_acc:0.985881
Step: 97720, Val_acc:0.950917
==================>
Step: 97730, Train_acc:0.986683
Step: 97730, Val_acc:0.953752
==================>
Step: 97740, Train_acc:0.989851
Step: 97740, Val_acc:0.931386
==================>
Step: 97750, Train_acc:0.981913
Step: 97750, Val_acc:0.938573
==================>
Step: 97760, Train_acc:0.980621
Step: 97760, Val_acc:0.962179
==================>
Step: 97770, Train_acc:0.98582
Step: 97770, Val_acc:0.96017
==================>
Step: 97780, Train_acc:0.982572
Step: 97780, Val_acc:0.958533
==================>
Step: 97790, Train_acc:0.983654
Step: 97790, Val_acc:0.93845
==================>
Step: 97800, Train_acc:0.99078
Step: 97800, Val_acc:0.957438
==================>
2017-11-12 11:52:53.949125 ---> Validation_loss: 0.146674
Step: 97810, Train_acc:0.982545
Step: 97810, Val_acc:0.951169
==================>
Step: 97820, Train_acc:0.984249
Step: 97820, Val_acc:0.964277
==================>
Step: 97830, Train_acc:0.984908
Step: 97830, Val_acc:0.960515
==================>
Step: 97840, Train_acc:0.988876
Step: 97840, Val_acc:0.952295
==================>
Step: 97850, Train_acc:0.9799
Step: 97850, Val_acc:0.953718
==================>
Step: 97860, Train_acc:0.988192
Step: 97860, Val_acc:0.942643
==================>
Step: 97870, Train_acc:0.987574
Step: 97870, Val_acc:0.942683
==================>
Step: 97880, Train_acc:0.984362
Step: 97880, Val_acc:0.948401
==================>
Step: 97890, Train_acc:0.984722
Step: 97890, Val_acc:0.942822
==================>
Step: 97900, Train_acc:0.991772
Step: 97900, Val_acc:0.928882
==================>
2017-11-12 11:55:30.505056 ---> Validation_loss: 0.0843745
Step: 97910, Train_acc:0.990447
Step: 97910, Val_acc:0.945463
==================>
Step: 97920, Train_acc:0.982025
Step: 97920, Val_acc:0.953298
==================>
Step: 97930, Train_acc:0.984586
Step: 97930, Val_acc:0.942041
==================>
Step: 97940, Train_acc:0.9839
Step: 97940, Val_acc:0.939933
==================>
Step: 97950, Train_acc:0.987328
Step: 97950, Val_acc:0.949135
==================>
Step: 97960, Train_acc:0.989027
Step: 97960, Val_acc:0.926145
==================>
Step: 97970, Train_acc:0.986342
Step: 97970, Val_acc:0.951794
==================>
Step: 97980, Train_acc:0.988326
Step: 97980, Val_acc:0.969388
==================>
Step: 97990, Train_acc:0.98504
Step: 97990, Val_acc:0.931511
==================>
Step: 98000, Train_acc:0.982134
Step: 98000, Val_acc:0.935626
==================>
****************** Epochs completed: 196******************
2017-11-12 11:58:06.692449 ---> Validation_loss: 0.068707
Step: 98010, Train_acc:0.987037
Step: 98010, Val_acc:0.958309
==================>
Step: 98020, Train_acc:0.98767
Step: 98020, Val_acc:0.960194
==================>
Step: 98030, Train_acc:0.983627
Step: 98030, Val_acc:0.949595
==================>
Step: 98040, Train_acc:0.98187
Step: 98040, Val_acc:0.9523
==================>
Step: 98050, Train_acc:0.98319
Step: 98050, Val_acc:0.934581
==================>
Step: 98060, Train_acc:0.986472
Step: 98060, Val_acc:0.950498
==================>
Step: 98070, Train_acc:0.983966
Step: 98070, Val_acc:0.950392
==================>
Step: 98080, Train_acc:0.982943
Step: 98080, Val_acc:0.944702
==================>
Step: 98090, Train_acc:0.985049
Step: 98090, Val_acc:0.943129
==================>
Step: 98100, Train_acc:0.984553
Step: 98100, Val_acc:0.972139
==================>
2017-11-12 12:00:42.989947 ---> Validation_loss: 0.159587
Step: 98110, Train_acc:0.986558
Step: 98110, Val_acc:0.947769
==================>
Step: 98120, Train_acc:0.984573
Step: 98120, Val_acc:0.96153
==================>
Step: 98130, Train_acc:0.981886
Step: 98130, Val_acc:0.949591
==================>
Step: 98140, Train_acc:0.987891
Step: 98140, Val_acc:0.934103
==================>
Step: 98150, Train_acc:0.983315
Step: 98150, Val_acc:0.946552
==================>
Step: 98160, Train_acc:0.982777
Step: 98160, Val_acc:0.954088
==================>
Step: 98170, Train_acc:0.986168
Step: 98170, Val_acc:0.93796
==================>
Step: 98180, Train_acc:0.983917
Step: 98180, Val_acc:0.956504
==================>
Step: 98190, Train_acc:0.981306
Step: 98190, Val_acc:0.964073
==================>
Step: 98200, Train_acc:0.985563
Step: 98200, Val_acc:0.961221
==================>
2017-11-12 12:03:19.602437 ---> Validation_loss: 0.155125
Step: 98210, Train_acc:0.980736
Step: 98210, Val_acc:0.960753
==================>
Step: 98220, Train_acc:0.983469
Step: 98220, Val_acc:0.95116
==================>
Step: 98230, Train_acc:0.990393
Step: 98230, Val_acc:0.952598
==================>
Step: 98240, Train_acc:0.984668
Step: 98240, Val_acc:0.954666
==================>
Step: 98250, Train_acc:0.98526
Step: 98250, Val_acc:0.940433
==================>
Step: 98260, Train_acc:0.983995
Step: 98260, Val_acc:0.951036
==================>
Step: 98270, Train_acc:0.983911
Step: 98270, Val_acc:0.955999
==================>
Step: 98280, Train_acc:0.979219
Step: 98280, Val_acc:0.959329
==================>
Step: 98290, Train_acc:0.987727
Step: 98290, Val_acc:0.952616
==================>
Step: 98300, Train_acc:0.980774
Step: 98300, Val_acc:0.954392
==================>
2017-11-12 12:05:56.231442 ---> Validation_loss: 0.111738
Step: 98310, Train_acc:0.985
Step: 98310, Val_acc:0.944462
==================>
Step: 98320, Train_acc:0.984407
Step: 98320, Val_acc:0.959761
==================>
Step: 98330, Train_acc:0.988569
Step: 98330, Val_acc:0.955227
==================>
Step: 98340, Train_acc:0.98349
Step: 98340, Val_acc:0.935155
==================>
Step: 98350, Train_acc:0.983802
Step: 98350, Val_acc:0.945068
==================>
Step: 98360, Train_acc:0.984242
Step: 98360, Val_acc:0.946971
==================>
Step: 98370, Train_acc:0.987731
Step: 98370, Val_acc:0.956327
==================>
Step: 98380, Train_acc:0.986312
Step: 98380, Val_acc:0.956704
==================>
Step: 98390, Train_acc:0.987393
Step: 98390, Val_acc:0.951248
==================>
Step: 98400, Train_acc:0.986593
Step: 98400, Val_acc:0.934631
==================>
2017-11-12 12:08:32.804403 ---> Validation_loss: 0.158364
Step: 98410, Train_acc:0.987733
Step: 98410, Val_acc:0.956627
==================>
Step: 98420, Train_acc:0.984242
Step: 98420, Val_acc:0.930737
==================>
Step: 98430, Train_acc:0.985225
Step: 98430, Val_acc:0.95705
==================>
Step: 98440, Train_acc:0.983823
Step: 98440, Val_acc:0.945653
==================>
Step: 98450, Train_acc:0.982706
Step: 98450, Val_acc:0.942023
==================>
Step: 98460, Train_acc:0.985697
Step: 98460, Val_acc:0.935387
==================>
Step: 98470, Train_acc:0.985769
Step: 98470, Val_acc:0.938134
==================>
Step: 98480, Train_acc:0.983531
Step: 98480, Val_acc:0.937173
==================>
Step: 98490, Train_acc:0.982888
Step: 98490, Val_acc:0.938801
==================>
Step: 98500, Train_acc:0.98397
Step: 98500, Val_acc:0.949841
==================>
****************** Epochs completed: 197******************
2017-11-12 12:11:09.380626 ---> Validation_loss: 0.103
Step: 98510, Train_acc:0.988087
Step: 98510, Val_acc:0.947869
==================>
Step: 98520, Train_acc:0.981306
Step: 98520, Val_acc:0.959037
==================>
Step: 98530, Train_acc:0.985044
Step: 98530, Val_acc:0.958647
==================>
Step: 98540, Train_acc:0.986566
Step: 98540, Val_acc:0.961096
==================>
Step: 98550, Train_acc:0.983036
Step: 98550, Val_acc:0.934833
==================>
Step: 98560, Train_acc:0.985432
Step: 98560, Val_acc:0.934952
==================>
Step: 98570, Train_acc:0.982043
Step: 98570, Val_acc:0.967461
==================>
Step: 98580, Train_acc:0.985051
Step: 98580, Val_acc:0.95465
==================>
Step: 98590, Train_acc:0.987495
Step: 98590, Val_acc:0.950475
==================>
Step: 98600, Train_acc:0.982634
Step: 98600, Val_acc:0.95025
==================>
2017-11-12 12:13:45.888736 ---> Validation_loss: 0.187933
Step: 98610, Train_acc:0.986881
Step: 98610, Val_acc:0.961099
==================>
Step: 98620, Train_acc:0.985596
Step: 98620, Val_acc:0.953071
==================>
Step: 98630, Train_acc:0.986892
Step: 98630, Val_acc:0.954484
==================>
Step: 98640, Train_acc:0.981381
Step: 98640, Val_acc:0.949869
==================>
Step: 98650, Train_acc:0.980344
Step: 98650, Val_acc:0.93198
==================>
Step: 98660, Train_acc:0.985756
Step: 98660, Val_acc:0.953304
==================>
Step: 98670, Train_acc:0.983157
Step: 98670, Val_acc:0.956627
==================>
Step: 98680, Train_acc:0.98627
Step: 98680, Val_acc:0.939399
==================>
Step: 98690, Train_acc:0.977413
Step: 98690, Val_acc:0.957538
==================>
Step: 98700, Train_acc:0.983761
Step: 98700, Val_acc:0.963798
==================>
2017-11-12 12:16:22.473490 ---> Validation_loss: 0.132602
Step: 98710, Train_acc:0.987664
Step: 98710, Val_acc:0.939017
==================>
Step: 98720, Train_acc:0.986696
Step: 98720, Val_acc:0.960584
==================>
Step: 98730, Train_acc:0.989104
Step: 98730, Val_acc:0.967911
==================>
Step: 98740, Train_acc:0.983123
Step: 98740, Val_acc:0.954703
==================>
Step: 98750, Train_acc:0.986637
Step: 98750, Val_acc:0.932253
==================>
Step: 98760, Train_acc:0.9795
Step: 98760, Val_acc:0.940082
==================>
Step: 98770, Train_acc:0.987017
Step: 98770, Val_acc:0.957269
==================>
Step: 98780, Train_acc:0.981213
Step: 98780, Val_acc:0.954128
==================>
Step: 98790, Train_acc:0.98391
Step: 98790, Val_acc:0.953791
==================>
Step: 98800, Train_acc:0.985233
Step: 98800, Val_acc:0.919731
==================>
2017-11-12 12:18:58.977133 ---> Validation_loss: 0.129756
Step: 98810, Train_acc:0.987909
Step: 98810, Val_acc:0.941816
==================>
Step: 98820, Train_acc:0.984326
Step: 98820, Val_acc:0.954102
==================>
Step: 98830, Train_acc:0.988378
Step: 98830, Val_acc:0.953553
==================>
Step: 98840, Train_acc:0.985167
Step: 98840, Val_acc:0.944585
==================>
Step: 98850, Train_acc:0.987423
Step: 98850, Val_acc:0.967377
==================>
Step: 98860, Train_acc:0.987983
Step: 98860, Val_acc:0.94382
==================>
Step: 98870, Train_acc:0.984299
Step: 98870, Val_acc:0.95234
==================>
Step: 98880, Train_acc:0.984396
Step: 98880, Val_acc:0.951478
==================>
Step: 98890, Train_acc:0.987698
Step: 98890, Val_acc:0.951553
==================>
Step: 98900, Train_acc:0.983789
Step: 98900, Val_acc:0.929817
==================>
2017-11-12 12:21:35.382993 ---> Validation_loss: 0.173735
Step: 98910, Train_acc:0.988928
Step: 98910, Val_acc:0.92959
==================>
Step: 98920, Train_acc:0.984631
Step: 98920, Val_acc:0.95381
==================>
Step: 98930, Train_acc:0.989122
Step: 98930, Val_acc:0.943639
==================>
Step: 98940, Train_acc:0.986895
Step: 98940, Val_acc:0.955032
==================>
Step: 98950, Train_acc:0.980933
Step: 98950, Val_acc:0.950565
==================>
Step: 98960, Train_acc:0.98262
Step: 98960, Val_acc:0.937839
==================>
Step: 98970, Train_acc:0.987412
Step: 98970, Val_acc:0.952126
==================>
Step: 98980, Train_acc:0.989028
Step: 98980, Val_acc:0.9486
==================>
Step: 98990, Train_acc:0.988613
Step: 98990, Val_acc:0.944922
==================>
Step: 99000, Train_acc:0.986807
Step: 99000, Val_acc:0.950394
==================>
****************** Epochs completed: 198******************
2017-11-12 12:24:11.834726 ---> Validation_loss: 0.190431
Step: 99010, Train_acc:0.984054
Step: 99010, Val_acc:0.933062
==================>
Step: 99020, Train_acc:0.98269
Step: 99020, Val_acc:0.953461
==================>
Step: 99030, Train_acc:0.98301
Step: 99030, Val_acc:0.960546
==================>
Step: 99040, Train_acc:0.985092
Step: 99040, Val_acc:0.953334
==================>
Step: 99050, Train_acc:0.98119
Step: 99050, Val_acc:0.945367
==================>
Step: 99060, Train_acc:0.988433
Step: 99060, Val_acc:0.941284
==================>
Step: 99070, Train_acc:0.988845
Step: 99070, Val_acc:0.954548
==================>
Step: 99080, Train_acc:0.983104
Step: 99080, Val_acc:0.954304
==================>
Step: 99090, Train_acc:0.986879
Step: 99090, Val_acc:0.948057
==================>
Step: 99100, Train_acc:0.981176
Step: 99100, Val_acc:0.953367
==================>
2017-11-12 12:26:48.232436 ---> Validation_loss: 0.09107
Step: 99110, Train_acc:0.986588
Step: 99110, Val_acc:0.918343
==================>
Step: 99120, Train_acc:0.985826
Step: 99120, Val_acc:0.956304
==================>
Step: 99130, Train_acc:0.985763
Step: 99130, Val_acc:0.964106
==================>
Step: 99140, Train_acc:0.981958
Step: 99140, Val_acc:0.949924
==================>
Step: 99150, Train_acc:0.985551
Step: 99150, Val_acc:0.936121
==================>
Step: 99160, Train_acc:0.986329
Step: 99160, Val_acc:0.959939
==================>
Step: 99170, Train_acc:0.984059
Step: 99170, Val_acc:0.937543
==================>
Step: 99180, Train_acc:0.988384
Step: 99180, Val_acc:0.951549
==================>
Step: 99190, Train_acc:0.987819
Step: 99190, Val_acc:0.962415
==================>
Step: 99200, Train_acc:0.98626
Step: 99200, Val_acc:0.966692
==================>
2017-11-12 12:29:24.646364 ---> Validation_loss: 0.201968
Step: 99210, Train_acc:0.982627
Step: 99210, Val_acc:0.942748
==================>
Step: 99220, Train_acc:0.983867
Step: 99220, Val_acc:0.935609
==================>
Step: 99230, Train_acc:0.986801
Step: 99230, Val_acc:0.944263
==================>
Step: 99240, Train_acc:0.989537
Step: 99240, Val_acc:0.93713
==================>
Step: 99250, Train_acc:0.989177
Step: 99250, Val_acc:0.923568
==================>
Step: 99260, Train_acc:0.988165
Step: 99260, Val_acc:0.958597
==================>
Step: 99270, Train_acc:0.98672
Step: 99270, Val_acc:0.933618
==================>
Step: 99280, Train_acc:0.988341
Step: 99280, Val_acc:0.948163
==================>
Step: 99290, Train_acc:0.983105
Step: 99290, Val_acc:0.944605
==================>
Step: 99300, Train_acc:0.985881
Step: 99300, Val_acc:0.963704
==================>
2017-11-12 12:32:01.013193 ---> Validation_loss: 0.122978
Step: 99310, Train_acc:0.981942
Step: 99310, Val_acc:0.931764
==================>
Step: 99320, Train_acc:0.985007
Step: 99320, Val_acc:0.93519
==================>
Step: 99330, Train_acc:0.980848
Step: 99330, Val_acc:0.943378
==================>
Step: 99340, Train_acc:0.98043
Step: 99340, Val_acc:0.960658
==================>
Step: 99350, Train_acc:0.986066
Step: 99350, Val_acc:0.945192
==================>
Step: 99360, Train_acc:0.983066
Step: 99360, Val_acc:0.929816
==================>
Step: 99370, Train_acc:0.983768
Step: 99370, Val_acc:0.966536
==================>
Step: 99380, Train_acc:0.984696
Step: 99380, Val_acc:0.949653
==================>
Step: 99390, Train_acc:0.981639
Step: 99390, Val_acc:0.960321
==================>
Step: 99400, Train_acc:0.987048
Step: 99400, Val_acc:0.945752
==================>
2017-11-12 12:34:37.380517 ---> Validation_loss: 0.116839
Step: 99410, Train_acc:0.984735
Step: 99410, Val_acc:0.940692
==================>
Step: 99420, Train_acc:0.986357
Step: 99420, Val_acc:0.953361
==================>
Step: 99430, Train_acc:0.982788
Step: 99430, Val_acc:0.946321
==================>
Step: 99440, Train_acc:0.98488
Step: 99440, Val_acc:0.953666
==================>
Step: 99450, Train_acc:0.986394
Step: 99450, Val_acc:0.944655
==================>
Step: 99460, Train_acc:0.984255
Step: 99460, Val_acc:0.944326
==================>
Step: 99470, Train_acc:0.983762
Step: 99470, Val_acc:0.952205
==================>
Step: 99480, Train_acc:0.987707
Step: 99480, Val_acc:0.959768
==================>
Step: 99490, Train_acc:0.983878
Step: 99490, Val_acc:0.941243
==================>
Step: 99500, Train_acc:0.986367
Step: 99500, Val_acc:0.961888
==================>
****************** Epochs completed: 199******************
2017-11-12 12:37:13.886633 ---> Validation_loss: 0.104821
Step: 99510, Train_acc:0.982421
Step: 99510, Val_acc:0.94434
==================>
Step: 99520, Train_acc:0.98416
Step: 99520, Val_acc:0.951418
==================>
Step: 99530, Train_acc:0.986265
Step: 99530, Val_acc:0.945562
==================>
Step: 99540, Train_acc:0.98183
Step: 99540, Val_acc:0.945311
==================>
Step: 99550, Train_acc:0.982471
Step: 99550, Val_acc:0.94231
==================>
Step: 99560, Train_acc:0.983297
Step: 99560, Val_acc:0.961787
==================>
Step: 99570, Train_acc:0.979893
Step: 99570, Val_acc:0.954012
==================>
Step: 99580, Train_acc:0.985667
Step: 99580, Val_acc:0.947677
==================>
Step: 99590, Train_acc:0.985537
Step: 99590, Val_acc:0.936016
==================>
Step: 99600, Train_acc:0.983684
Step: 99600, Val_acc:0.945482
==================>
2017-11-12 12:39:50.163657 ---> Validation_loss: 0.13427
Step: 99610, Train_acc:0.989884
Step: 99610, Val_acc:0.955283
==================>
Step: 99620, Train_acc:0.988027
Step: 99620, Val_acc:0.949573
==================>
Step: 99630, Train_acc:0.982627
Step: 99630, Val_acc:0.937363
==================>
Step: 99640, Train_acc:0.98254
Step: 99640, Val_acc:0.933206
==================>
Step: 99650, Train_acc:0.9845
Step: 99650, Val_acc:0.946567
==================>
Step: 99660, Train_acc:0.98723
Step: 99660, Val_acc:0.958839
==================>
Step: 99670, Train_acc:0.986035
Step: 99670, Val_acc:0.941732
==================>
Step: 99680, Train_acc:0.982825
Step: 99680, Val_acc:0.952772
==================>
Step: 99690, Train_acc:0.986077
Step: 99690, Val_acc:0.943104
==================>
Step: 99700, Train_acc:0.988586
Step: 99700, Val_acc:0.945212
==================>
2017-11-12 12:42:26.716242 ---> Validation_loss: 0.178984
Step: 99710, Train_acc:0.988215
Step: 99710, Val_acc:0.958102
==================>
Step: 99720, Train_acc:0.983409
Step: 99720, Val_acc:0.959324
==================>
Step: 99730, Train_acc:0.986707
Step: 99730, Val_acc:0.949126
==================>
Step: 99740, Train_acc:0.989971
Step: 99740, Val_acc:0.952969
==================>
Step: 99750, Train_acc:0.987572
Step: 99750, Val_acc:0.953719
==================>
Step: 99760, Train_acc:0.989462
Step: 99760, Val_acc:0.945404
==================>
Step: 99770, Train_acc:0.983324
Step: 99770, Val_acc:0.941973
==================>
Step: 99780, Train_acc:0.983265
Step: 99780, Val_acc:0.959579
==================>
Step: 99790, Train_acc:0.989467
Step: 99790, Val_acc:0.958369
==================>
Step: 99800, Train_acc:0.985753
Step: 99800, Val_acc:0.936064
==================>
2017-11-12 12:45:03.130639 ---> Validation_loss: 0.128911
Step: 99810, Train_acc:0.980548
Step: 99810, Val_acc:0.954451
==================>
Step: 99820, Train_acc:0.98705
Step: 99820, Val_acc:0.949266
==================>
Step: 99830, Train_acc:0.990803
Step: 99830, Val_acc:0.945934
==================>
Step: 99840, Train_acc:0.985841
Step: 99840, Val_acc:0.944825
==================>
Step: 99850, Train_acc:0.984
Step: 99850, Val_acc:0.960836
==================>
Step: 99860, Train_acc:0.983671
Step: 99860, Val_acc:0.963926
==================>
Step: 99870, Train_acc:0.984437
Step: 99870, Val_acc:0.941505
==================>
Step: 99880, Train_acc:0.98577
Step: 99880, Val_acc:0.944681
==================>
Step: 99890, Train_acc:0.988571
Step: 99890, Val_acc:0.950066
==================>
Step: 99900, Train_acc:0.989388
Step: 99900, Val_acc:0.943077
==================>
2017-11-12 12:47:39.356920 ---> Validation_loss: 0.123419
Step: 99910, Train_acc:0.985352
Step: 99910, Val_acc:0.956442
==================>
Step: 99920, Train_acc:0.978951
Step: 99920, Val_acc:0.924271
==================>
Step: 99930, Train_acc:0.983319
Step: 99930, Val_acc:0.948724
==================>
Step: 99940, Train_acc:0.986598
Step: 99940, Val_acc:0.95983
==================>
Step: 99950, Train_acc:0.984523
Step: 99950, Val_acc:0.95984
==================>
Step: 99960, Train_acc:0.985565
Step: 99960, Val_acc:0.944602
==================>
Step: 99970, Train_acc:0.982704
Step: 99970, Val_acc:0.928904
==================>
Step: 99980, Train_acc:0.980187
Step: 99980, Val_acc:0.955059
==================>
Step: 99990, Train_acc:0.985405
Step: 99990, Val_acc:0.951173
==================>
Step: 100000, Train_acc:0.986172
Step: 100000, Val_acc:0.937822
==================>
****************** Epochs completed: 200******************
2017-11-12 12:50:16.043489 ---> Validation_loss: 0.134477
